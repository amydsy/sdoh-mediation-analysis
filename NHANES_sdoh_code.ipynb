{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6321aae-088c-49a4-aa8b-0d59f8b12f00",
   "metadata": {},
   "source": [
    "<h1>Data prep and merge</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c2fcda",
   "metadata": {},
   "source": [
    "<h2>Install required package/libraries and directory</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "efe6e728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyreadstat in /Users/dengshuyue/amydsy/lib/python3.13/site-packages (1.3.0)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /Users/dengshuyue/amydsy/lib/python3.13/site-packages (from pyreadstat) (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/dengshuyue/amydsy/lib/python3.13/site-packages (from pandas>=1.2.0->pyreadstat) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/dengshuyue/amydsy/lib/python3.13/site-packages (from pandas>=1.2.0->pyreadstat) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/dengshuyue/amydsy/lib/python3.13/site-packages (from pandas>=1.2.0->pyreadstat) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/dengshuyue/amydsy/lib/python3.13/site-packages (from pandas>=1.2.0->pyreadstat) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/dengshuyue/amydsy/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadstat) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: openpyxl in /Users/dengshuyue/amydsy/lib/python3.13/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /Users/dengshuyue/amydsy/lib/python3.13/site-packages (from openpyxl) (2.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If not already installed, install pyreadstat (used to read .sas7bdat files)\n",
    "!pip install pyreadstat\n",
    "!pip install openpyxl\n",
    "\n",
    "# Import core packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pyreadstat\n",
    "from scipy.stats import sem\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "#path \n",
    "output_path = \"/Users/dengshuyue/Desktop/SDOH/analysis/output/demo_summary.csv\"\n",
    "data_path = \"/Users/dengshuyue/Desktop/SDOH/analysis/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0095018c",
   "metadata": {},
   "source": [
    "<h2>Load and preview SAS dataset</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "16e9a8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SEQN', 'SDDSRVYR', 'RIDSTATR', 'RIAGENDR', 'RIDAGEYR', 'RIDAGEMN', 'RIDRETH1', 'RIDRETH3', 'RIDEXMON', 'RIDEXAGM', 'DMQMILIZ', 'DMQADFC', 'DMDBORN4', 'DMDCITZN', 'DMDYRSUS', 'DMDEDUC3', 'DMDEDUC2', 'DMDMARTL', 'RIDEXPRG', 'SIALANG', 'SIAPROXY', 'SIAINTRP', 'FIALANG', 'FIAPROXY', 'FIAINTRP', 'MIALANG', 'MIAPROXY', 'MIAINTRP', 'AIALANGA', 'DMDHHSIZ', 'DMDFMSIZ', 'DMDHHSZA', 'DMDHHSZB', 'DMDHHSZE', 'DMDHRGND', 'DMDHRAGE', 'DMDHRBR4', 'DMDHREDU', 'DMDHRMAR', 'DMDHSEDU', 'WTINT2YR', 'WTMEC2YR', 'SDMVPSU', 'SDMVSTRA', 'INDHHIN2', 'INDFMIN2', 'INDFMPIR']\n"
     ]
    }
   ],
   "source": [
    "# Path to your .sas7bdat file\n",
    "file_path = \"/Users/dengshuyue/Desktop/SDOH/analysis/data/less_important/demo_i.sas7bdat\"\n",
    "\n",
    "# Load the dataset using pandas (requires pyreadstat)\n",
    "df = pd.read_sas(file_path, format=\"sas7bdat\")\n",
    "\n",
    "# Preview the data\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()\n",
    "\n",
    "# List all column names\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4371d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to your .sas7bdat file\n",
    "file_path = \"/Users/dengshuyue/Desktop/SDOH/analysis/data/less_important/gg.sas7bdat\"\n",
    "\n",
    "# Load the dataset using pandas (requires pyreadstat)\n",
    "df = pd.read_sas(file_path, format=\"sas7bdat\")\n",
    "\n",
    "# Preview the data\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()\n",
    "\n",
    "# List all column names\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "dbfd6ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>marriage</th>\n",
       "      <th>HOD050</th>\n",
       "      <th>HOQ065</th>\n",
       "      <th>EMPLOY</th>\n",
       "      <th>unemployment</th>\n",
       "      <th>ELIGSTAT</th>\n",
       "      <th>MORTSTAT</th>\n",
       "      <th>UCOD_LEADING</th>\n",
       "      <th>DIABETES</th>\n",
       "      <th>HYPERTEN</th>\n",
       "      <th>PERMTH_INT</th>\n",
       "      <th>PERMTH_EXM</th>\n",
       "      <th>Death_heart</th>\n",
       "      <th>Death_cancer</th>\n",
       "      <th>Death_resp</th>\n",
       "      <th>Death_cerev</th>\n",
       "      <th>Death_diabe</th>\n",
       "      <th>Death_other</th>\n",
       "      <th>death_cvd</th>\n",
       "      <th>death_cmd</th>\n",
       "      <th>FSDHH</th>\n",
       "      <th>SNAP</th>\n",
       "      <th>FS</th>\n",
       "      <th>ins</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>INDFMPIR</th>\n",
       "      <th>diabe</th>\n",
       "      <th>smk</th>\n",
       "      <th>smk_avg</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>HEI2015_TOTAL_SCORE</th>\n",
       "      <th>edu</th>\n",
       "      <th>alcg2</th>\n",
       "      <th>DAYS</th>\n",
       "      <th>WTDRD1</th>\n",
       "      <th>DR12DRST</th>\n",
       "      <th>WTDR2D</th>\n",
       "      <th>i_optup</th>\n",
       "      <th>i_FCS</th>\n",
       "      <th>i_HSR</th>\n",
       "      <th>i_nutri</th>\n",
       "      <th>perE_alco</th>\n",
       "      <th>sdmvpsu</th>\n",
       "      <th>sdmvstra</th>\n",
       "      <th>tchol</th>\n",
       "      <th>hdl</th>\n",
       "      <th>ldl</th>\n",
       "      <th>tg</th>\n",
       "      <th>bmi</th>\n",
       "      <th>dm_self</th>\n",
       "      <th>hba1c</th>\n",
       "      <th>cancer</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>dm_rx</th>\n",
       "      <th>chol_rx</th>\n",
       "      <th>angina_rx</th>\n",
       "      <th>CVD</th>\n",
       "      <th>lung_disease</th>\n",
       "      <th>angina</th>\n",
       "      <th>met_hr</th>\n",
       "      <th>wt10</th>\n",
       "      <th>wt</th>\n",
       "      <th>i_FCS_sd</th>\n",
       "      <th>i_Optup_sd</th>\n",
       "      <th>i_nutri_sd</th>\n",
       "      <th>i_HSR_sd</th>\n",
       "      <th>hei2015_sd</th>\n",
       "      <th>Death_inj</th>\n",
       "      <th>Death_alz</th>\n",
       "      <th>Death_infl</th>\n",
       "      <th>Death_kid</th>\n",
       "      <th>death_other1</th>\n",
       "      <th>Death_oth2</th>\n",
       "      <th>death_cmdk</th>\n",
       "      <th>death_cmdkh</th>\n",
       "      <th>death_multi</th>\n",
       "      <th>agesq</th>\n",
       "      <th>py</th>\n",
       "      <th>agestart</th>\n",
       "      <th>ageend</th>\n",
       "      <th>pir</th>\n",
       "      <th>bmic</th>\n",
       "      <th>include</th>\n",
       "      <th>ins2</th>\n",
       "      <th>unemployment2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21009.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>196.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.542908</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56998.593412</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170262.470827</td>\n",
       "      <td>42.652217</td>\n",
       "      <td>25.525713</td>\n",
       "      <td>4.324399</td>\n",
       "      <td>7.838628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>31.26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>5699.859341</td>\n",
       "      <td>21282.808853</td>\n",
       "      <td>2.343959</td>\n",
       "      <td>5.220590</td>\n",
       "      <td>-2.472753</td>\n",
       "      <td>4.281583</td>\n",
       "      <td>3.503301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3025.0</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>55.0</td>\n",
       "      <td>71.250000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.931080</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55313.014168</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75296.121197</td>\n",
       "      <td>44.072913</td>\n",
       "      <td>30.611291</td>\n",
       "      <td>5.652702</td>\n",
       "      <td>4.488967</td>\n",
       "      <td>10.617983</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>25.49</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>5531.301417</td>\n",
       "      <td>9412.015150</td>\n",
       "      <td>2.810954</td>\n",
       "      <td>5.394481</td>\n",
       "      <td>-1.416078</td>\n",
       "      <td>5.596735</td>\n",
       "      <td>3.994698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2704.0</td>\n",
       "      <td>15.083333</td>\n",
       "      <td>52.0</td>\n",
       "      <td>67.083333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21012.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'001'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38.637620</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18966.755482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29690.563714</td>\n",
       "      <td>46.390303</td>\n",
       "      <td>29.339153</td>\n",
       "      <td>4.508485</td>\n",
       "      <td>10.484242</td>\n",
       "      <td>10.935122</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>19.60</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.666667</td>\n",
       "      <td>64.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1896.675548</td>\n",
       "      <td>3711.320464</td>\n",
       "      <td>2.694137</td>\n",
       "      <td>5.678128</td>\n",
       "      <td>-3.307332</td>\n",
       "      <td>4.463846</td>\n",
       "      <td>2.972125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3969.0</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>63.0</td>\n",
       "      <td>73.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'001'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.249329</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16558.465868</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12824.553561</td>\n",
       "      <td>48.060086</td>\n",
       "      <td>40.101046</td>\n",
       "      <td>6.171980</td>\n",
       "      <td>5.366953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>28.32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.666667</td>\n",
       "      <td>1655.846587</td>\n",
       "      <td>1603.069195</td>\n",
       "      <td>3.682373</td>\n",
       "      <td>5.882507</td>\n",
       "      <td>-1.693045</td>\n",
       "      <td>6.110872</td>\n",
       "      <td>5.173025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6889.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>83.0</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>46.395227</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11616.087348</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9651.202301</td>\n",
       "      <td>53.498019</td>\n",
       "      <td>35.075704</td>\n",
       "      <td>6.260343</td>\n",
       "      <td>3.491417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>19.34</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.666667</td>\n",
       "      <td>67.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>1161.608735</td>\n",
       "      <td>1206.400288</td>\n",
       "      <td>3.220909</td>\n",
       "      <td>6.548105</td>\n",
       "      <td>-1.101393</td>\n",
       "      <td>6.198360</td>\n",
       "      <td>3.568864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1369.0</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>53.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SEQN  marriage  HOD050  HOQ065  EMPLOY  unemployment  ELIGSTAT  \\\n",
       "0  21009.0       1.0     6.0     1.0     1.0           0.0       1.0   \n",
       "1  21010.0       1.0     3.0     1.0     2.0           1.0       1.0   \n",
       "2  21012.0       1.0     7.0     1.0     3.0           0.0       1.0   \n",
       "3  21015.0       1.0     6.0     1.0     3.0           0.0       1.0   \n",
       "4  21017.0       1.0     3.0     2.0     1.0           0.0       1.0   \n",
       "\n",
       "   MORTSTAT UCOD_LEADING  DIABETES  HYPERTEN  PERMTH_INT  PERMTH_EXM  \\\n",
       "0       0.0          NaN       NaN       NaN       196.0       195.0   \n",
       "1       0.0          NaN       NaN       NaN       182.0       181.0   \n",
       "2       1.0       b'001'       0.0       0.0       127.0       126.0   \n",
       "3       1.0       b'001'       0.0       0.0        25.0        24.0   \n",
       "4       0.0          NaN       NaN       NaN       202.0       201.0   \n",
       "\n",
       "   Death_heart  Death_cancer  Death_resp  Death_cerev  Death_diabe  \\\n",
       "0          0.0           0.0         0.0          0.0          0.0   \n",
       "1          0.0           0.0         0.0          0.0          0.0   \n",
       "2          1.0           0.0         0.0          0.0          0.0   \n",
       "3          1.0           0.0         0.0          0.0          0.0   \n",
       "4          0.0           0.0         0.0          0.0          0.0   \n",
       "\n",
       "   Death_other  death_cvd  death_cmd  FSDHH  SNAP   FS  ins  RIDAGEYR  \\\n",
       "0          0.0        0.0        0.0    1.0   0.0  1.0  1.0      55.0   \n",
       "1          0.0        0.0        0.0    3.0   2.0  0.0  0.0      52.0   \n",
       "2          0.0        1.0        1.0    1.0   2.0  1.0  0.0      63.0   \n",
       "3          0.0        1.0        1.0    1.0   2.0  1.0  2.0      83.0   \n",
       "4          0.0        0.0        0.0    1.0   2.0  1.0  0.0      37.0   \n",
       "\n",
       "   INDFMPIR  diabe  smk  smk_avg  sex  race  HEI2015_TOTAL_SCORE  edu  alcg2  \\\n",
       "0      3.79    0.0  1.0      0.0  1.0   1.0            45.542908  2.0    1.0   \n",
       "1      1.24    0.0  4.0     20.0  2.0   1.0            51.931080  3.0    3.0   \n",
       "2      0.89    0.0  4.0     20.0  1.0   2.0            38.637620  2.0    4.0   \n",
       "3      1.20    0.0  2.0      0.0  1.0   1.0            67.249329  3.0    1.0   \n",
       "4      0.21    0.0  3.0      3.0  2.0   3.0            46.395227  1.0    1.0   \n",
       "\n",
       "   DAYS        WTDRD1  DR12DRST         WTDR2D    i_optup      i_FCS  \\\n",
       "0   1.0  56998.593412       1.0  170262.470827  42.652217  25.525713   \n",
       "1   1.0  55313.014168       1.0   75296.121197  44.072913  30.611291   \n",
       "2   1.0  18966.755482       1.0   29690.563714  46.390303  29.339153   \n",
       "3   1.0  16558.465868       1.0   12824.553561  48.060086  40.101046   \n",
       "4   1.0  11616.087348       1.0    9651.202301  53.498019  35.075704   \n",
       "\n",
       "      i_HSR    i_nutri  perE_alco  sdmvpsu  sdmvstra  tchol    hdl    ldl  \\\n",
       "0  4.324399   7.838628   0.000000      2.0      31.0  254.0   37.0  176.0   \n",
       "1  5.652702   4.488967  10.617983      1.0      29.0  174.0  119.0   39.0   \n",
       "2  4.508485  10.484242  10.935122      2.0      33.0  191.0   92.0   78.0   \n",
       "3  6.171980   5.366953   0.000000      2.0      33.0  141.0   34.0   94.0   \n",
       "4  6.260343   3.491417   0.000000      2.0      42.0  184.0   77.0   65.0   \n",
       "\n",
       "      tg    bmi  dm_self  hba1c  cancer         sbp        dbp  dm_rx  \\\n",
       "0  198.0  31.26      2.0    5.9     0.0  120.000000  86.000000    0.0   \n",
       "1   86.0  25.49      2.0    5.5     0.0  133.333333  84.000000    0.0   \n",
       "2  111.0  19.60      2.0    4.8     0.0  122.666667  64.666667    0.0   \n",
       "3   60.0  28.32      2.0    5.0     1.0  154.000000  54.000000    0.0   \n",
       "4  222.0  19.34      2.0    5.1     0.0  102.666667  67.333333    0.0   \n",
       "\n",
       "   chol_rx  angina_rx  CVD  lung_disease  angina      met_hr         wt10  \\\n",
       "0      0.0        0.0  0.0           0.0     0.0   16.000000  5699.859341   \n",
       "1      0.0        0.0  0.0           1.0     0.0  130.000000  5531.301417   \n",
       "2      0.0        0.0  0.0           0.0     0.0    0.000000  1896.675548   \n",
       "3      0.0        0.0  1.0           1.0     0.0   38.666667  1655.846587   \n",
       "4      0.0        0.0  0.0           0.0     0.0   11.333333  1161.608735   \n",
       "\n",
       "             wt  i_FCS_sd  i_Optup_sd  i_nutri_sd  i_HSR_sd  hei2015_sd  \\\n",
       "0  21282.808853  2.343959    5.220590   -2.472753  4.281583    3.503301   \n",
       "1   9412.015150  2.810954    5.394481   -1.416078  5.596735    3.994698   \n",
       "2   3711.320464  2.694137    5.678128   -3.307332  4.463846    2.972125   \n",
       "3   1603.069195  3.682373    5.882507   -1.693045  6.110872    5.173025   \n",
       "4   1206.400288  3.220909    6.548105   -1.101393  6.198360    3.568864   \n",
       "\n",
       "   Death_inj  Death_alz  Death_infl  Death_kid  death_other1  Death_oth2  \\\n",
       "0        0.0        0.0         0.0        0.0           0.0         0.0   \n",
       "1        0.0        0.0         0.0        0.0           0.0         0.0   \n",
       "2        0.0        0.0         0.0        0.0           0.0         0.0   \n",
       "3        0.0        0.0         0.0        0.0           0.0         0.0   \n",
       "4        0.0        0.0         0.0        0.0           0.0         0.0   \n",
       "\n",
       "   death_cmdk  death_cmdkh  death_multi   agesq         py  agestart  \\\n",
       "0         0.0          0.0          0.0  3025.0  16.250000      55.0   \n",
       "1         0.0          0.0          0.0  2704.0  15.083333      52.0   \n",
       "2         1.0          1.0          1.0  3969.0  10.500000      63.0   \n",
       "3         1.0          1.0          1.0  6889.0   2.000000      83.0   \n",
       "4         0.0          0.0          0.0  1369.0  16.750000      37.0   \n",
       "\n",
       "      ageend  pir  bmic  include  ins2  unemployment2  \n",
       "0  71.250000  3.0   3.0      1.0   1.0            0.0  \n",
       "1  67.083333  1.0   2.0      1.0   0.0            1.0  \n",
       "2  73.500000  1.0   0.0      1.0   0.0            1.0  \n",
       "3  85.000000  1.0   2.0      1.0   1.0            1.0  \n",
       "4  53.750000  1.0   0.0      1.0   0.0            0.0  "
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Path to your .sas7bdat file\n",
    "file_path = \"/Users/dengshuyue/Desktop/SDOH/analysis/data/sodh_diet_mort.sas7bdat\"\n",
    "\n",
    "# Load the dataset using pandas (requires pyreadstat)\n",
    "df = pd.read_sas(file_path, format=\"sas7bdat\")\n",
    "\n",
    "# Preview the data\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()\n",
    "\n",
    "# List all column names\n",
    "# print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ae37456-384b-43ef-a397-231c5e43cf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sample size: 38,900\n",
      "Age range: 20.0 to 85.0 years\n"
     ]
    }
   ],
   "source": [
    "# Display total number of rows (i.e., participants) in the dataset\n",
    "print(f\"Total sample size: {df.shape[0]:,}\")\n",
    "\n",
    "# Check the min and max age\n",
    "min_age = df['RIDAGEYR'].min()\n",
    "max_age = df['RIDAGEYR'].max()\n",
    "print(f\"Age range: {min_age} to {max_age} years\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0354e411-4071-4d2d-b78c-fca5f733ca15",
   "metadata": {},
   "source": [
    "<h2>Merge datasets step-by-step and track sample size</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea763e8-7ab0-4d7e-b17a-5afda4e7847b",
   "metadata": {},
   "source": [
    "<h3>Merge demo</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "7fe3423d-97e9-4c13-bcab-ae3de85d819b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total rows (age 20+): 39749\n",
      "✅ Unique SEQN values: 39749\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Set file path for NHANES demographic data\n",
    "folder_path = \"/Users/dengshuyue/Desktop/SDOH/analysis/data/less_important\"\n",
    "\n",
    "# Step 2: NHANES demographic files to include (2005–2018 cycles only)\n",
    "demo_files = [\n",
    "    \"demo_d\",  # 2005–2006\n",
    "    \"demo_e\",  # 2007–2008\n",
    "    \"demo_f\",  # 2009–2010\n",
    "    \"demo_g\",  # 2011–2012\n",
    "    \"demo_h\",  # 2013–2014\n",
    "    \"demo_i\",  # 2015–2016\n",
    "    \"demo_j\"   # 2017–2018\n",
    "]\n",
    "\n",
    "# Step 3: Load and append files if they exist\n",
    "demo_dfs = []\n",
    "for f in demo_files:\n",
    "    file_path = os.path.join(folder_path, f\"{f}.sas7bdat\")\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_sas(file_path)\n",
    "        demo_dfs.append(df)\n",
    "    else:\n",
    "        print(f\"⚠️ File not found: {file_path}\")\n",
    "\n",
    "# Step 4: Combine all loaded demographic datasets\n",
    "demoall = pd.concat(demo_dfs, ignore_index=True).copy()\n",
    "\n",
    "# Step 5: Filter to adults age 20+\n",
    "demoall = demoall[demoall[\"RIDAGEYR\"] >= 20]\n",
    "\n",
    "# Step 6: Recode marital status from DMDMARTL\n",
    "conditions = [\n",
    "    demoall['DMDMARTL'].isin([1, 6]),  # Married or living with partner\n",
    "    demoall['DMDMARTL'].isin([3, 4]),  # Widowed or divorced\n",
    "    demoall['DMDMARTL'] == 2,          # Never married\n",
    "    demoall['DMDMARTL'] == 5           # Separated\n",
    "]\n",
    "choices = [1, 2, 3, 4]\n",
    "demoall['marriage'] = np.select(conditions, choices, default=pd.NA)\n",
    "\n",
    "# Step 7: Keep only relevant variables\n",
    "# demoall = demoall[['SEQN', 'marriage', 'SDDSRVYR']]\n",
    "\n",
    "demoall = demoall[['SEQN', 'RIDAGEYR', 'marriage', 'SDDSRVYR']]\n",
    "\n",
    "\n",
    "# Step 8: Summary\n",
    "print(f\"✅ Total rows (age 20+): {demoall.shape[0]}\")\n",
    "print(f\"✅ Unique SEQN values: {demoall['SEQN'].nunique()}\")\n",
    "\n",
    "# Optional: Preview first few rows\n",
    "# print(demoall.head())\n",
    "\n",
    "# Step 9: Save cleaned demoall for reuse\n",
    "demoall.to_pickle(\"/Users/dengshuyue/Desktop/SDOH/analysis/data/demoall.pkl\")  # Fast & preserves types\n",
    "# Or as CSV if needed:\n",
    "# demoall.to_csv(\"/Users/dengshuyue/Desktop/SDOH/analysis/data/demoall.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "67dbb5db-41cc-4099-b9a8-991b09188d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 NHANES cycles in mortality data (age 20+):\n",
      "SDDSRVYR\n",
      "4.0     4977\n",
      "5.0     5926\n",
      "6.0     6201\n",
      "7.0     5546\n",
      "8.0     5757\n",
      "9.0     5701\n",
      "10.0    5524\n",
      "Name: count, dtype: int64\n",
      "📊 NHANES cycles in mortality data (age 20+):\n",
      "SDDSRVYR\n",
      "4.0     4977\n",
      "5.0     5926\n",
      "6.0     6201\n",
      "7.0     5546\n",
      "8.0     5757\n",
      "9.0     5701\n",
      "10.0    5524\n",
      "Name: count, dtype: int64\n",
      "Total valid mortality count (age 20+): 39632\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Merge in both age and SDDSRVYR from demoall\n",
    "mort_with_demo = mort.merge(\n",
    "    demoall[[\"SEQN\", \"RIDAGEYR\", \"SDDSRVYR\"]], on=\"SEQN\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Step 2: Filter for adults age ≥ 20\n",
    "mort_with_demo = mort_with_demo[mort_with_demo[\"RIDAGEYR\"] >= 20]\n",
    "\n",
    "# Step 3: Check NHANES cycles among adults 20+ with mortality data\n",
    "print(\"📊 NHANES cycles in mortality data (age 20+):\")\n",
    "print(mort_with_demo[\"SDDSRVYR\"].value_counts().sort_index())\n",
    "\n",
    "# 📊 NHANES cycles in mortality data (age 20+)\n",
    "cycle_counts = mort_with_demo[\"SDDSRVYR\"].value_counts().sort_index()\n",
    "print(\"📊 NHANES cycles in mortality data (age 20+):\")\n",
    "print(cycle_counts)\n",
    "\n",
    "# Print total count\n",
    "total_count = cycle_counts.sum()\n",
    "print(f\"Total valid mortality count (age 20+): {total_count}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb1804b-1f7d-46f5-a98a-19d6534ba831",
   "metadata": {},
   "source": [
    "<h3>Preprocess SDOH</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "4bd52bac-c8dd-497b-b42f-fc2d95baa41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Employment data (OCQ) ---\n",
    "ocq = pd.read_sas(f\"{folder_path}/ocq.sas7bdat\")\n",
    "\n",
    "ocq['employ'] = np.nan\n",
    "ocq.loc[ocq['OCD150'] == 1, 'employ'] = 1\n",
    "ocq.loc[(ocq['OCD150'] == 3) | (ocq['OCQ380'] == 5), 'employ'] = 2\n",
    "ocq.loc[ocq['OCQ380'] == 3, 'employ'] = 3\n",
    "ocq.loc[ocq['OCQ380'].isin([4, 6]), 'employ'] = 4\n",
    "ocq.loc[ocq['OCQ380'].isin([1, 2, 7]), 'employ'] = 5\n",
    "ocq['unemployment'] = (ocq['employ'] == 2).astype(int)\n",
    "ocq = ocq[['SEQN', 'employ', 'unemployment']]\n",
    "\n",
    "# --- Housing data (HOQ) ---\n",
    "hoq = pd.read_sas(f\"{folder_path}/hoq.sas7bdat\")\n",
    "hoq.loc[hoq['HOQ065'].isin([7, 9]), 'HOQ065'] = np.nan\n",
    "hoq = hoq[['SEQN', 'HOD050', 'HOQ065']]\n",
    "\n",
    "# --- Health insurance (HIQs) ---\n",
    "hiqs = pd.read_sas(f\"{folder_path}/hiqs.sas7bdat\")\n",
    "ins = pd.DataFrame({'SEQN': hiqs['SEQN']})\n",
    "ins['ins'] = np.nan\n",
    "\n",
    "# Private insurance\n",
    "ins.loc[(hiqs['HIQ031A'] == 14) | (hiqs['HID030A'] == 1), 'ins'] = 1\n",
    "\n",
    "# Medicare\n",
    "ins.loc[\n",
    "    ((hiqs['HIQ031B'] == 15) & (hiqs['HIQ031D'] != 17) & (hiqs['HIQ031E'] != 18)) |\n",
    "    ((hiqs['HID030B'] == 1) & (hiqs['HID030C'] != 1)),\n",
    "    'ins'\n",
    "] = 2\n",
    "\n",
    "# Medicaid\n",
    "ins.loc[\n",
    "    (((hiqs['HIQ031D'] == 17) | (hiqs['HIQ031E'] == 18)) & (hiqs['HIQ031B'] != 15)) |\n",
    "    ((hiqs['HID030B'] != 1) & (hiqs['HID030C'] == 1)),\n",
    "    'ins'\n",
    "] = 3\n",
    "ins.loc[\n",
    "    ((hiqs['HIQ031B'] == 15) & (hiqs['HIQ031D'] == 17)) |\n",
    "    ((hiqs['HID030B'] == 1) & (hiqs['HID030C'] == 1)),\n",
    "    'ins'\n",
    "] = 3\n",
    "\n",
    "# Other insurance\n",
    "ins.loc[\n",
    "    (hiqs[['HIQ031C', 'HIQ031F', 'HIQ031G', 'HIQ031H', 'HIQ031I']].eq(1).any(axis=1)) |\n",
    "    (hiqs['HID030D'] == 1),\n",
    "    'ins'\n",
    "] = 5\n",
    "\n",
    "# No insurance\n",
    "ins.loc[(hiqs['HIQ011'] == 2) | (hiqs['HID010'] == 2), 'ins'] = 0\n",
    "\n",
    "# --- SNAP and Food Security (FSQS) ---\n",
    "fsqs = pd.read_sas(f\"{folder_path}/fsqs.sas7bdat\")\n",
    "snap = pd.DataFrame({'SEQN': fsqs['SEQN'], 'FSDHH': fsqs['FSDHH']})\n",
    "\n",
    "snap['SNAP'] = np.nan\n",
    "snap.loc[fsqs['FSQ165'] == 2, 'SNAP'] = 0\n",
    "snap.loc[fsqs['FSQ012'] == 1, 'SNAP'] = 1\n",
    "snap.loc[fsqs['FSQ012'] == 2, 'SNAP'] = 0\n",
    "snap.loc[fsqs['FSQ171'] == 1, 'SNAP'] = 1\n",
    "snap.loc[fsqs['FSQ171'] == 2, 'SNAP'] = 0\n",
    "snap.loc[fsqs['FSD170N'] >= 1, 'SNAP'] = 1\n",
    "snap.loc[fsqs['FSQ170'] == 1, 'SNAP'] = 1\n",
    "snap.loc[(fsqs['FSQ170'] == 2) & (fsqs['FSD170N'] < 1), 'SNAP'] = 0\n",
    "snap.loc[fsqs['FSD200'] == 1, 'SNAP'] = 1\n",
    "\n",
    "# Food Security\n",
    "snap['FS'] = np.nan\n",
    "snap.loc[fsqs['FSDHH'].isin([1, 2]), 'FS'] = 1\n",
    "snap.loc[fsqs['FSDHH'] > 2, 'FS'] = 0\n",
    "\n",
    "# Keep only final columns\n",
    "snap = snap[['SEQN', 'SNAP', 'FSDHH', 'FS']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88a2a78-49cc-4ade-ac8e-eae71ea69aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f152e3-60c4-4836-a8ec-d078b1ad09b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2760d5c0-e576-4dcd-93bc-1dd406304d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe8ce36-fac2-4b81-ba8f-b52357bf3d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a8699e-a22a-426e-86c3-dc10f015d272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70952887-d00a-4352-a60a-5e961026d804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "6c04929c-7483-4d40-ae4f-b765e83417ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Step 0: Setup\n",
    "folder_path = \"/Users/dengshuyue/Desktop/SDOH/analysis/data/less_important\"\n",
    "\n",
    "# Step 1: Load demoall\n",
    "demoall = pd.read_pickle(\"/Users/dengshuyue/Desktop/SDOH/analysis/data/demoall.pkl\")\n",
    "\n",
    "if \"SEQN\" not in demoall.columns or \"RIDAGEYR\" not in demoall.columns:\n",
    "    raise ValueError(\"demoall is missing SEQN or RIDAGEYR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "12b28393-2b40-4624-8066-b36dec64d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Filter demoall to adults (age ≥ 20)\n",
    "age_df = demoall[[\"SEQN\", \"RIDAGEYR\"]].dropna()\n",
    "age_df = age_df[age_df[\"RIDAGEYR\"] >= 20]  # ✅ universal filter\n",
    "\n",
    "# Helper: Filter any df to age ≥ 20 using demoall\n",
    "def filter_adults(df):\n",
    "    return df.merge(age_df, on=\"SEQN\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "623d8534-b91e-46b8-8b9f-6e99c60fea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Employment (OCQ)\n",
    "ocq = filter_adults(pd.read_sas(f\"{folder_path}/ocq.sas7bdat\"))\n",
    "ocq['employ'] = np.nan\n",
    "ocq.loc[ocq['OCD150'] == 1, 'employ'] = 1\n",
    "ocq.loc[(ocq['OCD150'] == 3) | (ocq['OCQ380'] == 5), 'employ'] = 2\n",
    "ocq.loc[ocq['OCQ380'] == 3, 'employ'] = 3\n",
    "ocq.loc[ocq['OCQ380'].isin([4, 6]), 'employ'] = 4\n",
    "ocq.loc[ocq['OCQ380'].isin([1, 2, 7]), 'employ'] = 5\n",
    "ocq['unemployment'] = (ocq['employ'] == 2).astype(int)\n",
    "ocq = ocq[['SEQN', 'employ', 'unemployment']]\n",
    "\n",
    "# Step 4: Housing (HOQ)\n",
    "hoq = filter_adults(pd.read_sas(f\"{folder_path}/hoq.sas7bdat\"))\n",
    "hoq.loc[hoq['HOQ065'].isin([7, 9]), 'HOQ065'] = np.nan\n",
    "hoq = hoq[['SEQN', 'HOD050', 'HOQ065']]\n",
    "\n",
    "# Step 5: Insurance (HIQS)\n",
    "hiqs = filter_adults(pd.read_sas(f\"{folder_path}/hiqs.sas7bdat\"))\n",
    "ins = pd.DataFrame({'SEQN': hiqs['SEQN']})\n",
    "ins['ins'] = np.nan\n",
    "ins.loc[(hiqs['HIQ031A'] == 14) | (hiqs['HID030A'] == 1), 'ins'] = 1\n",
    "ins.loc[((hiqs['HIQ031B'] == 15) & (hiqs['HIQ031D'] != 17) & (hiqs['HIQ031E'] != 18)) |\n",
    "        ((hiqs['HID030B'] == 1) & (hiqs['HID030C'] != 1)), 'ins'] = 2\n",
    "ins.loc[(((hiqs['HIQ031D'] == 17) | (hiqs['HIQ031E'] == 18)) & (hiqs['HIQ031B'] != 15)) |\n",
    "        ((hiqs['HID030B'] != 1) & (hiqs['HID030C'] == 1)), 'ins'] = 3\n",
    "ins.loc[((hiqs['HIQ031B'] == 15) & (hiqs['HIQ031D'] == 17)) |\n",
    "        ((hiqs['HID030B'] == 1) & (hiqs['HID030C'] == 1)), 'ins'] = 3\n",
    "ins.loc[(hiqs[['HIQ031C', 'HIQ031F', 'HIQ031G', 'HIQ031H', 'HIQ031I']].eq(1).any(axis=1)) |\n",
    "        (hiqs['HID030D'] == 1), 'ins'] = 5\n",
    "ins.loc[(hiqs['HIQ011'] == 2) | (hiqs['HID010'] == 2), 'ins'] = 0\n",
    "\n",
    "# Step 6: SNAP & Food Security (FSQS)\n",
    "fsqs = filter_adults(pd.read_sas(f\"{folder_path}/fsqs.sas7bdat\"))\n",
    "snap = pd.DataFrame({'SEQN': fsqs['SEQN'], 'FSDHH': fsqs['FSDHH']})\n",
    "snap['SNAP'] = np.nan\n",
    "snap.loc[fsqs['FSQ165'] == 2, 'SNAP'] = 0\n",
    "snap.loc[fsqs['FSQ012'] == 1, 'SNAP'] = 1\n",
    "snap.loc[fsqs['FSQ012'] == 2, 'SNAP'] = 0\n",
    "snap.loc[fsqs['FSQ171'] == 1, 'SNAP'] = 1\n",
    "snap.loc[fsqs['FSQ171'] == 2, 'SNAP'] = 0\n",
    "snap.loc[fsqs['FSD170N'] >= 1, 'SNAP'] = 1\n",
    "snap.loc[fsqs['FSQ170'] == 1, 'SNAP'] = 1\n",
    "snap.loc[(fsqs['FSQ170'] == 2) & (fsqs['FSD170N'] < 1), 'SNAP'] = 0\n",
    "snap.loc[fsqs['FSD200'] == 1, 'SNAP'] = 1\n",
    "snap['FS'] = np.nan\n",
    "snap.loc[fsqs['FSDHH'].isin([1, 2]), 'FS'] = 1\n",
    "snap.loc[fsqs['FSDHH'] > 2, 'FS'] = 0\n",
    "snap = snap[['SEQN', 'SNAP', 'FSDHH', 'FS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e5ca16-ea4a-4e9b-a81c-fe4264eea952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5560aa-f09e-4990-a208-792e509c387d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93108342-9861-42c3-bb91-6f1c7e437e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb51458-37b6-431b-a9eb-ba225dc6e232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627089f5-c29e-46b2-8a3d-d9bcf5e96738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "340baed0-47e0-430c-a6d9-6f7949971219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores2:\n",
      "  Rows: 39746\n",
      "  Unique SEQN: 39746\n",
      "----------------------------------------\n",
      "covar:\n",
      "  Rows: 101316\n",
      "  Unique SEQN: 101316\n",
      "----------------------------------------\n",
      "covariates1:\n",
      "  Rows: 39262\n",
      "  Unique SEQN: 39262\n",
      "----------------------------------------\n",
      "dietwt:\n",
      "  Rows: 88413\n",
      "  Unique SEQN: 88413\n",
      "----------------------------------------\n",
      "mort:\n",
      "  Rows: 59064\n",
      "  Unique SEQN: 59064\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Read dietary score data\n",
    "scores = pd.read_excel(os.path.join(folder_path, \"i.scores.xlsx\"), engine=\"openpyxl\")\n",
    "\n",
    "# Rename columns to match desired output\n",
    "scores = scores.rename(columns={\n",
    "    \"seqn\": \"SEQN\",\n",
    "    \"i.FCS\": \"i_FCS\",\n",
    "    \"i.optup\": \"i_optup\",  # keep lowercase here first\n",
    "    \"i.HSR\": \"i_HSR\",\n",
    "    \"i.nutri\": \"i_nutri\"\n",
    "})\n",
    "\n",
    "# Then copy and rename for output\n",
    "scores2 = scores[[\"SEQN\", \"i_FCS\", \"i_optup\", \"i_HSR\", \"i_nutri\"]].copy()\n",
    "scores2 = scores2.rename(columns={\"i_optup\": \"i_Optup\"})\n",
    "scores2 = scores2.sort_values(\"SEQN\")\n",
    "\n",
    "\n",
    "# Step 2: Read covariates from Lu paper\n",
    "covar = pd.read_sas(os.path.join(folder_path, \"covar.sas7bdat\"), format=\"sas7bdat\")\n",
    "covar = covar.rename(columns=str.upper)  # make all column names uppercase to match SAS style\n",
    "# filter available variables only\n",
    "covar_vars = [\"SEQN\", \"RIDAGEYR\", \"SEX\", \"RACE\", \"EDU\", \"INDFMPIR\", \"SMK_AVG\", \"SMK_PAST\",\n",
    "              \"SMK\", \"ALCG2\", \"HEI2015_TOTAL_SCORE\", \"DIABE\"]\n",
    "covar = covar[[col for col in covar_vars if col in covar.columns]].copy()\n",
    "covar = covar.sort_values(\"SEQN\")\n",
    "\n",
    "# Step 3: Read covariates from Meghan paper\n",
    "covariates1_raw = pd.read_csv(os.path.join(folder_path, \"covariates.csv\"))\n",
    "covariates1 = covariates1_raw.rename(columns={\"seqn\": \"SEQN\"})\n",
    "covariates_vars = [\"SEQN\", \"sdmvpsu\", \"sdmvstra\", \"met_hr\", \"perE_alco\", \"dm_self\",\n",
    "                   \"tchol\", \"hdl\", \"ldl\", \"tg\", \"bmi\", \"CVD\", \"dm_rx\", \"chol_rx\",\n",
    "                   \"angina_rx\", \"lung_disease\", \"angina\", \"hba1c\", \"sbp\", \"dbp\", \"cancer\"]\n",
    "covariates1 = covariates1[[col for col in covariates_vars if col in covariates1.columns]].copy()\n",
    "covariates1 = covariates1.sort_values(\"SEQN\")\n",
    "\n",
    "# Step 4: Read dietary weight data (filter DAYS == 1)\n",
    "dietwt = pd.read_sas(os.path.join(folder_path, \"gg.sas7bdat\"), format=\"sas7bdat\")\n",
    "\n",
    "# Check for expected columns\n",
    "required_cols = [\"SEQN\", \"DAYS\", \"WTDRD1\", \"WTDR2D\", \"DR12DRST\"]\n",
    "missing = [col for col in required_cols if col not in dietwt.columns]\n",
    "if missing:\n",
    "    print(f\"Warning: Missing columns from gg.sas7bdat: {missing}\")\n",
    "\n",
    "# Filter and select\n",
    "dietwt = dietwt[dietwt[\"DAYS\"] == 1][[\"SEQN\", \"WTDRD1\", \"WTDR2D\", \"DR12DRST\"]].copy()\n",
    "dietwt = dietwt.sort_values(\"SEQN\")\n",
    "\n",
    "\n",
    "# Step 5: Read mortality data\n",
    "mort = pd.read_sas(os.path.join(folder_path, \"mortality9918.sas7bdat\"), format=\"sas7bdat\")\n",
    "mort = mort.sort_values(\"SEQN\")\n",
    "\n",
    "def summarize_df(name, df):\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Rows: {df.shape[0]}\")\n",
    "    print(f\"  Unique SEQN: {df['SEQN'].nunique()}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "summarize_df(\"scores2\", scores2)\n",
    "summarize_df(\"covar\", covar)\n",
    "summarize_df(\"covariates1\", covariates1)\n",
    "summarize_df(\"dietwt\", dietwt)\n",
    "summarize_df(\"mort\", mort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d72dcb-97f9-4681-a81f-3176921845e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bed3786-e96e-4a4d-9fca-c91f28013bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3cf7aa-8db1-49bc-8c3e-e5afe1dae728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc0d637-2830-4a1b-8545-59c9854101da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "d208411a-510b-4c13-ad33-1ef1bd57eaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Index(['SEQN', 'RIDAGEYR', 'marriage', 'SDDSRVYR'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"RIDAGEYR\" in demoall.columns)  # Should print True\n",
    "print(demoall.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "625ece01-37f0-44fd-a74e-84e4d729ad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure SEQN is int in all datasets\n",
    "for name, df in datasets.items():\n",
    "    df[\"SEQN\"] = df[\"SEQN\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "0044a5a0-83ab-48de-aa4f-dfb396953781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename RIDAGEYR in covar to avoid overwriting demoall's RIDAGEYR\n",
    "covar = covar.rename(columns={\"RIDAGEYR\": \"RIDAGEYR_covar\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "5408feb0-87e0-4fa6-942e-a83fc0f4d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "# ✅ Step 0: Merge all datasets by SEQN\n",
    "merge_list = [demoall, hoq, ocq, mort, snap, ins, covar, dietwt, scores2, covariates1]\n",
    "score_mort = reduce(lambda left, right: pd.merge(left, right, on=\"SEQN\", how=\"left\"), merge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "1b64dc0c-cb7b-4b56-b218-3a48a1a72d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Step 1: Filter to adults age ≥ 20\n",
    "if \"RIDAGEYR\" not in score_mort.columns:\n",
    "    raise ValueError(\"RIDAGEYR is missing after merge — check if demoall was merged correctly.\")\n",
    "score_mort = score_mort[score_mort[\"RIDAGEYR\"] >= 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "4294a2ac-4a00-4e88-bd93-5b3084ebf2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Variable transformations\n",
    "score_mort[\"wt10\"] = score_mort[\"WTDRD1\"] / 10\n",
    "score_mort[\"wt\"] = score_mort[\"WTDR2D\"] / 8\n",
    "score_mort[\"i_FCS_sd\"] = score_mort[\"i_FCS\"] / 10.89\n",
    "score_mort[\"i_Optup_sd\"] = score_mort[\"i_Optup\"] / 8.17\n",
    "score_mort[\"i_nutri_sd\"] = -score_mort[\"i_nutri\"] / 3.17\n",
    "score_mort[\"i_HSR_sd\"] = score_mort[\"i_HSR\"] / 1.01\n",
    "score_mort[\"hei2015_sd\"] = score_mort[\"HEI2015_TOTAL_SCORE\"] / 13\n",
    "\n",
    "# Step 3: Recode death indicators\n",
    "for cause, code in {\n",
    "    \"death_heart\": \"001\", \"death_cancer\": \"002\", \"death_resp\": \"003\", \"Death_inj\": \"004\",\n",
    "    \"death_cerev\": \"005\", \"Death_alz\": \"006\", \"death_diabe\": \"007\",\n",
    "    \"Death_infl\": \"008\", \"Death_kid\": \"009\", \"death_other1\": \"010\"\n",
    "}.items():\n",
    "    score_mort[cause] = (score_mort[\"UCOD_LEADING\"] == code).astype(int)\n",
    "\n",
    "# Step 4: Composite categories\n",
    "score_mort[\"Death_other\"] = score_mort[[\"death_resp\", \"Death_inj\", \"Death_alz\", \"Death_infl\"]].sum(axis=1).clip(upper=1)\n",
    "score_mort[\"Death_oth2\"] = score_mort[[\"death_resp\", \"Death_inj\", \"Death_alz\", \"Death_infl\", \"death_other1\"]].sum(axis=1).clip(upper=1)\n",
    "score_mort[\"death_cvd\"] = score_mort[[\"death_heart\", \"death_cerev\"]].sum(axis=1).clip(upper=1)\n",
    "score_mort[\"death_cmd\"] = score_mort[[\"death_heart\", \"death_cerev\", \"death_diabe\"]].sum(axis=1).clip(upper=1)\n",
    "score_mort[\"death_cmdk\"] = score_mort[[\"death_heart\", \"death_cerev\", \"death_diabe\", \"Death_kid\"]].sum(axis=1).clip(upper=1)\n",
    "score_mort[\"death_cmdkh\"] = score_mort[\"death_cmdk\"]\n",
    "score_mort.loc[score_mort[\"DIABETES\"] == 1, \"death_cmdkh\"] = 1\n",
    "score_mort.loc[score_mort[\"HYPERTEN\"] == 1, \"death_cmdkh\"] = 1\n",
    "score_mort[\"death_cmd\"] = score_mort[\"death_cmd\"].fillna(0)\n",
    "score_mort.loc[score_mort[\"death_cmd\"] == 1, [\"Death_other\", \"Death_oth2\"]] = 0\n",
    "\n",
    "# Step 5: Multiple cause mortality\n",
    "score_mort[\"death_multi\"] = score_mort[\"MORTSTAT\"]\n",
    "score_mort.loc[score_mort[\"death_cmd\"] == 1, \"death_multi\"] = 1\n",
    "score_mort.loc[score_mort[\"death_cancer\"] == 1, \"death_multi\"] = 2\n",
    "score_mort.loc[score_mort[\"Death_oth2\"] == 1, \"death_multi\"] = 3\n",
    "\n",
    "# Step 6: Age & time vars\n",
    "score_mort[\"agesq\"] = score_mort[\"RIDAGEYR\"] ** 2\n",
    "score_mort[\"py\"] = score_mort[\"PERMTH_EXM\"] / 12\n",
    "score_mort[\"agestart\"] = score_mort[\"RIDAGEYR\"]\n",
    "score_mort[\"ageend\"] = score_mort[\"RIDAGEYR\"] + score_mort[\"py\"]\n",
    "\n",
    "# Step 7: Poverty\n",
    "score_mort[\"pir\"] = 5\n",
    "score_mort.loc[(score_mort[\"INDFMPIR\"] < 1.3) & (score_mort[\"INDFMPIR\"].notna()), \"pir\"] = 1\n",
    "score_mort.loc[(score_mort[\"INDFMPIR\"] >= 1.3), \"pir\"] = 2\n",
    "score_mort.loc[(score_mort[\"INDFMPIR\"] >= 3), \"pir\"] = 3\n",
    "\n",
    "# Step 8: Recode SNAP\n",
    "score_mort.loc[(score_mort[\"INDFMPIR\"].between(0, 1.3)) & (score_mort[\"SNAP\"] != 1), \"SNAP\"] = 2\n",
    "\n",
    "# Step 9: BMI categories\n",
    "score_mort[\"bmic\"] = pd.NA\n",
    "score_mort.loc[(score_mort[\"bmi\"] > 0) & (score_mort[\"bmi\"] < 18.5), \"bmic\"] = 0\n",
    "score_mort.loc[(score_mort[\"bmi\"] >= 18.5) & (score_mort[\"bmi\"] < 25), \"bmic\"] = 1\n",
    "score_mort.loc[(score_mort[\"bmi\"] >= 25), \"bmic\"] = 2\n",
    "score_mort.loc[(score_mort[\"bmi\"] >= 30), \"bmic\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "76734187-4ed6-487d-8c2a-aff415f549c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After ELIGSTAT & MORTSTAT inclusion: {1: 39632, 0: 117}\n",
      "Dropped at Step 2 (diet data or recall quality): 4391\n",
      "Dropped at Step 3 (missing FS/SNAP or pir=4): 596\n",
      "Dropped at Step 4 (zero or negative WTDRD1): 0\n",
      "📊 Final include flag counts: {1: 34645, 2: 4391, 3: 596, 0: 117}\n",
      " Final analytic sample size: 34645\n"
     ]
    }
   ],
   "source": [
    "# check drop by step\n",
    "\n",
    "# Step 1: Initial inclusion based on ELIGSTAT and MORTSTAT\n",
    "score_mort[\"include\"] = np.where(\n",
    "    (score_mort[\"ELIGSTAT\"] == 1) & (score_mort[\"MORTSTAT\"].notna()), 1, 0\n",
    ")\n",
    "print(f\"After ELIGSTAT & MORTSTAT inclusion: {score_mort['include'].value_counts().to_dict()}\")\n",
    "\n",
    "# Step 2: Exclude missing HEI, or DR12DRST > 1 \n",
    "step2_cond = (\n",
    "    (score_mort[\"include\"] == 1) &\n",
    "    (\n",
    "        score_mort[\"HEI2015_TOTAL_SCORE\"].isna() |\n",
    "        #(score_mort[\"WTDRD1\"] <= 0) |\n",
    "        (score_mort[\"DR12DRST\"] > 1)\n",
    "    )\n",
    ")\n",
    "print(f\"Dropped at Step 2 (diet data or recall quality): {step2_cond.sum()}\")\n",
    "score_mort.loc[step2_cond, \"include\"] = 2\n",
    "\n",
    "# Step 3: Exclude missing FS, SNAP, or pir == 4\n",
    "step3_cond = (\n",
    "    (score_mort[\"include\"] == 1) &\n",
    "    (\n",
    "        score_mort[\"FS\"].isna() |\n",
    "        score_mort[\"SNAP\"].isna() |\n",
    "        (score_mort[\"pir\"] == 4)\n",
    "    )\n",
    ")\n",
    "print(f\"Dropped at Step 3 (missing FS/SNAP or pir=4): {step3_cond.sum()}\")\n",
    "score_mort.loc[step3_cond, \"include\"] = 3\n",
    "\n",
    "# Step 4: Exclude if WTDRD1 <= 0 \n",
    "step4_cond = (score_mort[\"include\"] == 1) & (score_mort[\"WTDRD1\"] <= 0)\n",
    "print(f\"Dropped at Step 4 (zero or negative WTDRD1): {step4_cond.sum()}\")\n",
    "score_mort.loc[step4_cond, \"include\"] = 4\n",
    "\n",
    "# Final count of each inclusion code\n",
    "print(f\"📊 Final include flag counts: {score_mort['include'].value_counts().to_dict()}\")\n",
    "\n",
    "# Apply final filter\n",
    "score_mort = score_mort[score_mort[\"include\"] == 1].copy()\n",
    "print(f\" Final analytic sample size: {score_mort.shape[0]}\")\n",
    "\n",
    "\n",
    "# Inclusion flag\n",
    "score_mort[\"include\"] = np.where(\n",
    "    (score_mort[\"ELIGSTAT\"] == 1) & (score_mort[\"MORTSTAT\"].notna()), 1, 0\n",
    ")\n",
    "score_mort.loc[\n",
    "    (score_mort[\"include\"] == 1) &\n",
    "    (\n",
    "        (score_mort[\"HEI2015_TOTAL_SCORE\"].isna()) |\n",
    "        (score_mort[\"WTDRD1\"] <= 0) |\n",
    "        (score_mort[\"DR12DRST\"] > 1)\n",
    "    ),\n",
    "    \"include\"\n",
    "] = 2\n",
    "score_mort.loc[\n",
    "    (score_mort[\"include\"] == 1) &\n",
    "    (\n",
    "        score_mort[\"FS\"].isna() |\n",
    "        score_mort[\"SNAP\"].isna() |\n",
    "        (score_mort[\"pir\"] == 4)\n",
    "    ),\n",
    "    \"include\"\n",
    "] = 3\n",
    "score_mort.loc[\n",
    "    (score_mort[\"include\"] == 1) & (score_mort[\"WTDRD1\"] <= 0),\n",
    "    \"include\"\n",
    "] = 4\n",
    "\n",
    "# Insurance binary\n",
    "score_mort[\"ins2\"] = np.where(score_mort[\"ins\"] == 0, 0, 1)\n",
    "\n",
    "# Unemployment indicator\n",
    "score_mort[\"unemployment2\"] = np.where(score_mort[\"employ\"] > 1, 1, 0)\n",
    "\n",
    "# Final filter to keep only those with include == 1\n",
    "score_mort = score_mort[score_mort[\"include\"] == 1].copy()\n",
    "\n",
    "# Save final dataset\n",
    "score_mort.to_pickle(os.path.join(folder_path, \"SODH_diet_mort.pkl\"))  # You can also use .csv or .parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aefee5b-6b6d-4dbf-95b5-9d44af87bf02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41941bd4-a755-4636-b600-bb425a546832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "299cbdb9-9f4f-45ee-9d9a-ac27efde94e1",
   "metadata": {},
   "source": [
    "<h3>check final merged data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "8cf05be6-2a0e-4022-909b-d08da3900193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total rows: 34645\n",
      " Unique SEQN values: 34645\n"
     ]
    }
   ],
   "source": [
    "SODH_diet_mort = pd.read_pickle(os.path.join(folder_path, \"SODH_diet_mort.pkl\"))\n",
    "\n",
    "score_mort.to_csv(\"/Users/dengshuyue/Desktop/SDOH/analysis/data/SODH_diet_mort_depr2.csv\", index=False)\n",
    "\n",
    "# Number of rows\n",
    "total_rows = SODH_diet_mort.shape[0]\n",
    "\n",
    "# Number of unique SEQN values\n",
    "unique_ids = SODH_diet_mort['SEQN'].nunique()\n",
    "\n",
    "print(f\" Total rows: {total_rows}\")\n",
    "print(f\" Unique SEQN values: {unique_ids}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "bbb9ed4d-66f8-45f5-b203-21551fd964e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Age range: 20.0 to 85.0\n"
     ]
    }
   ],
   "source": [
    "# Check age range\n",
    "min_age = score_mort[\"RIDAGEYR\"].min()\n",
    "max_age = score_mort[\"RIDAGEYR\"].max()\n",
    "\n",
    "print(f\" Age range: {min_age} to {max_age}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "10fec0a9-0c67-4437-9fdd-5e8a1231e648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SEQN', 'marriage', 'SDDSRVYR', 'HOD050', 'HOQ065', 'employ', 'unemployment', 'ELIGSTAT', 'MORTSTAT', 'UCOD_LEADING', 'DIABETES', 'HYPERTEN', 'PERMTH_INT', 'PERMTH_EXM', 'Death_heart', 'Death_cancer', 'Death_resp', 'Death_cerev', 'Death_diabe', 'Death_other', 'death_cvd', 'death_cmd', 'SNAP', 'FSDHH', 'FS', 'ins', 'RIDAGEYR', 'SEX', 'RACE', 'EDU', 'INDFMPIR', 'SMK_AVG', 'SMK', 'ALCG2', 'HEI2015_TOTAL_SCORE', 'DIABE', 'WTDRD1', 'WTDR2D', 'DR12DRST', 'i_FCS', 'i_Optup', 'i_HSR', 'i_nutri', 'sdmvpsu', 'sdmvstra', 'met_hr', 'perE_alco', 'dm_self', 'tchol', 'hdl', 'ldl', 'tg', 'bmi', 'CVD', 'dm_rx', 'chol_rx', 'angina_rx', 'lung_disease', 'angina', 'hba1c', 'sbp', 'dbp', 'cancer', 'wt10', 'wt', 'i_FCS_sd', 'i_Optup_sd', 'i_nutri_sd', 'i_HSR_sd', 'hei2015_sd', 'death_heart', 'death_cancer', 'death_resp', 'Death_inj', 'death_cerev', 'Death_alz', 'death_diabe', 'Death_infl', 'Death_kid', 'death_other1', 'Death_oth2', 'death_cmdk', 'death_cmdkh', 'death_multi', 'agesq', 'py', 'agestart', 'ageend', 'pir', 'bmic', 'include', 'ins2', 'unemployment2']\n"
     ]
    }
   ],
   "source": [
    "# View column names\n",
    "print(SODH_diet_mort.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63bab96-6045-4562-bc25-ac6aff06a0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b60085-19d6-4273-9e48-498e630c7202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca94725-3dbf-4c0f-9cc9-41fbf49f1b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de9496-7e60-414d-8985-17c00eb4202e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c6adb-c130-40fa-a2b4-ba60cecd8c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9be492-74d7-4489-9878-da7d5c791395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbaaf864-de3a-448d-9ab4-fc3a7147a9f7",
   "metadata": {},
   "source": [
    "<h1>Demographic Table</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03524dc6",
   "metadata": {},
   "source": [
    "<h2>🧮 Generate Weighted Demographic Summary Table</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14613ecd-1872-4ca4-9324-cb10cda0b4ec",
   "metadata": {},
   "source": [
    "<h3>try demo all item </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "b650ef50-71f9-4e05-b072-1013f9c5fcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conversion complete: .pkl → .csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the .pkl file\n",
    "pkl_path = \"/Users/dengshuyue/Desktop/SDOH/analysis/data/SODH_diet_mort.pkl\"\n",
    "df = pd.read_pickle(pkl_path)\n",
    "\n",
    "# Save as .csv\n",
    "csv_path = \"/Users/dengshuyue/Desktop/SDOH/analysis/data/SODH_diet_mort.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(\"✅ Conversion complete: .pkl → .csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "9715d92a-e1be-4bea-8d14-63827a63de26",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'linearmodels.survey'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[279]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m counts.round(\u001b[32m0\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m), (props * \u001b[32m100\u001b[39m).round(\u001b[32m1\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# === Use Taylor Linearization for SEs of continuous variables ===\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlinearmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msurvey\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SurveyDesign, SurveyMean\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msurvey_mean_se\u001b[39m(df, var, weight=\u001b[33m'\u001b[39m\u001b[33mwt10\u001b[39m\u001b[33m'\u001b[39m, strata=\u001b[33m'\u001b[39m\u001b[33msdmvstra\u001b[39m\u001b[33m'\u001b[39m, cluster=\u001b[33m'\u001b[39m\u001b[33msdmvpsu\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     27\u001b[39m     \u001b[38;5;66;03m# Remove missing\u001b[39;00m\n\u001b[32m     28\u001b[39m     d = df[[var, weight, strata, cluster]].dropna()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'linearmodels.survey'"
     ]
    }
   ],
   "source": [
    "# Python does not support full survey design (strata + PSU) out of the box\n",
    "# below code not working \n",
    "# === Load data ===\n",
    "data_path = \"/Users/dengshuyue/Desktop/SDOH/analysis/data/\"\n",
    "df = pd.read_pickle(os.path.join(data_path, \"SODH_diet_mort.pkl\"))\n",
    "\n",
    "# Drop rows missing survey design variables\n",
    "df = df.dropna(subset=['wt10', 'sdmvstra', 'sdmvpsu'])\n",
    "\n",
    "# === Weighted proportions for categorical variables ===\n",
    "def weighted_props(df, var, weight):\n",
    "    d = df[[var, weight]].dropna()\n",
    "    counts = d.groupby(var)[weight].sum()\n",
    "    total_weight = d[weight].sum()\n",
    "    props = (counts / total_weight).round(3)\n",
    "    return counts.round(0).astype(int), (props * 100).round(1)\n",
    "\n",
    "# === Use Taylor Linearization for SEs of continuous variables ===\n",
    "from linearmodels.survey import SurveyDesign, SurveyMean\n",
    "\n",
    "def survey_mean_se(df, var, weight='wt10', strata='sdmvstra', cluster='sdmvpsu'):\n",
    "    # Remove missing\n",
    "    d = df[[var, weight, strata, cluster]].dropna()\n",
    "\n",
    "    # Define survey design\n",
    "    design = sm.survey.SurveyDesign(\n",
    "        strata=d[strata],\n",
    "        cluster=d[cluster],\n",
    "        weights=d[weight],\n",
    "    )\n",
    "\n",
    "    # Fit the design-based estimator\n",
    "    survey_var = sm.survey.SurveyMean(d[var], design)\n",
    "    return float(survey_var.mean), float(survey_var.std)\n",
    "\n",
    "# === Variable dictionaries ===\n",
    "cat_vars = {\n",
    "    'SEX': {1: 'Male', 2: 'Female'},\n",
    "    'RACE': {1: 'Non-Hispanic White', 2: 'Non-Hispanic Black', 3: 'Hispanic', 4: 'Other'},\n",
    "    'EDU': {1: 'Less than high school', 2: 'High school or equivalent', 3: 'Some college', 4: 'College or above'},\n",
    "    'pir': {1: '<1.3', 2: '1.3~2.99', 3: '>=3'},\n",
    "    'SNAP': {0: 'Not participant', 1: 'Participant', 2: 'Income eligible non-participant'},\n",
    "    'SMK': {1: 'Nonsmokers', 2: 'Former smokers', 3: '<15 cigarettes/day', 4: '15-24.9 cigarettes/day', 5: '≥ 25 cigarettes/day'},\n",
    "    'ALCG2': {1: 'Nondrinkers', 2: 'Moderate drinker', 3: 'Heavy drinker', 4: 'Missing'},\n",
    "    'bmic': {1: 'BMI <18.5', 2: '18-24.9', 3: '25-29.9', 4: 'BMI ≥30'}\n",
    "}\n",
    "\n",
    "binary_vars = ['DIABETES', 'CVD', 'dm_rx', 'chol_rx', 'angina', 'cancer', 'lung_disease', 'MORTSTAT']\n",
    "cont_vars = ['RIDAGEYR', 'met_hr', 'bmi', 'hba1c', 'sbp', 'dbp', 'hdl', 'ldl', 'tg', 'HEI2015_TOTAL_SCORE']\n",
    "\n",
    "# === Generate summary ===\n",
    "rows = []\n",
    "\n",
    "# Categorical\n",
    "for var, mapping in cat_vars.items():\n",
    "    counts, props = weighted_props(df, var, 'wt10')\n",
    "    for code, label in mapping.items():\n",
    "        if code in counts.index:\n",
    "            rows.append({\n",
    "                \"Variable\": var,\n",
    "                \"Category\": label,\n",
    "                \"Overall\": f\"{counts[code]:,.0f} ({props[code]}%)\"\n",
    "            })\n",
    "\n",
    "# Binary (weighted %)\n",
    "for var in binary_vars:\n",
    "    val, se = survey_mean_se(df, var)\n",
    "    rows.append({\n",
    "        \"Variable\": var,\n",
    "        \"Category\": \"1\",\n",
    "        \"Overall\": f\"{val * 100:.1f}% ({se * 100:.1f})\"\n",
    "    })\n",
    "\n",
    "# Continuous (mean ± SE)\n",
    "for var in cont_vars:\n",
    "    mean, se = survey_mean_se(df, var)\n",
    "    rows.append({\n",
    "        \"Variable\": var,\n",
    "        \"Category\": \"\",\n",
    "        \"Overall\": f\"{mean:.2f} ({se:.2f})\"\n",
    "    })\n",
    "\n",
    "# === Create summary table ===\n",
    "demo_table = pd.DataFrame(rows)\n",
    "\n",
    "# === Save and preview ===\n",
    "output_path = os.path.join(data_path, \"demo_summary.csv\")\n",
    "demo_table.to_csv(output_path, index=False)\n",
    "\n",
    "# Show preview\n",
    "demo_table.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "01a00334-ef08-4a43-9926-9c7e2a0c18c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEX</td>\n",
       "      <td>Male</td>\n",
       "      <td>82,147,536 (47.8%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEX</td>\n",
       "      <td>Female</td>\n",
       "      <td>89,889,015 (52.2%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RACE</td>\n",
       "      <td>Non-Hispanic White</td>\n",
       "      <td>117,066,666 (68.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RACE</td>\n",
       "      <td>Non-Hispanic Black</td>\n",
       "      <td>19,270,383 (11.2%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RACE</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>23,166,597 (13.5%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RACE</td>\n",
       "      <td>Other</td>\n",
       "      <td>12,532,906 (7.3%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EDU</td>\n",
       "      <td>Less than high school</td>\n",
       "      <td>27,365,333 (15.9%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EDU</td>\n",
       "      <td>High school or equivalent</td>\n",
       "      <td>41,028,422 (23.9%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EDU</td>\n",
       "      <td>Some college</td>\n",
       "      <td>54,476,932 (31.7%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EDU</td>\n",
       "      <td>College or above</td>\n",
       "      <td>49,075,426 (28.5%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pir</td>\n",
       "      <td>&lt;1.3</td>\n",
       "      <td>35,288,368 (20.5%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pir</td>\n",
       "      <td>1.3~2.99</td>\n",
       "      <td>46,559,275 (27.1%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pir</td>\n",
       "      <td>&gt;=3</td>\n",
       "      <td>80,918,834 (47.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SNAP</td>\n",
       "      <td>Not participant</td>\n",
       "      <td>127,698,889 (74.2%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SNAP</td>\n",
       "      <td>Participant</td>\n",
       "      <td>24,672,009 (14.3%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SNAP</td>\n",
       "      <td>Income eligible non-participant</td>\n",
       "      <td>19,665,654 (11.4%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SMK</td>\n",
       "      <td>Nonsmokers</td>\n",
       "      <td>93,221,980 (54.2%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SMK</td>\n",
       "      <td>Former smokers</td>\n",
       "      <td>42,940,949 (25.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SMK</td>\n",
       "      <td>&lt;15 cigarettes/day</td>\n",
       "      <td>21,030,364 (12.2%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SMK</td>\n",
       "      <td>15-24.9 cigarettes/day</td>\n",
       "      <td>10,939,898 (6.4%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SMK</td>\n",
       "      <td>≥ 25 cigarettes/day</td>\n",
       "      <td>3,836,110 (2.2%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ALCG2</td>\n",
       "      <td>Nondrinkers</td>\n",
       "      <td>69,265,625 (40.3%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ALCG2</td>\n",
       "      <td>Moderate drinker</td>\n",
       "      <td>80,514,401 (46.8%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ALCG2</td>\n",
       "      <td>Heavy drinker</td>\n",
       "      <td>13,782,467 (8.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ALCG2</td>\n",
       "      <td>Missing</td>\n",
       "      <td>8,474,059 (4.9%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bmic</td>\n",
       "      <td>BMI &lt;18.5</td>\n",
       "      <td>2,736,947 (1.6%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bmic</td>\n",
       "      <td>18-24.9</td>\n",
       "      <td>56,978,492 (33.1%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bmic</td>\n",
       "      <td>25-29.9</td>\n",
       "      <td>63,146,301 (36.7%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DIABETES</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CVD</td>\n",
       "      <td>1</td>\n",
       "      <td>8.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>dm_rx</td>\n",
       "      <td>1</td>\n",
       "      <td>8.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>chol_rx</td>\n",
       "      <td>1</td>\n",
       "      <td>17.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>angina</td>\n",
       "      <td>1</td>\n",
       "      <td>4.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>cancer</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>lung_disease</td>\n",
       "      <td>1</td>\n",
       "      <td>19.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>MORTSTAT</td>\n",
       "      <td>1</td>\n",
       "      <td>9.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RIDAGEYR</td>\n",
       "      <td></td>\n",
       "      <td>47.44 (0.13)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>met_hr</td>\n",
       "      <td></td>\n",
       "      <td>62.34 (0.76)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>bmi</td>\n",
       "      <td></td>\n",
       "      <td>28.94 (0.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>hba1c</td>\n",
       "      <td></td>\n",
       "      <td>5.60 (0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>sbp</td>\n",
       "      <td></td>\n",
       "      <td>122.60 (0.13)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>dbp</td>\n",
       "      <td></td>\n",
       "      <td>70.61 (0.09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>hdl</td>\n",
       "      <td></td>\n",
       "      <td>53.65 (0.12)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ldl</td>\n",
       "      <td></td>\n",
       "      <td>117.40 (0.32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>tg</td>\n",
       "      <td></td>\n",
       "      <td>121.52 (0.78)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>HEI2015_TOTAL_SCORE</td>\n",
       "      <td></td>\n",
       "      <td>53.26 (0.10)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Variable                         Category              Overall\n",
       "0                   SEX                             Male   82,147,536 (47.8%)\n",
       "1                   SEX                           Female   89,889,015 (52.2%)\n",
       "2                  RACE               Non-Hispanic White  117,066,666 (68.0%)\n",
       "3                  RACE               Non-Hispanic Black   19,270,383 (11.2%)\n",
       "4                  RACE                         Hispanic   23,166,597 (13.5%)\n",
       "5                  RACE                            Other    12,532,906 (7.3%)\n",
       "6                   EDU            Less than high school   27,365,333 (15.9%)\n",
       "7                   EDU        High school or equivalent   41,028,422 (23.9%)\n",
       "8                   EDU                     Some college   54,476,932 (31.7%)\n",
       "9                   EDU                 College or above   49,075,426 (28.5%)\n",
       "10                  pir                             <1.3   35,288,368 (20.5%)\n",
       "11                  pir                         1.3~2.99   46,559,275 (27.1%)\n",
       "12                  pir                              >=3   80,918,834 (47.0%)\n",
       "13                 SNAP                  Not participant  127,698,889 (74.2%)\n",
       "14                 SNAP                      Participant   24,672,009 (14.3%)\n",
       "15                 SNAP  Income eligible non-participant   19,665,654 (11.4%)\n",
       "16                  SMK                       Nonsmokers   93,221,980 (54.2%)\n",
       "17                  SMK                   Former smokers   42,940,949 (25.0%)\n",
       "18                  SMK               <15 cigarettes/day   21,030,364 (12.2%)\n",
       "19                  SMK           15-24.9 cigarettes/day    10,939,898 (6.4%)\n",
       "20                  SMK              ≥ 25 cigarettes/day     3,836,110 (2.2%)\n",
       "21                ALCG2                      Nondrinkers   69,265,625 (40.3%)\n",
       "22                ALCG2                 Moderate drinker   80,514,401 (46.8%)\n",
       "23                ALCG2                    Heavy drinker    13,782,467 (8.0%)\n",
       "24                ALCG2                          Missing     8,474,059 (4.9%)\n",
       "25                 bmic                        BMI <18.5     2,736,947 (1.6%)\n",
       "26                 bmic                          18-24.9   56,978,492 (33.1%)\n",
       "27                 bmic                          25-29.9   63,146,301 (36.7%)\n",
       "28             DIABETES                                1                 1.0%\n",
       "29                  CVD                                1                 8.2%\n",
       "30                dm_rx                                1                 8.5%\n",
       "31              chol_rx                                1                17.9%\n",
       "32               angina                                1                 4.9%\n",
       "33               cancer                                1                10.1%\n",
       "34         lung_disease                                1                19.3%\n",
       "35             MORTSTAT                                1                 9.1%\n",
       "36             RIDAGEYR                                          47.44 (0.13)\n",
       "37               met_hr                                          62.34 (0.76)\n",
       "38                  bmi                                          28.94 (0.05)\n",
       "39                hba1c                                           5.60 (0.01)\n",
       "40                  sbp                                         122.60 (0.13)\n",
       "41                  dbp                                          70.61 (0.09)\n",
       "42                  hdl                                          53.65 (0.12)\n",
       "43                  ldl                                         117.40 (0.32)\n",
       "44                   tg                                         121.52 (0.78)\n",
       "45  HEI2015_TOTAL_SCORE                                          53.26 (0.10)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# === Load data ===\n",
    "df = pd.read_pickle(os.path.join(data_path, \"SODH_diet_mort.pkl\"))\n",
    "\n",
    "# Drop missing survey design variables (weight pooled: WTDRD1)\n",
    "df = df.dropna(subset=['wt10', 'sdmvstra', 'sdmvpsu'])\n",
    "\n",
    "# === Helper functions ===\n",
    "def weighted_mean(x, w):\n",
    "    d = pd.DataFrame({'x': x, 'w': w}).dropna()\n",
    "    return np.sum(d.x * d.w) / np.sum(d.w)\n",
    "\n",
    "# not standard \n",
    "# def weighted_se(x, w):\n",
    "#    d = pd.DataFrame({'x': x, 'w': w}).dropna()\n",
    "#    mean = weighted_mean(d.x, d.w)\n",
    "#    return np.sqrt(np.sum(d.w * (d.x - mean)**2) / ((len(d) - 1) * np.sum(d.w) / len(d)))\n",
    "\n",
    "# Only acceptable if weights are uniform\n",
    "# def weighted_se(x, w):\n",
    "#    d = pd.DataFrame({'x': x, 'w': w}).dropna()\n",
    "#    mean = np.sum(d.x * d.w) / np.sum(d.w)\n",
    "#    var = np.sum(d.w * (d.x - mean)**2) / np.sum(d.w)\n",
    "#    se = np.sqrt(var / len(d))  # Approximate\n",
    "#    return se\n",
    "\n",
    "# 🔥 Check best practice for estimating SE with survey weights\n",
    "\n",
    "def weighted_se(x, w):\n",
    "    d = pd.DataFrame({'x': x, 'w': w}).dropna()\n",
    "    mean = np.sum(d.x * d.w) / np.sum(d.w)\n",
    "    eff_n = (np.sum(d.w))**2 / np.sum(d.w**2)  # Effective sample size\n",
    "    var = np.sum(d.w * (d.x - mean)**2) / np.sum(d.w)\n",
    "    se = np.sqrt(var / eff_n)\n",
    "    return se\n",
    "\n",
    "    \n",
    "def weighted_props(df, var, weight):\n",
    "    d = df[[var, weight]].dropna()\n",
    "    counts = d.groupby(var)[weight].sum()\n",
    "    total_weight = d[weight].sum()\n",
    "    props = (counts / total_weight).round(3)\n",
    "    return counts.round(0).astype(int), (props * 100).round(1)\n",
    "\n",
    "# === Categorical variables ===\n",
    "cat_vars = {\n",
    "    'SEX': {1: 'Male', 2: 'Female'},\n",
    "    'RACE': {1: 'Non-Hispanic White', 2: 'Non-Hispanic Black', 3: 'Hispanic', 4: 'Other'},\n",
    "    'EDU': {1: 'Less than high school', 2: 'High school or equivalent', 3: 'Some college', 4: 'College or above'},\n",
    "    'pir': {1: '<1.3', 2: '1.3~2.99', 3: '>=3'},\n",
    "    'SNAP': {0: 'Not participant', 1: 'Participant', 2: 'Income eligible non-participant'},\n",
    "    'SMK': {1: 'Nonsmokers', 2: 'Former smokers', 3: '<15 cigarettes/day', 4: '15-24.9 cigarettes/day', 5: '≥ 25 cigarettes/day'},\n",
    "    'ALCG2': {1: 'Nondrinkers', 2: 'Moderate drinker', 3: 'Heavy drinker', 4: 'Missing'},\n",
    "    'bmic': {1: 'BMI <18.5', 2: '18-24.9', 3: '25-29.9', 4: 'BMI ≥30'}\n",
    "}\n",
    "\n",
    "rows = []\n",
    "\n",
    "for var, mapping in cat_vars.items():\n",
    "    counts, props = weighted_props(df, var, 'wt10')\n",
    "    for code, label in mapping.items():\n",
    "        if code in counts.index:\n",
    "            rows.append({\n",
    "                \"Variable\": var,\n",
    "                \"Category\": label,\n",
    "                \"Overall\": f\"{counts[code]:,.0f} ({props[code]}%)\"\n",
    "            })\n",
    "\n",
    "# === Binary variables ===\n",
    "binary_vars = ['DIABETES', 'CVD', 'dm_rx', 'chol_rx', 'angina', 'cancer', 'lung_disease', 'MORTSTAT']\n",
    "for var in binary_vars:\n",
    "    val = weighted_mean(df[var].fillna(0), df['wt10']) * 100\n",
    "    rows.append({\n",
    "        \"Variable\": var,\n",
    "        \"Category\": \"1\",\n",
    "        \"Overall\": f\"{val:.1f}%\"\n",
    "    })\n",
    "\n",
    "# === Continuous variables ===\n",
    "cont_vars = ['RIDAGEYR', 'met_hr', 'bmi', 'hba1c', 'sbp', 'dbp', 'hdl', 'ldl', 'tg', 'HEI2015_TOTAL_SCORE']\n",
    "for var in cont_vars:\n",
    "    mean = weighted_mean(df[var], df['wt10'])\n",
    "    se = weighted_se(df[var], df['wt10'])\n",
    "    rows.append({\n",
    "        \"Variable\": var,\n",
    "        \"Category\": \"\",\n",
    "        \"Overall\": f\"{mean:.2f} ({se:.2f})\"\n",
    "    })\n",
    "\n",
    "# === Create summary table ===\n",
    "demo_table = pd.DataFrame(rows)\n",
    "\n",
    "# Save, preview\n",
    "\n",
    "# Optionally: save to CSV\n",
    "# demo_table.to_csv(\"demo_summary.csv\", index=False)\n",
    "demo_table.to_csv(output_path, index=False)\n",
    "\n",
    "demo_table.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b12bfb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted percentage deceased: 9.1%\n"
     ]
    }
   ],
   "source": [
    "# Clean data: drop rows with missing mortality status or weight\n",
    "mort_df = df[['MORTSTAT', 'WTDRD1']].dropna()\n",
    "\n",
    "# Calculate total weighted sum\n",
    "total_weight = mort_df['WTDRD1'].sum()\n",
    "\n",
    "# Weighted percentage of deceased (MORTSTAT == 1)\n",
    "dead_weight = mort_df.loc[mort_df['MORTSTAT'] == 1, 'WTDRD1'].sum()\n",
    "weighted_pct_dead = (dead_weight / total_weight) * 100\n",
    "\n",
    "print(f\"Weighted percentage deceased: {weighted_pct_dead:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eae26a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male: 18845 (48.4%)\n",
      "Female: 20055 (51.6%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38420"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define unweighted counts and proportions\n",
    "def unweighted_props(df, var):\n",
    "    counts = df[var].value_counts(dropna=False).sort_index()\n",
    "    props = counts / counts.sum() * 100\n",
    "    return counts, props.round(1)\n",
    "\n",
    "# Now use it for 'sex'\n",
    "counts, props = unweighted_props(df, 'sex')\n",
    "\n",
    "# Optionally map codes to labels\n",
    "sex_labels = {1: 'Male', 2: 'Female'}\n",
    "for val in counts.index:\n",
    "    label = sex_labels.get(val, val)\n",
    "    print(f\"{label}: {counts[val]} ({props[val]}%)\")\n",
    "18530+19890\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9eae91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c1062d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63741b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ed50c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531b7645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2440f2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/dengshuyue/Desktop/SDOH/analysis/code/Ref/2.Prepare data_master.sas', 'r', encoding='latin1') as f:\n",
    "    sas_code = f.read()\n",
    "\n",
    "print(sas_code[:20000])  # Preview the first X,000 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e5a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/dengshuyue/Desktop/SDOH/analysis/code/Ref/2.1_Prepare data_covariates.sas', 'r', encoding='latin1') as f:\n",
    "    sas_code = f.read()\n",
    "\n",
    "print(sas_code[:20000])  # Preview the first X,000 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1742324",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/dengshuyue/Desktop/SDOH/analysis/code/Descriptions_1.sas', 'r', encoding='latin1') as f:\n",
    "    sas_code = f.read()\n",
    "\n",
    "print(sas_code[:20000])  # Preview the first 15,000 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9704426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diabetes Identification Note:\n",
    "# The final diabetes indicator variable used in the analysis is 'diabe2'.\n",
    "# This composite variable identifies diabetes based on the following criteria:\n",
    "# - Self-reported physician diagnosis (DIQ010), current insulin use (DIQ050), or oral medication use (DIQ070)\n",
    "# - Prescription drug data indicating diabetes treatment (dm_rx2)\n",
    "# - Fasting glucose ≥ 126 mg/dL (glu_dm)\n",
    "# - OGTT ≥ 200 mg/dL (ogtt_dm)\n",
    "# - HbA1c ≥ 6.5% (hb_dm)\n",
    "# Any one of these criteria being met will set 'diabe2' = 1, otherwise 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4508de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/dengshuyue/Desktop/SDOH/analysis/Analysis1_COX_allcause_bysub.sas', 'r', encoding='latin1') as f:\n",
    "    sas_code = f.read()\n",
    "\n",
    "print(sas_code[:10000])  # Preview the first 15,000 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bcc94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/dengshuyue/Desktop/SDOH/analysis/Analysis1_dataprep.sas', 'r', encoding='latin1') as f:\n",
    "    sas_code = f.read()\n",
    "\n",
    "print(sas_code[:20000])  # Preview the first 15,000 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58be0118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab19022e-5d46-4163-88b5-58f23781e962",
   "metadata": {},
   "source": [
    "<h1>SDOH score</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e7542aa-9952-439b-afe6-f53d66af6b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOQ065</th>\n",
       "      <th>HOD050</th>\n",
       "      <th>EMPLOY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38895</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38896</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38897</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38898</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38899</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38900 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HOQ065  HOD050  EMPLOY\n",
       "0         1.0     6.0     1.0\n",
       "1         1.0     3.0     2.0\n",
       "2         1.0     7.0     3.0\n",
       "3         1.0     6.0     3.0\n",
       "4         2.0     3.0     1.0\n",
       "...       ...     ...     ...\n",
       "38895     3.0     8.0     1.0\n",
       "38896     1.0     6.0     3.0\n",
       "38897     2.0     1.0     1.0\n",
       "38898     2.0     8.0     2.0\n",
       "38899     1.0     9.0     4.0\n",
       "\n",
       "[38900 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see housing and employ\n",
    "df[['HOQ065', 'HOD050', 'EMPLOY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "508bb06c-1993-4a1f-ad30-df81712d139c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== HOQ065 Summary ===\n",
      "Value counts:\n",
      "HOQ065\n",
      "1.0    24162\n",
      "2.0    13779\n",
      "3.0      907\n",
      "NaN       52\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Proportions:\n",
      "HOQ065\n",
      "1.0    62.11\n",
      "2.0    35.42\n",
      "3.0     2.33\n",
      "NaN     0.13\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Missing values: 52\n",
      "\n",
      "=== HOD050 Summary ===\n",
      "Value counts:\n",
      "HOD050\n",
      "5.0      8034\n",
      "6.0      7469\n",
      "4.0      6416\n",
      "7.0      5175\n",
      "8.0      3352\n",
      "3.0      3193\n",
      "9.0      1908\n",
      "10.0     1122\n",
      "2.0       820\n",
      "11.0      476\n",
      "12.0      285\n",
      "1.0       281\n",
      "13.0      260\n",
      "999.0      43\n",
      "777.0      39\n",
      "NaN        27\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Proportions:\n",
      "HOD050\n",
      "5.0      20.65\n",
      "6.0      19.20\n",
      "4.0      16.49\n",
      "7.0      13.30\n",
      "8.0       8.62\n",
      "3.0       8.21\n",
      "9.0       4.90\n",
      "10.0      2.88\n",
      "2.0       2.11\n",
      "11.0      1.22\n",
      "12.0      0.73\n",
      "1.0       0.72\n",
      "13.0      0.67\n",
      "999.0     0.11\n",
      "777.0     0.10\n",
      "NaN       0.07\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Missing values: 27\n",
      "\n",
      "=== EMPLOY Summary ===\n",
      "Value counts:\n",
      "EMPLOY\n",
      "1.0    20703\n",
      "3.0     7765\n",
      "5.0     4323\n",
      "4.0     3634\n",
      "2.0     1594\n",
      "NaN      881\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Proportions:\n",
      "EMPLOY\n",
      "1.0    53.22\n",
      "3.0    19.96\n",
      "5.0    11.11\n",
      "4.0     9.34\n",
      "2.0     4.10\n",
      "NaN     2.26\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Missing values: 881\n"
     ]
    }
   ],
   "source": [
    "# List of selected SDOH-related variables\n",
    "selected_cols = ['HOQ065', 'HOD050', 'MOR']\n",
    "\n",
    "# Summary function for each variable\n",
    "for col in selected_cols:\n",
    "    print(f\"\\n=== {col} Summary ===\")\n",
    "    print(\"Value counts:\")\n",
    "    print(df[col].value_counts(dropna=False))\n",
    "    print(\"\\nProportions:\")\n",
    "    print((df[col].value_counts(normalize=True, dropna=False) * 100).round(2))\n",
    "    print(f\"\\nMissing values: {df[col].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97dc217-6b45-4c00-b48f-d933c0aab82f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
