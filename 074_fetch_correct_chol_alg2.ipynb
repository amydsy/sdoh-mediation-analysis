{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2d532c4-67e7-42b6-bf51-531e36f243c7",
   "metadata": {},
   "source": [
    "## import previous file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3c2f0117-133a-4325-a414-bcbf500bdddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128809, 68)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>sdmvpsu</th>\n",
       "      <th>sdmvstra</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RACE</th>\n",
       "      <th>re</th>\n",
       "      <th>household_size</th>\n",
       "      <th>DMDHHSIZ</th>\n",
       "      <th>...</th>\n",
       "      <th>HOQ065_structural_missing</th>\n",
       "      <th>household_size_structural_missing</th>\n",
       "      <th>chol_rx_structural_missing</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>drinking</th>\n",
       "      <th>alcg2</th>\n",
       "      <th>perE_alco</th>\n",
       "      <th>METSCORE_fromPAQ</th>\n",
       "      <th>LTPA_fromPAQ</th>\n",
       "      <th>met_hr_recalc_from</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>F</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>77.0</td>\n",
       "      <td>M</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.065753</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>from_new_PAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>F</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>49.0</td>\n",
       "      <td>M</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>2</td>\n",
       "      <td>9.101101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>from_new_PAQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEQN  SDDSRVYR  sdmvpsu  sdmvstra  RIDAGEYR SEX  RACE                re  \\\n",
       "0     1       1.0        1         5       2.0   F   4.0    Other Hispanic   \n",
       "1     2       1.0        3         1      77.0   M   3.0  Mexican American   \n",
       "2     3       1.0        2         7      10.0   F   3.0  Mexican American   \n",
       "3     4       1.0        1         2       1.0   M   4.0    Other Hispanic   \n",
       "4     5       1.0        2         8      49.0   M   3.0  Mexican American   \n",
       "\n",
       "   household_size  DMDHHSIZ  ...  HOQ065_structural_missing  \\\n",
       "0               3       3.0  ...                      False   \n",
       "1               1       1.0  ...                      False   \n",
       "2               4       4.0  ...                      False   \n",
       "3               7       7.0  ...                      False   \n",
       "4               3       3.0  ...                      False   \n",
       "\n",
       "   household_size_structural_missing  chol_rx_structural_missing RIAGENDR  \\\n",
       "0                              False                       False      2.0   \n",
       "1                              False                       False      1.0   \n",
       "2                              False                       False      2.0   \n",
       "3                              False                       False      1.0   \n",
       "4                              False                       False      1.0   \n",
       "\n",
       "   drinking alcg2  perE_alco  METSCORE_fromPAQ  LTPA_fromPAQ  \\\n",
       "0       NaN  <NA>   0.000000               NaN           NaN   \n",
       "1  0.065753     2   0.000000               NaN           NaN   \n",
       "2       NaN  <NA>   0.000000               NaN           NaN   \n",
       "3       NaN  <NA>   0.000000               NaN           NaN   \n",
       "4  1.714286     2   9.101101               NaN           NaN   \n",
       "\n",
       "   met_hr_recalc_from  \n",
       "0                None  \n",
       "1        from_new_PAQ  \n",
       "2                None  \n",
       "3                None  \n",
       "4        from_new_PAQ  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "p = Path(\"/Users/dengshuyue/Desktop/SDOH/analysis/output/cov_addv4_99_23.parquet\")\n",
    "df_my_cov_aligned_short = pd.read_parquet(p)  # uses pyarrow/fastparquet if available\n",
    "print(df_my_cov_aligned_short.shape)\n",
    "df_my_cov_aligned_short.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e4c447-d947-4dc4-8390-3c223ea04e03",
   "metadata": {},
   "source": [
    "## show missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7cdf79ac-af8c-45ea-8f57-16301e89640d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          chol_rx  alcg2\n",
      "SDDSRVYR                \n",
      "1.0           0.0   62.9\n",
      "2.0           0.0   66.5\n",
      "3.0           0.0   62.9\n",
      "4.0           0.0   62.7\n",
      "5.0           0.0   55.4\n",
      "6.0           0.0   55.4\n",
      "7.0           0.0   55.1\n",
      "8.0           0.0   52.2\n",
      "9.0           0.0   52.8\n",
      "10.0          0.0   56.0\n",
      "12.0         29.1   61.4\n",
      "66.0        100.0   84.3\n"
     ]
    }
   ],
   "source": [
    "df = df_my_cov_aligned_short\n",
    "\n",
    "# use every column except the grouper\n",
    "# ignore PACK_YEARS, CIGS_PER_DAY, probable_depression and etc as missing naturally \n",
    "# ignore dulicate safe saved old column name\n",
    "\n",
    "exclude = {\"SDDSRVYR\",\"CIGS_PER_DAY\",\"PACK_YEARS\",\"probable_depression\",\"wt_phlebotomy\", \"WTSAFPRP\",\n",
    "           \"WTINT2YR\", \"WTMEC2YR\", \"WTPH2YR\", \"WTSAF2YR\", \"WTMEC4YR\", \"WTINTPRP\", \"WTMECPRP\", \"WTINT4YR\",\n",
    "           \"SNAP\", \"SNAP_src\", \"SNAP_bin\", \"SNAP_src_rank\", \"bmi\", \"RIAGENDR\",\n",
    "           \"SNAP_indiv_only\",\"FS\", \"ahei_total\", \"HOQ065\", \"marriage_label\", \"marriage_prev\",\n",
    "           \"METSCORE_fromPAQ\",\"perE_alco\",\"LTPA_fromPAQ\",\"SNAP_indiv_plus_singleton\", \n",
    "           \"SMK_AVG\", \"BMI_CLAS\", \"household_size\", \"DMDHHSIZ\"}\n",
    "cols_all = [c for c in df.columns if c not in exclude]\n",
    "\n",
    "# % missing by cycle (split into two lines)\n",
    "is_na = df[cols_all].isna()\n",
    "pct_miss = is_na.groupby(df[\"SDDSRVYR\"]).mean().mul(100)\n",
    "\n",
    "# keep only columns that exceed 80% missing in ANY cycle\n",
    "pct_miss_gt80 = pct_miss.loc[:, (pct_miss > 80).any(axis=0)].round(1)\n",
    "\n",
    "print(pct_miss_gt80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b900b14-41a2-4afc-a17f-33f2775198d5",
   "metadata": {},
   "source": [
    "## fetch chol and code chol_rx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ba60d2-cdd2-4d34-80d0-8164d8395895",
   "metadata": {},
   "source": [
    "#### check if previous cov code have mention chol_rx method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "49dab2ef-c631-414a-9f93-aceadb4a1f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\np = Path(\"/Users/dengshuyue/Desktop/SDOH/analysis/2.1_Prepare data_covariates.sas\")\\npat = re.compile(r\\'chol(_rx)?|HIGH_CHOL|BPQ0?80|BPQ10(0D|1D)|LBXTC|LBDLDL|LBXTR|HDL|RXQ_RX|RXDDRUG|STATIN|EZETIMIBE|FIBRATE\\', re.I)\\n\\nlines = p.read_text(errors=\"ignore\").splitlines()\\nfor i, line in enumerate(lines):\\n    if pat.search(line):\\n        start = max(0, i-3); end = min(len(lines), i+4)\\n        print(f\"\\n--- lines {start+1}-{end} ---\")\\n        for j in range(start, end):\\n            print(f\"{j+1:5d}: {lines[j]}\")\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "\"\"\"\n",
    "p = Path(\"/Users/dengshuyue/Desktop/SDOH/analysis/2.1_Prepare data_covariates.sas\")\n",
    "pat = re.compile(r'chol(_rx)?|HIGH_CHOL|BPQ0?80|BPQ10(0D|1D)|LBXTC|LBDLDL|LBXTR|HDL|RXQ_RX|RXDDRUG|STATIN|EZETIMIBE|FIBRATE', re.I)\n",
    "\n",
    "lines = p.read_text(errors=\"ignore\").splitlines()\n",
    "for i, line in enumerate(lines):\n",
    "    if pat.search(line):\n",
    "        start = max(0, i-3); end = min(len(lines), i+4)\n",
    "        print(f\"\\n--- lines {start+1}-{end} ---\")\n",
    "        for j in range(start, end):\n",
    "            print(f\"{j+1:5d}: {lines[j]}\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db0f024-c54d-4935-9585-398734351ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9505a9d0-d1d1-4b3f-89d2-1824162b1ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eea005a-29f8-4495-b6a8-98288d51c636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc6093ce-90bc-4c29-8706-209cd8ad0edc",
   "metadata": {},
   "source": [
    "#### Full cycle fetch 99-23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6760a145-4005-43d8-b66b-8ae0b51dbc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Unweighted QC (SAS-aligned, 1999â€“2022) ===\n",
      "                   n  chol_rx2_rate  dx_rate  lab200_rate  mean_tc  mean_hdl  \\\n",
      "period                                                                         \n",
      "1999-2000       8839          0.333    0.193        0.336  186.956    50.987   \n",
      "2001-2002       9682          0.336    0.201        0.324  186.684    51.649   \n",
      "2003-2004       8884          0.356    0.243        0.318   185.29    54.472   \n",
      "2005-2006       8334          0.358    0.226        0.309  184.471    54.782   \n",
      "2007-2008       8371          0.417    0.291        0.333  186.675    52.037   \n",
      "2009-2010       8763          0.408    0.272        0.326   185.64    52.648   \n",
      "2011-2012       8077          0.413    0.323         0.31  183.202    52.626   \n",
      "2013-2014       8489          0.400    0.341        0.272  179.534    53.105   \n",
      "2015-2016       8285          0.401    0.341        0.279  180.257    54.401   \n",
      "2017-2018       7768          0.417    0.358        0.273  179.895    53.393   \n",
      "2017-2020 (P)  12948          0.404    0.362        0.254  177.464    53.474   \n",
      "2021-2022 (L)   9954          0.426    0.364        0.295  181.541    54.113   \n",
      "\n",
      "               mean_ldl  \n",
      "period                   \n",
      "1999-2000       112.101  \n",
      "2001-2002       109.962  \n",
      "2003-2004       105.534  \n",
      "2005-2006       106.784  \n",
      "2007-2008        110.91  \n",
      "2009-2010       110.888  \n",
      "2011-2012       109.497  \n",
      "2013-2014       106.221  \n",
      "2015-2016       107.715  \n",
      "2017-2018       106.853  \n",
      "2017-2020 (P)   105.232  \n",
      "2021-2022 (L)      <NA>  \n",
      "\n",
      "=== Weighted QC (SAS-aligned) ===\n",
      "              weight_used  w_union   w_dx  w_lab200  w_mean_tc  w_mean_hdl  \\\n",
      "period                                                                       \n",
      "1999-2000        WTMEC2YR    0.418  0.224     0.401      193.9        50.3   \n",
      "2001-2002        WTMEC2YR    0.412  0.220     0.384      193.4        51.3   \n",
      "2003-2004        WTMEC2YR    0.446  0.272     0.390      193.0        54.0   \n",
      "2005-2006        WTMEC2YR    0.455  0.273     0.377      191.8        54.5   \n",
      "2007-2008        WTMEC2YR    0.455  0.282     0.365      190.1        51.9   \n",
      "2009-2010        WTMEC2YR    0.447  0.269     0.358      189.3        53.1   \n",
      "2011-2012        WTMEC2YR    0.481  0.328     0.359      188.5        52.8   \n",
      "2013-2014        WTMEC2YR    0.461  0.350     0.306      183.3        53.1   \n",
      "2015-2016        WTMEC2YR    0.468  0.340     0.330      185.9        55.4   \n",
      "2017-2018        WTMEC2YR    0.450  0.340     0.308      183.4        53.6   \n",
      "2017-2020 (P)    WTMECPRP    0.448  0.355     0.291      181.8        53.7   \n",
      "2021-2022 (L)    WTMEC2YR    0.447  0.336     0.308      183.3        53.5   \n",
      "\n",
      "               w_mean_ldl  \n",
      "period                     \n",
      "1999-2000           117.9  \n",
      "2001-2002           114.8  \n",
      "2003-2004           110.7  \n",
      "2005-2006           111.7  \n",
      "2007-2008           112.4  \n",
      "2009-2010           112.4  \n",
      "2011-2012           112.0  \n",
      "2013-2014           108.2  \n",
      "2015-2016           110.1  \n",
      "2017-2018           108.4  \n",
      "2017-2020 (P)       107.2  \n",
      "2021-2022 (L)         NaN  \n"
     ]
    }
   ],
   "source": [
    "import io, re, requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "# =========================================================\n",
    "# Helpers\n",
    "# =========================================================\n",
    "def _read_xpt(url, cols_upper=True):\n",
    "    r = requests.get(url); r.raise_for_status()\n",
    "    df = pd.read_sas(io.BytesIO(r.content), format=\"xport\", encoding=\"latin1\")\n",
    "    if cols_upper:\n",
    "        df.columns = [c.upper() for c in df.columns]\n",
    "    if \"SEQN\" in df.columns:\n",
    "        df[\"SEQN\"] = pd.to_numeric(df[\"SEQN\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    return df\n",
    "\n",
    "def _try_read_xpt(url, cols_upper=True):\n",
    "    try:\n",
    "        if not url:\n",
    "            return pd.DataFrame()\n",
    "        return _read_xpt(url, cols_upper=cols_upper)\n",
    "    except requests.HTTPError:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def _find_numeric_col(df, preferred, fallback_regex):\n",
    "    if df is None or df.empty:\n",
    "        return None\n",
    "    for c in preferred:\n",
    "        if c in df.columns and is_numeric_dtype(df[c]):\n",
    "            return c\n",
    "    pats = re.compile(fallback_regex, flags=re.I)\n",
    "    for c in df.columns:\n",
    "        if pats.search(c) and is_numeric_dtype(df[c]):\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _friedewald_ldl(tc, hdl, tg):\n",
    "    \"\"\"LDL = TC - HDL - TG/5 when TG < 400; else NA.\"\"\"\n",
    "    ldl = pd.Series(pd.NA, index=tc.index, dtype=\"Float64\")\n",
    "    cond = tc.notna() & hdl.notna() & tg.notna() & (tg < 400)\n",
    "    ldl.loc[cond] = (tc.loc[cond] - hdl.loc[cond] - (tg.loc[cond] / 5.0))\n",
    "    return ldl\n",
    "\n",
    "def wmean(x, w):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    w = pd.to_numeric(w, errors=\"coerce\")\n",
    "    m = x.notna() & w.notna() & (w > 0)\n",
    "    if m.sum() == 0: return np.nan\n",
    "    return float((x[m] * w[m]).sum() / w[m].sum())\n",
    "\n",
    "# =========================================================\n",
    "# File plumbing (1999â€“2018 two-year cycles)\n",
    "# =========================================================\n",
    "CYCLES_2YR = [\n",
    "    (\"\",   \"1999-2000\"),\n",
    "    (\"_B\", \"2001-2002\"),\n",
    "    (\"_C\", \"2003-2004\"),\n",
    "    (\"_D\", \"2005-2006\"),\n",
    "    (\"_E\", \"2007-2008\"),\n",
    "    (\"_F\", \"2009-2010\"),\n",
    "    (\"_G\", \"2011-2012\"),\n",
    "    (\"_H\", \"2013-2014\"),\n",
    "    (\"_I\", \"2015-2016\"),\n",
    "    (\"_J\", \"2017-2018\"),\n",
    "]\n",
    "\n",
    "def _base_folder_2yr(suffix):\n",
    "    return {\n",
    "        \"\":   \"1999\", \"_B\": \"2001\", \"_C\": \"2003\", \"_D\": \"2005\", \"_E\": \"2007\",\n",
    "        \"_F\": \"2009\", \"_G\": \"2011\", \"_H\": \"2013\", \"_I\": \"2015\", \"_J\": \"2017\"\n",
    "    }[suffix]\n",
    "\n",
    "def _url_2yr(folder, filebase):\n",
    "    return f\"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/{folder}/DataFiles/{filebase}.xpt\"\n",
    "\n",
    "def _read_first(folder, bases):\n",
    "    for base in bases:\n",
    "        df = _try_read_xpt(_url_2yr(folder, base))\n",
    "        if not df.empty:\n",
    "            return df\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# candidates per cycle for TC, HDL, LDL/TG\n",
    "def _tc_candidates(suffix):\n",
    "    if suffix == \"\":\n",
    "        return [\"LAB13\", \"TCHOL\"]                 # 1999â€“2000\n",
    "    if suffix in {\"_B\",\"_C\"}:\n",
    "        s = suffix.lstrip(\"_\")\n",
    "        return [f\"L13_{s}\", f\"TCHOL{suffix}\"]     # 2001â€“2004\n",
    "    return [f\"TCHOL{suffix}\"]                     # 2005+\n",
    "\n",
    "def _hdl_candidates(suffix):\n",
    "    if suffix == \"\":\n",
    "        return [\"LAB13\", \"HDL\"]                   # 1999â€“2000\n",
    "    if suffix in {\"_B\",\"_C\"}:\n",
    "        s = suffix.lstrip(\"_\")\n",
    "        return [f\"L13_{s}\", f\"HDL{suffix}\"]       # 2001â€“2004\n",
    "    return [f\"HDL{suffix}\"]                       # 2005+\n",
    "\n",
    "def _ldl_tg_candidates(suffix):\n",
    "    if suffix == \"\":\n",
    "        return [\"LAB13AM\", \"TRIGLY\", \"TCHOL\"]     # 1999â€“2000\n",
    "    if suffix in {\"_B\",\"_C\"}:\n",
    "        s = suffix.lstrip(\"_\")\n",
    "        return [f\"L13AM_{s}\", f\"TRIGLY{suffix}\", f\"TCHOL{suffix}\"]  # 2001â€“2004\n",
    "    return [f\"TRIGLY{suffix}\", f\"TCHOL{suffix}\"] # 2005+\n",
    "\n",
    "# =========================================================\n",
    "# Build ONE 2-yr cycle (SAS: dx = 080 OR 090D; flag = dx OR (TC>200))\n",
    "# =========================================================\n",
    "def build_cycle_2yr(suffix: str, label: str) -> pd.DataFrame:\n",
    "    folder = _base_folder_2yr(suffix)\n",
    "\n",
    "    # BPQ (dx items)\n",
    "    bpq = _try_read_xpt(_url_2yr(folder, f\"BPQ{suffix}\"))\n",
    "    bpq_keep = pd.DataFrame()\n",
    "    if not bpq.empty:\n",
    "        bpq_keep = bpq[[\"SEQN\"]].copy()\n",
    "        has_080 = pd.to_numeric(bpq.get(\"BPQ080\"),  errors=\"coerce\").eq(1) if \"BPQ080\"  in bpq.columns else pd.Series(False, index=bpq.index)\n",
    "        has_090 = pd.to_numeric(bpq.get(\"BPQ090D\"), errors=\"coerce\").eq(1) if \"BPQ090D\" in bpq.columns else pd.Series(False, index=bpq.index)\n",
    "        bpq_keep[\"hc_dx\"] = (has_080 | has_090).astype(\"Int64\")\n",
    "\n",
    "    # Labs (TC and HDL from their own sources; LDL/TG from LDL/TG source)\n",
    "    tc_df  = _read_first(folder, _tc_candidates(suffix))\n",
    "    hdl_df = _read_first(folder, _hdl_candidates(suffix))\n",
    "    ldl_tg = _read_first(folder, _ldl_tg_candidates(suffix))\n",
    "\n",
    "    # TC\n",
    "    tc_var  = _find_numeric_col(\n",
    "        tc_df,\n",
    "        preferred=[\"LBXTC\"],                      # total cholesterol\n",
    "        fallback_regex=r\"\\bTOTAL.*CHOL|^LB..TC$|\\bTC\\b\"\n",
    "    )\n",
    "    # HDL â€” prefer DIRECT (LBDHDD) when present, else conventional (LBDHDL/LBXHDL), else older naming (LBXHDD)\n",
    "    hdl_var = _find_numeric_col(\n",
    "        hdl_df,\n",
    "        preferred=[\"LBDHDD\",\"LBDHDL\",\"LBXHDL\",\"LBXHDD\",\"LBDHDD_1\"],\n",
    "        fallback_regex=r\"\\bHDL\\b|HDDS?\\b|^LB..HD\"\n",
    "    )\n",
    "    # LDL â€” look in TC file first, then LDL/TG file\n",
    "    ldl_var = _find_numeric_col(\n",
    "        tc_df,\n",
    "        preferred=[\"LBDLDL\",\"LBDLDLD\",\"LBDLDLL\"],\n",
    "        fallback_regex=r\"\\bLDL\\b|^LB.DLDL\"\n",
    "    )\n",
    "    if ldl_var is None:\n",
    "        ldl_var = _find_numeric_col(\n",
    "            ldl_tg,\n",
    "            preferred=[\"LBDLDL\",\"LBDLDLD\",\"LBDLDLL\"],\n",
    "            fallback_regex=r\"\\bLDL\\b|^LB.DLDL\"\n",
    "        )\n",
    "    # TG\n",
    "    tg_var  = _find_numeric_col(\n",
    "        ldl_tg,\n",
    "        preferred=[\"LBXTR\"],\n",
    "        fallback_regex=r\"\\bTRI?G|^LB..TR$\"\n",
    "    )\n",
    "\n",
    "    # Keep frames\n",
    "    tc_keep  = tc_df[[\"SEQN\", tc_var ]].rename(columns={tc_var : \"total_chol_mgdl\"}) if tc_var  else pd.DataFrame(columns=[\"SEQN\",\"total_chol_mgdl\"])\n",
    "    hdl_keep = hdl_df[[\"SEQN\", hdl_var]].rename(columns={hdl_var: \"hdl_mgdl\"})       if hdl_var else pd.DataFrame(columns=[\"SEQN\",\"hdl_mgdl\"])\n",
    "    ldl_keep = (tc_df if (ldl_var and ldl_var in tc_df.columns) else ldl_tg)\n",
    "    ldl_keep = ldl_keep[[\"SEQN\", ldl_var]].rename(columns={ldl_var: \"ldl_mgdl\"})     if ldl_var else pd.DataFrame(columns=[\"SEQN\",\"ldl_mgdl\"])\n",
    "    tg_keep  = ldl_tg[[\"SEQN\", tg_var]].rename(columns={tg_var: \"trig\"})             if tg_var  else pd.DataFrame(columns=[\"SEQN\",\"trig\"])\n",
    "\n",
    "    # Merge universe (union of sources)\n",
    "    bases = [f for f in (bpq_keep, tc_keep, hdl_keep, ldl_keep, tg_keep) if not f.empty]\n",
    "    if not bases:\n",
    "        return pd.DataFrame(columns=[\"SEQN\",\"period\",\"chol_rx2\",\"hc_dx\",\"hc_lab200\",\"total_chol_mgdl\",\"hdl_mgdl\",\"ldl_mgdl\",\"trig\"])\n",
    "    base = bases[0][[\"SEQN\"]].copy()\n",
    "    for f in bases[1:]:\n",
    "        base = base.merge(f[[\"SEQN\"]], on=\"SEQN\", how=\"outer\")\n",
    "\n",
    "    df = base\n",
    "    if not bpq_keep.empty: df = df.merge(bpq_keep, how=\"left\", on=\"SEQN\")\n",
    "    if not tc_keep.empty:  df = df.merge(tc_keep,  how=\"left\", on=\"SEQN\")\n",
    "    if not hdl_keep.empty: df = df.merge(hdl_keep, how=\"left\", on=\"SEQN\")\n",
    "    if not ldl_keep.empty: df = df.merge(ldl_keep, how=\"left\", on=\"SEQN\")\n",
    "    if not tg_keep.empty:  df = df.merge(tg_keep,  how=\"left\", on=\"SEQN\")\n",
    "\n",
    "    # Normalize labs\n",
    "    for c in [\"total_chol_mgdl\",\"hdl_mgdl\",\"ldl_mgdl\",\"trig\"]:\n",
    "        if c not in df.columns: df[c] = pd.NA\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(\"Float64\")\n",
    "\n",
    "    # Friedewald LDL (summaries only)\n",
    "    need_calc = df[\"ldl_mgdl\"].isna()\n",
    "    if need_calc.any() and df[\"total_chol_mgdl\"].notna().any() and df[\"hdl_mgdl\"].notna().any() and df[\"trig\"].notna().any():\n",
    "        ldl_est = _friedewald_ldl(df[\"total_chol_mgdl\"], df[\"hdl_mgdl\"], df[\"trig\"])\n",
    "        df.loc[need_calc, \"ldl_mgdl\"] = ldl_est.loc[need_calc]\n",
    "\n",
    "    # SAS rule\n",
    "    df[\"hc_lab200\"] = (df[\"total_chol_mgdl\"] > 200).astype(\"Int64\")\n",
    "    dx  = pd.to_numeric(df.get(\"hc_dx\"),     errors=\"coerce\").fillna(0).astype(int)\n",
    "    lab = pd.to_numeric(df.get(\"hc_lab200\"), errors=\"coerce\").fillna(0).astype(int)\n",
    "    df[\"chol_rx2\"] = ((dx == 1) | (lab == 1)).astype(int)\n",
    "\n",
    "    df[\"period\"] = label\n",
    "    return df[[\"SEQN\",\"period\",\"chol_rx2\",\"hc_dx\",\"hc_lab200\",\"total_chol_mgdl\",\"hdl_mgdl\",\"ldl_mgdl\",\"trig\"]]\n",
    "\n",
    "# =========================================================\n",
    "# P & L combined cycles (2017â€“2020, 2021â€“2022)\n",
    "# =========================================================\n",
    "BASE_2017 = \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles\"  # 'P' combined\n",
    "BASE_2021 = \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2021/DataFiles\"  # 'L'\n",
    "\n",
    "def _url_P(fn): return f\"{BASE_2017}/{fn}.xpt\"\n",
    "def _url_L(fn): return f\"{BASE_2021}/{fn}.xpt\"\n",
    "\n",
    "def build_P() -> pd.DataFrame:\n",
    "    # BPQ_P with dx = BPQ080 OR BPQ090D (SAS)\n",
    "    bpq = _read_xpt(_url_P(\"P_BPQ\"))\n",
    "    bpq_keep = bpq[[\"SEQN\"]].copy()\n",
    "    has_080 = pd.to_numeric(bpq.get(\"BPQ080\"),  errors=\"coerce\").eq(1) if \"BPQ080\" in bpq.columns else pd.Series(False, index=bpq.index)\n",
    "    has_090 = pd.to_numeric(bpq.get(\"BPQ090D\"), errors=\"coerce\").eq(1) if \"BPQ090D\" in bpq.columns else pd.Series(False, index=bpq.index)\n",
    "    bpq_keep[\"hc_dx\"] = (has_080 | has_090).astype(\"Int64\")\n",
    "\n",
    "    # Labs: separate files\n",
    "    tch  = _read_xpt(_url_P(\"P_TCHOL\"))\n",
    "    hdl  = _read_xpt(_url_P(\"P_HDL\"))\n",
    "    trig = _try_read_xpt(_url_P(\"P_TRIGLY\"))\n",
    "\n",
    "    tc_var  = _find_numeric_col(tch, preferred=[\"LBXTC\"], fallback_regex=r\"\\bTOTAL.*CHOL|^LB..TC$|\\bTC\\b\")\n",
    "    hdl_var = _find_numeric_col(hdl, preferred=[\"LBDHDD\",\"LBDHDL\",\"LBXHDL\",\"LBXHDD\",\"LBDHDD_1\"], fallback_regex=r\"\\bHDL\\b|HDDS?\\b|^LB..HD\")\n",
    "    ldl_var = _find_numeric_col(tch, preferred=[\"LBDLDL\",\"LBDLDLD\",\"LBDLDLL\"], fallback_regex=r\"\\bLDL\\b|^LB.DLDL\")\n",
    "    tg_var  = _find_numeric_col(trig, preferred=[\"LBXTR\"], fallback_regex=r\"\\bTRI?G|^LB..TR$\") if not trig.empty else None\n",
    "\n",
    "    tc_keep  = tch[[\"SEQN\", tc_var ]].rename(columns={tc_var : \"total_chol_mgdl\"}) if tc_var  else pd.DataFrame(columns=[\"SEQN\",\"total_chol_mgdl\"])\n",
    "    hdl_keep = hdl[[\"SEQN\", hdl_var]].rename(columns={hdl_var: \"hdl_mgdl\"})         if hdl_var else pd.DataFrame(columns=[\"SEQN\",\"hdl_mgdl\"])\n",
    "    ldl_keep = tch[[\"SEQN\", ldl_var]].rename(columns={ldl_var: \"ldl_mgdl\"})         if ldl_var else pd.DataFrame(columns=[\"SEQN\",\"ldl_mgdl\"])\n",
    "    tg_keep  = trig[[\"SEQN\", tg_var]].rename(columns={tg_var: \"trig\"})              if tg_var  else pd.DataFrame(columns=[\"SEQN\",\"trig\"])\n",
    "\n",
    "    bases = [f for f in (bpq_keep, tc_keep, hdl_keep, ldl_keep, tg_keep) if not f.empty]\n",
    "    base = bases[0][[\"SEQN\"]].copy()\n",
    "    for f in bases[1:]:\n",
    "        base = base.merge(f[[\"SEQN\"]], on=\"SEQN\", how=\"outer\")\n",
    "\n",
    "    df = base.merge(bpq_keep, how=\"left\", on=\"SEQN\")\n",
    "    for f in (tc_keep, hdl_keep, ldl_keep, tg_keep):\n",
    "        df = df.merge(f, how=\"left\", on=\"SEQN\")\n",
    "\n",
    "    for c in [\"total_chol_mgdl\",\"hdl_mgdl\",\"ldl_mgdl\",\"trig\"]:\n",
    "        if c not in df.columns: df[c] = pd.NA\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(\"Float64\")\n",
    "\n",
    "    need_calc = df[\"ldl_mgdl\"].isna()\n",
    "    if need_calc.any() and df[\"total_chol_mgdl\"].notna().any() and df[\"hdl_mgdl\"].notna().any() and df[\"trig\"].notna().any():\n",
    "        df.loc[need_calc, \"ldl_mgdl\"] = _friedewald_ldl(df[\"total_chol_mgdl\"], df[\"hdl_mgdl\"], df[\"trig\"])\n",
    "\n",
    "    df[\"hc_lab200\"] = (df[\"total_chol_mgdl\"] > 200).astype(\"Int64\")\n",
    "    df[\"chol_rx2\"]  = ((df[\"hc_dx\"].fillna(0).astype(int)==1) | (df[\"hc_lab200\"].fillna(0).astype(int)==1)).astype(int)\n",
    "    df[\"period\"]    = \"2017-2020 (P)\"\n",
    "    return df[[\"SEQN\",\"period\",\"chol_rx2\",\"hc_dx\",\"hc_lab200\",\"total_chol_mgdl\",\"hdl_mgdl\",\"ldl_mgdl\",\"trig\"]]\n",
    "\n",
    "def build_L() -> pd.DataFrame:\n",
    "    # BPQ_L with dx = BPQ080 OR BPQ090D (if present)\n",
    "    bpq = _read_xpt(_url_L(\"BPQ_L\"))\n",
    "    bpq_keep = bpq[[\"SEQN\"]].copy()\n",
    "    has_080 = pd.to_numeric(bpq.get(\"BPQ080\"),  errors=\"coerce\").eq(1) if \"BPQ080\" in bpq.columns else pd.Series(False, index=bpq.index)\n",
    "    has_090 = pd.to_numeric(bpq.get(\"BPQ090D\"), errors=\"coerce\").eq(1) if \"BPQ090D\" in bpq.columns else pd.Series(False, index=bpq.index)\n",
    "    bpq_keep[\"hc_dx\"] = (has_080 | has_090).astype(\"Int64\")\n",
    "\n",
    "    # Labs\n",
    "    tch  = _read_xpt(_url_L(\"TCHOL_L\"))\n",
    "    hdl  = _read_xpt(_url_L(\"HDL_L\"))\n",
    "    trig = _try_read_xpt(_url_L(\"TRIGLY_L\"))  # may not exist\n",
    "\n",
    "    tc_var  = _find_numeric_col(tch, preferred=[\"LBXTC\"], fallback_regex=r\"\\bTOTAL.*CHOL|^LB..TC$|\\bTC\\b\")\n",
    "    hdl_var = _find_numeric_col(hdl, preferred=[\"LBDHDD\",\"LBDHDL\",\"LBXHDL\",\"LBXHDD\",\"LBDHDD_1\"], fallback_regex=r\"\\bHDL\\b|HDDS?\\b|^LB..HD\")\n",
    "    ldl_var = _find_numeric_col(tch, preferred=[\"LBDLDL\",\"LBDLDLD\",\"LBDLDLL\"], fallback_regex=r\"\\bLDL\\b|^LB.DLDL\")\n",
    "    tg_var  = _find_numeric_col(trig, preferred=[\"LBXTR\"], fallback_regex=r\"\\bTRI?G|^LB..TR$\") if not trig.empty else None\n",
    "\n",
    "    tc_keep  = tch[[\"SEQN\", tc_var ]].rename(columns={tc_var : \"total_chol_mgdl\"}) if tc_var  else pd.DataFrame(columns=[\"SEQN\",\"total_chol_mgdl\"])\n",
    "    hdl_keep = hdl[[\"SEQN\", hdl_var]].rename(columns={hdl_var: \"hdl_mgdl\"})         if hdl_var else pd.DataFrame(columns=[\"SEQN\",\"hdl_mgdl\"])\n",
    "    ldl_keep = tch[[\"SEQN\", ldl_var]].rename(columns={ldl_var: \"ldl_mgdl\"})         if ldl_var else pd.DataFrame(columns=[\"SEQN\",\"ldl_mgdl\"])\n",
    "    tg_keep  = trig[[\"SEQN\", tg_var]].rename(columns={tg_var: \"trig\"})              if tg_var  else pd.DataFrame(columns=[\"SEQN\",\"trig\"])\n",
    "\n",
    "    bases = [f for f in (bpq_keep, tc_keep, hdl_keep, ldl_keep, tg_keep) if not f.empty]\n",
    "    base = bases[0][[\"SEQN\"]].copy()\n",
    "    for f in bases[1:]:\n",
    "        base = base.merge(f[[\"SEQN\"]], on=\"SEQN\", how=\"outer\")\n",
    "\n",
    "    df = base.merge(bpq_keep, how=\"left\", on=\"SEQN\")\n",
    "    for f in (tc_keep, hdl_keep, ldl_keep, tg_keep):\n",
    "        df = df.merge(f, how=\"left\", on=\"SEQN\")\n",
    "\n",
    "    for c in [\"total_chol_mgdl\",\"hdl_mgdl\",\"ldl_mgdl\",\"trig\"]:\n",
    "        if c not in df.columns: df[c] = pd.NA\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(\"Float64\")\n",
    "\n",
    "    need_calc = df[\"ldl_mgdl\"].isna()\n",
    "    if need_calc.any() and df[\"total_chol_mgdl\"].notna().any() and df[\"hdl_mgdl\"].notna().any() and df[\"trig\"].notna().any():\n",
    "        df.loc[need_calc, \"ldl_mgdl\"] = _friedewald_ldl(df[\"total_chol_mgdl\"], df[\"hdl_mgdl\"], df[\"trig\"])\n",
    "\n",
    "    df[\"hc_lab200\"] = (df[\"total_chol_mgdl\"] > 200).astype(\"Int64\")\n",
    "    df[\"chol_rx2\"]  = ((df[\"hc_dx\"].fillna(0).astype(int)==1) | (df[\"hc_lab200\"].fillna(0).astype(int)==1)).astype(int)\n",
    "    df[\"period\"]    = \"2021-2022 (L)\"\n",
    "    return df[[\"SEQN\",\"period\",\"chol_rx2\",\"hc_dx\",\"hc_lab200\",\"total_chol_mgdl\",\"hdl_mgdl\",\"ldl_mgdl\",\"trig\"]]\n",
    "\n",
    "# =========================================================\n",
    "# Build 1999â€“2018 (2-yr), 2017â€“2020 (P), 2021â€“2022 (L)\n",
    "# =========================================================\n",
    "dfs_2yr = []\n",
    "for suf, lab in CYCLES_2YR:\n",
    "    d = build_cycle_2yr(suf, lab)\n",
    "    if not d.empty:\n",
    "        dfs_2yr.append(d)\n",
    "df_99_18 = pd.concat(dfs_2yr, ignore_index=True) if dfs_2yr else pd.DataFrame(\n",
    "    columns=[\"SEQN\",\"period\",\"chol_rx2\",\"hc_dx\",\"hc_lab200\",\"total_chol_mgdl\",\"hdl_mgdl\",\"ldl_mgdl\",\"trig\"]\n",
    ")\n",
    "\n",
    "df_P = build_P()\n",
    "df_L = build_L()\n",
    "\n",
    "df_all = pd.concat([df_99_18, df_P, df_L], ignore_index=True)\n",
    "\n",
    "# =========================================================\n",
    "# Unweighted QC\n",
    "# =========================================================\n",
    "qc_unw = (\n",
    "    df_all.groupby(\"period\", dropna=False)\n",
    "          .agg(n=(\"SEQN\",\"count\"),\n",
    "               chol_rx2_rate=(\"chol_rx2\",\"mean\"),\n",
    "               dx_rate=(\"hc_dx\",\"mean\"),\n",
    "               lab200_rate=(\"hc_lab200\",\"mean\"),\n",
    "               mean_tc=(\"total_chol_mgdl\",\"mean\"),\n",
    "               mean_hdl=(\"hdl_mgdl\",\"mean\"),\n",
    "               mean_ldl=(\"ldl_mgdl\",\"mean\"))\n",
    "          .round(3)\n",
    "          .sort_index()\n",
    ")\n",
    "print(\"\\n=== Unweighted QC (SAS-aligned, 1999â€“2022) ===\")\n",
    "print(qc_unw)\n",
    "\n",
    "# =========================================================\n",
    "# Weighted QC\n",
    "# - 2-yr cycles: WTMEC2YR\n",
    "# - P combined:  WTMECPRP (fallback WTMEC2YR/WTINTPRP/WTINT2YR)\n",
    "# - L:           WTMEC2YR\n",
    "# =========================================================\n",
    "def _pick_weight_col(cols, cand):\n",
    "    for c in cand:\n",
    "        if c in cols: return c\n",
    "    return None\n",
    "\n",
    "def fetch_weight_for_period(period_label):\n",
    "    if period_label in [lab for _, lab in CYCLES_2YR]:\n",
    "        suffix = [s for s, lab in CYCLES_2YR if lab == period_label][0]\n",
    "        folder = _base_folder_2yr(suffix)\n",
    "        d = _try_read_xpt(_url_2yr(folder, f\"DEMO{suffix}\"))\n",
    "        if d.empty: return pd.DataFrame({\"SEQN\": pd.Series(dtype=\"Int64\"), \"W\": pd.Series(dtype=\"float\")})\n",
    "        wcol = _pick_weight_col(d.columns, [\"WTMEC2YR\"])\n",
    "        out = d[[\"SEQN\"]].copy()\n",
    "        out[\"W\"] = pd.to_numeric(d[wcol], errors=\"coerce\") if wcol else 1.0\n",
    "        out[\"_WCOL\"] = wcol if wcol else \"unit\"\n",
    "        return out\n",
    "\n",
    "    if period_label == \"2017-2020 (P)\":\n",
    "        d = _read_xpt(f\"{BASE_2017}/P_DEMO.xpt\")\n",
    "        wcol = _pick_weight_col(d.columns, [\"WTMECPRP\",\"WTMEC2YR\",\"WTINTPRP\",\"WTINT2YR\"])\n",
    "        out = d[[\"SEQN\"]].copy()\n",
    "        out[\"W\"] = pd.to_numeric(d[wcol], errors=\"coerce\") if wcol else 1.0\n",
    "        out[\"_WCOL\"] = wcol if wcol else \"unit\"\n",
    "        return out\n",
    "\n",
    "    if period_label == \"2021-2022 (L)\":\n",
    "        d = _read_xpt(f\"{BASE_2021}/DEMO_L.xpt\")\n",
    "        wcol = _pick_weight_col(d.columns, [\"WTMEC2YR\",\"WTINT2YR\"])\n",
    "        out = d[[\"SEQN\"]].copy()\n",
    "        out[\"W\"] = pd.to_numeric(d[wcol], errors=\"coerce\") if wcol else 1.0\n",
    "        out[\"_WCOL\"] = wcol if wcol else \"unit\"\n",
    "        return out\n",
    "\n",
    "    return pd.DataFrame({\"SEQN\": pd.Series(dtype=\"Int64\"), \"W\": pd.Series(dtype=\"float\")})\n",
    "\n",
    "rows = []\n",
    "for per in sorted(df_all[\"period\"].dropna().unique()):\n",
    "    demo = fetch_weight_for_period(per)\n",
    "    d = df_all[df_all[\"period\"]==per].merge(demo, on=\"SEQN\", how=\"left\")\n",
    "    rows.append({\n",
    "        \"period\": per,\n",
    "        \"weight_used\": d.get(\"_WCOL\", pd.Series([\"unknown\"])).mode().iat[0] if \"_WCOL\" in d.columns and not d[\"_WCOL\"].dropna().empty else \"unknown\",\n",
    "        \"w_union\":   round(wmean(d[\"chol_rx2\"],        d[\"W\"]), 3),\n",
    "        \"w_dx\":      round(wmean(d[\"hc_dx\"],           d[\"W\"]), 3),\n",
    "        \"w_lab200\":  round(wmean(d[\"hc_lab200\"],       d[\"W\"]), 3),\n",
    "        \"w_mean_tc\": round(wmean(d[\"total_chol_mgdl\"], d[\"W\"]), 1),\n",
    "        \"w_mean_hdl\":round(wmean(d[\"hdl_mgdl\"],        d[\"W\"]), 1),\n",
    "        \"w_mean_ldl\":round(wmean(d[\"ldl_mgdl\"],        d[\"W\"]), 1),\n",
    "    })\n",
    "\n",
    "qc_w = pd.DataFrame(rows).set_index(\"period\").sort_index()\n",
    "print(\"\\n=== Weighted QC (SAS-aligned) ===\")\n",
    "print(qc_w[[\"weight_used\",\"w_union\",\"w_dx\",\"w_lab200\",\"w_mean_tc\",\"w_mean_hdl\",\"w_mean_ldl\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a045c55d-c1bc-4025-b65e-251649969c55",
   "metadata": {},
   "source": [
    "## save and label new chol_rx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "46cc89fa-5f3f-4cb3-aa9b-5314fffdf5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    108394.000\n",
      "mean          0.389\n",
      "Name: chol_rx200, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Alias chol_rx2 -> chol_rx200 and merge into your covariates DF\n",
    "# (keeps only one column named 'chol_rx200')\n",
    "\n",
    "# 1) Build the add-on frame from df_all\n",
    "add = (\n",
    "    df_all.loc[:, [\"SEQN\", \"chol_rx2\"]]\n",
    "         .dropna(subset=[\"SEQN\"])\n",
    "         .drop_duplicates(subset=[\"SEQN\"])\n",
    "         .rename(columns={\"chol_rx2\": \"chol_rx200\"})\n",
    ")\n",
    "\n",
    "# 2) Harmonize key dtype\n",
    "df_my_cov_aligned_short[\"SEQN\"] = pd.to_numeric(df_my_cov_aligned_short[\"SEQN\"], errors=\"coerce\").astype(\"Int64\")\n",
    "add[\"SEQN\"] = pd.to_numeric(add[\"SEQN\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# 3) Merge (and replace any existing chol_rx200)\n",
    "df_my_cov_aligned_short = df_my_cov_aligned_short.drop(columns=[\"chol_rx200\"], errors=\"ignore\")\n",
    "df_my_cov_aligned_short = df_my_cov_aligned_short.merge(add, on=\"SEQN\", how=\"left\")\n",
    "\n",
    "# 4) Ensure nullable-int dtype\n",
    "df_my_cov_aligned_short[\"chol_rx200\"] = pd.to_numeric(df_my_cov_aligned_short[\"chol_rx200\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# (optional) quick sanity\n",
    "print(\n",
    "    df_my_cov_aligned_short[\"chol_rx200\"].agg([\"count\",\"mean\"]).round(3)\n",
    ")\n",
    "\n",
    "# (optional) save\n",
    "# df_my_cov_aligned_short.to_parquet(\"cov_addv4_99_23.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafe99e6-c733-4a73-b51e-f5108354b278",
   "metadata": {},
   "source": [
    "## check current missingness again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "178b6003-e34d-4958-8748-a47b34449d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SEQN', 'SDDSRVYR', 'sdmvpsu', 'sdmvstra', 'RIDAGEYR', 'SEX', 'RACE',\n",
       "       're', 'household_size', 'DMDHHSIZ', 'EDU', 'pir', 'SMK_AVG', 'SMK',\n",
       "       'met_hr', 'SMK_STATUS', 'CIGS_PER_DAY', 'PACK_YEARS', 'FORMER_SMOKER',\n",
       "       'METSCORE', 'LTPA', 'bmi_cat', 'BMI_CLAS', 'DIABE', 'HYPERTEN',\n",
       "       'chol_rx', 'CVD', 'cancer', 'probable_depression', 'ahei_total',\n",
       "       'unemployment2', 'ins', 'HOQ065', 'marriage', 'SNAP', 'FS', 'WTINT2YR',\n",
       "       'WTMEC2YR', 'WTSAF2YR', 'WTINT4YR', 'WTMEC4YR', 'WTPH2YR', 'WTINTPRP',\n",
       "       'WTMECPRP', 'WTSAFPRP', 'wt_int', 'wt_mec', 'wt_fasting',\n",
       "       'wt_phlebotomy', 'marriage_prev', 'marriage_label', 'marriage3',\n",
       "       'SNAP_src', 'SNAP_bin', 'SNAP_src_rank', 'SNAP_indiv_only',\n",
       "       'SNAP_indiv_plus_singleton', 'bmi', 'HOQ065_structural_missing',\n",
       "       'household_size_structural_missing', 'chol_rx_structural_missing',\n",
       "       'RIAGENDR', 'drinking', 'alcg2', 'perE_alco', 'METSCORE_fromPAQ',\n",
       "       'LTPA_fromPAQ', 'met_hr_recalc_from', 'chol_rx200'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_my_cov_aligned_short.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "96fba94f-e3c4-4489-b09d-60e9c17fec0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          alcg2\n",
      "SDDSRVYR       \n",
      "1.0        62.9\n",
      "2.0        66.5\n",
      "3.0        62.9\n",
      "4.0        62.7\n",
      "5.0        55.4\n",
      "6.0        55.4\n",
      "7.0        55.1\n",
      "8.0        52.2\n",
      "9.0        52.8\n",
      "10.0       56.0\n",
      "12.0       61.4\n",
      "66.0       84.3\n"
     ]
    }
   ],
   "source": [
    "df = df_my_cov_aligned_short\n",
    "\n",
    "# use every column except the grouper\n",
    "# ignore PACK_YEARS, CIGS_PER_DAY, probable_depression and etc as missing naturally \n",
    "# ignore dulicate safe saved old column name\n",
    "\n",
    "exclude = {\"SDDSRVYR\",\"CIGS_PER_DAY\",\"PACK_YEARS\",\"probable_depression\",\"wt_phlebotomy\", \"WTSAFPRP\",\n",
    "           \"WTINT2YR\", \"WTMEC2YR\", \"WTPH2YR\", \"WTSAF2YR\", \"WTMEC4YR\", \"WTINTPRP\", \"WTMECPRP\", \"WTINT4YR\",\n",
    "           \"SNAP\", \"SNAP_src\", \"SNAP_bin\", \"SNAP_src_rank\", \"bmi\", \"RIAGENDR\",\n",
    "           \"SNAP_indiv_only\",\"FS\", \"ahei_total\", \"HOQ065\", \"marriage_label\", \"marriage_prev\",\n",
    "           \"METSCORE_fromPAQ\",\"perE_alco\",\"LTPA_fromPAQ\",\"SNAP_indiv_plus_singleton\", \n",
    "           \"SMK_AVG\", \"BMI_CLAS\", \"household_size\", \"DMDHHSIZ\", \"chol_rx\", \"chol_rx_structural_missing\"}\n",
    "cols_all = [c for c in df.columns if c not in exclude]\n",
    "\n",
    "# % missing by cycle (split into two lines)\n",
    "is_na = df[cols_all].isna()\n",
    "pct_miss = is_na.groupby(df[\"SDDSRVYR\"]).mean().mul(100)\n",
    "\n",
    "# keep only columns that exceed 80% missing in ANY cycle\n",
    "pct_miss_gt80 = pct_miss.loc[:, (pct_miss > 80).any(axis=0)].round(1)\n",
    "\n",
    "print(pct_miss_gt80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9ab28178-e790-4f50-a672-ea88c816be82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcg2</th>\n",
       "      <th>drinking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.065753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128804</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128805</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128806</th>\n",
       "      <td>2</td>\n",
       "      <td>0.049315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128807</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128808</th>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128809 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        alcg2  drinking\n",
       "0        <NA>       NaN\n",
       "1           2  0.065753\n",
       "2        <NA>       NaN\n",
       "3        <NA>       NaN\n",
       "4           2  1.714286\n",
       "...       ...       ...\n",
       "128804   <NA>       NaN\n",
       "128805      1  0.004110\n",
       "128806      2  0.049315\n",
       "128807      1  0.000000\n",
       "128808      3  1.500000\n",
       "\n",
       "[128809 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_my_cov_aligned_short[[\"alcg2\", \"drinking\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b0aa9c-1a26-4b53-836e-aa7dbede73c3",
   "metadata": {},
   "source": [
    "## fix final missing alg2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3f628d79-5496-438c-b0fd-9bf6ea05d007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "=== alcg2 % by cycle (weighted; auto weight per cycle) ===\n",
      "         1     2     3    NA\n",
      "1.0   34.0  39.5   9.8  16.7\n",
      "2.0   25.9  39.8   8.7  25.5\n",
      "3.0   32.8  38.7   7.6  20.9\n",
      "4.0   31.6  39.6   9.7  19.0\n",
      "5.0   31.2  39.5   8.1  21.2\n",
      "6.0   26.3  41.4   9.6  22.7\n",
      "7.0   26.3  44.7  10.1  18.9\n",
      "8.0   31.0  45.0   8.6  15.4\n",
      "9.0   30.1  45.7   8.5  15.7\n",
      "10.0  25.9  44.4   8.6  21.1\n",
      "12.0  23.2  42.3   9.6  24.8\n",
      "66.0  24.9  45.7   9.3  20.2\n"
     ]
    }
   ],
   "source": [
    "import io, requests, numpy as np, pandas as pd\n",
    "\n",
    "# ---------------------------\n",
    "# Helper to read XPT\n",
    "# ---------------------------\n",
    "def _read_xpt(url, cols_upper=True):\n",
    "    r = requests.get(url); r.raise_for_status()\n",
    "    df = pd.read_sas(io.BytesIO(r.content), format=\"xport\", encoding=\"latin1\")\n",
    "    if cols_upper: df.columns = [c.upper() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "# ---------------------------\n",
    "# (Optional) attach gender/age for SDDSRVYR==66 only (no ALQ fields)\n",
    "# ---------------------------\n",
    "def attach_p_demo_gender(df: pd.DataFrame, replace_existing: bool=False) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for c in [\"SEQN\",\"SDDSRVYR\",\"RIAGENDR\",\"RIDAGEYR\"]:\n",
    "        if c not in out.columns: out[c] = np.nan\n",
    "\n",
    "    m66 = pd.to_numeric(out[\"SDDSRVYR\"], errors=\"coerce\").eq(66)\n",
    "    idx66 = out.index[m66]\n",
    "    if idx66.empty: return out\n",
    "\n",
    "    demo = _read_xpt(\"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/P_DEMO.xpt\")\n",
    "    demo = demo[[\"SEQN\",\"RIAGENDR\",\"RIDAGEYR\"]].copy()\n",
    "    for c in [\"RIAGENDR\",\"RIDAGEYR\"]:\n",
    "        demo[c] = pd.to_numeric(demo[c], errors=\"coerce\")\n",
    "\n",
    "    part = out.loc[idx66, [\"SEQN\"]].merge(demo, on=\"SEQN\", how=\"left\")\n",
    "    part.index = idx66  # align to original index\n",
    "\n",
    "    if replace_existing:\n",
    "        out.loc[idx66, [\"RIAGENDR\",\"RIDAGEYR\"]] = part[[\"RIAGENDR\",\"RIDAGEYR\"]].values\n",
    "    else:\n",
    "        need_g = idx66[out.loc[idx66, \"RIAGENDR\"].isna()]\n",
    "        need_a = idx66[out.loc[idx66, \"RIDAGEYR\"].isna()]\n",
    "        if len(need_g): out.loc[need_g, \"RIAGENDR\"] = part.loc[need_g, \"RIAGENDR\"].values\n",
    "        if len(need_a): out.loc[need_a, \"RIDAGEYR\"] = part.loc[need_a, \"RIDAGEYR\"].values\n",
    "    return out\n",
    "\n",
    "# ---------------------------\n",
    "# Compute alcg2 for cycle 66 WITHOUT persisting ALQ columns\n",
    "# Categories:\n",
    "#   1 = none/rare  (drinks/day < 0.03)\n",
    "#   2 = light/mod  (male: 0.03â€“<2; female: 0.03â€“<1)\n",
    "#   3 = heavy      (male: â‰¥2; female: â‰¥1)\n",
    "# ---------------------------\n",
    "def update_alcg2_for_p_cycle_no_intermediates(\n",
    "    df: pd.DataFrame,\n",
    "    replace_existing: bool=False,\n",
    "    rare_cutoff_per_day: float=0.03,\n",
    "    backfill_alq130_if_freq: bool=True\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    out = df.copy()\n",
    "    for c in [\"SEQN\",\"SDDSRVYR\",\"RIDAGEYR\",\"RIAGENDR\",\"alcg2\"]:\n",
    "        if c not in out.columns: out[c] = np.nan\n",
    "    if out[\"alcg2\"].dtype.name != \"Int64\":\n",
    "        out[\"alcg2\"] = pd.Series(out[\"alcg2\"]).astype(\"Int64\")\n",
    "\n",
    "    sdd   = pd.to_numeric(out[\"SDDSRVYR\"], errors=\"coerce\")\n",
    "    age18 = pd.to_numeric(out[\"RIDAGEYR\"], errors=\"coerce\").ge(18)\n",
    "    idx   = out.index[sdd.eq(66) & age18]\n",
    "    if idx.empty: return out\n",
    "\n",
    "    # Read ALQ for this cycle, but DO NOT add to df\n",
    "    alq = _read_xpt(\"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/P_ALQ.xpt\")\n",
    "    keep = [c for c in [\"SEQN\",\"ALQ111\",\"ALQ121\",\"ALQ130\"] if c in alq.columns]\n",
    "    alq = alq[keep].copy()\n",
    "    for c in [\"ALQ111\",\"ALQ121\",\"ALQ130\"]:\n",
    "        if c in alq.columns: alq[c] = pd.to_numeric(alq[c], errors=\"coerce\")\n",
    "    if \"ALQ130\" in alq.columns:\n",
    "        alq[\"ALQ130\"] = alq[\"ALQ130\"].replace({777: np.nan, 999: np.nan})\n",
    "\n",
    "    work = out.loc[idx, [\"SEQN\",\"RIAGENDR\",\"alcg2\"]].merge(alq, on=\"SEQN\", how=\"left\")\n",
    "    work.index = idx\n",
    "\n",
    "    if backfill_alq130_if_freq and {\"ALQ111\",\"ALQ121\",\"ALQ130\"} <= set(work.columns):\n",
    "        cond = (work[\"ALQ111\"] == 1) & (work[\"ALQ121\"] > 0) & (work[\"ALQ130\"].isna())\n",
    "        work.loc[cond, \"ALQ130\"] = 1.0\n",
    "\n",
    "    freq_map = {0:0.0, 1:1.0, 2:6/7, 3:3.5/7, 4:2/7, 5:1/7, 6:1/12.5, 7:1/30, 8:9/365, 9:4.5/365, 10:1.5/365}\n",
    "    mult = work[\"ALQ121\"].map(freq_map) if \"ALQ121\" in work.columns else pd.Series(np.nan, index=work.index)\n",
    "\n",
    "    drinks_per_day = mult * work.get(\"ALQ130\", np.nan)\n",
    "    if \"ALQ111\" in work.columns:\n",
    "        drinks_per_day = np.where(work[\"ALQ111\"] == 2, 0.0, drinks_per_day)\n",
    "\n",
    "    x = pd.to_numeric(drinks_per_day, errors=\"coerce\")\n",
    "    alc_new = pd.Series(pd.NA, index=work.index, dtype=\"Int64\")\n",
    "    alc_new = alc_new.mask((x >= 0) & (x < rare_cutoff_per_day), 1)  # none/rare\n",
    "    alc_new = alc_new.mask((work[\"RIAGENDR\"] == 1) & (x >= rare_cutoff_per_day) & (x < 2), 2)\n",
    "    alc_new = alc_new.mask((work[\"RIAGENDR\"] == 2) & (x >= rare_cutoff_per_day) & (x < 1), 2)\n",
    "    alc_new = alc_new.mask((work[\"RIAGENDR\"] == 1) & (x >= 2), 3)\n",
    "    alc_new = alc_new.mask((work[\"RIAGENDR\"] == 2) & (x >= 1), 3)\n",
    "\n",
    "    if replace_existing:\n",
    "        out.loc[idx, \"alcg2\"] = alc_new.values\n",
    "    else:\n",
    "        need = out.loc[idx, \"alcg2\"].isna()\n",
    "        out.loc[idx[need], \"alcg2\"] = alc_new.loc[idx[need]].values\n",
    "\n",
    "    return out\n",
    "\n",
    "# ---------------------------\n",
    "# Weighted % by cycle (auto weight: 66â†’WTMECPRP elseâ†’WTMEC2YR)\n",
    "# ---------------------------\n",
    "def _weighted_alcg2_for_cycle(df, cycle, weight_col):\n",
    "    a = df.copy()\n",
    "    a[\"SDDSRVYR\"] = pd.to_numeric(a[\"SDDSRVYR\"], errors=\"coerce\")\n",
    "    a = a[(a[\"SDDSRVYR\"] == cycle) & (pd.to_numeric(a[\"RIDAGEYR\"], errors=\"coerce\") >= 18)]\n",
    "    if a.empty:\n",
    "        return pd.Series({1: np.nan, 2: np.nan, 3: np.nan, \"NA\": np.nan}, name=cycle)\n",
    "    w = pd.to_numeric(a.get(weight_col), errors=\"coerce\")\n",
    "    denom = np.nansum(w)\n",
    "    if not np.isfinite(denom) or denom <= 0:\n",
    "        return pd.Series({1: np.nan, 2: np.nan, 3: np.nan, \"NA\": np.nan}, name=cycle)\n",
    "    return pd.Series({\n",
    "        1: float(np.nansum(w[a[\"alcg2\"] == 1]) / denom),\n",
    "        2: float(np.nansum(w[a[\"alcg2\"] == 2]) / denom),\n",
    "        3: float(np.nansum(w[a[\"alcg2\"] == 3]) / denom),\n",
    "        \"NA\": float(np.nansum(w[a[\"alcg2\"].isna()]) / denom),\n",
    "    }, name=cycle)\n",
    "\n",
    "def alcg2_by_cycle_auto_weight(df, include_cycles=None):\n",
    "    x = df.copy()\n",
    "    x[\"SDDSRVYR\"] = pd.to_numeric(x[\"SDDSRVYR\"], errors=\"coerce\")\n",
    "    cycles = sorted(x[\"SDDSRVYR\"].dropna().unique().tolist())\n",
    "    if include_cycles is not None:\n",
    "        cycles = [c for c in cycles if c in include_cycles]\n",
    "    rows = []\n",
    "    for cyc in cycles:\n",
    "        weight = \"WTMECPRP\" if cyc == 66 else \"WTMEC2YR\"\n",
    "        rows.append(_weighted_alcg2_for_cycle(x, cyc, weight))\n",
    "    res = pd.DataFrame(rows).sort_index()\n",
    "    print(\"=== alcg2 % by cycle (weighted; auto weight per cycle) ===\")\n",
    "    print((res * 100).round(1).to_string())\n",
    "    return res\n",
    "\n",
    "# ---------------------------\n",
    "# USAGE\n",
    "# ---------------------------\n",
    "# 1) start from your DF: df_my_cov_aligned_short\n",
    "# 2) (optional) ensure gender/age for 66 are present\n",
    "df_my_cov_aligned_short = attach_p_demo_gender(df_my_cov_aligned_short, replace_existing=False)\n",
    "\n",
    "# 3) compute alcg2 for 2017â€“Mar 2020 WITHOUT adding ALQ columns\n",
    "df_my_cov_aligned_short = update_alcg2_for_p_cycle_no_intermediates(\n",
    "    df_my_cov_aligned_short,\n",
    "    replace_existing=False,\n",
    "    rare_cutoff_per_day=0.03,\n",
    "    backfill_alq130_if_freq=True\n",
    ")\n",
    "\n",
    "# 4) quick sanity check that intermediates were NOT added\n",
    "print([c for c in [\"ALQ111\",\"ALQ121\",\"ALQ130\"] if c in df_my_cov_aligned_short.columns])  # expect []\n",
    "\n",
    "# 5) optional weighted table (66 uses WTMECPRP automatically)\n",
    "_ = alcg2_by_cycle_auto_weight(df_my_cov_aligned_short)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a57388e5-bb8e-4fea-8829-68019daf0421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SEQN', 'SDDSRVYR', 'sdmvpsu', 'sdmvstra', 'RIDAGEYR', 'SEX', 'RACE',\n",
       "       're', 'household_size', 'DMDHHSIZ', 'EDU', 'pir', 'SMK_AVG', 'SMK',\n",
       "       'met_hr', 'SMK_STATUS', 'CIGS_PER_DAY', 'PACK_YEARS', 'FORMER_SMOKER',\n",
       "       'METSCORE', 'LTPA', 'bmi_cat', 'BMI_CLAS', 'DIABE', 'HYPERTEN',\n",
       "       'chol_rx', 'CVD', 'cancer', 'probable_depression', 'ahei_total',\n",
       "       'unemployment2', 'ins', 'HOQ065', 'marriage', 'SNAP', 'FS', 'WTINT2YR',\n",
       "       'WTMEC2YR', 'WTSAF2YR', 'WTINT4YR', 'WTMEC4YR', 'WTPH2YR', 'WTINTPRP',\n",
       "       'WTMECPRP', 'WTSAFPRP', 'wt_int', 'wt_mec', 'wt_fasting',\n",
       "       'wt_phlebotomy', 'marriage_prev', 'marriage_label', 'marriage3',\n",
       "       'SNAP_src', 'SNAP_bin', 'SNAP_src_rank', 'SNAP_indiv_only',\n",
       "       'SNAP_indiv_plus_singleton', 'bmi', 'HOQ065_structural_missing',\n",
       "       'household_size_structural_missing', 'chol_rx_structural_missing',\n",
       "       'RIAGENDR', 'drinking', 'alcg2', 'perE_alco', 'METSCORE_fromPAQ',\n",
       "       'LTPA_fromPAQ', 'met_hr_recalc_from', 'chol_rx200'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_my_cov_aligned_short.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "37a3d74d-fa13-4837-a457-bdd6782a1037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_my_cov_aligned_short = df_my_cov_aligned_short.drop(columns=[\"ALQ111\",\"ALQ121\",\"ALQ130\"], errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d98b9fd-88c9-400b-9e0a-b2a104756d7e",
   "metadata": {},
   "source": [
    "## save as cov_addv5_99_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0f5096a9-dc58-4de6-aadb-aefd93b1161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "out_dir = Path(\"/Users/dengshuyue/Desktop/SDOH/analysis/output\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Parquet (preferred; needs `pyarrow` or `fastparquet`)\n",
    "df_my_cov_aligned_short.to_parquet(out_dir / \"cov_addv5_99_23.parquet\", index=False)\n",
    "\n",
    "# CSV fallback\n",
    "# df_my_cov_aligned_short.to_csv(out_dir / \"cov_addv5_99_23.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bae1efb-f399-4c6b-9417-1d2d5b5c4888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ddfddd-dde3-4397-af45-41200a132b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3caa8c-130e-4042-ba10-69ad35e50cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
