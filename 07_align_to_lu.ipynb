{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d3f2050-e263-48c8-ace0-48b75e929269",
   "metadata": {},
   "source": [
    "## set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3e39b36e-3c61-4228-8725-98d36a4373c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mine: (128809, 82) | lu: (101316, 75)\n",
      "Loaded: /Users/dengshuyue/Desktop/SDOH/analysis/output/demo_mt_cov_dp_sdoh.parquet\n",
      "Loaded: /Users/dengshuyue/Desktop/SDOH/analysis/data/cov/nhanes_primary_anal_full_singleimputation_v2.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = Path(\"/Users/dengshuyue/Desktop/SDOH/analysis\")\n",
    "OUT  = ROOT / \"output\"\n",
    "\n",
    "MY_PATH = OUT / \"demo_mt_cov_dp_sdoh.parquet\"\n",
    "LU_PATH = ROOT / \"data/cov/nhanes_primary_anal_full_singleimputation_v2.csv\"\n",
    "\n",
    "df_my_cov_1999_2023 = pd.read_parquet(MY_PATH)\n",
    "df_lu_cov_1999_2018 = pd.read_csv(LU_PATH)\n",
    "\n",
    "print(\"mine:\", df_my_cov_1999_2023.shape, \"| lu:\", df_lu_cov_1999_2018.shape)\n",
    "print(\"Loaded:\", MY_PATH)\n",
    "print(\"Loaded:\", LU_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f801de9a-af35-467e-b2c5-b964fe5ce35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>SDMVPSU</th>\n",
       "      <th>SDMVSTRA</th>\n",
       "      <th>WTMEC2YR</th>\n",
       "      <th>AGE_YR</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>SEX</th>\n",
       "      <th>FEMALE</th>\n",
       "      <th>SMK_STATUS</th>\n",
       "      <th>...</th>\n",
       "      <th>FS_HH</th>\n",
       "      <th>FS_ADULT</th>\n",
       "      <th>FS_FINAL</th>\n",
       "      <th>HHFDSEC</th>\n",
       "      <th>ADFDSEC</th>\n",
       "      <th>FS_HH4</th>\n",
       "      <th>FS_ADULT4</th>\n",
       "      <th>FS_SOURCE_HH</th>\n",
       "      <th>FS_SOURCE_FINAL</th>\n",
       "      <th>SNAP_SOURCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10982.898896</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28325.384898</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>NEVER</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>HHFDSEC</td>\n",
       "      <td>household</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>46192.256945</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10251.260020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>99445.065735</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>FORMER</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>HHFDSEC</td>\n",
       "      <td>household</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39656.600444</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25525.423409</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>FORMER</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>31510.587866</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7575.870247</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22445.808572</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>CURRENT</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEQN  SDDSRVYR  SDMVPSU  SDMVSTRA      WTMEC2YR  AGE_YR  RIAGENDR SEX  \\\n",
       "0     1       1.0      1.0       5.0  10982.898896     2.0         2   F   \n",
       "1     2       1.0      3.0       1.0  28325.384898    77.0         1   M   \n",
       "2     3       1.0      2.0       7.0  46192.256945    10.0         2   F   \n",
       "3     4       1.0      1.0       2.0  10251.260020     1.0         1   M   \n",
       "4     5       1.0      2.0       8.0  99445.065735    49.0         1   M   \n",
       "5     6       1.0      2.0       2.0  39656.600444    19.0         2   F   \n",
       "6     7       1.0      2.0       4.0  25525.423409    59.0         2   F   \n",
       "7     8       1.0      1.0       6.0  31510.587866    13.0         1   M   \n",
       "8     9       1.0      2.0       9.0   7575.870247    11.0         2   F   \n",
       "9    10       1.0      1.0       7.0  22445.808572    43.0         1   M   \n",
       "\n",
       "   FEMALE SMK_STATUS  ...  FS_HH  FS_ADULT  FS_FINAL  HHFDSEC ADFDSEC  FS_HH4  \\\n",
       "0       1        NaN  ...   <NA>      <NA>      <NA>     <NA>    <NA>    <NA>   \n",
       "1       0      NEVER  ...      0         0         0        1       1       1   \n",
       "2       1        NaN  ...   <NA>      <NA>      <NA>     <NA>    <NA>    <NA>   \n",
       "3       0        NaN  ...   <NA>      <NA>      <NA>     <NA>    <NA>    <NA>   \n",
       "4       0     FORMER  ...      0         0         0        1       1       1   \n",
       "5       1        NaN  ...   <NA>      <NA>      <NA>     <NA>    <NA>    <NA>   \n",
       "6       1     FORMER  ...   <NA>      <NA>      <NA>     <NA>    <NA>    <NA>   \n",
       "7       0        NaN  ...   <NA>      <NA>      <NA>     <NA>    <NA>    <NA>   \n",
       "8       1        NaN  ...   <NA>      <NA>      <NA>     <NA>    <NA>    <NA>   \n",
       "9       0    CURRENT  ...   <NA>      <NA>      <NA>     <NA>    <NA>    <NA>   \n",
       "\n",
       "   FS_ADULT4  FS_SOURCE_HH  FS_SOURCE_FINAL  SNAP_SOURCE  \n",
       "0       <NA>          <NA>             <NA>         <NA>  \n",
       "1          1       HHFDSEC        household         <NA>  \n",
       "2       <NA>          <NA>             <NA>         <NA>  \n",
       "3       <NA>          <NA>             <NA>         <NA>  \n",
       "4          1       HHFDSEC        household         <NA>  \n",
       "5       <NA>          <NA>             <NA>         <NA>  \n",
       "6       <NA>          <NA>             <NA>         <NA>  \n",
       "7       <NA>          <NA>             <NA>         <NA>  \n",
       "8       <NA>          <NA>             <NA>         <NA>  \n",
       "9       <NA>          <NA>             <NA>         <NA>  \n",
       "\n",
       "[10 rows x 82 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_my_cov_1999_2023.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f9e039-fde5-4a1e-9282-a4937ea3fc0e",
   "metadata": {},
   "source": [
    "#### 1) Helpers (used later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f735d0c5-a7c0-482f-abfd-3375b3cec0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) HELPERS (robust + imports np)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _norm_str_col(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Lowercase + strip + turn 'nan' into actual NaN.\"\"\"\n",
    "    s = series.astype(str).str.strip().str.lower()\n",
    "    return s.replace({\"nan\": np.nan})\n",
    "\n",
    "def _num_summary(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"Lightweight numeric summary for a set of columns.\"\"\"\n",
    "    rows = []\n",
    "    for c in cols:\n",
    "        s = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "        rows.append({\n",
    "            \"column\": c,\n",
    "            \"n\": len(s),\n",
    "            \"na_rate\": float(s.isna().mean()),\n",
    "            \"min\": np.nanmin(s.values),\n",
    "            \"p25\": np.nanpercentile(s.values, 25),\n",
    "            \"median\": np.nanmedian(s.values),\n",
    "            \"p75\": np.nanpercentile(s.values, 75),\n",
    "            \"max\": np.nanmax(s.values),\n",
    "            \"mean\": np.nanmean(s.values),\n",
    "            \"std\": np.nanstd(s.values),\n",
    "            \"unique_non_na\": int(s.nunique(dropna=True)),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def _binary_sig(series: pd.Series) -> str | None:\n",
    "    \"\"\"Detect common binary encodings.\"\"\"\n",
    "    vals = set(_norm_str_col(series).dropna().unique())\n",
    "    if vals <= {\"0\",\"1\"}: return \"0/1\"\n",
    "    if vals <= {\"yes\",\"no\"}: return \"yes/no\"\n",
    "    if vals <= {\"true\",\"false\"}: return \"true/false\"\n",
    "    if vals <= {\"male\",\"female\"}: return \"male/female\"\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c72ac48-4459-436b-8b33-47a79e540bdb",
   "metadata": {},
   "source": [
    "#### 2) Column set differences (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "bbaacf23-26c4-4d58-85ee-ecc295b2bd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Columns] only_in_lu: 69 | only_in_my: 76 | in_both: 6\n",
      "• only_in_lu (first 20): ['MetS', 'MetS_bp', 'MetS_count', 'MetS_fpg', 'MetS_hdl', 'MetS_triglycerides', 'MetS_wc', 'WTINT2YR', 'WTSAF2YR', 'X', 'adiposity_pri', 'adiposity_sec', 'age', 'age_cat', 'angina', 'angina_rx', 'asthma', 'bmi', 'bp_pri', 'bp_sec']\n",
      "• only_in_my (first 20): ['ADFDSEC', 'AGE_YR', 'ALCOHOL_CAT', 'BMI', 'BMI_CLAS', 'BMXHT', 'BMXWT', 'CANCER', 'CENSORED', 'CIDI_12M_MDE', 'CIDI_SCORE_RAW', 'CIGS_PER_DAY', 'DBP', 'DEP_HARMONIZED', 'DEP_IMP', 'DEP_SOURCE', 'DIABETES', 'DMDHHSIZ', 'DPQ_CAT', 'DRINKS_PER_DAY']\n"
     ]
    }
   ],
   "source": [
    "# 2) COLUMN SET DIFFERENCES (a)\n",
    "\n",
    "cols_my = set(df_my_cov_1999_2023.columns)\n",
    "cols_lu = set(df_lu_cov_1999_2018.columns)\n",
    "\n",
    "audit_only_in_lu = sorted(cols_lu - cols_my)\n",
    "audit_only_in_my = sorted(cols_my - cols_lu)\n",
    "audit_in_both    = sorted(cols_my & cols_lu)\n",
    "\n",
    "print(f\"[Columns] only_in_lu: {len(audit_only_in_lu)} | only_in_my: {len(audit_only_in_my)} | in_both: {len(audit_in_both)}\")\n",
    "print(\"• only_in_lu (first 20):\", audit_only_in_lu[:20])\n",
    "print(\"• only_in_my (first 20):\", audit_only_in_my[:20])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "67beccc1-932f-43f6-a166-1ed8867afbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 columns\n",
      "['SEQN', 'SDDSRVYR', 'SDMVPSU', 'SDMVSTRA', 'WTMEC2YR', 'AGE_YR', 'RIAGENDR', 'SEX', 'FEMALE', 'SMK_STATUS', 'CIGS_PER_DAY', 'PACK_YEARS', 'FORMER_SMOKER', 'DRINKS_PER_DAY', 'ALCOHOL_CAT', 'LTPA', 'METSCORE', 'IMP', 'BMXWT', 'BMXHT', 'BMI', 'BMI_CLAS', 'DIABETES', 'HTN', 'HIGH_CHOL', 'CVD', 'CANCER', 'SBP', 'DBP', 'TCHOL', 'HDL', 'LDL', 'TG', 'DMDHHSIZ', 'ELIGSTAT', 'MORTSTAT', 'PERMTH_EXM', 'PERMTH_INT', 'UCOD_LEADING', 'IS_POST2018', 'IS_ADULT', 'MORTALITY_COVERED', 'EVENT', 'CENSORED', 'FU_YRS_EXM', 'FU_YRS_INT', 'UCOD_LABEL', 'PHQ9', 'PHQ9_GE10', 'DPQ_CAT', 'DEP_IMP', 'CIDI_SCORE_RAW', 'CIDI_12M_MDE', 'WTSCI2YR', 'DEP_HARMONIZED', 'DEP_SOURCE', 'PIR', 'PIR_CAT', 'INDFMINC', 'EDU', 'EDU_CAT', 'RACE_ETH', 'MARITAL', 'MARITAL_CAT', 'EMPLOY', 'UNEMPLOYMENT', 'HOD050', 'HOQ065', 'INS', 'SNAP', 'FSDHH', 'FS', 'FS_HH', 'FS_ADULT', 'FS_FINAL', 'HHFDSEC', 'ADFDSEC', 'FS_HH4', 'FS_ADULT4', 'FS_SOURCE_HH', 'FS_SOURCE_FINAL', 'SNAP_SOURCE']\n",
      "75 columns\n",
      "['X', 'SEQN', 'SDDSRVYR', 'WTINT2YR', 'WTMEC2YR', 'WTSAF2YR', 'SDMVPSU', 'SDMVSTRA', 'age', 'sex', 're', 'edu', 'pir', 'tchol', 'hdl', 'ldl', 'tg', 'wc', 'bmi', 'dm_self', 'hba1c', 'fpg', 'chf', 'chd', 'mi', 'stroke', 'cancer', 'emphysema', 'bronchitis', 'asthma', 're2', 'copd', 'sbp', 'dbp', 'dm_rx', 'chol_rx', 'angina_rx', 'htn_rx', 'roseQ', 'no_na', 'age_cat', 'pir_cat', 'edu2', 'CVD', 'lung_disease', 'diabetes', 'tchol_hdl', 'angina', 'lipid_pri', 'adiposity_pri', 'bp_pri', 'glucose_pri', 'cvd_pri', 'lipid_sec', 'adiposity_sec', 'bp_sec', 'glucose_sec', 'cvd_sec', 'optimal_pri_count', 'intermediate_pri_count', 'poor_pri_count', 'optimal_sec_count', 'intermediate_sec_count', 'poor_sec_count', 'optimal_all', 'poor_all', 'optimal_all_sec', 'poor_all_sec', 'MetS_hdl', 'MetS_triglycerides', 'MetS_bp', 'MetS_wc', 'MetS_fpg', 'MetS_count', 'MetS']\n"
     ]
    }
   ],
   "source": [
    "# mine\n",
    "print(len(df_my_cov_1999_2023.columns), \"columns\")\n",
    "print(df_my_cov_1999_2023.columns.tolist())\n",
    "\n",
    "# lu\n",
    "print(len(df_lu_cov_1999_2018.columns), \"columns\")\n",
    "print(df_lu_cov_1999_2018.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34575e49-2360-4d48-912e-0fea2df49d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "7bfad80d-91ca-4d43-9bf0-5bc1efc110d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %whos DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "678b5491-1541-4e55-a8c0-7f25b7788af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_my_cov_1999_2023[['MORTALITY_COVERED', 'EVENT', \"UCOD_LABEL\", \"CANCER\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe75417-424d-40b0-843a-61fdb05e689b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e31c2cc-a3de-4aa4-b520-32a3ef182a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a4a1f-76d6-46fc-b9af-ab27acadd403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b9d2ee-8cb1-4bca-8041-28b411616d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dbeec05-2a00-401b-bf34-a9962ef84005",
   "metadata": {},
   "source": [
    "## Align column same as lu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8363147b-a244-46dc-ae0d-74f24846e2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed 15 columns automatically.\n",
      "Examples: [('AGE_YR', 'age'), ('BMI', 'bmi'), ('CANCER', 'cancer'), ('DBP', 'dbp'), ('DIABETES', 'diabetes'), ('EDU', 'edu'), ('HDL', 'hdl'), ('LDL', 'ldl'), ('PIR', 'pir'), ('PIR_CAT', 'pir_cat')]\n",
      "Still missing from your data (present in Lu): ['X', 'WTINT2YR', 'WTSAF2YR', 'wc', 'dm_self', 'hba1c', 'fpg', 'chf', 'chd', 'mi', 'stroke', 'emphysema', 'bronchitis', 'asthma', 're2', 'copd', 'dm_rx', 'chol_rx', 'angina_rx', 'htn_rx', 'roseQ', 'no_na', 'age_cat', 'edu2', 'lung_disease', 'tchol_hdl', 'angina', 'lipid_pri', 'adiposity_pri', 'bp_pri', 'glucose_pri', 'cvd_pri', 'lipid_sec', 'adiposity_sec', 'bp_sec', 'glucose_sec', 'cvd_sec', 'optimal_pri_count', 'intermediate_pri_count', 'poor_pri_count', 'optimal_sec_count', 'intermediate_sec_count', 'poor_sec_count', 'optimal_all', 'poor_all', 'optimal_all_sec', 'poor_all_sec', 'MetS_hdl', 'MetS_triglycerides', 'MetS_bp', 'MetS_wc', 'MetS_fpg', 'MetS_count', 'MetS']\n",
      "Final order starts with: ['SEQN', 'SDDSRVYR', 'WTMEC2YR', 'SDMVPSU', 'SDMVSTRA', 'age', 'sex', 're', 'edu', 'pir', 'tchol', 'hdl', 'ldl', 'tg', 'bmi']\n"
     ]
    }
   ],
   "source": [
    "import re, difflib\n",
    "import pandas as pd\n",
    "\n",
    "# === Inputs (your two originals) ===\n",
    "mine = df_my_cov_1999_2023.copy()\n",
    "lu   = df_lu_cov_1999_2018.copy()\n",
    "\n",
    "lu_cols = list(lu.columns)\n",
    "mine_cols = list(mine.columns)\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def norm(s: str) -> str:\n",
    "    # Lower, drop non-alnum (so AGE_YR -> ageyr; RACE_ETH -> raceeth)\n",
    "    return re.sub(r'[^0-9a-z]+', '', s.lower()) if isinstance(s, str) else s\n",
    "\n",
    "lu_norm_to_name = {}\n",
    "for c in lu_cols:\n",
    "    lu_norm_to_name.setdefault(norm(c), c)  # keep first occurrence\n",
    "\n",
    "# Minimal synonyms (expand as needed if you see mismatches)\n",
    "# YOUR column name -> Lu column name\n",
    "synonyms = {\n",
    "    'AGE_YR':'age',\n",
    "    'SEX':'sex',\n",
    "    'RACE_ETH':'re',\n",
    "    'EDU':'edu',\n",
    "    'PIR':'pir',\n",
    "    'TCHOL':'tchol',\n",
    "    'HDL':'hdl',\n",
    "    'LDL':'ldl',\n",
    "    'TG':'tg',\n",
    "    'WC':'wc',\n",
    "    'BMI':'bmi',\n",
    "    'SBP':'sbp',\n",
    "    'DBP':'dbp',\n",
    "    'DIABETES':'diabetes',\n",
    "    'CVD':'CVD',          # Lu uses uppercase \"CVD\" in your list\n",
    "    'CANCER':'cancer',\n",
    "    'DM_RX':'dm_rx',\n",
    "    'CHOL_RX':'chol_rx',\n",
    "    'HTN_RX':'htn_rx',\n",
    "    'ANGINA_RX':'angina_rx',\n",
    "    'ANGINA':'angina',\n",
    "    'AGE_CAT':'age_cat',\n",
    "    'PIR_CAT':'pir_cat',\n",
    "    'EDU2':'edu2',\n",
    "    'METS_HDL':'MetS_hdl',\n",
    "    'METS_TRIGLYCERIDES':'MetS_triglycerides',\n",
    "    'METS_BP':'MetS_bp',\n",
    "    'METS_WC':'MetS_wc',\n",
    "    'METS_FPG':'MetS_fpg',\n",
    "    'METS_COUNT':'MetS_count',\n",
    "    'ROSEQ':'roseQ',\n",
    "    'NO_NA':'no_na',\n",
    "    'LUNG_DISEASE':'lung_disease',\n",
    "    'BP_PRI':'bp_pri',\n",
    "    'GLUCOSE_PRI':'glucose_pri',\n",
    "    'LIPID_PRI':'lipid_pri',\n",
    "    'ADIPOSITY_PRI':'adiposity_pri',\n",
    "    'CVD_PRI':'cvd_pri',\n",
    "    'BP_SEC':'bp_sec',\n",
    "    'GLUCOSE_SEC':'glucose_sec',\n",
    "    'LIPID_SEC':'lipid_sec',\n",
    "    'ADIPOSITY_SEC':'adiposity_sec',\n",
    "    'CVD_SEC':'cvd_sec',\n",
    "    # Common admin/weight vars:\n",
    "    'WTMEC2YR':'WTMEC2YR',\n",
    "    'SDDSRVYR':'SDDSRVYR',\n",
    "    'SDMVPSU':'SDMVPSU',\n",
    "    'SDMVSTRA':'SDMVSTRA',\n",
    "}\n",
    "\n",
    "# Columns we should **never** rename (IDs/keys that already match)\n",
    "protect_exact = set(['SEQN','SDDSRVYR','SDMVPSU','SDMVSTRA','WTMEC2YR'])\n",
    "\n",
    "# ---------- Build mapping (your -> lu) ----------\n",
    "mapping = {}          # final mapping to apply\n",
    "used_targets = set()  # to avoid collisions (two src -> one dst)\n",
    "\n",
    "for src in mine_cols:\n",
    "    if src in protect_exact or src.endswith('_lu'):\n",
    "        continue\n",
    "\n",
    "    # 1) If exact Lu name already, keep as-is\n",
    "    if src in lu_cols:\n",
    "        continue\n",
    "\n",
    "    # 2) Synonym override\n",
    "    if src in synonyms and synonyms[src] in lu_cols and synonyms[src] not in used_targets and synonyms[src] not in mine_cols:\n",
    "        mapping[src] = synonyms[src]\n",
    "        used_targets.add(synonyms[src])\n",
    "        continue\n",
    "\n",
    "    # 3) Case-insensitive exact\n",
    "    ci = next((dst for dst in lu_cols if isinstance(dst, str) and dst.lower() == src.lower()), None)\n",
    "    if ci and ci not in used_targets and ci not in mine_cols:\n",
    "        mapping[src] = ci\n",
    "        used_targets.add(ci)\n",
    "        continue\n",
    "\n",
    "    # 4) Normalized name match\n",
    "    nsrc = norm(src)\n",
    "    if nsrc in lu_norm_to_name:\n",
    "        dst = lu_norm_to_name[nsrc]\n",
    "        if dst not in used_targets and dst not in mine_cols:\n",
    "            mapping[src] = dst\n",
    "            used_targets.add(dst)\n",
    "            continue\n",
    "\n",
    "    # 5) Fuzzy match for stragglers (safe threshold)\n",
    "    # Only attempt for alphas; ignore obviously different admin columns you don't want changed\n",
    "    candidates = difflib.get_close_matches(src, lu_cols, n=1, cutoff=0.92)\n",
    "    if candidates:\n",
    "        dst = candidates[0]\n",
    "        if dst not in used_targets and dst not in mine_cols:\n",
    "            mapping[src] = dst\n",
    "            used_targets.add(dst)\n",
    "            continue\n",
    "\n",
    "# ---------- Apply rename ----------\n",
    "mine_renamed = mine.rename(columns=mapping).copy()\n",
    "\n",
    "# ---------- Reorder to Lu’s order (extras at end; keep *_lu at very end) ----------\n",
    "ordered = [c for c in lu_cols if c in mine_renamed.columns]\n",
    "extras  = [c for c in mine_renamed.columns if c not in ordered and not c.endswith('_lu')]\n",
    "audit   = [c for c in mine_renamed.columns if c.endswith('_lu')]\n",
    "\n",
    "df_my_cov_aligned = mine_renamed[ordered + extras + audit].copy()\n",
    "\n",
    "# ---------- Report ----------\n",
    "renamed_pairs = sorted(mapping.items(), key=lambda x: x[0].lower())\n",
    "missing_in_mine = [c for c in lu_cols if c not in df_my_cov_aligned.columns]\n",
    "\n",
    "print(f\"Renamed {len(renamed_pairs)} columns automatically.\")\n",
    "print(\"Examples:\", renamed_pairs[:10])\n",
    "print(\"Still missing from your data (present in Lu):\", missing_in_mine)\n",
    "print(\"Final order starts with:\", df_my_cov_aligned.columns[:15].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e97df4b-008b-4040-bd01-36bde77cd0a9",
   "metadata": {},
   "source": [
    "#### Adding missing column merge from lu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a1a71025-28dc-4f8d-a728-5d304affe7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-renamed 15 columns to Lu names.\n",
      "Filled from Lu (newly added): ['X', 'WTINT2YR', 'WTSAF2YR', 'wc', 'dm_self', 'hba1c', 'fpg', 'chf', 'chd', 'mi', 'stroke', 'emphysema', 'bronchitis', 'asthma', 're2', 'copd', 'dm_rx', 'chol_rx', 'angina_rx', 'htn_rx'] ...\n",
      "Still missing Lu cols: []\n",
      "Final starts with: ['X', 'SEQN', 'SDDSRVYR', 'WTINT2YR', 'WTMEC2YR', 'WTSAF2YR', 'SDMVPSU', 'SDMVSTRA', 'age', 'sex', 're', 'edu', 'pir', 'tchol', 'hdl']\n"
     ]
    }
   ],
   "source": [
    "import re, pandas as pd\n",
    "\n",
    "# === 0) Start from the two originals ===\n",
    "mine = df_my_cov_1999_2023.copy()\n",
    "lu   = df_lu_cov_1999_2018.copy()\n",
    "\n",
    "# === 1) Auto-rename YOUR columns to Lu's names (case/underscore-insensitive + synonyms) ===\n",
    "def norm(s: str) -> str:\n",
    "    return re.sub(r'[^0-9a-z]+', '', s.lower()) if isinstance(s, str) else s\n",
    "\n",
    "lu_cols = list(lu.columns)\n",
    "mine_cols = list(mine.columns)\n",
    "\n",
    "# First pass: normalized name index for Lu\n",
    "lu_norm_to_name = {}\n",
    "for c in lu_cols:\n",
    "    lu_norm_to_name.setdefault(norm(c), c)\n",
    "\n",
    "# Synonyms (YOUR -> Lu)\n",
    "synonyms = {\n",
    "    'AGE_YR':'age','SEX':'sex','RACE_ETH':'re','EDU':'edu','PIR':'pir',\n",
    "    'TCHOL':'tchol','HDL':'hdl','LDL':'ldl','TG':'tg',\n",
    "    'WC':'wc','BMI':'bmi','SBP':'sbp','DBP':'dbp',\n",
    "    'DIABETES':'diabetes','CVD':'CVD','CANCER':'cancer',\n",
    "    'DM_RX':'dm_rx','CHOL_RX':'chol_rx','HTN_RX':'htn_rx','ANGINA_RX':'angina_rx','ANGINA':'angina',\n",
    "    'AGE_CAT':'age_cat','PIR_CAT':'pir_cat','EDU2':'edu2',\n",
    "    'METS_HDL':'MetS_hdl','METS_TRIGLYCERIDES':'MetS_triglycerides','METS_BP':'MetS_bp',\n",
    "    'METS_WC':'MetS_wc','METS_FPG':'MetS_fpg','METS_COUNT':'MetS_count',\n",
    "    'ROSEQ':'roseQ','NO_NA':'no_na','LUNG_DISEASE':'lung_disease',\n",
    "    'BP_PRI':'bp_pri','GLUCOSE_PRI':'glucose_pri','LIPID_PRI':'lipid_pri','ADIPOSITY_PRI':'adiposity_pri',\n",
    "    'CVD_PRI':'cvd_pri','BP_SEC':'bp_sec','GLUCOSE_SEC':'glucose_sec','LIPID_SEC':'lipid_sec',\n",
    "    'ADIPOSITY_SEC':'adiposity_sec','CVD_SEC':'cvd_sec',\n",
    "    # admin/weights that already match:\n",
    "    'WTMEC2YR':'WTMEC2YR','SDDSRVYR':'SDDSRVYR','SDMVPSU':'SDMVPSU','SDMVSTRA':'SDMVSTRA'\n",
    "}\n",
    "\n",
    "protect_exact = {'SEQN','SDDSRVYR','SDMVPSU','SDMVSTRA','WTMEC2YR'}\n",
    "\n",
    "mapping = {}\n",
    "used_targets = set()\n",
    "for src in mine_cols:\n",
    "    if src in protect_exact or src.endswith('_lu'):\n",
    "        continue\n",
    "    if src in lu_cols:\n",
    "        continue\n",
    "    # synonyms first\n",
    "    if src in synonyms and synonyms[src] in lu_cols and synonyms[src] not in used_targets and synonyms[src] not in mine.columns:\n",
    "        mapping[src] = synonyms[src]; used_targets.add(synonyms[src]); continue\n",
    "    # case-insensitive exact\n",
    "    ci = next((dst for dst in lu_cols if isinstance(dst, str) and dst.lower()==src.lower()), None)\n",
    "    if ci and ci not in used_targets and ci not in mine.columns:\n",
    "        mapping[src] = ci; used_targets.add(ci); continue\n",
    "    # normalized match\n",
    "    nc = norm(src)\n",
    "    if nc in lu_norm_to_name:\n",
    "        dst = lu_norm_to_name[nc]\n",
    "        if dst not in used_targets and dst not in mine.columns:\n",
    "            mapping[src] = dst; used_targets.add(dst); continue\n",
    "\n",
    "mine = mine.rename(columns=mapping)\n",
    "\n",
    "# === 2) Identify Lu columns you still lack, and merge ONLY those in ===\n",
    "missing = [c for c in lu_cols if c not in mine.columns]\n",
    "# keys must exist in both:\n",
    "for k in ['SEQN','SDDSRVYR']:\n",
    "    if k not in mine.columns or k not in lu.columns:\n",
    "        raise KeyError(f\"Key {k} missing in one of the frames\")\n",
    "\n",
    "# subset Lu to keys + missing, drop dup keys, then merge\n",
    "lu_sub = lu[['SEQN','SDDSRVYR'] + missing].copy()\n",
    "dup_ct = lu_sub.duplicated(['SEQN','SDDSRVYR']).sum()\n",
    "if dup_ct:\n",
    "    print(f\"[warn] Dropping {dup_ct} duplicate rows on keys in Lu subset\")\n",
    "    lu_sub = lu_sub.drop_duplicates(['SEQN','SDDSRVYR'], keep='first')\n",
    "\n",
    "# Merge (no suffix needed—these cols are missing in 'mine')\n",
    "aligned = mine.merge(lu_sub, on=['SEQN','SDDSRVYR'], how='left')\n",
    "\n",
    "# === 3) Reorder to Lu order first, then any extras ===\n",
    "order = [c for c in lu_cols if c in aligned.columns]\n",
    "extras = [c for c in aligned.columns if c not in order]\n",
    "df_my_cov_aligned = aligned[order + extras].copy()\n",
    "\n",
    "# === 4) Quick report\n",
    "print(f\"Auto-renamed {len(mapping)} columns to Lu names.\")\n",
    "print(\"Filled from Lu (newly added):\", missing[:20], \"...\" if len(missing)>20 else \"\")\n",
    "still_missing = [c for c in lu_cols if c not in df_my_cov_aligned.columns]  # should be empty\n",
    "print(\"Still missing Lu cols:\", still_missing)\n",
    "print(\"Final starts with:\", df_my_cov_aligned.columns[:15].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a387281-7882-4c51-ba81-c3900f687368",
   "metadata": {},
   "source": [
    "#### clean and check merged file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "08296f13-4ec7-45fd-b717-6b71de8c01f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X' in df_my_cov_aligned.columns:\n",
    "    df_my_cov_aligned = df_my_cov_aligned.drop(columns=['X'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "d3eef66a-68ac-49ee-9d7e-a540b2df4565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# binary flags\n",
    "bin_cols = ['dm_self','chf','chd','mi','stroke','emphysema','bronchitis','asthma',\n",
    "            'copd','dm_rx','chol_rx','angina_rx','htn_rx','angina']\n",
    "for c in df_my_cov_aligned.columns.intersection(bin_cols):\n",
    "    df_my_cov_aligned[c] = pd.to_numeric(df_my_cov_aligned[c], errors='coerce').astype('Int8')\n",
    "\n",
    "# labs/metrics\n",
    "num_cols = ['wc','hba1c','fpg','tchol_hdl','MetS_hdl','MetS_triglycerides',\n",
    "            'MetS_bp','MetS_wc','MetS_fpg','MetS_count']\n",
    "for c in df_my_cov_aligned.columns.intersection(num_cols):\n",
    "    df_my_cov_aligned[c] = pd.to_numeric(df_my_cov_aligned[c], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "7dd60df9-88e2-4fc9-850d-e2123eb130db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>WTINT2YR</th>\n",
       "      <th>WTMEC2YR</th>\n",
       "      <th>WTSAF2YR</th>\n",
       "      <th>SDMVPSU</th>\n",
       "      <th>SDMVSTRA</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>re</th>\n",
       "      <th>...</th>\n",
       "      <th>FS_HH</th>\n",
       "      <th>FS_ADULT</th>\n",
       "      <th>FS_FINAL</th>\n",
       "      <th>HHFDSEC</th>\n",
       "      <th>ADFDSEC</th>\n",
       "      <th>FS_HH4</th>\n",
       "      <th>FS_ADULT4</th>\n",
       "      <th>FS_SOURCE_HH</th>\n",
       "      <th>FS_SOURCE_FINAL</th>\n",
       "      <th>SNAP_SOURCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9727.078709</td>\n",
       "      <td>10982.898896</td>\n",
       "      <td>75131.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26678.636376</td>\n",
       "      <td>28325.384898</td>\n",
       "      <td>60586.147294</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>HHFDSEC</td>\n",
       "      <td>household</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43621.680548</td>\n",
       "      <td>46192.256945</td>\n",
       "      <td>121969.841152</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10346.119327</td>\n",
       "      <td>10251.260020</td>\n",
       "      <td>4624.687273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91050.846620</td>\n",
       "      <td>99445.065735</td>\n",
       "      <td>234895.205650</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>HHFDSEC</td>\n",
       "      <td>household</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36508.250375</td>\n",
       "      <td>39656.600444</td>\n",
       "      <td>13379.800000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>F</td>\n",
       "      <td>NH Black</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22352.088620</td>\n",
       "      <td>25525.423409</td>\n",
       "      <td>57661.621988</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31600.089655</td>\n",
       "      <td>31510.587866</td>\n",
       "      <td>76026.438279</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7529.435502</td>\n",
       "      <td>7575.870247</td>\n",
       "      <td>14694.924957</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21071.164059</td>\n",
       "      <td>22445.808572</td>\n",
       "      <td>60202.416895</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEQN  SDDSRVYR      WTINT2YR      WTMEC2YR       WTSAF2YR  SDMVPSU  \\\n",
       "0     1       1.0   9727.078709  10982.898896   75131.200000      1.0   \n",
       "1     2       1.0  26678.636376  28325.384898   60586.147294      3.0   \n",
       "2     3       1.0  43621.680548  46192.256945  121969.841152      2.0   \n",
       "3     4       1.0  10346.119327  10251.260020    4624.687273      1.0   \n",
       "4     5       1.0  91050.846620  99445.065735  234895.205650      2.0   \n",
       "5     6       1.0  36508.250375  39656.600444   13379.800000      2.0   \n",
       "6     7       1.0  22352.088620  25525.423409   57661.621988      2.0   \n",
       "7     8       1.0  31600.089655  31510.587866   76026.438279      1.0   \n",
       "8     9       1.0   7529.435502   7575.870247   14694.924957      2.0   \n",
       "9    10       1.0  21071.164059  22445.808572   60202.416895      1.0   \n",
       "\n",
       "   SDMVSTRA   age sex                re  ...  FS_HH  FS_ADULT  FS_FINAL  \\\n",
       "0       5.0   2.0   F    Other Hispanic  ...   <NA>      <NA>      <NA>   \n",
       "1       1.0  77.0   M  Mexican American  ...      0         0         0   \n",
       "2       7.0  10.0   F  Mexican American  ...   <NA>      <NA>      <NA>   \n",
       "3       2.0   1.0   M    Other Hispanic  ...   <NA>      <NA>      <NA>   \n",
       "4       8.0  49.0   M  Mexican American  ...      0         0         0   \n",
       "5       2.0  19.0   F          NH Black  ...   <NA>      <NA>      <NA>   \n",
       "6       4.0  59.0   F    Other Hispanic  ...   <NA>      <NA>      <NA>   \n",
       "7       6.0  13.0   M  Mexican American  ...   <NA>      <NA>      <NA>   \n",
       "8       9.0  11.0   F    Other Hispanic  ...   <NA>      <NA>      <NA>   \n",
       "9       7.0  43.0   M    Other Hispanic  ...   <NA>      <NA>      <NA>   \n",
       "\n",
       "   HHFDSEC  ADFDSEC  FS_HH4  FS_ADULT4  FS_SOURCE_HH  FS_SOURCE_FINAL  \\\n",
       "0     <NA>     <NA>    <NA>       <NA>          <NA>             <NA>   \n",
       "1        1        1       1          1       HHFDSEC        household   \n",
       "2     <NA>     <NA>    <NA>       <NA>          <NA>             <NA>   \n",
       "3     <NA>     <NA>    <NA>       <NA>          <NA>             <NA>   \n",
       "4        1        1       1          1       HHFDSEC        household   \n",
       "5     <NA>     <NA>    <NA>       <NA>          <NA>             <NA>   \n",
       "6     <NA>     <NA>    <NA>       <NA>          <NA>             <NA>   \n",
       "7     <NA>     <NA>    <NA>       <NA>          <NA>             <NA>   \n",
       "8     <NA>     <NA>    <NA>       <NA>          <NA>             <NA>   \n",
       "9     <NA>     <NA>    <NA>       <NA>          <NA>             <NA>   \n",
       "\n",
       "   SNAP_SOURCE  \n",
       "0         <NA>  \n",
       "1         <NA>  \n",
       "2         <NA>  \n",
       "3         <NA>  \n",
       "4         <NA>  \n",
       "5         <NA>  \n",
       "6         <NA>  \n",
       "7         <NA>  \n",
       "8         <NA>  \n",
       "9         <NA>  \n",
       "\n",
       "[10 rows x 135 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check \n",
    "df_my_cov_aligned.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b3ff89-2d9c-473f-8b17-b938772b085a",
   "metadata": {},
   "source": [
    "## Keep important column for this analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "38f8d560-375d-4307-978e-027714e5e36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping 19 columns; missing 26:\n",
      "Missing: ['RIDAGEYR', 'SEX', 'RACE', 'household_size', 'SMK_AVG', 'SMK', 'ALCG2', 'met_hr', 'bmic', 'DIABE', 'HYPERTEN', 'probable_depression', 'sdoh_score', 'ahei_total', 'unemployment2', 'EDU', 'sdoh_access', 'ins', 'marriage', 'BPQ020', 'BPQ050A', 'sdmvpsu', 'sdmvstra', 'wt', 'wt10', 'SNAP3']\n",
      "df_desc shape: (128809, 19)\n",
      "NA rates (top 10):\n",
      "SNAP            0.587\n",
      "HOQ065          0.581\n",
      "MORTSTAT        0.541\n",
      "FS              0.518\n",
      "chol_rx         0.213\n",
      "dm_rx           0.213\n",
      "ldl             0.213\n",
      "hdl             0.213\n",
      "hba1c           0.213\n",
      "lung_disease    0.213\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = df_my_cov_aligned.copy()\n",
    "\n",
    "needed_core = [\n",
    "    # final table / missing checks\n",
    "    \"RIDAGEYR\",\"SEX\",\"RACE\",\"household_size\",\n",
    "    \"SMK_AVG\",\"SMK\",\"ALCG2\",\"met_hr\",\n",
    "    \"bmic\",\"DIABE\",\"HYPERTEN\",\"chol_rx\",\"CVD\",\"cancer\",\n",
    "    \"probable_depression\",\"sdoh_score\",\"ahei_total\",\n",
    "]\n",
    "\n",
    "needed_build = [\n",
    "    # for sdoh_score\n",
    "    \"unemployment2\",\"pir\",\"SNAP\",\"EDU\",\"sdoh_access\",\"ins\",\"HOQ065\",\"marriage\",\n",
    "    # for HYPERTEN\n",
    "    \"BPQ020\",\"BPQ050A\",\"sbp\",\"dbp\",\n",
    "]\n",
    "\n",
    "needed_survey = [\"sdmvpsu\",\"sdmvstra\",\"wt\", \"wt10\"]  # keep wt10 if you still reference it\n",
    "needed_keys   = [\"SEQN\",\"SDDSRVYR\"]\n",
    "\n",
    "needed_optional = [\n",
    "    \"FS\",\"SNAP3\",\"dm_rx\",\"angina\",\"lung_disease\",\"MORTSTAT\",\n",
    "    \"hba1c\",\"hdl\",\"ldl\",\"tg\"\n",
    "]\n",
    "\n",
    "NEEDED = needed_core + needed_build + needed_survey + needed_keys + needed_optional\n",
    "\n",
    "# Only keep those present; report what's missing\n",
    "present = [c for c in NEEDED if c in df.columns]\n",
    "missing = [c for c in NEEDED if c not in df.columns]\n",
    "\n",
    "print(f\"Keeping {len(present)} columns; missing {len(missing)}:\")\n",
    "print(\"Missing:\", missing)\n",
    "\n",
    "df_desc = df[present].copy()\n",
    "\n",
    "# (Optional) sanity peek\n",
    "print(\"df_desc shape:\", df_desc.shape)\n",
    "print(\"NA rates (top 10):\")\n",
    "print(df_desc.isna().mean().sort_values(ascending=False).head(10).round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a93ca235-ba14-472e-bcdc-76446f8ceee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 columns:\n",
      " ['SEQN', 'SDDSRVYR', 'WTINT2YR', 'WTMEC2YR', 'WTSAF2YR', 'SDMVPSU', 'SDMVSTRA', 'age', 'sex', 're', 'edu', 'pir', 'tchol', 'hdl', 'ldl', 'tg', 'wc', 'bmi', 'dm_self', 'hba1c', 'fpg', 'chf', 'chd', 'mi', 'stroke', 'cancer', 'emphysema', 'bronchitis', 'asthma', 're2', 'copd', 'sbp', 'dbp', 'dm_rx', 'chol_rx', 'angina_rx', 'htn_rx', 'roseQ', 'no_na', 'age_cat', 'pir_cat', 'edu2', 'CVD', 'lung_disease', 'diabetes', 'tchol_hdl', 'angina', 'lipid_pri', 'adiposity_pri', 'bp_pri', 'glucose_pri', 'cvd_pri', 'lipid_sec', 'adiposity_sec', 'bp_sec', 'glucose_sec', 'cvd_sec', 'optimal_pri_count', 'intermediate_pri_count', 'poor_pri_count', 'optimal_sec_count', 'intermediate_sec_count', 'poor_sec_count', 'optimal_all', 'poor_all', 'optimal_all_sec', 'poor_all_sec', 'MetS_hdl', 'MetS_triglycerides', 'MetS_bp', 'MetS_wc', 'MetS_fpg', 'MetS_count', 'MetS', 'RIAGENDR', 'FEMALE', 'SMK_STATUS', 'CIGS_PER_DAY', 'PACK_YEARS', 'FORMER_SMOKER', 'DRINKS_PER_DAY', 'ALCOHOL_CAT', 'LTPA', 'METSCORE', 'IMP', 'BMXWT', 'BMXHT', 'BMI_CLAS', 'HTN', 'HIGH_CHOL', 'DMDHHSIZ', 'ELIGSTAT', 'MORTSTAT', 'PERMTH_EXM', 'PERMTH_INT', 'UCOD_LEADING', 'IS_POST2018', 'IS_ADULT', 'MORTALITY_COVERED', 'EVENT', 'CENSORED', 'FU_YRS_EXM', 'FU_YRS_INT', 'UCOD_LABEL', 'PHQ9', 'PHQ9_GE10', 'DPQ_CAT', 'DEP_IMP', 'CIDI_SCORE_RAW', 'CIDI_12M_MDE', 'WTSCI2YR', 'DEP_HARMONIZED', 'DEP_SOURCE', 'INDFMINC', 'EDU_CAT', 'MARITAL', 'MARITAL_CAT', 'EMPLOY', 'UNEMPLOYMENT', 'HOD050', 'HOQ065', 'INS', 'SNAP', 'FSDHH', 'FS', 'FS_HH', 'FS_ADULT', 'FS_FINAL', 'HHFDSEC', 'ADFDSEC', 'FS_HH4', 'FS_ADULT4', 'FS_SOURCE_HH', 'FS_SOURCE_FINAL', 'SNAP_SOURCE']\n"
     ]
    }
   ],
   "source": [
    "# 1) Plain list (sorted)\n",
    "cols = (df_my_cov_aligned.columns.tolist())\n",
    "print(f\"{len(cols)} columns:\\n\", cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe24ac2b-d69d-4fac-9911-5dc438a04ab5",
   "metadata": {},
   "source": [
    "#### adjust column name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "e46cfaa5-9eae-4a09-ad4b-ef15dac83fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aliases/derivations created: {'RIDAGEYR': 'age', 'SEX': 'sex', 'RACE': 're', 'household_size': 'DMDHHSIZ', 'sdmvpsu': 'SDMVPSU', 'sdmvstra': 'SDMVSTRA', 'wt': 'WTMEC2YR', 'wt10': 'WTMEC2YR', 'SMK_AVG': 'CIGS_PER_DAY', 'SMK': 'FORMER_SMOKER', 'ALCG2': 'ALCOHOL_CAT', 'met_hr': 'METSCORE', 'bmic': 'BMI_CLAS', 'DIABE': 'diabetes', 'probable_depression': 'DEP_HARMONIZED', 'unemployment2': 'UNEMPLOYMENT', 'EDU': 'edu', 'ins': 'INS', 'marriage': 'MARITAL', 'SNAP3': 'SNAP'}\n",
      "df_desc columns kept: 40\n",
      "Still missing (not found in df): ['sdoh_score', 'ahei_total', 'sdoh_access', 'BPQ020', 'BPQ050A']\n",
      "Smoking-related kept: ['SMK_STATUS', 'SMK', 'SMK_AVG', 'FORMER_SMOKER', 'CIGS_PER_DAY']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = df_my_cov_aligned.copy()\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def ci_pick(*names):\n",
    "    \"\"\"case-insensitive column pick: returns first match or None\"\"\"\n",
    "    lowmap = {c.lower(): c for c in df.columns}\n",
    "    for n in names:\n",
    "        if n in df.columns: return n\n",
    "        if n.lower() in lowmap: return lowmap[n.lower()]\n",
    "    return None\n",
    "\n",
    "def pick_best(cands):\n",
    "    cols = []\n",
    "    for c in cands:\n",
    "        col = ci_pick(c)\n",
    "        if col: cols.append(col)\n",
    "    if not cols: return None\n",
    "    cov = {c: df[c].notna().mean() for c in cols}\n",
    "    return max(cov, key=cov.get)  # highest coverage\n",
    "\n",
    "created = {}\n",
    "\n",
    "# ---------- 1) alias to canonical (adds BPQ+MM fallbacks, AHEI fallbacks) ----------\n",
    "aliases = {\n",
    "    # IDs / survey\n",
    "    \"RIDAGEYR\": [\"RIDAGEYR\",\"AGE_YR\",\"age\"],\n",
    "    \"SEX\":      [\"SEX\",\"sex\",\"RIAGENDR\"],\n",
    "    \"RACE\":     [\"RACE\",\"re2\",\"re\"],\n",
    "    \"household_size\": [\"household_size\",\"DMDHHSIZ\"],\n",
    "    \"sdmvpsu\":  [\"sdmvpsu\",\"SDMVPSU\"],\n",
    "    \"sdmvstra\": [\"sdmvstra\",\"SDMVSTRA\"],\n",
    "    \"wt\":       [\"wt\",\"WTMEC2YR\"],\n",
    "    \"wt10\":     [\"wt10\",\"WTMEC2YR\"],\n",
    "\n",
    "    # behavior\n",
    "    \"SMK_AVG\":  [\"SMK_AVG\",\"CIGS_PER_DAY\"],\n",
    "    \"SMK\":      [\"SMK\",\"FORMER_SMOKER\",\"SMK_STATUS\"],\n",
    "    \"ALCG2\":    [\"ALCG2\",\"ALCOHOL_CAT\"],\n",
    "    \"met_hr\":   [\"met_hr\",\"METSCORE\",\"LTPA\"],\n",
    "\n",
    "    # clinical\n",
    "    \"bmic\":     [\"bmic\",\"BMI_CLAS\"],\n",
    "    \"DIABE\":    [\"DIABE\",\"DIABETES\",\"diabetes\"],\n",
    "    \"chol_rx\":  [\"chol_rx\"],\n",
    "    \"CVD\":      [\"CVD\"],\n",
    "    \"cancer\":   [\"cancer\"],\n",
    "\n",
    "    # outcomes / scores\n",
    "    \"probable_depression\": [\"probable_depression\",\"DEP_HARMONIZED\",\"PHQ9_GE10\",\"DEP_IMP\"],\n",
    "    \"sdoh_score\": [\"sdoh_score\"],\n",
    "    \"ahei_total\": [\"ahei_total\",\"AHEI\",\"ahei\",\"HEI2015_TOTAL_SCORE\",\"HEI2015_TOTAL\"],\n",
    "\n",
    "    # building blocks (for possible compute later)\n",
    "    \"unemployment2\": [\"unemployment2\",\"UNEMPLOYMENT\",\"EMPLOY\"],\n",
    "    \"pir\":           [\"pir\"],\n",
    "    \"SNAP\":          [\"SNAP\"],\n",
    "    \"EDU\":           [\"EDU\",\"EDU_CAT\",\"edu\",\"edu2\"],\n",
    "    \"sdoh_access\":   [\"sdoh_access\",\"HUQ_ACCESS\",\"huq_access\"],\n",
    "    \"ins\":           [\"ins\",\"INS\"],\n",
    "    \"HOQ065\":        [\"HOQ065\"],\n",
    "    \"marriage\":      [\"marriage\",\"MARITAL\",\"MARITAL_CAT\"],\n",
    "\n",
    "    # HTN components (case-insensitive)\n",
    "    \"BPQ020\":        [\"BPQ020\",\"bpq020\"],\n",
    "    \"BPQ050A\":       [\"BPQ050A\",\"bpq050a\"],\n",
    "    \"sbp\":           [\"sbp\",\"SBP\"],\n",
    "    \"dbp\":           [\"dbp\",\"DBP\"],\n",
    "\n",
    "    # SNAP3 label variant\n",
    "    \"SNAP3\":         [\"SNAP3\",\"SNAP\"],\n",
    "}\n",
    "\n",
    "for target, cands in aliases.items():\n",
    "    src = pick_best(cands)\n",
    "    if src:\n",
    "        if target != src:\n",
    "            df[target] = df[src]\n",
    "            created[target] = src\n",
    "\n",
    "# Normalize SEX if it came from RIAGENDR (1/2)\n",
    "if \"SEX\" in df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df[\"SEX\"]):\n",
    "        df[\"SEX\"] = df[\"SEX\"].map({1: \"Male\", 2: \"Female\"}).fillna(df[\"SEX\"])\n",
    "    else:\n",
    "        df[\"SEX\"] = df[\"SEX\"].astype(str).str.strip().str.capitalize()\n",
    "\n",
    "# HYPERTEN compute if missing (your R rule)\n",
    "if \"HYPERTEN\" not in df.columns:\n",
    "    bpq020 = df[ci_pick(\"BPQ020\",\"bpq020\")] if ci_pick(\"BPQ020\",\"bpq020\") else pd.Series(np.nan, index=df.index)\n",
    "    bpq050a= df[ci_pick(\"BPQ050A\",\"bpq050a\")] if ci_pick(\"BPQ050A\",\"bpq050a\") else pd.Series(np.nan, index=df.index)\n",
    "    sbp = df[ci_pick(\"sbp\",\"SBP\")] if ci_pick(\"sbp\",\"SBP\") else pd.Series(np.nan, index=df.index)\n",
    "    dbp = df[ci_pick(\"dbp\",\"DBP\")] if ci_pick(\"dbp\",\"DBP\") else pd.Series(np.nan, index=df.index)\n",
    "    df[\"HYPERTEN\"] = np.where(((bpq020==1) | (bpq050a==1) | (sbp>=130) | (dbp>=85)), 1,\n",
    "                              np.where(bpq020.notna() | bpq050a.notna() | sbp.notna() | dbp.notna(), 0, np.nan))\n",
    "\n",
    "# ---------- 2) keep BOTH canonical + source columns ----------\n",
    "# Define source groups to retain alongside canonical\n",
    "source_groups = {\n",
    "    \"SMK_AVG\": [\"CIGS_PER_DAY\"],\n",
    "    \"SMK\":     [\"FORMER_SMOKER\",\"SMK_STATUS\"],\n",
    "    \"ALCG2\":   [\"ALCOHOL_CAT\"],\n",
    "    \"met_hr\":  [\"METSCORE\",\"LTPA\"],\n",
    "    \"bmic\":    [\"BMI_CLAS\",\"BMI\"],        # keep BMI if you like for context\n",
    "    \"DIABE\":   [\"DIABETES\",\"diabetes\"],\n",
    "    \"sbp\":     [\"SBP\"],\n",
    "    \"dbp\":     [\"DBP\"],\n",
    "    \"ahei_total\": [\"AHEI\",\"ahei\",\"HEI2015_TOTAL_SCORE\",\"HEI2015_TOTAL\"],\n",
    "}\n",
    "\n",
    "# Core variables your R script needs\n",
    "needed_core = [\n",
    "  \"RIDAGEYR\",\"SEX\",\"RACE\",\"household_size\",\n",
    "  \"SMK_AVG\",\"SMK\",\"ALCG2\",\"met_hr\",\n",
    "  \"bmic\",\"DIABE\",\"HYPERTEN\",\"chol_rx\",\"CVD\",\"cancer\",\n",
    "  \"probable_depression\",\"sdoh_score\",\"ahei_total\",\n",
    "  \"unemployment2\",\"pir\",\"SNAP\",\"EDU\",\"sdoh_access\",\"ins\",\"HOQ065\",\"marriage\",\n",
    "  \"BPQ020\",\"BPQ050A\",\"sdmvpsu\",\"sdmvstra\",\"wt\",\"wt10\",\"SNAP3\",\n",
    "  \"SEQN\",\"SDDSRVYR\"\n",
    "]\n",
    "\n",
    "retain = set()\n",
    "# always keep canonicals that exist\n",
    "retain.update([c for c in needed_core if c in df.columns])\n",
    "# also keep sources if present\n",
    "for canon, sources in source_groups.items():\n",
    "    if canon in df.columns:\n",
    "        for s in sources:\n",
    "            s_real = ci_pick(s)\n",
    "            if s_real: retain.add(s_real)\n",
    "\n",
    "df_desc = df[list(retain)].copy()\n",
    "\n",
    "# ---------- 3) report ----------\n",
    "still_missing = [c for c in needed_core if c not in df_desc.columns]\n",
    "print(\"Aliases/derivations created:\", created)\n",
    "print(f\"df_desc columns kept: {len(df_desc.columns)}\")\n",
    "print(\"Still missing (not found in df):\", still_missing)\n",
    "print(\"Smoking-related kept:\",\n",
    "      [c for c in df_desc.columns if c.upper() in {\"SMK_AVG\",\"CIGS_PER_DAY\",\"SMK\",\"FORMER_SMOKER\",\"SMK_STATUS\"}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "431eadb8-e96a-4c70-b4c5-781748c35742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aliases/derivations created: {'RIDAGEYR': 'age', 'SEX': 'sex', 'RACE': 're', 'household_size': 'DMDHHSIZ', 'sdmvpsu': 'SDMVPSU', 'sdmvstra': 'SDMVSTRA', 'SMK_AVG': 'CIGS_PER_DAY', 'SMK': 'FORMER_SMOKER', 'ALCG2': 'ALCOHOL_CAT', 'met_hr': 'METSCORE', 'bmic': 'BMI_CLAS', 'DIABE': 'diabetes', 'probable_depression': 'DEP_HARMONIZED', 'unemployment2': 'UNEMPLOYMENT', 'EDU': 'edu', 'ins': 'INS', 'marriage': 'MARITAL', 'SNAP3': 'SNAP'}\n",
      "df_desc columns kept: 40\n",
      "Still missing (not found in df): ['sdoh_score', 'ahei_total', 'sdoh_access', 'BPQ020', 'BPQ050A', 'WTDRD1', 'WTDR2D', 'wt', 'wt10', 'WTINT4YR', 'WTMEC4YR']\n",
      "Weights present in df_desc: ['WTINT2YR', 'WTMEC2YR', 'WTSAF2YR']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = df_my_cov_aligned.copy()\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def ci_pick(*names):\n",
    "    lowmap = {c.lower(): c for c in df.columns}\n",
    "    for n in names:\n",
    "        if n in df.columns: return n\n",
    "        if n.lower() in lowmap: return lowmap[n.lower()]\n",
    "    return None\n",
    "\n",
    "def pick_best(cands):\n",
    "    cols = []\n",
    "    for c in cands:\n",
    "        col = ci_pick(c)\n",
    "        if col: cols.append(col)\n",
    "    if not cols: return None\n",
    "    cov = {c: df[c].notna().mean() for c in cols}\n",
    "    return max(cov, key=cov.get)\n",
    "\n",
    "created = {}\n",
    "\n",
    "# ---------- 1) alias to canonical (NO coalescing of weights) ----------\n",
    "aliases = {\n",
    "    # IDs / survey\n",
    "    \"RIDAGEYR\": [\"RIDAGEYR\",\"AGE_YR\",\"age\"],\n",
    "    \"SEX\":      [\"SEX\",\"sex\",\"RIAGENDR\"],\n",
    "    \"RACE\":     [\"RACE\",\"re2\",\"re\"],\n",
    "    \"household_size\": [\"household_size\",\"DMDHHSIZ\"],\n",
    "    \"sdmvpsu\":  [\"sdmvpsu\",\"SDMVPSU\"],\n",
    "    \"sdmvstra\": [\"sdmvstra\",\"SDMVSTRA\"],\n",
    "    # keep user's wt/wt10 AS-IS if present\n",
    "    \"wt\":       [\"wt\"],\n",
    "    \"wt10\":     [\"wt10\"],\n",
    "    # keep ALL NHANES weights separately (standardize casing only)\n",
    "    \"WTINT2YR\": [\"WTINT2YR\",\"wtint2yr\"],\n",
    "    \"WTMEC2YR\": [\"WTMEC2YR\",\"wtmec2yr\"],\n",
    "    \"WTSAF2YR\": [\"WTSAF2YR\",\"wtsaf2yr\"],\n",
    "    \"WTDRD1\":   [\"WTDRD1\",\"wtdrd1\",\"wtdrd1d\"],\n",
    "    \"WTDR2D\":   [\"WTDR2D\",\"wtdr2d\"],\n",
    "\n",
    "    # behavior\n",
    "    \"SMK_AVG\":  [\"SMK_AVG\",\"CIGS_PER_DAY\"],\n",
    "    \"SMK\":      [\"SMK\",\"FORMER_SMOKER\",\"SMK_STATUS\"],\n",
    "    \"ALCG2\":    [\"ALCG2\",\"ALCOHOL_CAT\"],\n",
    "    \"met_hr\":   [\"met_hr\",\"METSCORE\",\"LTPA\"],\n",
    "\n",
    "    # clinical\n",
    "    \"bmic\":     [\"bmic\",\"BMI_CLAS\"],\n",
    "    \"DIABE\":    [\"DIABE\",\"DIABETES\",\"diabetes\"],\n",
    "    \"chol_rx\":  [\"chol_rx\"],\n",
    "    \"CVD\":      [\"CVD\"],\n",
    "    \"cancer\":   [\"cancer\"],\n",
    "\n",
    "    # outcomes / scores\n",
    "    \"probable_depression\": [\"probable_depression\",\"DEP_HARMONIZED\",\"PHQ9_GE10\",\"DEP_IMP\"],\n",
    "    \"sdoh_score\": [\"sdoh_score\"],\n",
    "    \"ahei_total\": [\"ahei_total\",\"AHEI\",\"ahei\",\"HEI2015_TOTAL_SCORE\",\"HEI2015_TOTAL\"],\n",
    "\n",
    "    # building blocks\n",
    "    \"unemployment2\": [\"unemployment2\",\"UNEMPLOYMENT\",\"EMPLOY\"],\n",
    "    \"pir\":           [\"pir\"],\n",
    "    \"SNAP\":          [\"SNAP\"],\n",
    "    \"EDU\":           [\"EDU\",\"EDU_CAT\",\"edu\",\"edu2\"],\n",
    "    \"sdoh_access\":   [\"sdoh_access\",\"HUQ_ACCESS\",\"huq_access\"],\n",
    "    \"ins\":           [\"ins\",\"INS\"],\n",
    "    \"HOQ065\":        [\"HOQ065\"],\n",
    "    \"marriage\":      [\"marriage\",\"MARITAL\",\"MARITAL_CAT\"],\n",
    "\n",
    "    # HTN components (case-insensitive)\n",
    "    \"BPQ020\":        [\"BPQ020\",\"bpq020\"],\n",
    "    \"BPQ050A\":       [\"BPQ050A\",\"bpq050a\"],\n",
    "    \"sbp\":           [\"sbp\",\"SBP\"],\n",
    "    \"dbp\":           [\"dbp\",\"DBP\"],\n",
    "\n",
    "    # SNAP3 alias\n",
    "    \"SNAP3\":         [\"SNAP3\",\"SNAP\"],\n",
    "}\n",
    "\n",
    "for target, cands in aliases.items():\n",
    "    src = pick_best(cands)\n",
    "    if src:\n",
    "        if target != src:\n",
    "            df[target] = df[src]\n",
    "            created[target] = src\n",
    "\n",
    "# Normalize SEX if it came from RIAGENDR (1/2)\n",
    "if \"SEX\" in df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df[\"SEX\"]):\n",
    "        df[\"SEX\"] = df[\"SEX\"].map({1: \"Male\", 2: \"Female\"}).fillna(df[\"SEX\"])\n",
    "    else:\n",
    "        df[\"SEX\"] = df[\"SEX\"].astype(str).str.strip().str.capitalize()\n",
    "\n",
    "# HYPERTEN compute if missing (same rule)\n",
    "if \"HYPERTEN\" not in df.columns:\n",
    "    bpq020 = df[ci_pick(\"BPQ020\",\"bpq020\")] if ci_pick(\"BPQ020\",\"bpq020\") else pd.Series(np.nan, index=df.index)\n",
    "    bpq050a= df[ci_pick(\"BPQ050A\",\"bpq050a\")] if ci_pick(\"BPQ050A\",\"bpq050a\") else pd.Series(np.nan, index=df.index)\n",
    "    sbp = df[ci_pick(\"sbp\",\"SBP\")] if ci_pick(\"sbp\",\"SBP\") else pd.Series(np.nan, index=df.index)\n",
    "    dbp = df[ci_pick(\"dbp\",\"DBP\")] if ci_pick(\"dbp\",\"DBP\") else pd.Series(np.nan, index=df.index)\n",
    "    df[\"HYPERTEN\"] = np.where(((bpq020==1) | (bpq050a==1) | (sbp>=130) | (dbp>=85)), 1,\n",
    "                              np.where(bpq020.notna() | bpq050a.notna() | sbp.notna() | dbp.notna(), 0, np.nan))\n",
    "\n",
    "# ---------- 2) keep BOTH canonical + source columns ----------\n",
    "source_groups = {\n",
    "    \"SMK_AVG\":   [\"CIGS_PER_DAY\"],\n",
    "    \"SMK\":       [\"FORMER_SMOKER\",\"SMK_STATUS\"],\n",
    "    \"ALCG2\":     [\"ALCOHOL_CAT\"],\n",
    "    \"met_hr\":    [\"METSCORE\",\"LTPA\"],\n",
    "    \"bmic\":      [\"BMI_CLAS\",\"BMI\"],\n",
    "    \"DIABE\":     [\"DIABETES\",\"diabetes\"],\n",
    "    \"sbp\":       [\"SBP\"],\n",
    "    \"dbp\":       [\"DBP\"],\n",
    "    \"ahei_total\":[\"AHEI\",\"ahei\",\"HEI2015_TOTAL_SCORE\",\"HEI2015_TOTAL\"],\n",
    "    # weights: keep raw variants too if present\n",
    "    \"WTINT2YR\":  [\"wtint2yr\"],\n",
    "    \"WTMEC2YR\":  [\"wtmec2yr\",\"wt\",\"wt10\"],  # keep user's wt/wt10 alongside\n",
    "    \"WTSAF2YR\":  [\"wtsaf2yr\"],\n",
    "    \"WTDRD1\":    [\"wtdrd1\",\"wtdrd1d\"],\n",
    "    \"WTDR2D\":    [\"wtdr2d\"],\n",
    "}\n",
    "\n",
    "# Core variables your R script needs + all distinct weights\n",
    "needed_core = [\n",
    "  \"RIDAGEYR\",\"SEX\",\"RACE\",\"household_size\",\n",
    "  \"SMK_AVG\",\"SMK\",\"ALCG2\",\"met_hr\",\n",
    "  \"bmic\",\"DIABE\",\"HYPERTEN\",\"chol_rx\",\"CVD\",\"cancer\",\n",
    "  \"probable_depression\",\"sdoh_score\",\"ahei_total\",\n",
    "  \"unemployment2\",\"pir\",\"SNAP\",\"EDU\",\"sdoh_access\",\"ins\",\"HOQ065\",\"marriage\",\n",
    "  \"BPQ020\",\"BPQ050A\",\"sdmvpsu\",\"sdmvstra\",\"SEQN\",\"SDDSRVYR\",\n",
    "  # weights (keep all if present)\n",
    "  \"WTINT2YR\",\"WTMEC2YR\",\"WTSAF2YR\",\"WTDRD1\",\"WTDR2D\",\"wt\",\"wt10\",\"WTINT4YR\",\"WTMEC4YR\"\n",
    "]\n",
    "\n",
    "retain = set()\n",
    "retain.update([c for c in needed_core if c in df.columns])\n",
    "for canon, sources in source_groups.items():\n",
    "    if canon in df.columns:\n",
    "        for s in sources:\n",
    "            s_real = ci_pick(s)\n",
    "            if s_real: retain.add(s_real)\n",
    "\n",
    "df_desc = df[list(retain)].copy()\n",
    "\n",
    "# ---------- 3) report ----------\n",
    "still_missing = [c for c in needed_core if c not in df_desc.columns]\n",
    "print(\"Aliases/derivations created:\", created)\n",
    "print(f\"df_desc columns kept: {len(df_desc.columns)}\")\n",
    "print(\"Still missing (not found in df):\", still_missing)\n",
    "\n",
    "# quick peek at which weights you have\n",
    "weight_cols = [c for c in [\"WTINT2YR\",\"WTMEC2YR\",\"WTSAF2YR\",\"WTDRD1\",\"WTDR2D\",\"wt\",\"wt10\",\"WTINT4YR\",\"WTMEC4YR\"] if c in df_desc.columns]\n",
    "print(\"Weights present in df_desc:\", weight_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82803bd-cc3d-47d4-adeb-48934b0490e0",
   "metadata": {},
   "source": [
    "#### add 2017-2020 special weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "71ad6aab-6d82-40f8-a8bc-b33c1f0ee7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added/updated: ['WTINT4YR', 'WTMEC4YR', 'SDMVPSU', 'SDMVSTRA']\n",
      "Non-missing rates: {'WTINT4YR': 0.12079901249136318, 'WTMEC4YR': 0.12079901249136318, 'SDMVPSU': 1.0, 'SDMVSTRA': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Base DF\n",
    "df = df_my_cov_aligned.copy()\n",
    "\n",
    "# NHANES P_DEMO (2017–Mar 2020 pre-pandemic)\n",
    "urls = [\n",
    "    \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/P_DEMO.xpt\",\n",
    "    \"https://wwwn.cdc.gov/Nchs/Nhanes/2017-2020/P_DEMO.XPT\",\n",
    "]\n",
    "\n",
    "demo = None\n",
    "for u in urls:\n",
    "    try:\n",
    "        demo = pd.read_sas(u, format=\"xport\", encoding=\"utf-8\")\n",
    "        break\n",
    "    except Exception:\n",
    "        pass\n",
    "if demo is None:\n",
    "    raise RuntimeError(\"Failed to download P_DEMO.xpt from both URLs.\")\n",
    "\n",
    "# Keep + standardize\n",
    "keep = [\"SEQN\", \"WTINTPRP\", \"WTMECPRP\", \"SDMVPSU\", \"SDMVSTRA\", \"SDDSRVYR\"]\n",
    "demo = demo[keep].copy()\n",
    "\n",
    "# Optional sanity check: SDDSRVYR==66 for this file\n",
    "# assert demo[\"SDDSRVYR\"].dropna().eq(66).all()\n",
    "\n",
    "# Map to your 4-year convention\n",
    "demo = demo.rename(columns={\n",
    "    \"WTINTPRP\": \"WTINT4YR\",\n",
    "    \"WTMECPRP\": \"WTMEC4YR\",\n",
    "})\n",
    "\n",
    "# Ensure target cols exist pre-merge (so we can suffix the right-hand side)\n",
    "for col in [\"WTINT4YR\", \"WTMEC4YR\", \"SDMVPSU\", \"SDMVSTRA\"]:\n",
    "    if col not in df.columns:\n",
    "        df[col] = pd.NA\n",
    "\n",
    "# Merge (right-hand columns get *_src)\n",
    "df = df.merge(demo, on=[\"SEQN\"], how=\"left\", suffixes=(\"\", \"_src\"))\n",
    "\n",
    "# Fill only missing (mask assignment avoids FutureWarning), then drop *_src\n",
    "for col in [\"WTINT4YR\", \"WTMEC4YR\", \"SDMVPSU\", \"SDMVSTRA\"]:\n",
    "    src = f\"{col}_src\"\n",
    "    if src in df.columns:\n",
    "        mask = df[col].isna() & df[src].notna()\n",
    "        if mask.any():\n",
    "            df.loc[mask, col] = df.loc[mask, src]\n",
    "        df.drop(columns=[src], inplace=True)\n",
    "\n",
    "# Dtypes: weights as float; PSU/STRATA as nullable int\n",
    "for col in [\"WTINT4YR\", \"WTMEC4YR\", \"WTINT2YR\", \"WTMEC2YR\", \"WTSAF2YR\", \"WTDRD1\", \"WTDR2D\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")  # float\n",
    "\n",
    "for col in [\"SDMVPSU\", \"SDMVSTRA\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Quick audit\n",
    "have = [c for c in [\"WTINT4YR\",\"WTMEC4YR\",\"SDMVPSU\",\"SDMVSTRA\"] if c in df.columns]\n",
    "print(\"Added/updated:\", have)\n",
    "print(\"Non-missing rates:\", {c: float(df[c].notna().mean()) for c in have})\n",
    "\n",
    "df_my_cov_aligned = df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177a03d1-bb42-4206-8a9b-7ff02ba9d7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd421f27-dab7-4f6b-b54e-bda162f2eafb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b59012-ce19-431c-b003-3d9a18e9074f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e063f55-9342-4043-a112-32a7e3a73f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70567b4d-34d5-41cb-ab4f-c3dec601042a",
   "metadata": {},
   "source": [
    "#### Add ahei score build in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "baabfb8f-5a35-42d1-90de-0e6e17c44935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ahei_total merged from ahei_1999_2018_combined.csv. Non-missing: 46169 (added 46169).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA = Path(\"/Users/dengshuyue/Desktop/SDOH/analysis/output\")\n",
    "cand = [DATA/\"ahei_1999_2018_combined.csv\", DATA/\"ahei_9904_wjfrt_ssbfix.csv\"]\n",
    "\n",
    "ahei_path = next((p for p in cand if p.exists()), None)\n",
    "if ahei_path is None:\n",
    "    raise FileNotFoundError(\"No AHEI combined file found. Please write ahei_1999_2018_combined.csv in R.\")\n",
    "\n",
    "# --- read header only to discover exact column names (case-insensitive) ---\n",
    "hdr = pd.read_csv(ahei_path, nrows=0, low_memory=False)\n",
    "lower_map = {c.lower(): c for c in hdr.columns}\n",
    "\n",
    "seqn_col = lower_map.get(\"seqn\")\n",
    "tot_col = next((lower_map[k] for k in [\"ahei_all\",\"ahei_all_recomp\"] if k in lower_map), None)\n",
    "if not seqn_col or not tot_col:\n",
    "    raise ValueError(f\"Couldn’t find SEQN or AHEI total in {ahei_path.name}. \"\n",
    "                     f\"Columns present include: {list(hdr.columns)[:12]} ...\")\n",
    "\n",
    "# --- now read ONLY what we need, with dtypes set → no DtypeWarning ---\n",
    "try:\n",
    "    # use pyarrow if available (fast, no type guessing); falls back if not installed\n",
    "    ahei = pd.read_csv(ahei_path, usecols=[seqn_col, tot_col],\n",
    "                       dtype={seqn_col: \"Int64\"}, engine=\"pyarrow\")\n",
    "except Exception:\n",
    "    ahei = pd.read_csv(ahei_path, usecols=[seqn_col, tot_col],\n",
    "                       dtype={seqn_col: \"Int64\"}, low_memory=False)\n",
    "\n",
    "ahei = ahei.rename(columns={seqn_col: \"SEQN\", tot_col: \"ahei_total\"})\n",
    "ahei[\"ahei_total\"] = pd.to_numeric(ahei[\"ahei_total\"], errors=\"coerce\")\n",
    "ahei = ahei.dropna(subset=[\"SEQN\"]).drop_duplicates(\"SEQN\", keep=\"last\")\n",
    "\n",
    "# --- merge into your frame ---\n",
    "df = df_my_cov_aligned.copy()\n",
    "df[\"SEQN\"] = pd.to_numeric(df[\"SEQN\"], errors=\"coerce\")\n",
    "pre = df[\"ahei_total\"].notna().sum() if \"ahei_total\" in df.columns else 0\n",
    "\n",
    "df = df.merge(ahei, on=\"SEQN\", how=\"left\", suffixes=(\"\", \"_ahei\"))\n",
    "if \"ahei_total_ahei\" in df.columns:\n",
    "    df[\"ahei_total\"] = df[\"ahei_total\"].where(df[\"ahei_total\"].notna(), df[\"ahei_total_ahei\"])\n",
    "    df.drop(columns=[\"ahei_total_ahei\"], inplace=True)\n",
    "\n",
    "post = df[\"ahei_total\"].notna().sum()\n",
    "print(f\"✓ ahei_total merged from {ahei_path.name}. Non-missing: {post} (added {post-pre}).\")\n",
    "\n",
    "df_my_cov_aligned = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898fe3f9-035a-4ce8-a5a1-b0922b1cb29d",
   "metadata": {},
   "source": [
    "#### check again what is missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "cbc1b9f4-a835-42f9-9e4e-e5acceb62b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Present: 14 Missing: 22\n",
      "Still missing: ['RIDAGEYR', 'SEX', 'RACE', 'household_size', 'SMK_AVG', 'SMK', 'ALCG2', 'met_hr', 'bmic', 'DIABE', 'HYPERTEN', 'probable_depression', 'sdoh_score', 'unemployment2', 'EDU', 'sdoh_access', 'ins', 'marriage', 'sdmvpsu', 'sdmvstra', 'WTDRD1', 'WTDR2D']\n",
      "NHANES weights present: ['WTINT2YR', 'WTMEC2YR', 'WTSAF2YR', 'WTINT4YR', 'WTMEC4YR']\n"
     ]
    }
   ],
   "source": [
    "# Start from your earlier needed_core and trim\n",
    "needed_core = [\n",
    "  \"RIDAGEYR\",\"SEX\",\"RACE\",\"household_size\",\n",
    "  \"SMK_AVG\",\"SMK\",\"ALCG2\",\"met_hr\",\n",
    "  \"bmic\",\"DIABE\",\"HYPERTEN\",\"chol_rx\",\"CVD\",\"cancer\",\n",
    "  \"probable_depression\",\"sdoh_score\",\"ahei_total\",\n",
    "  \"unemployment2\",\"pir\",\"SNAP\",\"EDU\",\"sdoh_access\",\"ins\",\"HOQ065\",\"marriage\",\n",
    "  \"sdmvpsu\",\"sdmvstra\",\"SEQN\",\"SDDSRVYR\",\n",
    "  # weights (NHANES only)\n",
    "  \"WTINT2YR\",\"WTMEC2YR\",\"WTSAF2YR\",\"WTDRD1\",\"WTDR2D\",\"WTINT4YR\",\"WTMEC4YR\"\n",
    "]\n",
    "\n",
    "# Check what's still missing\n",
    "present = [c for c in needed_core if c in df_my_cov_aligned.columns]\n",
    "missing = [c for c in needed_core if c not in df_my_cov_aligned.columns]\n",
    "weights_present = [c for c in [\"WTINT2YR\",\"WTMEC2YR\",\"WTSAF2YR\",\"WTDRD1\",\"WTDR2D\",\"WTINT4YR\",\"WTMEC4YR\"]\n",
    "                   if c in df_my_cov_aligned.columns]\n",
    "\n",
    "print(\"Present:\", len(present), \"Missing:\", len(missing))\n",
    "print(\"Still missing:\", missing)\n",
    "print(\"NHANES weights present:\", weights_present)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b5e31984-5ded-4751-bad9-06622ff3dd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEQN, SDDSRVYR, WTINT2YR, WTMEC2YR, WTSAF2YR, SDMVPSU, SDMVSTRA, age, sex, re, edu, pir, tchol, hdl,\n",
      "ldl, tg, wc, bmi, dm_self, hba1c, fpg, chf, chd, mi, stroke, cancer, emphysema, bronchitis, asthma,\n",
      "re2, copd, sbp, dbp, dm_rx, chol_rx, angina_rx, htn_rx, roseQ, no_na, age_cat, pir_cat, edu2, CVD,\n",
      "lung_disease, diabetes, tchol_hdl, angina, lipid_pri, adiposity_pri, bp_pri, glucose_pri, cvd_pri,\n",
      "lipid_sec, adiposity_sec, bp_sec, glucose_sec, cvd_sec, optimal_pri_count, intermediate_pri_count,\n",
      "poor_pri_count, optimal_sec_count, intermediate_sec_count, poor_sec_count, optimal_all, poor_all,\n",
      "optimal_all_sec, poor_all_sec, MetS_hdl, MetS_triglycerides, MetS_bp, MetS_wc, MetS_fpg, MetS_count,\n",
      "MetS, RIAGENDR, FEMALE, SMK_STATUS, CIGS_PER_DAY, PACK_YEARS, FORMER_SMOKER, DRINKS_PER_DAY,\n",
      "ALCOHOL_CAT, LTPA, METSCORE, IMP, BMXWT, BMXHT, BMI_CLAS, HTN, HIGH_CHOL, DMDHHSIZ, ELIGSTAT,\n",
      "MORTSTAT, PERMTH_EXM, PERMTH_INT, UCOD_LEADING, IS_POST2018, IS_ADULT, MORTALITY_COVERED, EVENT,\n",
      "CENSORED, FU_YRS_EXM, FU_YRS_INT, UCOD_LABEL, PHQ9, PHQ9_GE10, DPQ_CAT, DEP_IMP, CIDI_SCORE_RAW,\n",
      "CIDI_12M_MDE, WTSCI2YR, DEP_HARMONIZED, DEP_SOURCE, INDFMINC, EDU_CAT, MARITAL, MARITAL_CAT, EMPLOY,\n",
      "UNEMPLOYMENT, HOD050, HOQ065, INS, SNAP, FSDHH, FS, FS_HH, FS_ADULT, FS_FINAL, HHFDSEC, ADFDSEC,\n",
      "FS_HH4, FS_ADULT4, FS_SOURCE_HH, FS_SOURCE_FINAL, SNAP_SOURCE, WTINT4YR, WTMEC4YR, SDDSRVYR_src,\n",
      "ahei_total\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "print(textwrap.fill(\", \".join(map(str, df_my_cov_aligned.columns)), width=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8610376-2edf-483b-9654-1f6afa4db4dc",
   "metadata": {},
   "source": [
    "#### adjust column name and check missingness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "52b25cd1-a4c8-4f6c-8a92-750163fc712e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Present: 33  Missing: 3\n",
      "Aliased (canonical ← source): {'RIDAGEYR': 'age', 'SEX': 'sex', 'RACE': 're2', 'household_size': 'DMDHHSIZ', 'SMK_AVG': 'CIGS_PER_DAY', 'SMK': 'SMK_STATUS', 'ALCG2': 'ALCOHOL_CAT', 'met_hr': 'METSCORE', 'bmic': 'BMI_CLAS', 'DIABE': 'diabetes', 'HYPERTEN': 'HTN', 'probable_depression': 'DEP_HARMONIZED', 'unemployment2': 'UNEMPLOYMENT', 'EDU': 'edu', 'sdoh_access': 'HOD050', 'ins': 'INS', 'marriage': 'MARITAL', 'sdmvpsu': 'SDMVPSU', 'sdmvstra': 'SDMVSTRA'}\n",
      "Still missing: ['sdoh_score', 'WTDRD1', 'WTDR2D']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Canonical set (HTN stays; BPQ020/050A removed per your earlier choice)\n",
    "needed_core = [\n",
    "  \"RIDAGEYR\",\"SEX\",\"RACE\",\"household_size\",\n",
    "  \"SMK_AVG\",\"SMK\",\"ALCG2\",\"met_hr\",\n",
    "  \"bmic\",\"DIABE\",\"HYPERTEN\",\"chol_rx\",\"CVD\",\"cancer\",\n",
    "  \"probable_depression\",\"sdoh_score\",\"ahei_total\",\n",
    "  \"unemployment2\",\"pir\",\"SNAP\",\"EDU\",\"sdoh_access\",\"ins\",\"HOQ065\",\"marriage\",\n",
    "  \"sdmvpsu\",\"sdmvstra\",\"SEQN\",\"SDDSRVYR\",\n",
    "  \"WTINT2YR\",\"WTMEC2YR\",\"WTSAF2YR\",\"WTDRD1\",\"WTDR2D\",\"WTINT4YR\",\"WTMEC4YR\"\n",
    "]\n",
    "\n",
    "# Map your existing columns → canonical (no coalescing; just alias-by-best)\n",
    "aliases = {\n",
    "    \"RIDAGEYR\": [\"RIDAGEYR\",\"age\"],\n",
    "    \"SEX\":      [\"SEX\",\"RIAGENDR\",\"sex\"],\n",
    "    \"RACE\":     [\"RACE\",\"re2\",\"re\"],\n",
    "    \"household_size\": [\"household_size\",\"DMDHHSIZ\"],\n",
    "    \"SMK_AVG\":  [\"SMK_AVG\",\"CIGS_PER_DAY\"],\n",
    "    \"SMK\":      [\"SMK\",\"SMK_STATUS\",\"FORMER_SMOKER\"],\n",
    "    \"ALCG2\":    [\"ALCG2\",\"ALCOHOL_CAT\"],\n",
    "    \"met_hr\":   [\"met_hr\",\"METSCORE\",\"LTPA\"],\n",
    "    \"bmic\":     [\"bmic\",\"BMI_CLAS\",\"bmi\"],\n",
    "    \"DIABE\":    [\"DIABE\",\"diabetes\",\"DIABETES\",\"dm_self\"],\n",
    "    \"HYPERTEN\": [\"HYPERTEN\",\"HTN\"],\n",
    "    \"chol_rx\":  [\"chol_rx\"],\n",
    "    \"CVD\":      [\"CVD\"],\n",
    "    \"cancer\":   [\"cancer\"],\n",
    "    \"probable_depression\": [\"probable_depression\",\"DEP_HARMONIZED\",\"PHQ9_GE10\",\"DEP_IMP\"],\n",
    "    \"sdoh_score\": [\"sdoh_score\"],  # likely missing\n",
    "    \"ahei_total\": [\"ahei_total\",\"AHEI\",\"HEI2015_TOTAL_SCORE\",\"HEI2015_TOTAL\"],\n",
    "    \"unemployment2\": [\"unemployment2\",\"UNEMPLOYMENT\",\"EMPLOY\"],\n",
    "    \"pir\":      [\"pir\"],\n",
    "    \"SNAP\":     [\"SNAP\"],\n",
    "    \"EDU\":      [\"EDU\",\"edu\",\"edu2\",\"EDU_CAT\"],\n",
    "    \"sdoh_access\": [\"sdoh_access\",\"HOD050\",\"HOQ065\"],  # if you treat these as access proxies\n",
    "    \"ins\":      [\"ins\",\"INS\"],\n",
    "    \"HOQ065\":   [\"HOQ065\"],\n",
    "    \"marriage\": [\"marriage\",\"MARITAL\",\"MARITAL_CAT\"],\n",
    "    \"sdmvpsu\":  [\"sdmvpsu\",\"SDMVPSU\"],\n",
    "    \"sdmvstra\": [\"sdmvstra\",\"SDMVSTRA\"],\n",
    "    \"SEQN\":     [\"SEQN\"],\n",
    "    \"SDDSRVYR\": [\"SDDSRVYR\"],\n",
    "    # weights\n",
    "    \"WTINT2YR\": [\"WTINT2YR\"],\n",
    "    \"WTMEC2YR\": [\"WTMEC2YR\"],\n",
    "    \"WTSAF2YR\": [\"WTSAF2YR\",\"WTSCI2YR\"],  # your frame has WTSCI2YR (safety)\n",
    "    \"WTDRD1\":   [\"WTDRD1\"],               # likely missing\n",
    "    \"WTDR2D\":   [\"WTDR2D\"],               # likely missing\n",
    "    \"WTINT4YR\": [\"WTINT4YR\",\"WTINTPRP\"],\n",
    "    \"WTMEC4YR\": [\"WTMEC4YR\",\"WTMECPRP\"],\n",
    "}\n",
    "\n",
    "def ci_pick(df, names):\n",
    "    low = {c.lower(): c for c in df.columns}\n",
    "    for n in names:\n",
    "        if n in df.columns: return n\n",
    "        if n.lower() in low: return low[n.lower()]\n",
    "    return None\n",
    "\n",
    "created = {}\n",
    "for target, cands in aliases.items():\n",
    "    src = ci_pick(df_my_cov_aligned, cands)\n",
    "    if src and target not in df_my_cov_aligned.columns:\n",
    "        df_my_cov_aligned[target] = df_my_cov_aligned[src]\n",
    "        created[target] = src\n",
    "\n",
    "present = [c for c in needed_core if c in df_my_cov_aligned.columns]\n",
    "missing = [c for c in needed_core if c not in df_my_cov_aligned.columns]\n",
    "\n",
    "print(f\"Present: {len(present)}  Missing: {len(missing)}\")\n",
    "print(\"Aliased (canonical ← source):\", {k:v for k,v in created.items()})\n",
    "print(\"Still missing:\", missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "eaa5caf3-f138-4cc7-b4b2-80f02a4ca989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCQ → present: ['EMPLOY', 'UNEMPLOYMENT'] | missing: []\n",
      "HOQ → present: ['HOD050', 'HOQ065'] | missing: []\n",
      "HIQ → present: ['INS'] | missing: []\n",
      "FSQ → present: ['FSDHH', 'HHFDSEC', 'ADFDSEC', 'FS_HH4', 'FS_ADULT4', 'FS_HH', 'FS_ADULT', 'FS_FINAL', 'FS_SOURCE_HH', 'FS_SOURCE_FINAL', 'SNAP'] | missing: []\n"
     ]
    }
   ],
   "source": [
    "blocks = {\n",
    "    \"OCQ\": [\"EMPLOY\",\"UNEMPLOYMENT\"],\n",
    "    \"HOQ\": [\"HOD050\",\"HOQ065\"],\n",
    "    \"HIQ\": [\"INS\"],\n",
    "    \"FSQ\": [\"FSDHH\",\"HHFDSEC\",\"ADFDSEC\",\"FS_HH4\",\"FS_ADULT4\",\"FS_HH\",\"FS_ADULT\",\"FS_FINAL\",\"FS_SOURCE_HH\",\"FS_SOURCE_FINAL\",\"SNAP\"],\n",
    "}\n",
    "\n",
    "for name, cols in blocks.items():\n",
    "    present = [c for c in cols if c in df_my_cov_aligned.columns]\n",
    "    missing = [c for c in cols if c not in df_my_cov_aligned.columns]\n",
    "    print(f\"{name} → present: {present} | missing: {missing}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "b4298441-7e20-4db0-a25b-8d9b2062a754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>WTINT2YR</th>\n",
       "      <th>WTMEC2YR</th>\n",
       "      <th>WTSAF2YR</th>\n",
       "      <th>SDMVPSU</th>\n",
       "      <th>SDMVSTRA</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>re</th>\n",
       "      <th>...</th>\n",
       "      <th>DIABE</th>\n",
       "      <th>HYPERTEN</th>\n",
       "      <th>probable_depression</th>\n",
       "      <th>unemployment2</th>\n",
       "      <th>EDU</th>\n",
       "      <th>sdoh_access</th>\n",
       "      <th>ins</th>\n",
       "      <th>marriage</th>\n",
       "      <th>sdmvpsu</th>\n",
       "      <th>sdmvstra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9727.078709</td>\n",
       "      <td>10982.898896</td>\n",
       "      <td>75131.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26678.636376</td>\n",
       "      <td>28325.384898</td>\n",
       "      <td>60586.147294</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>77.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43621.680548</td>\n",
       "      <td>46192.256945</td>\n",
       "      <td>121969.841152</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10346.119327</td>\n",
       "      <td>10251.260020</td>\n",
       "      <td>4624.687273</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91050.846620</td>\n",
       "      <td>99445.065735</td>\n",
       "      <td>234895.205650</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>49.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36508.250375</td>\n",
       "      <td>39656.600444</td>\n",
       "      <td>13379.800000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>F</td>\n",
       "      <td>NH Black</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22352.088620</td>\n",
       "      <td>25525.423409</td>\n",
       "      <td>57661.621988</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>59.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31600.089655</td>\n",
       "      <td>31510.587866</td>\n",
       "      <td>76026.438279</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7529.435502</td>\n",
       "      <td>7575.870247</td>\n",
       "      <td>14694.924957</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21071.164059</td>\n",
       "      <td>22445.808572</td>\n",
       "      <td>60202.416895</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>43.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEQN  SDDSRVYR      WTINT2YR      WTMEC2YR       WTSAF2YR  SDMVPSU  \\\n",
       "0     1       1.0   9727.078709  10982.898896   75131.200000        1   \n",
       "1     2       1.0  26678.636376  28325.384898   60586.147294        3   \n",
       "2     3       1.0  43621.680548  46192.256945  121969.841152        2   \n",
       "3     4       1.0  10346.119327  10251.260020    4624.687273        1   \n",
       "4     5       1.0  91050.846620  99445.065735  234895.205650        2   \n",
       "5     6       1.0  36508.250375  39656.600444   13379.800000        2   \n",
       "6     7       1.0  22352.088620  25525.423409   57661.621988        2   \n",
       "7     8       1.0  31600.089655  31510.587866   76026.438279        1   \n",
       "8     9       1.0   7529.435502   7575.870247   14694.924957        2   \n",
       "9    10       1.0  21071.164059  22445.808572   60202.416895        1   \n",
       "\n",
       "   SDMVSTRA   age sex                re  ...  DIABE  HYPERTEN  \\\n",
       "0         5   2.0   F    Other Hispanic  ...      0         0   \n",
       "1         1  77.0   M  Mexican American  ...      0         0   \n",
       "2         7  10.0   F  Mexican American  ...      0         0   \n",
       "3         2   1.0   M    Other Hispanic  ...      0         0   \n",
       "4         8  49.0   M  Mexican American  ...      0         1   \n",
       "5         2  19.0   F          NH Black  ...      0         0   \n",
       "6         4  59.0   F    Other Hispanic  ...      0         0   \n",
       "7         6  13.0   M  Mexican American  ...      0         0   \n",
       "8         9  11.0   F    Other Hispanic  ...      0         0   \n",
       "9         7  43.0   M    Other Hispanic  ...      0         1   \n",
       "\n",
       "   probable_depression  unemployment2   EDU  sdoh_access   ins  marriage  \\\n",
       "0                 <NA>           <NA>  <NA>          NaN  <NA>      <NA>   \n",
       "1                 <NA>              0     5          2.0     1      <NA>   \n",
       "2                 <NA>           <NA>     3          NaN  <NA>      <NA>   \n",
       "3                 <NA>           <NA>  <NA>          NaN  <NA>      <NA>   \n",
       "4                 <NA>              0     5          7.0     1         1   \n",
       "5                 <NA>           <NA>    15          NaN  <NA>         5   \n",
       "6                 <NA>              0     2          NaN  <NA>         1   \n",
       "7                 <NA>           <NA>     5          NaN  <NA>      <NA>   \n",
       "8                 <NA>           <NA>     5          NaN  <NA>      <NA>   \n",
       "9                 <NA>              0     3          4.0     2         4   \n",
       "\n",
       "   sdmvpsu  sdmvstra  \n",
       "0        1         5  \n",
       "1        3         1  \n",
       "2        2         7  \n",
       "3        1         2  \n",
       "4        2         8  \n",
       "5        2         2  \n",
       "6        2         4  \n",
       "7        1         6  \n",
       "8        2         9  \n",
       "9        1         7  \n",
       "\n",
       "[10 rows x 158 columns]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_my_cov_aligned.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89651525-84a7-4042-b62e-3cea6ec66bba",
   "metadata": {},
   "source": [
    "#### Keep important column and name it df_my_cov_aligned_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "4856d43e-10cc-47e0-b509-120cef75b7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_my_cov_aligned_short shape: (128809, 40)\n",
      "Created (canonical ← source): {'SEQN': 'SEQN', 'SDDSRVYR': 'SDDSRVYR', 'sdmvpsu': 'sdmvpsu', 'sdmvstra': 'sdmvstra', 'RIDAGEYR': 'RIDAGEYR', 'SEX': 'SEX', 'RACE': 'RACE', 'household_size': 'household_size', 'EDU': 'EDU', 'pir': 'pir', 'SMK_AVG': 'SMK_AVG', 'SMK': 'SMK', 'ALCG2': 'ALCG2', 'met_hr': 'met_hr', 'SMK_STATUS': 'SMK_STATUS', 'CIGS_PER_DAY': 'CIGS_PER_DAY', 'PACK_YEARS': 'PACK_YEARS', 'FORMER_SMOKER': 'FORMER_SMOKER', 'DRINKS_PER_DAY': 'DRINKS_PER_DAY', 'ALCOHOL_CAT': 'ALCOHOL_CAT', 'bmic': 'bmic', 'DIABE': 'DIABE', 'HYPERTEN': 'HYPERTEN', 'chol_rx': 'chol_rx', 'CVD': 'CVD', 'cancer': 'cancer', 'probable_depression': 'probable_depression', 'ahei_total': 'ahei_total', 'unemployment2': 'unemployment2', 'sdoh_access': 'sdoh_access', 'ins': 'ins', 'HOQ065': 'HOQ065', 'marriage': 'marriage', 'SNAP': 'SNAP', 'FS': 'FS_FINAL', 'WTINT2YR': 'WTINT2YR', 'WTMEC2YR': 'WTMEC2YR', 'WTSAF2YR': 'WTSAF2YR', 'WTINT4YR': 'WTINT4YR', 'WTMEC4YR': 'WTMEC4YR'}\n",
      "Still missing after aliasing: ['sdoh_score']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "src = df_my_cov_aligned.copy()\n",
    "\n",
    "# ---- 1) Canonical columns to keep (core + key derived + requested raw fields) ----\n",
    "canonical_order = [\n",
    "    # IDs / survey design\n",
    "    \"SEQN\",\"SDDSRVYR\",\"sdmvpsu\",\"sdmvstra\",\n",
    "    # demographics\n",
    "    \"RIDAGEYR\",\"SEX\",\"RACE\",\"household_size\",\"EDU\",\"pir\",\n",
    "    # behavior (canonical)\n",
    "    \"SMK_AVG\",\"SMK\",\"ALCG2\",\"met_hr\",\n",
    "    # behavior (raw fields to keep)\n",
    "    \"SMK_STATUS\",\"CIGS_PER_DAY\",\"PACK_YEARS\",\"FORMER_SMOKER\",\"DRINKS_PER_DAY\",\"ALCOHOL_CAT\",\n",
    "    # clinical\n",
    "    \"bmic\",\"DIABE\",\"HYPERTEN\",\"chol_rx\",\"CVD\",\"cancer\",\n",
    "    # scores/outcomes\n",
    "    \"probable_depression\",\"sdoh_score\",\"ahei_total\",\n",
    "    # SDOH / access / insurance / marital / SNAP / FS\n",
    "    \"unemployment2\",\"sdoh_access\",\"ins\",\"HOQ065\",\"marriage\",\"SNAP\",\"FS\",\n",
    "    # weights (interview/exam + pre-pandemic 4-yr + safety)\n",
    "    \"WTINT2YR\",\"WTMEC2YR\",\"WTSAF2YR\",\"WTINT4YR\",\"WTMEC4YR\",\n",
    "]\n",
    "\n",
    "# ---- 2) Alias map: canonical -> possible sources in your frame ----\n",
    "aliases = {\n",
    "    \"SEQN\": [\"SEQN\"],\n",
    "    \"SDDSRVYR\": [\"SDDSRVYR\",\"SDDSRVYR_src\"],\n",
    "\n",
    "    \"sdmvpsu\": [\"sdmvpsu\",\"SDMVPSU\"],\n",
    "    \"sdmvstra\":[\"sdmvstra\",\"SDMVSTRA\"],\n",
    "\n",
    "    \"RIDAGEYR\": [\"RIDAGEYR\",\"age\"],\n",
    "    \"SEX\": [\"SEX\",\"RIAGENDR\",\"sex\"],\n",
    "    \"RACE\": [\"RACE\",\"re2\",\"re\"],\n",
    "    \"household_size\": [\"household_size\",\"DMDHHSIZ\"],\n",
    "    \"EDU\": [\"EDU\",\"edu\",\"edu2\",\"EDU_CAT\"],\n",
    "    \"pir\": [\"pir\"],\n",
    "\n",
    "    # canonical behavior\n",
    "    \"SMK_AVG\": [\"SMK_AVG\",\"CIGS_PER_DAY\"],\n",
    "    \"SMK\": [\"SMK\",\"SMK_STATUS\",\"FORMER_SMOKER\"],\n",
    "    \"ALCG2\": [\"ALCG2\",\"ALCOHOL_CAT\"],\n",
    "    \"met_hr\": [\"met_hr\",\"METSCORE\",\"LTPA\"],\n",
    "\n",
    "    # raw behavior fields (keep as-is)\n",
    "    \"SMK_STATUS\": [\"SMK_STATUS\"],\n",
    "    \"CIGS_PER_DAY\": [\"CIGS_PER_DAY\"],\n",
    "    \"PACK_YEARS\": [\"PACK_YEARS\"],\n",
    "    \"FORMER_SMOKER\": [\"FORMER_SMOKER\"],\n",
    "    \"DRINKS_PER_DAY\": [\"DRINKS_PER_DAY\"],\n",
    "    \"ALCOHOL_CAT\": [\"ALCOHOL_CAT\"],\n",
    "\n",
    "    # clinical\n",
    "    \"bmic\": [\"bmic\",\"BMI_CLAS\",\"bmi\"],\n",
    "    \"DIABE\": [\"DIABE\",\"diabetes\",\"DIABETES\",\"dm_self\"],\n",
    "    \"HYPERTEN\": [\"HYPERTEN\",\"HTN\"],\n",
    "    \"chol_rx\": [\"chol_rx\"],\n",
    "    \"CVD\": [\"CVD\"],\n",
    "    \"cancer\": [\"cancer\"],\n",
    "\n",
    "    # outcomes/scores\n",
    "    \"probable_depression\": [\"probable_depression\",\"DEP_HARMONIZED\",\"PHQ9_GE10\",\"DEP_IMP\"],\n",
    "    \"sdoh_score\": [\"sdoh_score\"],\n",
    "    \"ahei_total\": [\"ahei_total\",\"AHEI\",\"HEI2015_TOTAL_SCORE\",\"HEI2015_TOTAL\"],\n",
    "\n",
    "    # SDOH etc.\n",
    "    \"unemployment2\": [\"unemployment2\",\"UNEMPLOYMENT\",\"EMPLOY\"],\n",
    "    \"sdoh_access\": [\"sdoh_access\"],\n",
    "    \"ins\": [\"ins\",\"INS\"],\n",
    "    \"HOQ065\": [\"HOQ065\"],\n",
    "    \"marriage\": [\"marriage\",\"MARITAL\",\"MARITAL_CAT\"],\n",
    "\n",
    "    \"SNAP\": [\"SNAP\"],\n",
    "    \"FS\": [\"FS_FINAL\",\"FS\"],  # prefer your final FS binary\n",
    "\n",
    "    # weights\n",
    "    \"WTINT2YR\": [\"WTINT2YR\"],\n",
    "    \"WTMEC2YR\": [\"WTMEC2YR\"],\n",
    "    \"WTSAF2YR\": [\"WTSAF2YR\",\"WTSCI2YR\"],\n",
    "    \"WTINT4YR\": [\"WTINT4YR\",\"WTINTPRP\"],\n",
    "    \"WTMEC4YR\": [\"WTMEC4YR\",\"WTMECPRP\"],\n",
    "}\n",
    "\n",
    "def ci_pick(df, names):\n",
    "    low = {c.lower(): c for c in df.columns}\n",
    "    for n in names:\n",
    "        if n in df.columns: return n\n",
    "        if n.lower() in low: return low[n.lower()]\n",
    "    return None\n",
    "\n",
    "# ---- 3) Build df_short with canonical names, copying from the best source ----\n",
    "short_cols = {}\n",
    "created_from = {}\n",
    "for canon, cands in aliases.items():\n",
    "    src_col = ci_pick(src, cands)\n",
    "    if src_col is not None:\n",
    "        short_cols[canon] = src[src_col]\n",
    "        created_from[canon] = src_col\n",
    "\n",
    "df_my_cov_aligned_short = pd.DataFrame(short_cols)\n",
    "\n",
    "# ---- 4) Light harmonization / typing ----\n",
    "# SEX\n",
    "if \"SEX\" in df_my_cov_aligned_short.columns:\n",
    "    s = df_my_cov_aligned_short[\"SEX\"]\n",
    "    if pd.api.types.is_numeric_dtype(s):\n",
    "        df_my_cov_aligned_short[\"SEX\"] = s.map({1:\"Male\", 2:\"Female\"}).astype(\"string\")\n",
    "    else:\n",
    "        df_my_cov_aligned_short[\"SEX\"] = s.astype(str).str.strip().str.capitalize()\n",
    "\n",
    "# Binary-ish ints\n",
    "for col_bin in [\"DIABE\",\"HYPERTEN\",\"CVD\",\"cancer\",\"SNAP\",\"FS\",\"unemployment2\",\"FORMER_SMOKER\"]:\n",
    "    if col_bin in df_my_cov_aligned_short.columns:\n",
    "        df_my_cov_aligned_short[col_bin] = pd.to_numeric(df_my_cov_aligned_short[col_bin], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Continuous behavior\n",
    "for col_num in [\"CIGS_PER_DAY\",\"PACK_YEARS\",\"DRINKS_PER_DAY\",\"SMK_AVG\",\"met_hr\",\"pir\"]:\n",
    "    if col_num in df_my_cov_aligned_short.columns:\n",
    "        df_my_cov_aligned_short[col_num] = pd.to_numeric(df_my_cov_aligned_short[col_num], errors=\"coerce\")\n",
    "\n",
    "# PSU/STRATA → nullable ints; weights → float\n",
    "for col in [\"sdmvpsu\",\"sdmvstra\"]:\n",
    "    if col in df_my_cov_aligned_short.columns:\n",
    "        df_my_cov_aligned_short[col] = pd.to_numeric(df_my_cov_aligned_short[col], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "for col in [\"WTINT2YR\",\"WTMEC2YR\",\"WTSAF2YR\",\"WTINT4YR\",\"WTMEC4YR\"]:\n",
    "    if col in df_my_cov_aligned_short.columns:\n",
    "        df_my_cov_aligned_short[col] = pd.to_numeric(df_my_cov_aligned_short[col], errors=\"coerce\")\n",
    "\n",
    "# Keep final column order (only those that exist)\n",
    "cols_final = [c for c in canonical_order if c in df_my_cov_aligned_short.columns]\n",
    "df_my_cov_aligned_short = df_my_cov_aligned_short[cols_final].copy()\n",
    "\n",
    "# ---- 5) Report coverage ----\n",
    "missing_after = [c for c in canonical_order if c not in df_my_cov_aligned_short.columns]\n",
    "print(\"df_my_cov_aligned_short shape:\", df_my_cov_aligned_short.shape)\n",
    "print(\"Created (canonical ← source):\", created_from)\n",
    "print(\"Still missing after aliasing:\", missing_after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16244657-3102-4101-a392-209c8844d018",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### HERE !!!! KEEP working on this!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336eeadb-1cd6-4e6b-b72e-0b2d2f1183a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d64f2e-1e68-4a1a-9e9e-a77f52d6377c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "79b42464-c65b-4b31-a616-27394ff18d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Checked why SMK_AVG etc missing \n",
    "## Pre-2018 cycles have ~10–13% non-missing (expected: only current smokers report cigs/day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd25fb-0bca-42cd-a7d3-e1bb614a84fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce647ff8-8946-4011-b2e6-e6f469f86204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce88a305-711c-49c4-8fc2-de471bb6e39d",
   "metadata": {},
   "source": [
    "## Check what column missing post 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "dd77d87b-f737-4b27-8595-02fe562ec2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WTINT2YR</th>\n",
       "      <th>WTMEC2YR</th>\n",
       "      <th>WTSAF2YR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9727.078709</td>\n",
       "      <td>10982.898896</td>\n",
       "      <td>75131.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26678.636376</td>\n",
       "      <td>28325.384898</td>\n",
       "      <td>60586.147294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43621.680548</td>\n",
       "      <td>46192.256945</td>\n",
       "      <td>121969.841152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10346.119327</td>\n",
       "      <td>10251.260020</td>\n",
       "      <td>4624.687273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91050.846620</td>\n",
       "      <td>99445.065735</td>\n",
       "      <td>234895.205650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36508.250375</td>\n",
       "      <td>39656.600444</td>\n",
       "      <td>13379.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22352.088620</td>\n",
       "      <td>25525.423409</td>\n",
       "      <td>57661.621988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31600.089655</td>\n",
       "      <td>31510.587866</td>\n",
       "      <td>76026.438279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7529.435502</td>\n",
       "      <td>7575.870247</td>\n",
       "      <td>14694.924957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21071.164059</td>\n",
       "      <td>22445.808572</td>\n",
       "      <td>60202.416895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       WTINT2YR      WTMEC2YR       WTSAF2YR\n",
       "0   9727.078709  10982.898896   75131.200000\n",
       "1  26678.636376  28325.384898   60586.147294\n",
       "2  43621.680548  46192.256945  121969.841152\n",
       "3  10346.119327  10251.260020    4624.687273\n",
       "4  91050.846620  99445.065735  234895.205650\n",
       "5  36508.250375  39656.600444   13379.800000\n",
       "6  22352.088620  25525.423409   57661.621988\n",
       "7  31600.089655  31510.587866   76026.438279\n",
       "8   7529.435502   7575.870247   14694.924957\n",
       "9  21071.164059  22445.808572   60202.416895"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_lu_cov_1999_2018[[  'WTINT2YR', 'WTMEC2YR', 'WTSAF2YR']].head(10) \n",
    "\n",
    "# 'SEQN','SDDSRVYR', 'SDMVPSU', 'SDMVSTRA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c720b760-0644-418d-a3e4-6c684ab4b75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DMDHHSIZ</th>\n",
       "      <th>WTINT4YR</th>\n",
       "      <th>WTMEC4YR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128789</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128790</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128791</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128792</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128793</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128794</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128795</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128796</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128797</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128798</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128799</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128800</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128801</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128802</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128803</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128804</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128805</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128806</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128807</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128808</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DMDHHSIZ  WTINT4YR  WTMEC4YR\n",
       "128789       4.0       NaN       NaN\n",
       "128790       7.0       NaN       NaN\n",
       "128791       4.0       NaN       NaN\n",
       "128792       2.0       NaN       NaN\n",
       "128793       1.0       NaN       NaN\n",
       "128794       4.0       NaN       NaN\n",
       "128795       1.0       NaN       NaN\n",
       "128796       3.0       NaN       NaN\n",
       "128797       2.0       NaN       NaN\n",
       "128798       5.0       NaN       NaN\n",
       "128799       1.0       NaN       NaN\n",
       "128800       2.0       NaN       NaN\n",
       "128801       2.0       NaN       NaN\n",
       "128802       5.0       NaN       NaN\n",
       "128803       4.0       NaN       NaN\n",
       "128804       2.0       NaN       NaN\n",
       "128805       5.0       NaN       NaN\n",
       "128806       3.0       NaN       NaN\n",
       "128807       5.0       NaN       NaN\n",
       "128808       2.0       NaN       NaN"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_my_cov_aligned.loc[df_my_cov_aligned[\"SDDSRVYR\"].eq(66), [\"DMDHHSIZ\",\"WTINT4YR\",\"WTMEC4YR\"]].tail(9000)\n",
    "\n",
    "\n",
    "df_my_cov_aligned[[\"DMDHHSIZ\",'WTINT4YR', 'WTMEC4YR']].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "97667301-77db-43a4-b6d1-c9836a41bbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DMDHHSIZ</th>\n",
       "      <th>household_size</th>\n",
       "      <th>HOQ065</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128799</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128800</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128801</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128802</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128803</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128804</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128805</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128806</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128807</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128808</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DMDHHSIZ  household_size  HOQ065\n",
       "128799       1.0             1.0    <NA>\n",
       "128800       2.0             2.0    <NA>\n",
       "128801       2.0             2.0    <NA>\n",
       "128802       5.0             5.0    <NA>\n",
       "128803       4.0             4.0    <NA>\n",
       "128804       2.0             2.0    <NA>\n",
       "128805       5.0             5.0    <NA>\n",
       "128806       3.0             3.0    <NA>\n",
       "128807       5.0             5.0    <NA>\n",
       "128808       2.0             2.0    <NA>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_my_cov_aligned[[\"DMDHHSIZ\", \"household_size\", \"HOQ065\"]].tail(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761d8d86-9cfe-4106-a0a2-129603d4a831",
   "metadata": {},
   "source": [
    "## Fill columns missing post 2018   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc72500-e807-4b89-a189-d7ebeaacde96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d26337a-e99f-4c31-bc13-0e8ca9f3c593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82e7570-8b0e-4eaf-8182-7eb4fa313204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b18dad-e22e-473a-9b14-3a217bc83797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce73e108-5ca1-41a2-bd51-78b1bbb4b0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094b725c-3454-4006-bca5-2d552ec31f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deaf76d-0d7e-4087-9743-87763449cd48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a317e30b-3ce9-4cfc-a0c3-61e18bc76d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340c05c8-e1f7-4409-aaf9-20678869cd18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2916ea6-1f21-44ac-aa68-0489630d4a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d786da-a7cb-4858-a381-a2b327b0cdc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
