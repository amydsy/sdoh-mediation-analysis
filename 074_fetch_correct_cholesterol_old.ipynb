{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2d532c4-67e7-42b6-bf51-531e36f243c7",
   "metadata": {},
   "source": [
    "## import previous file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c2f0117-133a-4325-a414-bcbf500bdddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128809, 68)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>sdmvpsu</th>\n",
       "      <th>sdmvstra</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RACE</th>\n",
       "      <th>re</th>\n",
       "      <th>household_size</th>\n",
       "      <th>DMDHHSIZ</th>\n",
       "      <th>...</th>\n",
       "      <th>HOQ065_structural_missing</th>\n",
       "      <th>household_size_structural_missing</th>\n",
       "      <th>chol_rx_structural_missing</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>drinking</th>\n",
       "      <th>alcg2</th>\n",
       "      <th>perE_alco</th>\n",
       "      <th>METSCORE_fromPAQ</th>\n",
       "      <th>LTPA_fromPAQ</th>\n",
       "      <th>met_hr_recalc_from</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>F</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>77.0</td>\n",
       "      <td>M</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.065753</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>from_new_PAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>F</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>49.0</td>\n",
       "      <td>M</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>2</td>\n",
       "      <td>9.101101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>from_new_PAQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEQN  SDDSRVYR  sdmvpsu  sdmvstra  RIDAGEYR SEX  RACE                re  \\\n",
       "0     1       1.0        1         5       2.0   F   4.0    Other Hispanic   \n",
       "1     2       1.0        3         1      77.0   M   3.0  Mexican American   \n",
       "2     3       1.0        2         7      10.0   F   3.0  Mexican American   \n",
       "3     4       1.0        1         2       1.0   M   4.0    Other Hispanic   \n",
       "4     5       1.0        2         8      49.0   M   3.0  Mexican American   \n",
       "\n",
       "   household_size  DMDHHSIZ  ...  HOQ065_structural_missing  \\\n",
       "0               3       3.0  ...                      False   \n",
       "1               1       1.0  ...                      False   \n",
       "2               4       4.0  ...                      False   \n",
       "3               7       7.0  ...                      False   \n",
       "4               3       3.0  ...                      False   \n",
       "\n",
       "   household_size_structural_missing  chol_rx_structural_missing RIAGENDR  \\\n",
       "0                              False                       False      2.0   \n",
       "1                              False                       False      1.0   \n",
       "2                              False                       False      2.0   \n",
       "3                              False                       False      1.0   \n",
       "4                              False                       False      1.0   \n",
       "\n",
       "   drinking alcg2  perE_alco  METSCORE_fromPAQ  LTPA_fromPAQ  \\\n",
       "0       NaN  <NA>   0.000000               NaN           NaN   \n",
       "1  0.065753     2   0.000000               NaN           NaN   \n",
       "2       NaN  <NA>   0.000000               NaN           NaN   \n",
       "3       NaN  <NA>   0.000000               NaN           NaN   \n",
       "4  1.714286     2   9.101101               NaN           NaN   \n",
       "\n",
       "   met_hr_recalc_from  \n",
       "0                None  \n",
       "1        from_new_PAQ  \n",
       "2                None  \n",
       "3                None  \n",
       "4        from_new_PAQ  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "p = Path(\"/Users/dengshuyue/Desktop/SDOH/analysis/output/cov_addv4_99_23.parquet\")\n",
    "df_my_cov_aligned_short = pd.read_parquet(p)  # uses pyarrow/fastparquet if available\n",
    "print(df_my_cov_aligned_short.shape)\n",
    "df_my_cov_aligned_short.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e4c447-d947-4dc4-8390-3c223ea04e03",
   "metadata": {},
   "source": [
    "## show missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cdf79ac-af8c-45ea-8f57-16301e89640d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          chol_rx  alcg2\n",
      "SDDSRVYR                \n",
      "1.0           0.0   62.9\n",
      "2.0           0.0   66.5\n",
      "3.0           0.0   62.9\n",
      "4.0           0.0   62.7\n",
      "5.0           0.0   55.4\n",
      "6.0           0.0   55.4\n",
      "7.0           0.0   55.1\n",
      "8.0           0.0   52.2\n",
      "9.0           0.0   52.8\n",
      "10.0          0.0   56.0\n",
      "12.0         29.1   61.4\n",
      "66.0        100.0   84.3\n"
     ]
    }
   ],
   "source": [
    "df = df_my_cov_aligned_short\n",
    "\n",
    "# use every column except the grouper\n",
    "# ignore PACK_YEARS, CIGS_PER_DAY, probable_depression and etc as missing naturally \n",
    "# ignore dulicate safe saved old column name\n",
    "\n",
    "exclude = {\"SDDSRVYR\",\"CIGS_PER_DAY\",\"PACK_YEARS\",\"probable_depression\",\"wt_phlebotomy\", \"WTSAFPRP\",\n",
    "           \"WTINT2YR\", \"WTMEC2YR\", \"WTPH2YR\", \"WTSAF2YR\", \"WTMEC4YR\", \"WTINTPRP\", \"WTMECPRP\", \"WTINT4YR\",\n",
    "           \"SNAP\", \"SNAP_src\", \"SNAP_bin\", \"SNAP_src_rank\", \"bmi\", \"RIAGENDR\",\n",
    "           \"SNAP_indiv_only\",\"FS\", \"ahei_total\", \"HOQ065\", \"marriage_label\", \"marriage_prev\",\n",
    "           \"METSCORE_fromPAQ\",\"perE_alco\",\"LTPA_fromPAQ\",\"SNAP_indiv_plus_singleton\", \n",
    "           \"SMK_AVG\", \"BMI_CLAS\", \"household_size\", \"DMDHHSIZ\"}\n",
    "cols_all = [c for c in df.columns if c not in exclude]\n",
    "\n",
    "# % missing by cycle (split into two lines)\n",
    "is_na = df[cols_all].isna()\n",
    "pct_miss = is_na.groupby(df[\"SDDSRVYR\"]).mean().mul(100)\n",
    "\n",
    "# keep only columns that exceed 80% missing in ANY cycle\n",
    "pct_miss_gt80 = pct_miss.loc[:, (pct_miss > 80).any(axis=0)].round(1)\n",
    "\n",
    "print(pct_miss_gt80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b900b14-41a2-4afc-a17f-33f2775198d5",
   "metadata": {},
   "source": [
    "## fetch chol and code chol_rx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18728765-87b5-4cb9-abfc-f4fabeea9559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   n  chol_rx_rate  dx_rate  lab200_rate  mean_tc  mean_hdl  \\\n",
      "period                                                                        \n",
      "2017-2020 (P)  10195         0.502    0.362        0.259  183.056    53.339   \n",
      "2021-2022 (L)   8501         0.493    0.364        0.233  185.691    54.314   \n",
      "\n",
      "               mean_ldl  \n",
      "period                   \n",
      "2017-2020 (P)   107.112  \n",
      "2021-2022 (L)      <NA>  \n"
     ]
    }
   ],
   "source": [
    "import io, re, requests\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "# =========================\n",
    "# Core helpers\n",
    "# =========================\n",
    "def _read_xpt(url, cols_upper=True):\n",
    "    r = requests.get(url); r.raise_for_status()\n",
    "    df = pd.read_sas(io.BytesIO(r.content), format=\"xport\", encoding=\"latin1\")\n",
    "    if cols_upper:\n",
    "        df.columns = [c.upper() for c in df.columns]\n",
    "    if \"SEQN\" in df.columns:\n",
    "        df[\"SEQN\"] = pd.to_numeric(df[\"SEQN\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    return df\n",
    "\n",
    "def _try_read_xpt(url, cols_upper=True):\n",
    "    \"\"\"Return empty DataFrame on HTTP errors so optional files don't crash.\"\"\"\n",
    "    try:\n",
    "        if not url:\n",
    "            return pd.DataFrame()\n",
    "        return _read_xpt(url, cols_upper=cols_upper)\n",
    "    except requests.HTTPError:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def _find_numeric_col(df, preferred, fallback_regex):\n",
    "    \"\"\"Pick first existing preferred col, else first numeric matching fallback regex.\"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return None\n",
    "    for c in preferred:\n",
    "        if c in df.columns and is_numeric_dtype(df[c]):\n",
    "            return c\n",
    "    pats = re.compile(fallback_regex, flags=re.I)\n",
    "    for c in df.columns:\n",
    "        if pats.search(c) and is_numeric_dtype(df[c]):\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _friedewald_ldl(tc, hdl, tg):\n",
    "    \"\"\"LDL = TC - HDL - TG/5 when TG < 400; else NA.\"\"\"\n",
    "    ldl = pd.Series(pd.NA, index=tc.index, dtype=\"Float64\")\n",
    "    cond = tc.notna() & hdl.notna() & tg.notna() & (tg < 400)\n",
    "    ldl.loc[cond] = (tc.loc[cond] - hdl.loc[cond] - (tg.loc[cond] / 5.0))\n",
    "    return ldl\n",
    "\n",
    "# =========================\n",
    "# Period-specific sources\n",
    "# =========================\n",
    "BASE_2017 = \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles\"\n",
    "BASE_2021 = \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2021/DataFiles\"\n",
    "\n",
    "URLS_P = {\n",
    "    \"bpq\":   f\"{BASE_2017}/P_BPQ.xpt\",      # BPQ080 (dx), BPQ090D (also used), BPQ100D (meds; not used for flag)\n",
    "    \"hdl\":   f\"{BASE_2017}/P_HDL.xpt\",      # HDL\n",
    "    \"tchol\": f\"{BASE_2017}/P_TCHOL.xpt\",    # Total chol (and sometimes direct LDL)\n",
    "    \"trig\":  f\"{BASE_2017}/P_TRIGLY.xpt\",   # TG (optional)\n",
    "}\n",
    "\n",
    "URLS_L = {\n",
    "    \"bpq\":   f\"{BASE_2021}/BPQ_L.xpt\",      # BPQ080, BPQ090D (if present), BPQ101D\n",
    "    \"hdl\":   f\"{BASE_2021}/HDL_L.xpt\",\n",
    "    \"tchol\": f\"{BASE_2021}/TCHOL_L.xpt\",\n",
    "    # TRIGLY_L not published\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# Builder for a given period (matches SAS: high_chol2 = high_chol OR (LBXTC > 200))\n",
    "# =========================\n",
    "def build_period_df(urls: dict, period_label: str) -> pd.DataFrame:\n",
    "    # --- BPQ: ever told high cholesterol ---\n",
    "    bpq = _read_xpt(urls[\"bpq\"])\n",
    "    bpq_keep = bpq[[\"SEQN\"]].copy()\n",
    "\n",
    "    # DX = (BPQ080 == 1) OR (BPQ090D == 1 if present)\n",
    "    has_080 = pd.to_numeric(bpq.get(\"BPQ080\"), errors=\"coerce\").eq(1) if \"BPQ080\" in bpq.columns else pd.Series(False, index=bpq.index)\n",
    "    has_090 = pd.to_numeric(bpq.get(\"BPQ090D\"), errors=\"coerce\").eq(1) if \"BPQ090D\" in bpq.columns else pd.Series(False, index=bpq.index)\n",
    "    bpq_keep[\"hc_dx\"] = (has_080 | has_090).astype(\"Int64\")\n",
    "\n",
    "    # --- Labs (for flag and summaries) ---\n",
    "    hdl  = _read_xpt(urls[\"hdl\"])\n",
    "    tch  = _read_xpt(urls[\"tchol\"])\n",
    "    trig = _try_read_xpt(urls.get(\"trig\", \"\"), cols_upper=True) if \"trig\" in urls else pd.DataFrame()\n",
    "\n",
    "    # Robust variable discovery\n",
    "    hdl_var = _find_numeric_col(hdl, preferred=[\"LBDHDD\", \"LBXHDD\", \"LBDHDD_1\"], fallback_regex=r\"\\bHDL\\b|HDDS?\\b|^LB..HD\")\n",
    "    tc_var  = _find_numeric_col(tch, preferred=[\"LBXTC\"], fallback_regex=r\"\\bTOTAL.*CHOL|^LB..TC$|\\bTC\\b\")\n",
    "    ldl_var = _find_numeric_col(tch, preferred=[\"LBDLDL\", \"LBDLDLD\", \"LBDLDLL\"], fallback_regex=r\"\\bLDL\\b|^LB.DLDL\")\n",
    "    tg_var  = _find_numeric_col(trig, preferred=[\"LBXTR\"], fallback_regex=r\"\\bTRI?G|^LB..TR$\") if not trig.empty else None\n",
    "\n",
    "    # Keep frames\n",
    "    hdl_keep = hdl[[\"SEQN\", hdl_var]].rename(columns={hdl_var: \"hdl_mgdl\"}) if hdl_var else pd.DataFrame(columns=[\"SEQN\",\"hdl_mgdl\"])\n",
    "    tc_keep  = tch[[\"SEQN\", tc_var ]].rename(columns={tc_var : \"total_chol_mgdl\"}) if tc_var  else pd.DataFrame(columns=[\"SEQN\",\"total_chol_mgdl\"])\n",
    "    ldl_keep = tch[[\"SEQN\", ldl_var]].rename(columns={ldl_var: \"ldl_mgdl\"}) if ldl_var else pd.DataFrame(columns=[\"SEQN\",\"ldl_mgdl\"])\n",
    "    tg_keep  = trig[[\"SEQN\", tg_var]].rename(columns={tg_var: \"trig\"}) if tg_var else pd.DataFrame(columns=[\"SEQN\",\"trig\"])\n",
    "\n",
    "    # Merge\n",
    "    df = (\n",
    "        bpq_keep\n",
    "        .merge(hdl_keep, how=\"left\", on=\"SEQN\")\n",
    "        .merge(tc_keep,  how=\"left\", on=\"SEQN\")\n",
    "        .merge(ldl_keep, how=\"left\", on=\"SEQN\")\n",
    "        .merge(tg_keep,  how=\"left\", on=\"SEQN\")\n",
    "    )\n",
    "\n",
    "    # Compute LDL if missing and feasible (for summaries only; not used in flag)\n",
    "    need_calc = df[\"ldl_mgdl\"].isna() if \"ldl_mgdl\" in df.columns else pd.Series(False, index=df.index)\n",
    "    have_cols = {\"total_chol_mgdl\",\"hdl_mgdl\",\"trig\"} <= set(df.columns)\n",
    "    if need_calc.any() and have_cols and df[\"trig\"].notna().any():\n",
    "        ldl_est = _friedewald_ldl(df[\"total_chol_mgdl\"], df[\"hdl_mgdl\"], df[\"trig\"])\n",
    "        df.loc[need_calc, \"ldl_mgdl\"] = ldl_est.loc[need_calc]\n",
    "\n",
    "    # SAS lab rule: LBXTC > 200 (strictly greater than 200)\n",
    "    df[\"hc_lab200\"] = (df[\"total_chol_mgdl\"] > 200).astype(\"Int64\")\n",
    "\n",
    "    # Final SAS-aligned flag: high_chol2 = high_chol (dx) OR (LBXTC > 200)\n",
    "    df[\"chol_rx\"] = ((df[\"hc_dx\"].fillna(0).astype(int) == 1) | (df[\"hc_lab200\"].fillna(0).astype(int) == 1)).astype(int)\n",
    "\n",
    "    df[\"period\"] = period_label\n",
    "\n",
    "    # Normalize numeric dtypes\n",
    "    for c in [\"total_chol_mgdl\",\"hdl_mgdl\",\"ldl_mgdl\",\"trig\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(\"Float64\")\n",
    "\n",
    "    keep_cols = [\"SEQN\",\"period\",\"chol_rx\",\"hc_dx\",\"hc_lab200\",\n",
    "                 \"total_chol_mgdl\",\"hdl_mgdl\",\"ldl_mgdl\",\"trig\"]\n",
    "    for c in keep_cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = pd.NA\n",
    "    return df[keep_cols]\n",
    "\n",
    "# =========================\n",
    "# Build both periods & QC (SAS-aligned definition)\n",
    "# =========================\n",
    "df_p = build_period_df(URLS_P, period_label=\"2017-2020 (P)\")\n",
    "df_l = build_period_df(URLS_L, period_label=\"2021-2022 (L)\")\n",
    "df_both = pd.concat([df_p, df_l], ignore_index=True)\n",
    "\n",
    "qc = (\n",
    "    df_both.groupby(\"period\", dropna=False)\n",
    "    .agg(n=(\"SEQN\",\"count\"),\n",
    "         chol_rx_rate=(\"chol_rx\",\"mean\"),\n",
    "         dx_rate=(\"hc_dx\",\"mean\"),\n",
    "         lab200_rate=(\"hc_lab200\",\"mean\"),\n",
    "         mean_tc=(\"total_chol_mgdl\",\"mean\"),\n",
    "         mean_hdl=(\"hdl_mgdl\",\"mean\"),\n",
    "         mean_ldl=(\"ldl_mgdl\",\"mean\"))\n",
    "    .round(3)\n",
    ")\n",
    "print(qc)\n",
    "\n",
    "# =========================\n",
    "# (Optional) mmol/L conversions\n",
    "# =========================\n",
    "# df_both[\"tc_mmol\"]  = (df_both[\"total_chol_mgdl\"] * 0.02586).astype(\"Float64\")\n",
    "# df_both[\"hdl_mmol\"] = (df_both[\"hdl_mgdl\"]        * 0.02586).astype(\"Float64\")\n",
    "# df_both[\"ldl_mmol\"] = (df_both[\"ldl_mgdl\"]        * 0.02586).astype(\"Float64\")\n",
    "\n",
    "# =========================\n",
    "# (Optional) Join into your main covariate DF and save\n",
    "# =========================\n",
    "# df_my_cov_aligned_short = df_my_cov_aligned_short.merge(\n",
    "#     df_both.drop(columns=[\"period\"]), on=\"SEQN\", how=\"left\"\n",
    "# )\n",
    "# out_path = \"cov_addv4_99_23.parquet\"\n",
    "# df_my_cov_aligned_short.to_parquet(out_path, index=False)\n",
    "# print(\"✓ Saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c591e-699f-40b5-96f8-89629cd0d876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a1b00c3-9202-4331-a0a9-33d6d85b2452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Marginal & overlap rates ---\n",
      "                   n  dx_rate  lab200_rate  both_rate  union_rate\n",
      "period                                                           \n",
      "2017-2020 (P)  10195    0.362        0.259      0.119       0.502\n",
      "2021-2022 (L)   8501    0.364        0.233      0.104       0.493\n",
      "\n",
      "--- Combination breakdown (counts, share of sample, share among chol_rx=1) ---\n",
      "          period combo_label     n  share_of_sample  share_among_chol_rx\n",
      "0  2017-2020 (P)        none  5082            0.498                0.000\n",
      "1  2017-2020 (P)    lab only  1426            0.140                0.279\n",
      "2  2017-2020 (P)     dx only  2473            0.243                0.484\n",
      "3  2017-2020 (P)      dx+lab  1214            0.119                0.237\n",
      "4  2021-2022 (L)        none  4313            0.507                0.000\n",
      "5  2021-2022 (L)    lab only  1092            0.128                0.261\n",
      "6  2021-2022 (L)     dx only  2211            0.260                0.528\n",
      "7  2021-2022 (L)      dx+lab   885            0.104                0.211\n",
      "\n",
      "--- Among chol_rx=1: shares with dx, lab200, and both present ---\n",
      "               share_pos_with_dx  share_pos_with_lab200  share_pos_with_both\n",
      "period                                                                      \n",
      "2017-2020 (P)              0.721                  0.516                0.237\n",
      "2021-2022 (L)              0.739                  0.472                0.211\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83e61b9-3129-4250-8af9-f40c0c7cd402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2f7e2df-58bf-45ab-9296-971fa8af6258",
   "metadata": {},
   "source": [
    "#### check why chol_rx rate is high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00dbf400-ca91-4228-8018-7f3b8a4ee6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Marginal & overlap rates ---\n",
      "                   n  dx_rate  lab200_rate  both_rate  union_rate\n",
      "period                                                           \n",
      "2017-2020 (P)  10195    0.362        0.259      0.119       0.502\n",
      "2021-2022 (L)   8501    0.364        0.233      0.104       0.493\n",
      "\n",
      "--- Combination breakdown (counts, share of sample, share among chol_rx=1) ---\n",
      "          period combo_label     n  share_of_sample  share_among_chol_rx\n",
      "0  2017-2020 (P)        none  5082            0.498                0.000\n",
      "1  2017-2020 (P)    lab only  1426            0.140                0.279\n",
      "2  2017-2020 (P)     dx only  2473            0.243                0.484\n",
      "3  2017-2020 (P)      dx+lab  1214            0.119                0.237\n",
      "4  2021-2022 (L)        none  4313            0.507                0.000\n",
      "5  2021-2022 (L)    lab only  1092            0.128                0.261\n",
      "6  2021-2022 (L)     dx only  2211            0.260                0.528\n",
      "7  2021-2022 (L)      dx+lab   885            0.104                0.211\n",
      "\n",
      "--- Among chol_rx=1: shares with dx, lab200, and both present ---\n",
      "               share_pos_with_dx  share_pos_with_lab200  share_pos_with_both\n",
      "period                                                                      \n",
      "2017-2020 (P)              0.721                  0.516                0.237\n",
      "2021-2022 (L)              0.739                  0.472                0.211\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = df_both.copy()\n",
    "for c in [\"hc_dx\",\"hc_lab200\",\"chol_rx\"]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "# Sanity: chol_rx should be the union of dx and lab200\n",
    "if not (df[\"chol_rx\"].eq((df[\"hc_dx\"] | df[\"hc_lab200\"]).astype(int))).all():\n",
    "    raise ValueError(\"chol_rx is not equal to (hc_dx OR hc_lab200) somewhere.\")\n",
    "\n",
    "# 1) Marginal and overlap rates (per period)\n",
    "df[\"both\"] = (df[\"hc_dx\"].eq(1) & df[\"hc_lab200\"].eq(1)).astype(int)\n",
    "margins = (\n",
    "    df.groupby(\"period\", dropna=False)\n",
    "      .agg(n=(\"SEQN\",\"count\"),\n",
    "           dx_rate=(\"hc_dx\",\"mean\"),\n",
    "           lab200_rate=(\"hc_lab200\",\"mean\"),\n",
    "           both_rate=(\"both\",\"mean\"),\n",
    "           union_rate=(\"chol_rx\",\"mean\"))\n",
    "      .round(3)\n",
    ")\n",
    "print(\"\\n--- Marginal & overlap rates ---\")\n",
    "print(margins)\n",
    "\n",
    "# 2) Combination counts & shares\n",
    "# combos: 00=none, 10=dx only, 01=lab only, 11=both\n",
    "df[\"combo\"] = df[[\"hc_dx\",\"hc_lab200\"]].astype(str).agg(\"\".join, axis=1)\n",
    "combo_map = {\"00\":\"none\",\"10\":\"dx only\",\"01\":\"lab only\",\"11\":\"dx+lab\"}\n",
    "\n",
    "combo_counts = (\n",
    "    df.groupby([\"period\",\"combo\"], as_index=False)\n",
    "      .size()\n",
    "      .rename(columns={\"size\":\"n\"})\n",
    ")\n",
    "# share of full sample\n",
    "combo_counts[\"share_of_sample\"] = (\n",
    "    combo_counts[\"n\"] / combo_counts.groupby(\"period\")[\"n\"].transform(\"sum\")\n",
    ").round(3)\n",
    "\n",
    "# share among chol_rx = 1 (exclude 'none' by definition)\n",
    "n_pos = df.groupby(\"period\")[\"chol_rx\"].sum().rename(\"n_pos\")\n",
    "combo_counts = combo_counts.merge(n_pos, on=\"period\", how=\"left\")\n",
    "combo_counts[\"share_among_chol_rx\"] = (\n",
    "    combo_counts.apply(lambda r: r[\"n\"]/r[\"n_pos\"] if (r[\"combo\"]!=\"00\" and r[\"n_pos\"]>0) else 0, axis=1)\n",
    ").round(3)\n",
    "\n",
    "combo_counts[\"combo_label\"] = combo_counts[\"combo\"].map(combo_map)\n",
    "combo_counts = combo_counts.sort_values([\"period\",\"combo\"])\n",
    "\n",
    "print(\"\\n--- Combination breakdown (counts, share of sample, share among chol_rx=1) ---\")\n",
    "print(combo_counts[[\"period\",\"combo_label\",\"n\",\"share_of_sample\",\"share_among_chol_rx\"]])\n",
    "\n",
    "# 3) Quick “drivers among positives”\n",
    "drivers = (\n",
    "    df.loc[df[\"chol_rx\"]==1]\n",
    "      .groupby(\"period\")[[\"hc_dx\",\"hc_lab200\",\"both\"]]\n",
    "      .mean()\n",
    "      .rename(columns={\n",
    "          \"hc_dx\":\"share_pos_with_dx\",\n",
    "          \"hc_lab200\":\"share_pos_with_lab200\",\n",
    "          \"both\":\"share_pos_with_both\"\n",
    "      })\n",
    "      .round(3)\n",
    ")\n",
    "print(\"\\n--- Among chol_rx=1: shares with dx, lab200, and both present ---\")\n",
    "print(drivers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf119a67-b020-432d-98c0-12cea0d51b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n, n_dx, n_pos, n_dx_among_pos = 10195 3687 5113 3687\n",
      "dx_rate (overall) = 0.362\n",
      "share_dx_among_chol_rx = 0.721\n"
     ]
    }
   ],
   "source": [
    "p = df_both.query(\"period == '2017-2020 (P)'\").copy()\n",
    "# overall (marginal) dx rate\n",
    "dx_rate = (p[\"hc_dx\"] == 1).mean()\n",
    "\n",
    "# conditional share among chol_rx positives\n",
    "share_dx_among_pos = (p.loc[p[\"chol_rx\"] == 1, \"hc_dx\"] == 1).mean()\n",
    "\n",
    "# counts to match your tables\n",
    "n = p.shape[0]\n",
    "n_dx = (p[\"hc_dx\"] == 1).sum()\n",
    "n_pos = (p[\"chol_rx\"] == 1).sum()\n",
    "n_dx_among_pos = (p[\"hc_dx\"].eq(1) & p[\"chol_rx\"].eq(1)).sum()\n",
    "\n",
    "print(\"n, n_dx, n_pos, n_dx_among_pos =\", n, n_dx, n_pos, n_dx_among_pos)\n",
    "print(\"dx_rate (overall) =\", round(dx_rate, 3))\n",
    "print(\"share_dx_among_chol_rx =\", round(share_dx_among_pos, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ba60d2-cdd2-4d34-80d0-8164d8395895",
   "metadata": {},
   "source": [
    "#### check if previous cov code have mention chol_rx method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49dab2ef-c631-414a-9f93-aceadb4a1f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\np = Path(\"/Users/dengshuyue/Desktop/SDOH/analysis/2.1_Prepare data_covariates.sas\")\\npat = re.compile(r\\'chol(_rx)?|HIGH_CHOL|BPQ0?80|BPQ10(0D|1D)|LBXTC|LBDLDL|LBXTR|HDL|RXQ_RX|RXDDRUG|STATIN|EZETIMIBE|FIBRATE\\', re.I)\\n\\nlines = p.read_text(errors=\"ignore\").splitlines()\\nfor i, line in enumerate(lines):\\n    if pat.search(line):\\n        start = max(0, i-3); end = min(len(lines), i+4)\\n        print(f\"\\n--- lines {start+1}-{end} ---\")\\n        for j in range(start, end):\\n            print(f\"{j+1:5d}: {lines[j]}\")\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "\"\"\"\n",
    "p = Path(\"/Users/dengshuyue/Desktop/SDOH/analysis/2.1_Prepare data_covariates.sas\")\n",
    "pat = re.compile(r'chol(_rx)?|HIGH_CHOL|BPQ0?80|BPQ10(0D|1D)|LBXTC|LBDLDL|LBXTR|HDL|RXQ_RX|RXDDRUG|STATIN|EZETIMIBE|FIBRATE', re.I)\n",
    "\n",
    "lines = p.read_text(errors=\"ignore\").splitlines()\n",
    "for i, line in enumerate(lines):\n",
    "    if pat.search(line):\n",
    "        start = max(0, i-3); end = min(len(lines), i+4)\n",
    "        print(f\"\\n--- lines {start+1}-{end} ---\")\n",
    "        for j in range(start, end):\n",
    "            print(f\"{j+1:5d}: {lines[j]}\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db0f024-c54d-4935-9585-398734351ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4467d146-33c2-46d5-a23d-79b2f10a1d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9505a9d0-d1d1-4b3f-89d2-1824162b1ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eea005a-29f8-4495-b6a8-98288d51c636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83726a68-71ee-4af6-b5db-932456349464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted chol_rx prevalence by cycle:\n",
      "    SDDSRVYR      n  cases  chol_rx_rate\n",
      "0        1.0   9965    422      0.042348\n",
      "1        2.0  11039    613       0.05553\n",
      "2        3.0  10122    735      0.072614\n",
      "3        4.0  10348    773        0.0747\n",
      "4        5.0  10149   1194      0.117647\n",
      "5        6.0  10537   1232      0.116921\n",
      "6        7.0   9756   1100      0.112751\n",
      "7        8.0  10175   1226      0.120491\n",
      "8        9.0   9971   1170       0.11734\n",
      "9       10.0   9254   1318      0.142425\n",
      "10      12.0   8465   2126      0.251152\n",
      "\n",
      "WTMEC2YR-weighted chol_rx prevalence by cycle:\n",
      "    SDDSRVYR      n  chol_rx_rate\n",
      "0        1.0   9282      0.055405\n",
      "1        2.0  10477      0.070017\n",
      "2        3.0   9643      0.090047\n",
      "3        4.0   9950      0.103745\n",
      "4        5.0   9762      0.119686\n",
      "5        6.0  10253      0.125808\n",
      "6        7.0   9338      0.135788\n",
      "7        8.0   9813      0.152367\n",
      "8        9.0   9544      0.138229\n",
      "9       10.0   8704      0.145363\n",
      "10      12.0   8465      0.211396\n"
     ]
    }
   ],
   "source": [
    "df = df_my_cov_aligned_short.copy()\n",
    "\n",
    "# --- make sure chol_rx is a clean 0/1 Int64 and ignore NAs for the rate denom ---\n",
    "if \"chol_rx\" not in df.columns:\n",
    "    raise ValueError(\"chol_rx not found. Merge the cholesterol builder outputs first.\")\n",
    "chol = pd.to_numeric(df[\"chol_rx\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# =============== Unweighted prevalence by cycle ===============\n",
    "unw = (\n",
    "    pd.DataFrame({\"SDDSRVYR\": df[\"SDDSRVYR\"], \"chol_rx\": chol})\n",
    "    .dropna(subset=[\"chol_rx\"])\n",
    "    .groupby(\"SDDSRVYR\")\n",
    "    .agg(n=(\"chol_rx\", \"size\"),\n",
    "         cases=(\"chol_rx\", \"sum\"))\n",
    "    .assign(chol_rx_rate=lambda d: d[\"cases\"]/d[\"n\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"Unweighted chol_rx prevalence by cycle:\")\n",
    "print(unw)\n",
    "\n",
    "# =============== Weighted prevalence by cycle (optional) ===============\n",
    "# Prefer WTMEC2YR (exam weights). If not present, fall back to WTINT2YR.\n",
    "wt_col = None\n",
    "for cand in [\"WTMEC2YR\", \"WTINT2YR\", \"WTMECPRP\", \"WTINTPRP\"]:\n",
    "    if cand in df.columns:\n",
    "        wt_col = cand\n",
    "        break\n",
    "\n",
    "if wt_col:\n",
    "    tmp = (\n",
    "        pd.DataFrame({\n",
    "            \"SDDSRVYR\": df[\"SDDSRVYR\"],\n",
    "            \"chol_rx\": chol,\n",
    "            \"wt\": pd.to_numeric(df[wt_col], errors=\"coerce\")\n",
    "        })\n",
    "        .dropna(subset=[\"chol_rx\", \"wt\"])\n",
    "    )\n",
    "    w = (\n",
    "        tmp.assign(w_cases=lambda d: d[\"wt\"]*d[\"chol_rx\"])\n",
    "          .groupby(\"SDDSRVYR\")\n",
    "          .agg(w_sum=(\"wt\",\"sum\"),\n",
    "               w_cases=(\"w_cases\",\"sum\"),\n",
    "               n=(\"chol_rx\",\"size\"))  # n shown for reference\n",
    "          .assign(chol_rx_rate_wt=lambda d: d[\"w_cases\"]/d[\"w_sum\"])\n",
    "          .reset_index()\n",
    "    )\n",
    "    print(f\"\\n{wt_col}-weighted chol_rx prevalence by cycle:\")\n",
    "    print(w[[\"SDDSRVYR\",\"n\",\"chol_rx_rate_wt\"]].rename(columns={\"chol_rx_rate_wt\":\"chol_rx_rate\"}))\n",
    "else:\n",
    "    print(\"\\nNo weight column found; skipped weighted prevalence.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6093ce-90bc-4c29-8706-209cd8ad0edc",
   "metadata": {},
   "source": [
    "#### Full cycle fetch 99-23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6760a145-4005-43d8-b66b-8ae0b51dbc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Unweighted QC (SAS-aligned, 1999–2018) ===\n",
      "              n  chol_rx2_rate  dx_rate  lab200_rate  mean_tc  mean_hdl  \\\n",
      "period                                                                    \n",
      "1999-2000  8839          0.333    0.193        0.336  186.956      <NA>   \n",
      "2001-2002  9682          0.336    0.201        0.324  186.684      <NA>   \n",
      "2003-2004  8884          0.356    0.243        0.318   185.29    54.472   \n",
      "2005-2006  8334          0.358    0.226        0.309  184.471      <NA>   \n",
      "2007-2008  8371          0.417    0.291        0.333  186.675      <NA>   \n",
      "2009-2010  8763          0.408    0.272        0.326   185.64      <NA>   \n",
      "2011-2012  8077          0.413    0.323         0.31  183.202      <NA>   \n",
      "2013-2014  8489          0.400    0.341        0.272  179.534      <NA>   \n",
      "2015-2016  8285          0.401    0.341        0.279  180.257      <NA>   \n",
      "2017-2018  7768          0.417    0.358        0.273  179.895      <NA>   \n",
      "\n",
      "           mean_ldl  \n",
      "period               \n",
      "1999-2000   112.293  \n",
      "2001-2002   110.191  \n",
      "2003-2004   105.534  \n",
      "2005-2006   106.784  \n",
      "2007-2008    110.91  \n",
      "2009-2010   110.888  \n",
      "2011-2012   109.497  \n",
      "2013-2014   106.221  \n",
      "2015-2016   107.715  \n",
      "2017-2018   106.853  \n",
      "\n",
      "=== Weighted QC (WTMEC2YR; SAS-aligned, 1999–2018) ===\n",
      "           w_union   w_dx  w_lab200  w_mean_tc  w_mean_hdl  w_mean_ldl\n",
      "period                                                                \n",
      "1999-2000    0.418  0.224     0.401      193.9         NaN       118.5\n",
      "2001-2002    0.412  0.220     0.384      193.4         NaN       115.2\n",
      "2003-2004    0.446  0.272     0.390      193.0        54.0       110.7\n",
      "2005-2006    0.455  0.273     0.377      191.8         NaN       111.7\n",
      "2007-2008    0.455  0.282     0.365      190.1         NaN       112.4\n",
      "2009-2010    0.447  0.269     0.358      189.3         NaN       112.4\n",
      "2011-2012    0.481  0.328     0.359      188.5         NaN       112.0\n",
      "2013-2014    0.461  0.350     0.306      183.3         NaN       108.2\n",
      "2015-2016    0.468  0.340     0.330      185.9         NaN       110.1\n",
      "2017-2018    0.450  0.340     0.308      183.4         NaN       108.4\n"
     ]
    }
   ],
   "source": [
    "import io, re, requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def _read_xpt(url, cols_upper=True):\n",
    "    r = requests.get(url); r.raise_for_status()\n",
    "    df = pd.read_sas(io.BytesIO(r.content), format=\"xport\", encoding=\"latin1\")\n",
    "    if cols_upper:\n",
    "        df.columns = [c.upper() for c in df.columns]\n",
    "    if \"SEQN\" in df.columns:\n",
    "        df[\"SEQN\"] = pd.to_numeric(df[\"SEQN\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    return df\n",
    "\n",
    "def _try_read_xpt(url, cols_upper=True):\n",
    "    try:\n",
    "        if not url:\n",
    "            return pd.DataFrame()\n",
    "        return _read_xpt(url, cols_upper=cols_upper)\n",
    "    except requests.HTTPError:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def _find_numeric_col(df, preferred, fallback_regex):\n",
    "    if df is None or df.empty:\n",
    "        return None\n",
    "    for c in preferred:\n",
    "        if c in df.columns and is_numeric_dtype(df[c]):\n",
    "            return c\n",
    "    pats = re.compile(fallback_regex, flags=re.I)\n",
    "    for c in df.columns:\n",
    "        if pats.search(c) and is_numeric_dtype(df[c]):\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _friedewald_ldl(tc, hdl, tg):\n",
    "    \"\"\"LDL = TC - HDL - TG/5 when TG < 400; else NA.\"\"\"\n",
    "    ldl = pd.Series(pd.NA, index=tc.index, dtype=\"Float64\")\n",
    "    cond = tc.notna() & hdl.notna() & tg.notna() & (tg < 400)\n",
    "    ldl.loc[cond] = (tc.loc[cond] - hdl.loc[cond] - (tg.loc[cond] / 5.0))\n",
    "    return ldl\n",
    "\n",
    "def wmean(x, w):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    w = pd.to_numeric(w, errors=\"coerce\")\n",
    "    m = x.notna() & w.notna() & (w > 0)\n",
    "    if m.sum() == 0:\n",
    "        return np.nan\n",
    "    return float((x[m] * w[m]).sum() / w[m].sum())\n",
    "\n",
    "# =========================\n",
    "# Cycle plumbing (1999–2018)\n",
    "# =========================\n",
    "CYCLES = [\n",
    "    (\"\",   \"1999-2000\"),\n",
    "    (\"_B\", \"2001-2002\"),\n",
    "    (\"_C\", \"2003-2004\"),\n",
    "    (\"_D\", \"2005-2006\"),\n",
    "    (\"_E\", \"2007-2008\"),\n",
    "    (\"_F\", \"2009-2010\"),\n",
    "    (\"_G\", \"2011-2012\"),\n",
    "    (\"_H\", \"2013-2014\"),\n",
    "    (\"_I\", \"2015-2016\"),\n",
    "    (\"_J\", \"2017-2018\"),\n",
    "]\n",
    "\n",
    "def _base_folder(suffix):\n",
    "    return {\n",
    "        \"\":   \"1999\", \"_B\": \"2001\", \"_C\": \"2003\", \"_D\": \"2005\", \"_E\": \"2007\",\n",
    "        \"_F\": \"2009\", \"_G\": \"2011\", \"_H\": \"2013\", \"_I\": \"2015\", \"_J\": \"2017\"\n",
    "    }[suffix]\n",
    "\n",
    "def _url(folder, filebase):\n",
    "    return f\"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/{folder}/DataFiles/{filebase}.xpt\"\n",
    "\n",
    "def _tc_hdl_candidates(suffix):\n",
    "    \"\"\"Return ordered candidates for Total/HDL file names by cycle.\"\"\"\n",
    "    if suffix == \"\":      # 1999–2000\n",
    "        return [\"LAB13\", \"TCHOL\", \"HDL\"]  # LAB13 preferred; fallbacks split\n",
    "    s = suffix.lstrip(\"_\")\n",
    "    if suffix in {\"_B\",\"_C\"}:\n",
    "        return [f\"L13_{s}\", f\"TCHOL{suffix}\", f\"HDL{suffix}\"]\n",
    "    # 2005+ use split files\n",
    "    return [f\"TCHOL{suffix}\", f\"HDL{suffix}\"]\n",
    "\n",
    "def _ldl_tg_candidates(suffix):\n",
    "    \"\"\"Return ordered candidates for LDL/TG file names by cycle.\"\"\"\n",
    "    if suffix == \"\":      # 1999–2000\n",
    "        return [\"LAB13AM\", \"TRIGLY\", \"TCHOL\"]  # LAB13AM preferred; fallbacks\n",
    "    s = suffix.lstrip(\"_\")\n",
    "    if suffix in {\"_B\",\"_C\"}:\n",
    "        return [f\"L13AM_{s}\", f\"TRIGLY{suffix}\", f\"TCHOL{suffix}\"]\n",
    "    # 2005+ use split files\n",
    "    return [f\"TRIGLY{suffix}\", f\"TCHOL{suffix}\"]\n",
    "\n",
    "# =========================\n",
    "# Build ONE cycle (SAS-aligned: dx = 080 OR 090D; flag = dx OR (TC>200))\n",
    "# =========================\n",
    "def build_cycle_df(suffix: str, label: str) -> pd.DataFrame:\n",
    "    folder = _base_folder(suffix)\n",
    "\n",
    "    # --- BPQ (dx items) ---\n",
    "    bpq = _try_read_xpt(_url(folder, f\"BPQ{suffix}\"))\n",
    "    bpq_keep = pd.DataFrame()\n",
    "    if not bpq.empty:\n",
    "        bpq_keep = bpq[[\"SEQN\"]].copy()\n",
    "        has_080 = pd.to_numeric(bpq.get(\"BPQ080\"),  errors=\"coerce\").eq(1) if \"BPQ080\"  in bpq.columns else pd.Series(False, index=bpq.index)\n",
    "        has_090 = pd.to_numeric(bpq.get(\"BPQ090D\"), errors=\"coerce\").eq(1) if \"BPQ090D\" in bpq.columns else pd.Series(False, index=bpq.index)\n",
    "        bpq_keep[\"hc_dx\"] = (has_080 | has_090).astype(\"Int64\")\n",
    "\n",
    "    # --- Labs: try multiple filename patterns per cycle ---\n",
    "    # Total & HDL\n",
    "    tc_hdl = pd.DataFrame()\n",
    "    for base in _tc_hdl_candidates(suffix):\n",
    "        tc_hdl = _try_read_xpt(_url(folder, base))\n",
    "        if not tc_hdl.empty:\n",
    "            break\n",
    "\n",
    "    # LDL & TG\n",
    "    ldl_tg = pd.DataFrame()\n",
    "    for base in _ldl_tg_candidates(suffix):\n",
    "        ldl_tg = _try_read_xpt(_url(folder, base))\n",
    "        if not ldl_tg.empty:\n",
    "            break\n",
    "\n",
    "    # Variable discovery (works across all file types)\n",
    "    hdl_var = _find_numeric_col(tc_hdl, preferred=[\"LBDHDD\",\"LBXHDD\",\"LBDHDD_1\"], fallback_regex=r\"\\bHDL\\b|HDDS?\\b|^LB..HD\")\n",
    "    tc_var  = _find_numeric_col(tc_hdl, preferred=[\"LBXTC\"],                        fallback_regex=r\"\\bTOTAL.*CHOL|^LB..TC$|\\bTC\\b\")\n",
    "    # LDL can be in either file; try tc_hdl first, then ldl_tg\n",
    "    ldl_var = _find_numeric_col(tc_hdl, preferred=[\"LBDLDL\",\"LBDLDLD\",\"LBDLDLL\"],   fallback_regex=r\"\\bLDL\\b|^LB.DLDL\")\n",
    "    if ldl_var is None:\n",
    "        ldl_var = _find_numeric_col(ldl_tg, preferred=[\"LBDLDL\",\"LBDLDLD\",\"LBDLDLL\"], fallback_regex=r\"\\bLDL\\b|^LB.DLDL\")\n",
    "    tg_var  = _find_numeric_col(ldl_tg, preferred=[\"LBXTR\"],                        fallback_regex=r\"\\bTRI?G|^LB..TR$\")\n",
    "\n",
    "    # Keep frames\n",
    "    tc_keep  = tc_hdl[[\"SEQN\", tc_var ]].rename(columns={tc_var : \"total_chol_mgdl\"}) if tc_var  else pd.DataFrame(columns=[\"SEQN\",\"total_chol_mgdl\"])\n",
    "    hdl_keep = tc_hdl[[\"SEQN\", hdl_var]].rename(columns={hdl_var: \"hdl_mgdl\"})       if hdl_var else pd.DataFrame(columns=[\"SEQN\",\"hdl_mgdl\"])\n",
    "    ldl_keep = (tc_hdl if (ldl_var and ldl_var in tc_hdl.columns) else ldl_tg)\n",
    "    ldl_keep = ldl_keep[[\"SEQN\", ldl_var]].rename(columns={ldl_var: \"ldl_mgdl\"})     if ldl_var else pd.DataFrame(columns=[\"SEQN\",\"ldl_mgdl\"])\n",
    "    tg_keep  = ldl_tg[[\"SEQN\", tg_var]].rename(columns={tg_var: \"trig\"})             if tg_var  else pd.DataFrame(columns=[\"SEQN\",\"trig\"])\n",
    "\n",
    "    # --- Build SEQN universe: union of sources ---\n",
    "    bases = [f for f in (bpq_keep, tc_keep, hdl_keep, ldl_keep, tg_keep) if not f.empty]\n",
    "    if not bases:\n",
    "        return pd.DataFrame(columns=[\"SEQN\",\"period\",\"chol_rx2\",\"hc_dx\",\"hc_lab200\",\"total_chol_mgdl\",\"hdl_mgdl\",\"ldl_mgdl\",\"trig\"])\n",
    "\n",
    "    base = bases[0][[\"SEQN\"]].copy()\n",
    "    for f in bases[1:]:\n",
    "        base = base.merge(f[[\"SEQN\"]], on=\"SEQN\", how=\"outer\")\n",
    "\n",
    "    # --- Merge person-level data ---\n",
    "    df = base\n",
    "    if not bpq_keep.empty: df = df.merge(bpq_keep, how=\"left\", on=\"SEQN\")\n",
    "    if not tc_keep.empty:  df = df.merge(tc_keep,  how=\"left\", on=\"SEQN\")\n",
    "    if not hdl_keep.empty: df = df.merge(hdl_keep, how=\"left\", on=\"SEQN\")\n",
    "    if not ldl_keep.empty: df = df.merge(ldl_keep, how=\"left\", on=\"SEQN\")\n",
    "    if not tg_keep.empty:  df = df.merge(tg_keep,  how=\"left\", on=\"SEQN\")\n",
    "\n",
    "    # Normalize lab dtypes\n",
    "    for c in [\"total_chol_mgdl\",\"hdl_mgdl\",\"ldl_mgdl\",\"trig\"]:\n",
    "        if c not in df.columns: df[c] = pd.NA\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(\"Float64\")\n",
    "\n",
    "    # Friedewald LDL for summaries (not used in SAS flag)\n",
    "    need_calc = df[\"ldl_mgdl\"].isna()\n",
    "    if need_calc.any() and df[\"total_chol_mgdl\"].notna().any() and df[\"hdl_mgdl\"].notna().any() and df[\"trig\"].notna().any():\n",
    "        ldl_est = _friedewald_ldl(df[\"total_chol_mgdl\"], df[\"hdl_mgdl\"], df[\"trig\"])\n",
    "        df.loc[need_calc, \"ldl_mgdl\"] = ldl_est.loc[need_calc]\n",
    "\n",
    "    # --- SAS rule ---\n",
    "    df[\"hc_lab200\"] = (df[\"total_chol_mgdl\"] > 200).astype(\"Int64\")\n",
    "    dx = pd.to_numeric(df.get(\"hc_dx\"), errors=\"coerce\").fillna(0).astype(int)\n",
    "    lab = pd.to_numeric(df.get(\"hc_lab200\"), errors=\"coerce\").fillna(0).astype(int)\n",
    "    df[\"chol_rx2\"] = ((dx == 1) | (lab == 1)).astype(int)\n",
    "\n",
    "    df[\"period\"] = label\n",
    "    keep = [\"SEQN\",\"period\",\"chol_rx2\",\"hc_dx\",\"hc_lab200\",\"total_chol_mgdl\",\"hdl_mgdl\",\"ldl_mgdl\",\"trig\"]\n",
    "    return df[keep]\n",
    "\n",
    "# =========================\n",
    "# Build 1999–2018\n",
    "# =========================\n",
    "dfs = []\n",
    "for suf, lab in CYCLES:\n",
    "    d = build_cycle_df(suf, lab)\n",
    "    if not d.empty: dfs.append(d)\n",
    "\n",
    "df_99_18 = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame(\n",
    "    columns=[\"SEQN\",\"period\",\"chol_rx2\",\"hc_dx\",\"hc_lab200\",\"total_chol_mgdl\",\"hdl_mgdl\",\"ldl_mgdl\",\"trig\"]\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Unweighted QC\n",
    "# =========================\n",
    "qc_unw = (\n",
    "    df_99_18.groupby(\"period\", dropna=False)\n",
    "            .agg(n=(\"SEQN\",\"count\"),\n",
    "                 chol_rx2_rate=(\"chol_rx2\",\"mean\"),\n",
    "                 dx_rate=(\"hc_dx\",\"mean\"),\n",
    "                 lab200_rate=(\"hc_lab200\",\"mean\"),\n",
    "                 mean_tc=(\"total_chol_mgdl\",\"mean\"),\n",
    "                 mean_hdl=(\"hdl_mgdl\",\"mean\"),\n",
    "                 mean_ldl=(\"ldl_mgdl\",\"mean\"))\n",
    "            .round(3)\n",
    "            .sort_index()\n",
    ")\n",
    "print(\"\\n=== Unweighted QC (SAS-aligned, 1999–2018) ===\")\n",
    "print(qc_unw)\n",
    "\n",
    "# =========================\n",
    "# Weighted QC (WTMEC2YR by 2-yr cycle)\n",
    "# =========================\n",
    "def fetch_demo_weight_for_cycle(suffix: str):\n",
    "    folder = _base_folder(suffix)\n",
    "    d = _try_read_xpt(_url(folder, f\"DEMO{suffix}\"))\n",
    "    if d.empty:\n",
    "        return pd.DataFrame({\"SEQN\": pd.Series(dtype=\"Int64\"), \"W\": pd.Series(dtype=\"float\")})\n",
    "    w = pd.to_numeric(d.get(\"WTMEC2YR\"), errors=\"coerce\")\n",
    "    out = d[[\"SEQN\"]].copy()\n",
    "    out[\"W\"] = w if w is not None else 1.0\n",
    "    return out\n",
    "\n",
    "rows = []\n",
    "for suf, lab in CYCLES:\n",
    "    demo = fetch_demo_weight_for_cycle(suf)\n",
    "    d = df_99_18[df_99_18[\"period\"] == lab].merge(demo, on=\"SEQN\", how=\"left\")\n",
    "    rows.append({\n",
    "        \"period\": lab,\n",
    "        \"w_union\":   round(wmean(d[\"chol_rx2\"],        d[\"W\"]), 3),\n",
    "        \"w_dx\":      round(wmean(d[\"hc_dx\"],           d[\"W\"]), 3),\n",
    "        \"w_lab200\":  round(wmean(d[\"hc_lab200\"],       d[\"W\"]), 3),\n",
    "        \"w_mean_tc\": round(wmean(d[\"total_chol_mgdl\"], d[\"W\"]), 1),\n",
    "        \"w_mean_hdl\":round(wmean(d[\"hdl_mgdl\"],        d[\"W\"]), 1),\n",
    "        \"w_mean_ldl\":round(wmean(d[\"ldl_mgdl\"],        d[\"W\"]), 1),\n",
    "    })\n",
    "\n",
    "qc_w = pd.DataFrame(rows).set_index(\"period\").sort_index()\n",
    "print(\"\\n=== Weighted QC (WTMEC2YR; SAS-aligned, 1999–2018) ===\")\n",
    "print(qc_w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a1060a-742a-4f73-b8a6-676420b33020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cc89fa-5f3f-4cb3-aa9b-5314fffdf5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178b6003-e34d-4958-8748-a47b34449d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fba94f-e3c4-4489-b09d-60e9c17fec0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab28178-e790-4f50-a672-ea88c816be82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba9704e-fc2c-4877-a191-be44ddf6c1a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
