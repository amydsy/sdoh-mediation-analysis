{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2da36e1",
   "metadata": {},
   "source": [
    "\n",
    "# covariates_builder_9923.ipynb\n",
    "\n",
    "A readable notebook version of the NHANES **1999–2023 Covariates Builder**.\n",
    "\n",
    "**What this builds (to your `Config.out_dir`):**\n",
    "- `cov_smk_1999_2023.parquet`\n",
    "- `cov_alc_1999_2023.parquet`\n",
    "- `cov_pa_1999_2023.parquet`\n",
    "- `cov_bmx_1999_2023.parquet`\n",
    "- `cov_clinical_1999_2023.parquet`\n",
    "- `cov_household_1999_2023.parquet`\n",
    "- `cov_core_1999_2023.parquet`\n",
    "\n",
    "Tip: keep this notebook for reading, and call the functions from your thin `02_build_covariates.ipynb`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c388470",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc5daf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Display options (optional)\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6400001",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d61eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Base project folder (adjust if needed)\n",
    "BASE = Path(\"/Users/dengshuyue/Desktop/SDOH/analysis\")\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Where inputs/outputs live\n",
    "    raw_dir: Path = BASE / \"data\"\n",
    "    interim_dir: Path = BASE / \"data\" / \"cov\"\n",
    "    out_dir: Path = BASE / \"output\"\n",
    "\n",
    "    # Preferred inputs\n",
    "    demo_9923: Path = BASE / \"data\" / \"cov\" / \"demo9923.parquet\"\n",
    "    demo_9918: Optional[Path] = None\n",
    "\n",
    "    bmx_9923: Optional[Path] = None\n",
    "\n",
    "    smk_9918: Optional[Path] = None\n",
    "    smk_1923: Optional[Path] = None\n",
    "\n",
    "    pa_9918_imputed: Optional[Path] = None\n",
    "    pa_1923: Optional[Path] = None\n",
    "\n",
    "    clinical_9918: Optional[Path] = None\n",
    "    clinical_1923: Optional[Path] = None\n",
    "\n",
    "    # Output file names\n",
    "    cov_smk: str = \"cov_smk_1999_2023.parquet\"\n",
    "    cov_alc: str = \"cov_alc_1999_2023.parquet\"\n",
    "    cov_pa: str = \"cov_pa_1999_2023.parquet\"\n",
    "    cov_bmx: str = \"cov_bmx_1999_2023.parquet\"\n",
    "    cov_clinical: str = \"cov_clinical_1999_2023.parquet\"\n",
    "    cov_household: str = \"cov_household_1999_2023.parquet\"\n",
    "    cov_core: str = \"cov_core_1999_2023.parquet\"\n",
    "\n",
    "CONFIG = Config()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6e990f",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5264c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NHANES_MISS = {7, 9, 77, 99, 777, 999, 7777, 9999, 77777, 99999}\n",
    "\n",
    "def log(msg: str) -> None:\n",
    "    print(msg, flush=True)\n",
    "\n",
    "def ensure_dir(p: Path) -> None:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def upper_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    d = df.copy()\n",
    "    d.columns = [c.upper() for c in d.columns]\n",
    "    return d\n",
    "\n",
    "def nhanes_na(s: pd.Series) -> pd.Series:\n",
    "    return pd.to_numeric(s, errors=\"coerce\").mask(lambda x: x.isin(NHANES_MISS))\n",
    "\n",
    "def read_any(p: Path) -> pd.DataFrame:\n",
    "    return pd.read_parquet(p) if p.suffix == \".parquet\" else pd.read_csv(p, low_memory=False)\n",
    "\n",
    "def pick_first_existing(*candidates: Optional[Path]) -> Optional[Path]:\n",
    "    for c in candidates:\n",
    "        if c and Path(c).exists():\n",
    "            return Path(c)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa3c2c0",
   "metadata": {},
   "source": [
    "## Smoking (SMQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a93e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMK_STATUS_CATS = pd.CategoricalDtype([\"NEVER\", \"FORMER\", \"CURRENT\"], ordered=True)\n",
    "\n",
    "def build_smk(cfg: Config = CONFIG) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build smoking covariates with tolerant inputs.\n",
    "\n",
    "    Accepts either a pre-standardized stack (columns already include:\n",
    "      SEQN, SMK_STATUS, CIGS_PER_DAY, PACK_YEARS, FORMER_SMOKER)\n",
    "    OR derives those columns from common legacy/raw fields:\n",
    "      - SMK (1=NEVER, 2=FORMER, 3=CURRENT)\n",
    "      - SMK_AVG (cigs/day)\n",
    "      - PACK_YR (pack-years)\n",
    "      - SMK_YR (years smoked)\n",
    "      - Optionally SMQ020/SMQ040/SMQ050Q/SMQ050U/SMD030 if present\n",
    "    \"\"\"\n",
    "    ensure_dir(cfg.out_dir)\n",
    "\n",
    "    def _read_any(p: Path) -> pd.DataFrame:\n",
    "        return pd.read_parquet(p) if str(p).endswith(\".parquet\") else pd.read_csv(p, low_memory=False)\n",
    "\n",
    "    # 1) Locate sources (prefer combined 99–23; else 99–18 (+ optional 19–23))\n",
    "    smk_9923 = pick_first_existing(\n",
    "        cfg.interim_dir / \"smk_9923.parquet\",\n",
    "        cfg.interim_dir / \"smk_9923.csv\",\n",
    "    )\n",
    "    if smk_9923:\n",
    "        smk = upper_df(_read_any(smk_9923))\n",
    "        src_msg = f\"using {smk_9923.name}\"\n",
    "    else:\n",
    "        p9918 = pick_first_existing(cfg.smk_9918, cfg.interim_dir / \"smk_9918.parquet\", cfg.interim_dir / \"smk_9918.csv\")\n",
    "        p1923 = pick_first_existing(cfg.smk_1923, cfg.interim_dir / \"smk_1923.parquet\", cfg.interim_dir / \"smk_1923.csv\")\n",
    "        if p9918 is None:\n",
    "            raise FileNotFoundError(\"Provide smk_9923 or smk_9918 (csv/parquet) under interim.\")\n",
    "        smk = upper_df(_read_any(p9918))\n",
    "        if p1923:\n",
    "            smk = pd.concat([smk, upper_df(_read_any(p1923))], ignore_index=True)\n",
    "            src_msg = f\"using {Path(p9918).name} + {Path(p1923).name}\"\n",
    "        else:\n",
    "            src_msg = f\"using {Path(p9918).name}\"\n",
    "\n",
    "    # 2) If standardized columns already exist, just use them\n",
    "    needed = {\"SEQN\", \"SMK_STATUS\", \"CIGS_PER_DAY\", \"PACK_YEARS\", \"FORMER_SMOKER\"}\n",
    "    have_std = needed.issubset(set(smk.columns))\n",
    "\n",
    "    if not have_std:\n",
    "        # 3) Derive standardized columns from legacy/raw fields\n",
    "        d = smk.copy()\n",
    "\n",
    "        # Drop obvious junk index cols if present\n",
    "        for junk in [\"UNNAMED: 0\", \"INDEX\"]:\n",
    "            if junk in d.columns:\n",
    "                d = d.drop(columns=[junk])\n",
    "\n",
    "        out = pd.DataFrame({\"SEQN\": d[\"SEQN\"]})\n",
    "\n",
    "        # --- SMK_STATUS ---\n",
    "        # Priority 1: direct SMK_STATUS if it exists but wasn’t part of 'needed'\n",
    "        if \"SMK_STATUS\" in d.columns:\n",
    "            smk_status = d[\"SMK_STATUS\"].astype(\"string\").str.strip().str.upper()\n",
    "        else:\n",
    "            # Priority 2: numeric SMK (1=NEVER,2=FORMER,3=CURRENT)\n",
    "            smk_num = pd.to_numeric(d.get(\"SMK\"), errors=\"coerce\")\n",
    "            smk_status = smk_num.map({1: \"NEVER\", 2: \"FORMER\", 3: \"CURRENT\"}).astype(\"string\")\n",
    "\n",
    "            # Priority 3: derive from SMQ020/SMQ040 if available\n",
    "            if smk_status.isna().all() and ((\"SMQ020\" in d.columns) or (\"SMQ040\" in d.columns)):\n",
    "                ever = d.get(\"SMQ020\")  # 1=Yes (ever 100 cigs), 2=No\n",
    "                if ever is not None:\n",
    "                    ever = pd.to_numeric(ever, errors=\"coerce\").replace({2: 0, 1: 1})\n",
    "                smq040 = pd.to_numeric(d.get(\"SMQ040\"), errors=\"coerce\")  # 1=Every day,2=Some days,3=Not at all\n",
    "\n",
    "                # default NEVER; flip to FORMER/CURRENT based on ever/smq040\n",
    "                smk_status = pd.Series(\"NEVER\", index=d.index, dtype=\"string\")\n",
    "                if ever is not None:\n",
    "                    smk_status = smk_status.mask(ever == 1, \"FORMER\")\n",
    "                if smq040 is not None:\n",
    "                    smk_status = smk_status.mask(smq040.isin([1, 2]), \"CURRENT\")\n",
    "                    smk_status = smk_status.mask(smq040 == 3, \"FORMER\")\n",
    "\n",
    "        out[\"SMK_STATUS\"] = smk_status.astype(\"string\").str.upper()\n",
    "\n",
    "        # --- CIGS_PER_DAY ---\n",
    "        cigs = pd.to_numeric(d.get(\"SMK_AVG\"), errors=\"coerce\")  # your legacy field\n",
    "        if cigs.isna().all():\n",
    "            # try SMQ050Q/U (quantity + unit 1=day,2=week,3=month)\n",
    "            q = pd.to_numeric(d.get(\"SMQ050Q\"), errors=\"coerce\")\n",
    "            u = pd.to_numeric(d.get(\"SMQ050U\"), errors=\"coerce\")\n",
    "            if q is not None and u is not None:\n",
    "                cigs = (\n",
    "                    q.where(u == 1)\n",
    "                    .fillna((q / 7.0).where(u == 2))\n",
    "                    .fillna((q / 30.0).where(u == 3))\n",
    "                )\n",
    "        out[\"CIGS_PER_DAY\"] = cigs\n",
    "\n",
    "        # --- PACK_YEARS ---\n",
    "        pack_years = pd.to_numeric(d.get(\"PACK_YR\"), errors=\"coerce\")\n",
    "        if pack_years.isna().all():\n",
    "            years = pd.to_numeric(d.get(\"SMK_YR\"), errors=\"coerce\")\n",
    "            if years is None or years.isna().all():\n",
    "                years = pd.to_numeric(d.get(\"SMD030\"), errors=\"coerce\")  # years smoked in some SMQ cycles\n",
    "            pack_years = (out[\"CIGS_PER_DAY\"] / 20.0) * years\n",
    "        out[\"PACK_YEARS\"] = pack_years\n",
    "\n",
    "        # --- FORMER_SMOKER ---\n",
    "        out[\"FORMER_SMOKER\"] = out[\"SMK_STATUS\"].eq(\"FORMER\").fillna(False).astype(\"int8\")\n",
    "\n",
    "        # Clean up obviously invalid values\n",
    "        out.loc[out[\"CIGS_PER_DAY\"] < 0, \"CIGS_PER_DAY\"] = np.nan\n",
    "        out.loc[out[\"PACK_YEARS\"] < 0, \"PACK_YEARS\"] = np.nan\n",
    "\n",
    "        smk_std = out\n",
    "\n",
    "    else:\n",
    "        # Already standardized\n",
    "        smk_std = smk[list(needed)].copy()\n",
    "        smk_std[\"SMK_STATUS\"] = smk_std[\"SMK_STATUS\"].astype(\"string\").str.upper()\n",
    "        smk_std[\"FORMER_SMOKER\"] = pd.to_numeric(smk_std[\"FORMER_SMOKER\"], errors=\"coerce\").fillna(0).astype(\"int8\")\n",
    "\n",
    "    # 4) Final tidy + write\n",
    "    smk_std = smk_std.drop_duplicates(\"SEQN\")\n",
    "    smk_std[\"SMK_STATUS\"] = smk_std[\"SMK_STATUS\"].astype(\"category\").cat.set_categories(SMK_STATUS_CATS.categories, ordered=True)\n",
    "    outp = cfg.out_dir / cfg.cov_smk\n",
    "    smk_std.to_parquet(outp, index=False)\n",
    "\n",
    "    # Light telemetry\n",
    "    miss_rate = smk_std[[\"SMK_STATUS\", \"CIGS_PER_DAY\", \"PACK_YEARS\"]].isna().mean().round(3).to_dict()\n",
    "    log(f\"✓ SMK → {outp} ({src_msg}); missing: {miss_rate}\")\n",
    "\n",
    "    return smk_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b076035",
   "metadata": {},
   "source": [
    "## Alcohol (ALQ) 99-23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c98addf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Alcohol builder with optional CDC fetch (revised) ----------\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# --- tiny local helpers (safe fallbacks if your notebook didn't define them) ---\n",
    "def upper_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.columns = [c.upper() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "def ensure_dir(p: Path | str):\n",
    "    Path(p).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def pick_first_existing(*paths):\n",
    "    for p in paths:\n",
    "        if p and Path(p).exists():\n",
    "            return Path(p)\n",
    "    return None\n",
    "\n",
    "def log(msg: str):  # nice-to-have\n",
    "    print(msg)\n",
    "\n",
    "# --- IO helpers ---\n",
    "def _read_any(p: Path) -> pd.DataFrame:\n",
    "    p = Path(p)\n",
    "    if p.suffix.lower() == \".parquet\":\n",
    "        return pd.read_parquet(p)\n",
    "    return pd.read_csv(p, low_memory=False)\n",
    "\n",
    "def _clean_num(s: pd.Series) -> pd.Series:\n",
    "    NH_MISS = {7, 9, 77, 99, 777, 999, 7777, 9999, 77777, 99999}\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    return s.mask(s.isin(NH_MISS))\n",
    "\n",
    "def _download(url: str, dest: Path, timeout=90):\n",
    "    import requests\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    headers = {\"User-Agent\": \"nhanes-fetch/1.0\"}\n",
    "    with requests.get(url, headers=headers, stream=True, timeout=timeout) as r:\n",
    "        r.raise_for_status()\n",
    "        tmp = dest.with_suffix(dest.suffix + \".downloading\")\n",
    "        with open(tmp, \"wb\") as f:\n",
    "            for chunk in r.iter_content(1 << 15):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        tmp.rename(dest)\n",
    "    return dest\n",
    "\n",
    "def _read_xpt(p: Path) -> pd.DataFrame:\n",
    "    try:\n",
    "        import pyreadstat\n",
    "        df, _ = pyreadstat.read_xport(p)\n",
    "    except Exception:\n",
    "        df = pd.read_sas(p, format=\"xport\")\n",
    "    df.columns = [c.upper() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "# --- minimal DEMO sex loader (RIAGENDR) ---\n",
    "def _ensure_demo_sex(cfg) -> pd.DataFrame:\n",
    "    \"\"\"Return DEMO with SEQN, RIAGENDR. Try configured paths; else build minimal by fetching.\"\"\"\n",
    "    # 1) Try configured demo\n",
    "    demo_path = None\n",
    "    for cand in [\n",
    "        getattr(cfg, \"demo_9923\", None),\n",
    "        getattr(cfg, \"demo_9918\", None),\n",
    "        cfg.interim_dir / \"demo_9923.parquet\",\n",
    "        cfg.interim_dir / \"demo_9918.parquet\",\n",
    "    ]:\n",
    "        if cand and Path(cand).exists():\n",
    "            demo_path = Path(cand)\n",
    "            break\n",
    "    if demo_path:\n",
    "        demo = _read_any(demo_path)\n",
    "        demo = upper_df(demo)\n",
    "        if \"RIAGENDR\" in demo.columns:\n",
    "            return demo[[\"SEQN\", \"RIAGENDR\"]].drop_duplicates(\"SEQN\")\n",
    "\n",
    "    # 2) Build minimal by fetching RIAGENDR across cycles\n",
    "    DEMO_URLS = {\n",
    "        \"1999-2000\": [\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/1999/DataFiles/DEMO.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/1999-2000/DEMO.XPT\",\n",
    "        ],\n",
    "        \"2001-2002\": [\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2001/DataFiles/DEMO_B.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/2001-2002/DEMO_B.XPT\",\n",
    "        ],\n",
    "        \"2003-2004\": [\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2003/DataFiles/DEMO_C.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/2003-2004/DEMO_C.XPT\",\n",
    "        ],\n",
    "        \"2005-2006\": [\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2005/DataFiles/DEMO_D.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/2005-2006/DEMO_D.XPT\",\n",
    "        ],\n",
    "        \"2007-2008\": [\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2007/DataFiles/DEMO_E.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/2007-2008/DEMO_E.XPT\",\n",
    "        ],\n",
    "        \"2009-2010\": [\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2009/DataFiles/DEMO_F.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/2009-2010/DEMO_F.XPT\",\n",
    "        ],\n",
    "        \"2011-2012\": [\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2011/DataFiles/DEMO_G.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/2011-2012/DEMO_G.XPT\",\n",
    "        ],\n",
    "        \"2013-2014\": [\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2013/DataFiles/DEMO_H.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/DEMO_H.XPT\",\n",
    "        ],\n",
    "        \"2015-2016\": [\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2015/DataFiles/DEMO_I.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DEMO_I.XPT\",\n",
    "        ],\n",
    "        \"2017-2018\": [\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/DEMO_J.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/DEMO_J.XPT\",\n",
    "        ],\n",
    "        \"2017-March 2020 (pre-pandemic)\": [\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/P_DEMO.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/2017-2020/P_DEMO.XPT\",\n",
    "        ],\n",
    "        \"August 2021–August 2023\": [\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2021/DataFiles/DEMO_L.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/2021-2023/DEMO_L.XPT\",\n",
    "        ],\n",
    "    }\n",
    "    store = Path(cfg.interim_dir)\n",
    "    parts = []\n",
    "    for cyc, urls in DEMO_URLS.items():\n",
    "        got = None\n",
    "        for u in urls:\n",
    "            try:\n",
    "                dst = store / Path(u).name\n",
    "                if not dst.exists():\n",
    "                    print(f\"⬇️ DEMO {cyc} → {dst.name}\")\n",
    "                    _download(u, dst)\n",
    "                got = dst\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(\"  ⚠️\", e)\n",
    "        if got is None:\n",
    "            continue\n",
    "        df = _read_xpt(got)\n",
    "        if {\"SEQN\", \"RIAGENDR\"}.issubset(df.columns):\n",
    "            parts.append(df[[\"SEQN\", \"RIAGENDR\"]])\n",
    "    if not parts:\n",
    "        raise RuntimeError(\"Could not build minimal DEMO (RIAGENDR).\")\n",
    "    demo = pd.concat(parts, ignore_index=True).drop_duplicates(\"SEQN\")\n",
    "    out_demo = store / \"demo_riagendr_min.parquet\"\n",
    "    demo.to_parquet(out_demo, index=False)\n",
    "    return demo\n",
    "\n",
    "# --- ALQ downloader/stacker ---\n",
    "def _download_and_stack_alq(cfg) -> pd.DataFrame:\n",
    "    \"\"\"Download ALQ XPTs to interim/alcohol/, stack minimal columns used for dpd.\"\"\"\n",
    "    ALC_STORE = Path(cfg.interim_dir) / \"alcohol\"\n",
    "    ALC_STORE.mkdir(parents=True, exist_ok=True)\n",
    "    ALQ_URLS = {\n",
    "        \"1999-2000\": [\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/1999/DataFiles/ALQ.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/1999-2000/ALQ.XPT\",\n",
    "        ],\n",
    "        \"2001-2002\": [\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2001/DataFiles/ALQ_B.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/2001-2002/ALQ_B.XPT\",\n",
    "        ],\n",
    "        \"2003-2004\": [\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2003/DataFiles/ALQ_C.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/2003-2004/ALQ_C.XPT\",\n",
    "        ],\n",
    "        \"2005-2006\": [\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2005/DataFiles/ALQ_D.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/2005-2006/ALQ_D.XPT\",\n",
    "        ],\n",
    "        \"2007-2008\": [\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2007/DataFiles/ALQ_E.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/2007-2008/ALQ_E.XPT\",\n",
    "        ],\n",
    "        \"2009-2010\": [\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2009/DataFiles/ALQ_F.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/2009-2010/ALQ_F.XPT\",\n",
    "        ],\n",
    "        \"2011-2012\": [\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2011/DataFiles/ALQ_G.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/2011-2012/ALQ_G.XPT\",\n",
    "        ],\n",
    "        \"2013-2014\": [\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2013/DataFiles/ALQ_H.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/ALQ_H.XPT\",\n",
    "        ],\n",
    "        \"2015-2016\": [\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2015/DataFiles/ALQ_I.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/ALQ_I.XPT\",\n",
    "        ],\n",
    "        \"2017-2018\": [\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/ALQ_J.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/ALQ_J.XPT\",\n",
    "        ],\n",
    "        \"2017-March 2020 (pre-pandemic)\": [\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/P_ALQ.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/2017-2020/P_ALQ.XPT\",\n",
    "        ],\n",
    "        \"August 2021–August 2023\": [\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2021/DataFiles/ALQ_L.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/2021-2023/ALQ_L.XPT\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2021/DataFiles/ALQ_Q.xpt\",\n",
    "            \"https://wwwn.cdc.gov/Nchs/Nhanes/2021-2023/ALQ_Q.XPT\",\n",
    "        ],\n",
    "    }\n",
    "    parts = []\n",
    "    for cycle, urls in ALQ_URLS.items():\n",
    "        got = None\n",
    "        for u in urls:\n",
    "            try:\n",
    "                dst = ALC_STORE / Path(u).name\n",
    "                if not dst.exists():\n",
    "                    print(f\"⬇️ ALQ {cycle} → {dst.name}\")\n",
    "                    _download(u, dst)\n",
    "                got = dst\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(\"  ⚠️\", e)\n",
    "        if got is None:\n",
    "            continue\n",
    "        df = _read_xpt(got)\n",
    "        df[\"CYCLE\"] = cycle\n",
    "        keep = [c for c in [\"SEQN\", \"CYCLE\", \"ALQ110\", \"ALQ151\", \"ALQ120Q\", \"ALQ120U\", \"ALQ130\"] if c in df.columns]\n",
    "        parts.append(df[keep])\n",
    "    if not parts:\n",
    "        raise RuntimeError(\"No ALQ data available (download failed).\")\n",
    "    alq = pd.concat(parts, ignore_index=True)\n",
    "    # Persist stacked ALQ for reuse\n",
    "    stacked = Path(cfg.interim_dir) / \"alq_9923.parquet\"\n",
    "    stacked.parent.mkdir(parents=True, exist_ok=True)\n",
    "    alq.to_parquet(stacked, index=False)\n",
    "    return alq\n",
    "\n",
    "# --- derive drinks/day ---\n",
    "def _drinks_per_day_from_alq(alq: pd.DataFrame) -> pd.Series:\n",
    "    d = upper_df(alq)\n",
    "    count = _clean_num(d.get(\"ALQ120Q\", pd.Series(np.nan, index=d.index)))\n",
    "    unit  = d.get(\"ALQ120U\", pd.Series(np.nan, index=d.index))\n",
    "    per_year = pd.Series(np.nan, index=d.index, dtype=\"float\")\n",
    "    per_year = per_year.where(~(unit == 1), 365.0)\n",
    "    per_year = per_year.where(~(unit == 2), 52.142)\n",
    "    per_year = per_year.where(~(unit == 3), 12.0)\n",
    "    per_year = per_year.where(~(unit == 4), 1.0)\n",
    "    occasions_per_year = count * per_year\n",
    "\n",
    "    drinks_per_occasion = _clean_num(d.get(\"ALQ130\", pd.Series(np.nan, index=d.index)))\n",
    "    dpd = (occasions_per_year * drinks_per_occasion) / 365.0\n",
    "    return dpd.where(occasions_per_year.notna() & drinks_per_occasion.notna())\n",
    "\n",
    "# --- categorize with explicit index alignment (fixes FutureWarning) ---\n",
    "def _categorize_alcohol(dpd: pd.Series, sex: pd.Series, lifetime_lt12: pd.Series | None) -> pd.Series:\n",
    "    # Normalize inputs and drop index labels to ensure 1:1 positional alignment\n",
    "    dpd  = pd.to_numeric(dpd, errors=\"coerce\").reset_index(drop=True)\n",
    "    sexM = pd.to_numeric(sex, errors=\"coerce\").map({1: \"M\", 2: \"F\"}).astype(\"string\").reset_index(drop=True)\n",
    "    if lifetime_lt12 is None:\n",
    "        life = pd.Series(pd.NA, index=dpd.index)\n",
    "    else:\n",
    "        life = pd.to_numeric(lifetime_lt12, errors=\"coerce\").reset_index(drop=True)\n",
    "\n",
    "    # Masks (now same RangeIndex → no alignment warning)\n",
    "    none_mask     = dpd.isna() | (dpd < 0.03) | (life == 1)               # <12 lifetime OR <0.03/day\n",
    "    heavy_mask    = ((sexM == \"F\") & (dpd >= 1.0)) | ((sexM == \"M\") & (dpd >= 2.0))\n",
    "    moderate_mask = (~none_mask) & (~heavy_mask)\n",
    "\n",
    "    cat = pd.Series(\"NONE\", index=dpd.index, dtype=\"string\")\n",
    "    cat.loc[moderate_mask] = \"MODERATE\"\n",
    "    cat.loc[heavy_mask]    = \"HEAVY\"\n",
    "    return pd.Categorical(cat, categories=[\"NONE\", \"MODERATE\", \"HEAVY\"], ordered=True)\n",
    "\n",
    "# --- public builder ---\n",
    "def build_alc(cfg: \"Config\" = CONFIG, allow_fetch: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build alcohol covariates.\n",
    "      • Prefer existing output in cfg.out_dir\n",
    "      • Else prefer stacked ALQ in cfg.interim_dir\n",
    "      • Else, if allow_fetch: download ALQ XPTs and stack\n",
    "    Writes {cfg.out_dir}/{cfg.cov_alc}\n",
    "    \"\"\"\n",
    "    ensure_dir(cfg.out_dir)\n",
    "\n",
    "    # A) If already built, return it\n",
    "    out_path = Path(cfg.out_dir) / cfg.cov_alc\n",
    "    if out_path.exists():\n",
    "        return pd.read_parquet(out_path)\n",
    "\n",
    "    # B) Load ALQ stack (prefer 99–23, else 99–18). If missing and allowed, fetch.\n",
    "    alq_path = pick_first_existing(\n",
    "        Path(cfg.interim_dir) / \"alq_9923.parquet\",\n",
    "        Path(cfg.interim_dir) / \"alq_9918.parquet\",\n",
    "    )\n",
    "    if alq_path:\n",
    "        alq = _read_any(alq_path)\n",
    "    else:\n",
    "        if not allow_fetch:\n",
    "            raise FileNotFoundError(\n",
    "                \"ALQ stack not found (alq_9923 / alq_9918). Set allow_fetch=True to download from CDC.\"\n",
    "            )\n",
    "        alq = _download_and_stack_alq(cfg)\n",
    "\n",
    "    alq = upper_df(alq)\n",
    "    dpd = _drinks_per_day_from_alq(alq)\n",
    "\n",
    "    # lifetime <12 drinks indicator\n",
    "    life = None\n",
    "    if \"ALQ110\" in alq.columns:\n",
    "        life = (pd.to_numeric(alq[\"ALQ110\"], errors=\"coerce\") == 2).astype(\"Int8\")\n",
    "    elif \"ALQ151\" in alq.columns:\n",
    "        life = (pd.to_numeric(alq[\"ALQ151\"], errors=\"coerce\") == 2).astype(\"Int8\")\n",
    "\n",
    "    # Bring in sex (1=male, 2=female) aligned to ALQ rows\n",
    "    demo = _ensure_demo_sex(cfg)\n",
    "    demo = upper_df(demo).drop_duplicates(\"SEQN\")\n",
    "    sex = demo.set_index(\"SEQN\").reindex(alq[\"SEQN\"])[\"RIAGENDR\"]\n",
    "\n",
    "    # Categorize with aligned masks\n",
    "    alc_cat = _categorize_alcohol(dpd, sex=sex, lifetime_lt12=life)\n",
    "\n",
    "    out = pd.DataFrame(\n",
    "        {\n",
    "            \"SEQN\": alq[\"SEQN\"].reset_index(drop=True),\n",
    "            \"DRINKS_PER_DAY\": pd.to_numeric(dpd, errors=\"coerce\").reset_index(drop=True),\n",
    "            \"ALCOHOL_CAT\": alc_cat,\n",
    "        }\n",
    "    )\n",
    "    out.to_parquet(out_path, index=False)\n",
    "    log(f\"✓ ALC → {out_path}\")\n",
    "    return out\n",
    "# ---------- end alcohol builder (revised) ----------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45bcd18",
   "metadata": {},
   "source": [
    "## Physical Activity (PA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6433c347",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_pa(cfg: Config = CONFIG) -> pd.DataFrame:\n",
    "    ensure_dir(cfg.out_dir)\n",
    "\n",
    "    pa_9923 = pick_first_existing(\n",
    "        cfg.interim_dir / \"totalpa_9923_imputed.parquet\",\n",
    "        cfg.interim_dir / \"totalpa_9923_imputed.csv\",\n",
    "    )\n",
    "    if pa_9923:\n",
    "        pa = read_any(pa_9923)\n",
    "    else:\n",
    "        p9918 = pick_first_existing(cfg.pa_9918_imputed, cfg.interim_dir / \"totalpa_9918_imputed.parquet\", cfg.interim_dir / \"totalpa_9918_imputed.csv\")\n",
    "        if p9918 is None:\n",
    "            raise FileNotFoundError(\"Provide totalpa_9923_imputed or totalpa_9918_imputed under interim.\")\n",
    "        pa = read_any(p9918)\n",
    "        p1923 = pick_first_existing(cfg.pa_1923, cfg.interim_dir / \"totalpa_1923_imputed.parquet\", cfg.interim_dir / \"totalpa_1923_imputed.csv\")\n",
    "        if p1923:\n",
    "            pa = pd.concat([pa, read_any(p1923)], ignore_index=True)\n",
    "\n",
    "    pa = upper_df(pa)\n",
    "    if \"SEQN\" not in pa.columns:\n",
    "        raise ValueError(\"PA table missing SEQN.\")\n",
    "\n",
    "    def _find(cols, candidates):\n",
    "        for c in candidates:\n",
    "            if c in cols:\n",
    "                return c\n",
    "        return None\n",
    "\n",
    "    cols = list(pa.columns)\n",
    "    met_hr_col = _find(cols, [\"LTPA_MET_HR_WK\", \"TOTALPA_MET_HR_WK\", \"TOTPA_MET_HR_WK\", \"PA_MET_HR_WK\", \"MET_HR_WK\", \"TOTAL_PA_MET_HR_WK\"])\n",
    "    met_min_col = _find(cols, [\"LTPA_MET_MIN_WK\", \"TOTALPA_MET_MIN_WK\", \"TOTPA_MET_MIN_WK\", \"PA_MET_MIN_WK\", \"MET_MIN_WK\", \"TOTAL_PA_MET_MIN_WK\"])\n",
    "\n",
    "    if met_hr_col is not None:\n",
    "        met_hr = pd.to_numeric(pa[met_hr_col], errors=\"coerce\")\n",
    "    elif met_min_col is not None:\n",
    "        met_hr = pd.to_numeric(pa[met_min_col], errors=\"coerce\") / 60.0\n",
    "    else:\n",
    "        tot_min_col = next((c for c in cols if (\"MIN\" in c and (\"WK\" in c or \"WEEK\" in c))), None)\n",
    "        met_hr = pd.to_numeric(pa[tot_min_col], errors=\"coerce\") / 60.0 if tot_min_col else pd.Series(np.nan, index=pa.index)\n",
    "\n",
    "    flag_col = _find(cols, [\"LTPA_IMPUTED_FLAG\", \"PA_IMPUTED_FLAG\", \"TOTALPA_IMPUTED_FLAG\", \"IMPUTED_FLAG\", \"IMPUTED\"]) or                next((c for c in cols if \"IMPUT\" in c), None)\n",
    "    imputed = pd.to_numeric(pa[flag_col], errors=\"coerce\").fillna(0).astype(\"int8\") if flag_col else pd.Series(0, index=pa.index, dtype=\"int8\")\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"SEQN\": pa[\"SEQN\"],\n",
    "        \"LTPA_MET_HR_WK\": met_hr,\n",
    "        \"LTPA_IMPUTED_FLAG\": imputed,\n",
    "    })\n",
    "    outp = cfg.out_dir / cfg.cov_pa\n",
    "    out.to_parquet(outp, index=False)\n",
    "    log(f\"✓ PA  → {outp}\")\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090ac294",
   "metadata": {},
   "source": [
    "## Anthropometrics (BMX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51d739da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bmx(cfg: Config = CONFIG) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load anthropometrics (BMX), tolerate csv/parquet and 99–18 vs 99–23 stacks,\n",
    "    and compute BMI when BMXBMI is missing.\n",
    "    Writes cov_bmx_1999_2023.parquet to cfg.out_dir.\n",
    "    \"\"\"\n",
    "    ensure_dir(cfg.out_dir)\n",
    "\n",
    "    def _read_any(p: Path) -> pd.DataFrame:\n",
    "        return pd.read_parquet(p) if str(p).lower().endswith(\".parquet\") else pd.read_csv(p, low_memory=False)\n",
    "\n",
    "    # 1) Choose a source\n",
    "    if cfg.bmx_9923 and Path(cfg.bmx_9923).exists():\n",
    "        src = Path(cfg.bmx_9923)\n",
    "    else:\n",
    "        src = pick_first_existing(\n",
    "            cfg.interim_dir / \"bmx_9923.parquet\",\n",
    "            cfg.interim_dir / \"bmx_9923.csv\",\n",
    "            cfg.interim_dir / \"bmx_9918.parquet\",\n",
    "            cfg.interim_dir / \"bmx_9918.csv\",\n",
    "        )\n",
    "    if src is None:\n",
    "        raise FileNotFoundError(\n",
    "            \"BMX not found. Provide bmx_9923.parquet (preferred) or bmx_9918.parquet/csv under \"\n",
    "            f\"{cfg.interim_dir}, or set CONFIG.bmx_9923 to a file.\"\n",
    "        )\n",
    "\n",
    "    # 2) Read + normalize\n",
    "    bmx = upper_df(_read_any(src))\n",
    "    for need in [\"SEQN\", \"BMXWT\", \"BMXHT\"]:\n",
    "        if need not in bmx.columns:\n",
    "            raise ValueError(f\"BMX table missing required column: {need}\")\n",
    "\n",
    "    # helper: NaN series aligned to df\n",
    "    def nan_series(df): \n",
    "        return pd.Series(np.nan, index=df.index, dtype=\"float\")\n",
    "\n",
    "    # 3) BMI: use BMXBMI if present, else compute weight(kg) / (height(m))^2\n",
    "    bmi_src = pd.to_numeric(bmx[\"BMXBMI\"], errors=\"coerce\") if \"BMXBMI\" in bmx.columns else nan_series(bmx)\n",
    "    wt = pd.to_numeric(bmx[\"BMXWT\"], errors=\"coerce\")\n",
    "    ht_cm = pd.to_numeric(bmx[\"BMXHT\"], errors=\"coerce\")\n",
    "\n",
    "    bmi = bmi_src.copy()\n",
    "    missing = bmi.isna()\n",
    "    if missing.any():\n",
    "        bmi.loc[missing] = wt.loc[missing] / (ht_cm.loc[missing] / 100.0) ** 2\n",
    "\n",
    "    out = pd.DataFrame(\n",
    "        {\n",
    "            \"SEQN\": bmx[\"SEQN\"],\n",
    "            \"BMXWT\": wt,\n",
    "            \"BMXHT\": ht_cm,\n",
    "            \"BMI\": pd.to_numeric(bmi, errors=\"coerce\"),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    outp = cfg.out_dir / cfg.cov_bmx\n",
    "    out.to_parquet(outp, index=False)\n",
    "    log(f\"✓ BMX → {outp} (source: {src.name})\")\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d00420",
   "metadata": {},
   "source": [
    "## Clinical & Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc391756",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class ClinicalThresholds:\n",
    "    htn_sbp: float = 140.0\n",
    "    htn_dbp: float = 90.0\n",
    "    a1c_diabetes: float = 6.5\n",
    "    fpg_diabetes: float = 126.0  # mg/dL\n",
    "\n",
    "THR = ClinicalThresholds()\n",
    "\n",
    "def build_clinical(cfg: Config = CONFIG, thr: ClinicalThresholds = THR) -> pd.DataFrame:\n",
    "    ensure_dir(cfg.out_dir)\n",
    "\n",
    "    clin_9923 = pick_first_existing(cfg.interim_dir / \"clinical_9923.parquet\", cfg.interim_dir / \"clinical_9923.csv\")\n",
    "    if clin_9923:\n",
    "        clin = read_any(clin_9923)\n",
    "    else:\n",
    "        p9918 = pick_first_existing(\n",
    "            cfg.clinical_9918,\n",
    "            cfg.interim_dir / \"clinical_9918.parquet\",\n",
    "            cfg.interim_dir / \"clinical_9918.csv\",\n",
    "            cfg.interim_dir / \"nhanes_primary_anal_full_singleimputation_v2.parquet\",\n",
    "            cfg.interim_dir / \"nhanes_primary_anal_full_singleimputation_v2.csv\",\n",
    "        )\n",
    "        p1923 = pick_first_existing(cfg.clinical_1923, cfg.interim_dir / \"clinical_1923.parquet\", cfg.interim_dir / \"clinical_1923.csv\")\n",
    "        if p9918 is None:\n",
    "            raise FileNotFoundError(\"Provide clinical_9923 or clinical_9918 under interim.\")\n",
    "        clin = read_any(p9918)\n",
    "        if p1923:\n",
    "            clin = pd.concat([clin, read_any(p1923)], ignore_index=True)\n",
    "\n",
    "    clin = upper_df(clin)\n",
    "\n",
    "    # Derive BMI_CLAS if missing\n",
    "    if \"BMI_CLAS\" not in clin.columns:\n",
    "        bmi_src = None\n",
    "        bmx_path = cfg.out_dir / cfg.cov_bmx\n",
    "        if bmx_path.exists():\n",
    "            bmx = upper_df(pd.read_parquet(bmx_path))\n",
    "            if {\"SEQN\", \"BMI\"}.issubset(bmx.columns) and \"SEQN\" in clin.columns:\n",
    "                bmi_src = clin[\"SEQN\"].map(bmx.set_index(\"SEQN\")[\"BMI\"]).astype(float)\n",
    "        if bmi_src is None:\n",
    "            bmi_src = pd.to_numeric(clin.get(\"BMI\", np.nan), errors=\"coerce\")\n",
    "\n",
    "        def bmi_class(x):\n",
    "            if pd.isna(x):\n",
    "                return pd.NA\n",
    "            if x < 18.5:\n",
    "                return \"UNDER\"\n",
    "            if x < 25:\n",
    "                return \"NORMAL\"\n",
    "            if x < 30:\n",
    "                return \"OVER\"\n",
    "            return \"OBESE\"\n",
    "\n",
    "        clin[\"BMI_CLAS\"] = pd.Series([bmi_class(v) for v in bmi_src], dtype=\"string\")\n",
    "\n",
    "    # Derive HTN if missing\n",
    "    if \"HTN\" not in clin.columns:\n",
    "        sbp = pd.to_numeric(clin.get(\"SBP\", np.nan), errors=\"coerce\")\n",
    "        dbp = pd.to_numeric(clin.get(\"DBP\", np.nan), errors=\"coerce\")\n",
    "        diag_col = next((c for c in clin.columns if ((\"HTN\" in c or \"HYPERT\" in c) and \"MED\" not in c and c != \"HTN\")), None)\n",
    "        med_col = next((c for c in clin.columns if (\"MED\" in c and (\"BP\" in c or \"HYPER\" in c))), None)\n",
    "        htn = pd.Series(0, index=clin.index, dtype=\"Int8\")\n",
    "        if diag_col:\n",
    "            diag = pd.to_numeric(clin[diag_col], errors=\"coerce\")\n",
    "            htn = ((diag == 1) | (diag > 0)).astype(\"Int8\")\n",
    "        if med_col:\n",
    "            med = pd.to_numeric(clin[med_col], errors=\"coerce\")\n",
    "            htn = ((htn == 1) | (med == 1) | (med > 0)).astype(\"Int8\")\n",
    "        htn = ((htn == 1) | (sbp >= thr.htn_sbp) | (dbp >= thr.htn_dbp)).astype(\"Int8\")\n",
    "        clin[\"HTN\"] = htn\n",
    "\n",
    "    # Derive HIGH_CHOL if missing\n",
    "    if \"HIGH_CHOL\" not in clin.columns:\n",
    "        tch = pd.to_numeric(clin.get(\"TCHOL\", np.nan), errors=\"coerce\")\n",
    "        ldl = pd.to_numeric(clin.get(\"LDL\", np.nan), errors=\"coerce\")\n",
    "        med_col = next((c for c in clin.columns if (\"CHOL\" in c and \"MED\" in c)), None)\n",
    "        high = ((tch >= 240) | (ldl >= 160)).astype(\"Int8\")\n",
    "        if med_col:\n",
    "            med = pd.to_numeric(clin[med_col], errors=\"coerce\")\n",
    "            high = ((high == 1) | (med == 1) | (med > 0)).astype(\"Int8\")\n",
    "        clin[\"HIGH_CHOL\"] = high\n",
    "\n",
    "    keep = [\"SEQN\", \"BMI_CLAS\", \"DIABETES\", \"HTN\", \"HIGH_CHOL\", \"CVD\", \"CANCER\", \"SBP\", \"DBP\", \"TCHOL\", \"HDL\", \"LDL\", \"TG\"]\n",
    "    for k in keep:\n",
    "        if k not in clin.columns:\n",
    "            clin[k] = pd.Series(np.nan, index=clin.index)\n",
    "\n",
    "    out = clin[keep].copy()\n",
    "    for b in [\"DIABETES\", \"HTN\", \"HIGH_CHOL\", \"CVD\", \"CANCER\"]:\n",
    "        out[b] = pd.to_numeric(out[b], errors=\"coerce\").astype(\"Int8\")\n",
    "\n",
    "    outp = cfg.out_dir / cfg.cov_clinical\n",
    "    out.to_parquet(outp, index=False)\n",
    "    log(f\"✓ CLN → {outp}\")\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98831e35",
   "metadata": {},
   "source": [
    "## Household & Survey Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b08d357",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SURVEY_KEEP = [\"SEQN\", \"SDDSRVYR\", \"SDMVPSU\", \"SDMVSTRA\", \"WTMEC2YR\"]\n",
    "\n",
    "def build_household(cfg: Config = CONFIG) -> pd.DataFrame:\n",
    "    ensure_dir(cfg.out_dir)\n",
    "    demo = upper_df(pd.read_parquet(cfg.demo_9923))\n",
    "    if \"DMDHHSIZ\" not in demo.columns:\n",
    "        raise ValueError(\"DMDHHSIZ not found in DEMO stack.\")\n",
    "    out = demo[[\"SEQN\", \"DMDHHSIZ\"]].copy()\n",
    "    outp = cfg.out_dir / cfg.cov_household\n",
    "    out.to_parquet(outp, index=False)\n",
    "    log(f\"✓ HH  → {outp}\")\n",
    "    return out\n",
    "\n",
    "def get_survey_core(cfg: Config = CONFIG) -> pd.DataFrame:\n",
    "    demo_p = None\n",
    "    if cfg.demo_9923 and Path(cfg.demo_9923).exists():\n",
    "        demo_p = cfg.demo_9923\n",
    "    elif cfg.demo_9918 and Path(cfg.demo_9918).exists():\n",
    "        demo_p = cfg.demo_9918\n",
    "    else:\n",
    "        demo_p = pick_first_existing(cfg.interim_dir / \"demo_9923.parquet\", cfg.interim_dir / \"demo_9918.parquet\")\n",
    "    if demo_p is None:\n",
    "        raise FileNotFoundError(\"Could not find DEMO table.\")\n",
    "\n",
    "    demo = upper_df(pd.read_parquet(demo_p))\n",
    "    miss = [c for c in SURVEY_KEEP if c not in demo.columns]\n",
    "    if miss:\n",
    "        raise ValueError(f\"Missing survey fields in DEMO: {miss}\")\n",
    "    return demo[SURVEY_KEEP].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86702c27",
   "metadata": {},
   "source": [
    "## Merge to Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5711533",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_core(cfg: Config = CONFIG) -> pd.DataFrame:\n",
    "    ensure_dir(cfg.out_dir)\n",
    "\n",
    "    smk = pd.read_parquet(cfg.out_dir / cfg.cov_smk)\n",
    "    alc = pd.read_parquet(cfg.out_dir / cfg.cov_alc)\n",
    "    pa = pd.read_parquet(cfg.out_dir / cfg.cov_pa)\n",
    "    bmx = pd.read_parquet(cfg.out_dir / cfg.cov_bmx)\n",
    "    clin = pd.read_parquet(cfg.out_dir / cfg.cov_clinical)\n",
    "    hh = pd.read_parquet(cfg.out_dir / cfg.cov_household)\n",
    "    survey = get_survey_core(cfg)\n",
    "\n",
    "    core = survey\n",
    "    for part in [smk, alc, pa, bmx, clin, hh]:\n",
    "        core = core.merge(part, on=\"SEQN\", how=\"left\")\n",
    "\n",
    "    core.columns = [c.upper() for c in core.columns]\n",
    "    outp = cfg.out_dir / cfg.cov_core\n",
    "    core.to_parquet(outp, index=False)\n",
    "    log(f\"✓ CORE → {outp}\")\n",
    "    return core\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566a8a6a",
   "metadata": {},
   "source": [
    "## Orchestrator & Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8512c6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_all(cfg: Config = CONFIG) -> Dict[str, pd.DataFrame]:\n",
    "    ensure_dir(cfg.out_dir)\n",
    "    out: Dict[str, pd.DataFrame] = {}\n",
    "    out[\"smk\"] = build_smk(cfg)\n",
    "    out[\"alc\"] = build_alc(cfg)\n",
    "    out[\"pa\"] = build_pa(cfg)\n",
    "    out[\"bmx\"] = build_bmx(cfg)\n",
    "    out[\"clinical\"] = build_clinical(cfg)\n",
    "    out[\"household\"] = build_household(cfg)\n",
    "    out[\"core\"] = build_core(cfg)\n",
    "    return out\n",
    "\n",
    "def quick_checks(cfg: Config = CONFIG) -> pd.Series:\n",
    "    core = pd.read_parquet(cfg.out_dir / cfg.cov_core)\n",
    "    checks = {\n",
    "        \"n_rows\": int(len(core)),\n",
    "        \"n_unique_seqn\": int(core[\"SEQN\"].nunique()),\n",
    "        \"missing_bmi_pct\": float(core[\"BMI\"].isna().mean()),\n",
    "        \"missing_alcohol_cat_pct\": float(core[\"ALCOHOL_CAT\"].isna().mean()),\n",
    "        \"missing_smk_status_pct\": float(core[\"SMK_STATUS\"].isna().mean()),\n",
    "        \"has_weights\": int(\"WTMEC2YR\" in core.columns),\n",
    "    }\n",
    "    return pd.Series(checks)\n",
    "\n",
    "def missingness_by_era(cfg: Config = CONFIG) -> pd.DataFrame:\n",
    "    core = pd.read_parquet(cfg.out_dir / cfg.cov_core)\n",
    "    era = np.where(core[\"SDDSRVYR\"] <= 10, \"1999–2018\", \"2019–2023\")\n",
    "\n",
    "    def miss(col: str) -> pd.Series:\n",
    "        return core[col].isna().groupby(era).mean().mul(100).round(1)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"SMK_STATUS %NA\": miss(\"SMK_STATUS\"),\n",
    "        \"LTPA_MET_HR_WK %NA\": miss(\"LTPA_MET_HR_WK\"),\n",
    "        \"BMI %NA\": miss(\"BMI\"),\n",
    "        \"WTMEC2YR %NA\": miss(\"WTMEC2YR\"),\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdaad51",
   "metadata": {},
   "source": [
    "## Quick Start (run these)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d3b6194f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ SMK → /Users/dengshuyue/Desktop/SDOH/analysis/output/cov_smk_1999_2023.parquet (using smk_9918.csv); missing: {'SMK_STATUS': 0.001, 'CIGS_PER_DAY': 0.794, 'PACK_YEARS': 0.78}\n",
      "✓ ALC → /Users/dengshuyue/Desktop/SDOH/analysis/output/cov_alc_1999_2023.parquet\n",
      "✓ PA  → /Users/dengshuyue/Desktop/SDOH/analysis/output/cov_pa_1999_2023.parquet\n",
      "✓ BMX → /Users/dengshuyue/Desktop/SDOH/analysis/output/cov_bmx_1999_2023.parquet (source: bmx_9918.csv)\n",
      "✓ CLN → /Users/dengshuyue/Desktop/SDOH/analysis/output/cov_clinical_1999_2023.parquet\n",
      "✓ HH  → /Users/dengshuyue/Desktop/SDOH/analysis/output/cov_household_1999_2023.parquet\n",
      "✓ CORE → /Users/dengshuyue/Desktop/SDOH/analysis/output/cov_core_1999_2023.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'smk':            SEQN SMK_STATUS  CIGS_PER_DAY  PACK_YEARS  FORMER_SMOKER\n",
       " 0           2.0      NEVER           NaN         NaN              0\n",
       " 1           5.0     FORMER           NaN         NaN              1\n",
       " 2           7.0     FORMER           NaN   8030.0000              1\n",
       " 3          10.0    CURRENT           1.0         NaN              0\n",
       " 4          12.0      NEVER           NaN         NaN              0\n",
       " ...         ...        ...           ...         ...            ...\n",
       " 55076  102950.0     FORMER           NaN   6198.0000              1\n",
       " 55077  102952.0      NEVER           NaN         NaN              0\n",
       " 55078  102953.0     FORMER           NaN    387.8125              1\n",
       " 55079  102954.0      NEVER           NaN         NaN              0\n",
       " 55080  102956.0    CURRENT           2.0         NaN              0\n",
       " \n",
       " [55081 rows x 5 columns],\n",
       " 'alc':            SEQN  DRINKS_PER_DAY ALCOHOL_CAT\n",
       " 0           2.0        0.789041    MODERATE\n",
       " 1           5.0       12.000000       HEAVY\n",
       " 2           7.0             NaN        NONE\n",
       " 3          10.0        0.197260    MODERATE\n",
       " 4          12.0        0.857129    MODERATE\n",
       " ...         ...             ...         ...\n",
       " 68856  142305.0             NaN        NONE\n",
       " 68857  142307.0             NaN        NONE\n",
       " 68858  142308.0             NaN        NONE\n",
       " 68859  142309.0             NaN        NONE\n",
       " 68860  142310.0             NaN        NONE\n",
       " \n",
       " [68861 rows x 3 columns],\n",
       " 'pa':          SEQN  LTPA_MET_HR_WK  LTPA_IMPUTED_FLAG\n",
       " 0           2             NaN                  0\n",
       " 1           5             NaN                  0\n",
       " 2           7             NaN                  0\n",
       " 3          10             NaN                  0\n",
       " 4          12             NaN                  0\n",
       " ...       ...             ...                ...\n",
       " 55076  102950             NaN                  0\n",
       " 55077  102952             NaN                  0\n",
       " 55078  102953             NaN                  0\n",
       " 55079  102954             NaN                  0\n",
       " 55080  102956             NaN                  0\n",
       " \n",
       " [55081 rows x 3 columns],\n",
       " 'bmx':            SEQN  BMXWT  BMXHT        BMI\n",
       " 0           1.0   12.5   91.6  14.897695\n",
       " 1           2.0   75.4  174.0  24.904215\n",
       " 2           3.0   32.9  136.6  17.631713\n",
       " 3           4.0   13.3    NaN        NaN\n",
       " 4           5.0   92.5  178.3  29.096386\n",
       " ...         ...    ...    ...        ...\n",
       " 96761  102952.0   49.0  156.5  20.006329\n",
       " 96762  102953.0   97.4  164.9  35.819345\n",
       " 96763  102954.0   69.1  162.6  26.135870\n",
       " 96764  102955.0  111.9  156.6  45.629590\n",
       " 96765  102956.0  111.5  175.8  36.077557\n",
       " \n",
       " [96766 rows x 4 columns],\n",
       " 'clinical':             SEQN BMI_CLAS  DIABETES  HTN  HIGH_CHOL  CVD  CANCER         SBP        DBP  TCHOL  HDL  LDL   TG\n",
       " 0            1.0    UNDER         0    0          0    0       0   91.333333  56.000000    131   59   54   99\n",
       " 1            2.0   NORMAL         0    0          0    0       1  100.666667  56.666667    215   54  136  128\n",
       " 2            3.0    UNDER         0    0          0    0       0  108.666667  62.000000    129   30   58  202\n",
       " 3            4.0     <NA>         0    0          1    0       0   95.333333  61.333333    211   43  161   37\n",
       " 4            5.0     OVER         0    1          1    0       0  122.000000  82.666667    279   42  168  347\n",
       " ...          ...      ...       ...  ...        ...  ...     ...         ...        ...    ...  ...  ...  ...\n",
       " 101311  102952.0   NORMAL         1    0          0    0       0  139.333300  73.333330    119   60   43   78\n",
       " 101312  102953.0    OBESE         0    0          0    0       0  120.666700  75.333330    182   49   73  299\n",
       " 101313  102954.0     OVER         0    0          0    0       0  116.000000  70.666670    172   54  108   49\n",
       " 101314  102955.0    OBESE         0    0          0    0       0  114.000000  62.000000    150   34   77  193\n",
       " 101315  102956.0    OBESE         0    1          0    0       0  148.000000  96.000000    163   34   75  269\n",
       " \n",
       " [101316 rows x 13 columns],\n",
       " 'household':             SEQN  DMDHHSIZ\n",
       " 0            1.0       3.0\n",
       " 1            2.0       1.0\n",
       " 2            3.0       4.0\n",
       " 3            4.0       7.0\n",
       " 4            5.0       3.0\n",
       " ...          ...       ...\n",
       " 128804  142306.0       2.0\n",
       " 128805  142307.0       5.0\n",
       " 128806  142308.0       3.0\n",
       " 128807  142309.0       5.0\n",
       " 128808  142310.0       2.0\n",
       " \n",
       " [128809 rows x 2 columns],\n",
       " 'core':             SEQN  SDDSRVYR  SDMVPSU  SDMVSTRA      WTMEC2YR SMK_STATUS  CIGS_PER_DAY  PACK_YEARS  FORMER_SMOKER  DRINKS_PER_DAY ALCOHOL_CAT  LTPA_MET_HR_WK  LTPA_IMPUTED_FLAG  BMXWT  BMXHT  \\\n",
       " 0            1.0       1.0      1.0       5.0  10982.898896        NaN           NaN         NaN            NaN             NaN         NaN             NaN                NaN   12.5   91.6   \n",
       " 1            2.0       1.0      3.0       1.0  28325.384898      NEVER           NaN         NaN            0.0        0.789041    MODERATE             NaN                0.0   75.4  174.0   \n",
       " 2            3.0       1.0      2.0       7.0  46192.256945        NaN           NaN         NaN            NaN             NaN         NaN             NaN                NaN   32.9  136.6   \n",
       " 3            4.0       1.0      1.0       2.0  10251.260020        NaN           NaN         NaN            NaN             NaN         NaN             NaN                NaN   13.3    NaN   \n",
       " 4            5.0       1.0      2.0       8.0  99445.065735     FORMER           NaN         NaN            1.0       12.000000       HEAVY             NaN                0.0   92.5  178.3   \n",
       " ...          ...       ...      ...       ...           ...        ...           ...         ...            ...             ...         ...             ...                ...    ...    ...   \n",
       " 128804  142306.0      12.0      1.0     176.0  13459.129019        NaN           NaN         NaN            NaN             NaN         NaN             NaN                NaN    NaN    NaN   \n",
       " 128805  142307.0      12.0      1.0     181.0  64962.328962        NaN           NaN         NaN            NaN             NaN        NONE             NaN                NaN    NaN    NaN   \n",
       " 128806  142308.0      12.0      2.0     183.0  44367.534132        NaN           NaN         NaN            NaN             NaN        NONE             NaN                NaN    NaN    NaN   \n",
       " 128807  142309.0      12.0      1.0     176.0  46249.361849        NaN           NaN         NaN            NaN             NaN        NONE             NaN                NaN    NaN    NaN   \n",
       " 128808  142310.0      12.0      2.0     187.0  49647.225467        NaN           NaN         NaN            NaN             NaN        NONE             NaN                NaN    NaN    NaN   \n",
       " \n",
       "               BMI BMI_CLAS  DIABETES   HTN  HIGH_CHOL   CVD  CANCER         SBP        DBP  TCHOL   HDL    LDL     TG  DMDHHSIZ  \n",
       " 0       14.897695    UNDER         0     0          0     0       0   91.333333  56.000000  131.0  59.0   54.0   99.0       3.0  \n",
       " 1       24.904215   NORMAL         0     0          0     0       1  100.666667  56.666667  215.0  54.0  136.0  128.0       1.0  \n",
       " 2       17.631713    UNDER         0     0          0     0       0  108.666667  62.000000  129.0  30.0   58.0  202.0       4.0  \n",
       " 3             NaN     <NA>         0     0          1     0       0   95.333333  61.333333  211.0  43.0  161.0   37.0       7.0  \n",
       " 4       29.096386     OVER         0     1          1     0       0  122.000000  82.666667  279.0  42.0  168.0  347.0       3.0  \n",
       " ...           ...      ...       ...   ...        ...   ...     ...         ...        ...    ...   ...    ...    ...       ...  \n",
       " 128804        NaN     <NA>      <NA>  <NA>       <NA>  <NA>    <NA>         NaN        NaN    NaN   NaN    NaN    NaN       2.0  \n",
       " 128805        NaN     <NA>      <NA>  <NA>       <NA>  <NA>    <NA>         NaN        NaN    NaN   NaN    NaN    NaN       5.0  \n",
       " 128806        NaN     <NA>      <NA>  <NA>       <NA>  <NA>    <NA>         NaN        NaN    NaN   NaN    NaN    NaN       3.0  \n",
       " 128807        NaN     <NA>      <NA>  <NA>       <NA>  <NA>    <NA>         NaN        NaN    NaN   NaN    NaN    NaN       5.0  \n",
       " 128808        NaN     <NA>      <NA>  <NA>       <NA>  <NA>    <NA>         NaN        NaN    NaN   NaN    NaN    NaN       2.0  \n",
       " \n",
       " [128809 rows x 29 columns]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Optional: Adjust paths if needed\n",
    "# CONFIG.out_dir = Path(\"/Users/dengshuyue/Desktop/SDOH/analysis/output\")\n",
    "# CONFIG.interim_dir = Path(\"/Users/dengshuyue/Desktop/SDOH/analysis/data/cov\")\n",
    "# CONFIG.demo_9923 = Path(\"/Users/dengshuyue/Desktop/SDOH/analysis/data/cov/demo9923.parquet\")\n",
    "\n",
    "# delete stale alcohol file and rebuild\n",
    "(CONFIG.out_dir / CONFIG.cov_alc).unlink(missing_ok=True)\n",
    "run_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "23332b4c-7df3-4118-8654-8d14029443f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128809, 29),\n",
       " Index(['SEQN', 'SDDSRVYR', 'SDMVPSU', 'SDMVSTRA', 'WTMEC2YR', 'SMK_STATUS', 'CIGS_PER_DAY', 'PACK_YEARS', 'FORMER_SMOKER', 'DRINKS_PER_DAY', 'ALCOHOL_CAT', 'LTPA_MET_HR_WK', 'LTPA_IMPUTED_FLAG',\n",
       "        'BMXWT', 'BMXHT', 'BMI', 'BMI_CLAS', 'DIABETES', 'HTN', 'HIGH_CHOL', 'CVD', 'CANCER', 'SBP', 'DBP', 'TCHOL', 'HDL', 'LDL', 'TG', 'DMDHHSIZ'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core.shape, core.columns[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c02ac5a1-8236-4932-9201-aeb2b1996efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>SDMVPSU</th>\n",
       "      <th>SDMVSTRA</th>\n",
       "      <th>WTMEC2YR</th>\n",
       "      <th>SMK_STATUS</th>\n",
       "      <th>CIGS_PER_DAY</th>\n",
       "      <th>PACK_YEARS</th>\n",
       "      <th>FORMER_SMOKER</th>\n",
       "      <th>DRINKS_PER_DAY</th>\n",
       "      <th>ALCOHOL_CAT</th>\n",
       "      <th>LTPA_MET_HR_WK</th>\n",
       "      <th>LTPA_IMPUTED_FLAG</th>\n",
       "      <th>BMXWT</th>\n",
       "      <th>BMXHT</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BMI_CLAS</th>\n",
       "      <th>DIABETES</th>\n",
       "      <th>HTN</th>\n",
       "      <th>HIGH_CHOL</th>\n",
       "      <th>CVD</th>\n",
       "      <th>CANCER</th>\n",
       "      <th>SBP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>TCHOL</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>TG</th>\n",
       "      <th>DMDHHSIZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10982.898896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.5</td>\n",
       "      <td>91.6</td>\n",
       "      <td>14.897695</td>\n",
       "      <td>UNDER</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91.333333</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>131.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28325.384898</td>\n",
       "      <td>NEVER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.789041</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.4</td>\n",
       "      <td>174.0</td>\n",
       "      <td>24.904215</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.666667</td>\n",
       "      <td>56.666667</td>\n",
       "      <td>215.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>46192.256945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.9</td>\n",
       "      <td>136.6</td>\n",
       "      <td>17.631713</td>\n",
       "      <td>UNDER</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.666667</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>129.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10251.260020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95.333333</td>\n",
       "      <td>61.333333</td>\n",
       "      <td>211.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>99445.065735</td>\n",
       "      <td>FORMER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>HEAVY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.5</td>\n",
       "      <td>178.3</td>\n",
       "      <td>29.096386</td>\n",
       "      <td>OVER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>82.666667</td>\n",
       "      <td>279.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39656.600444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.2</td>\n",
       "      <td>162.0</td>\n",
       "      <td>22.557537</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>114.666667</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>153.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25525.423409</td>\n",
       "      <td>FORMER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8030.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>162.9</td>\n",
       "      <td>29.393577</td>\n",
       "      <td>OVER</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125.333333</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>245.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>31510.587866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.7</td>\n",
       "      <td>162.0</td>\n",
       "      <td>15.508307</td>\n",
       "      <td>UNDER</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.666667</td>\n",
       "      <td>49.333333</td>\n",
       "      <td>162.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7575.870247</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.5</td>\n",
       "      <td>156.9</td>\n",
       "      <td>18.482704</td>\n",
       "      <td>UNDER</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.333333</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>148.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22445.808572</td>\n",
       "      <td>CURRENT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197260</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.8</td>\n",
       "      <td>190.1</td>\n",
       "      <td>30.936955</td>\n",
       "      <td>OBESE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>145.333333</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEQN  SDDSRVYR  SDMVPSU  SDMVSTRA      WTMEC2YR SMK_STATUS  CIGS_PER_DAY  PACK_YEARS  FORMER_SMOKER  DRINKS_PER_DAY ALCOHOL_CAT  LTPA_MET_HR_WK  LTPA_IMPUTED_FLAG  BMXWT  BMXHT        BMI  \\\n",
       "0   1.0       1.0      1.0       5.0  10982.898896        NaN           NaN         NaN            NaN             NaN         NaN             NaN                NaN   12.5   91.6  14.897695   \n",
       "1   2.0       1.0      3.0       1.0  28325.384898      NEVER           NaN         NaN            0.0        0.789041    MODERATE             NaN                0.0   75.4  174.0  24.904215   \n",
       "2   3.0       1.0      2.0       7.0  46192.256945        NaN           NaN         NaN            NaN             NaN         NaN             NaN                NaN   32.9  136.6  17.631713   \n",
       "3   4.0       1.0      1.0       2.0  10251.260020        NaN           NaN         NaN            NaN             NaN         NaN             NaN                NaN   13.3    NaN        NaN   \n",
       "4   5.0       1.0      2.0       8.0  99445.065735     FORMER           NaN         NaN            1.0       12.000000       HEAVY             NaN                0.0   92.5  178.3  29.096386   \n",
       "5   6.0       1.0      2.0       2.0  39656.600444        NaN           NaN         NaN            NaN             NaN         NaN             NaN                NaN   59.2  162.0  22.557537   \n",
       "6   7.0       1.0      2.0       4.0  25525.423409     FORMER           NaN      8030.0            1.0             NaN        NONE             NaN                0.0   78.0  162.9  29.393577   \n",
       "7   8.0       1.0      1.0       6.0  31510.587866        NaN           NaN         NaN            NaN             NaN         NaN             NaN                NaN   40.7  162.0  15.508307   \n",
       "8   9.0       1.0      2.0       9.0   7575.870247        NaN           NaN         NaN            NaN             NaN         NaN             NaN                NaN   45.5  156.9  18.482704   \n",
       "9  10.0       1.0      1.0       7.0  22445.808572    CURRENT           1.0         NaN            0.0        0.197260    MODERATE             NaN                0.0  111.8  190.1  30.936955   \n",
       "\n",
       "  BMI_CLAS  DIABETES  HTN  HIGH_CHOL  CVD  CANCER         SBP        DBP  TCHOL    HDL    LDL     TG  DMDHHSIZ  \n",
       "0    UNDER         0    0          0    0       0   91.333333  56.000000  131.0   59.0   54.0   99.0       3.0  \n",
       "1   NORMAL         0    0          0    0       1  100.666667  56.666667  215.0   54.0  136.0  128.0       1.0  \n",
       "2    UNDER         0    0          0    0       0  108.666667  62.000000  129.0   30.0   58.0  202.0       4.0  \n",
       "3     <NA>         0    0          1    0       0   95.333333  61.333333  211.0   43.0  161.0   37.0       7.0  \n",
       "4     OVER         0    1          1    0       0  122.000000  82.666667  279.0   42.0  168.0  347.0       3.0  \n",
       "5   NORMAL         0    0          0    0       0  114.666667  68.000000  153.0   61.0   59.0  181.0       2.0  \n",
       "6     OVER         0    0          1    0       0  125.333333  80.000000  245.0  105.0  127.0   62.0       1.0  \n",
       "7    UNDER         0    0          0    0       0  100.666667  49.333333  162.0   67.0   88.0   33.0       7.0  \n",
       "8    UNDER         0    0          0    0       0  109.333333  53.333333  148.0   58.0   79.0   56.0       4.0  \n",
       "9    OBESE         0    1          0    0       0  145.333333  96.000000  140.0   51.0   80.0   45.0       1.0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37cd9236-c057-4048-a153-517cbc050d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ SMK → /Users/dengshuyue/Desktop/SDOH/analysis/output/cov_smk_1999_2023.parquet (using smk_9918.csv); missing: {'SMK_STATUS': 0.001, 'CIGS_PER_DAY': 0.794, 'PACK_YEARS': 0.78}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SMK_STATUS</th>\n",
       "      <th>CIGS_PER_DAY</th>\n",
       "      <th>PACK_YEARS</th>\n",
       "      <th>FORMER_SMOKER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NEVER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>FORMER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>FORMER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8030.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>CURRENT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.0</td>\n",
       "      <td>NEVER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEQN SMK_STATUS  CIGS_PER_DAY  PACK_YEARS  FORMER_SMOKER\n",
       "0   2.0      NEVER           NaN         NaN              0\n",
       "1   5.0     FORMER           NaN         NaN              1\n",
       "2   7.0     FORMER           NaN      8030.0              1\n",
       "3  10.0    CURRENT           1.0         NaN              0\n",
       "4  12.0      NEVER           NaN         NaN              0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only (re)build smoking\n",
    "smk = build_smk(CONFIG)          # writes cov_smk_1999_2023.parquet\n",
    "smk.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e37b16-a0f2-4e2a-b605-770cff407320",
   "metadata": {},
   "source": [
    "<h2> Merge Mortality </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "062801bf-cbe5-45cf-900c-787162c4914a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/dengshuyue/Desktop/SDOH/analysis/output/core_mort_1999_2018.parquet (59064, 32)\n",
      "Age non-missing: 1.0\n",
      "Events (%): 15.66\n",
      "TIME_Y median (y): 9.416666666666666\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "BASE = Path(\"/Users/dengshuyue/Desktop/SDOH/analysis\")\n",
    "DATA = BASE / \"data\" / \"cov\"\n",
    "OUT  = BASE / \"output\"\n",
    "\n",
    "# 1) Load\n",
    "core = pd.read_parquet(OUT / \"cov_core_1999_2023.parquet\")\n",
    "mort_with_demo = pd.read_parquet(OUT / \"mort_with_demo.parquet\")  # built earlier\n",
    "demo_age = pd.read_parquet(DATA / \"demo9923.parquet\")[[\"SEQN\", \"RIDAGEYR\"]].drop_duplicates(\"SEQN\")\n",
    "\n",
    "# 2) Merge mortality fields you need\n",
    "need_from_mort = [\"SEQN\", \"TIME_Y\", \"EVENT\"]\n",
    "missing = [c for c in need_from_mort if c not in mort_with_demo.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"mort_with_demo is missing columns: {missing}\")\n",
    "\n",
    "core_mort = core.merge(mort_with_demo[need_from_mort], on=\"SEQN\", how=\"inner\")\n",
    "\n",
    "# 3) Add age (RIDAGEYR) from DEMO\n",
    "core_mort = core_mort.merge(demo_age, on=\"SEQN\", how=\"left\")\n",
    "\n",
    "# 4) Keep mortality-linked cycles using SDDSRVYR from *core*\n",
    "core_mort_9918 = core_mort[core_mort[\"SDDSRVYR\"].between(1, 10)].copy()\n",
    "\n",
    "# 5) Save\n",
    "out_path = OUT / \"core_mort_1999_2018.parquet\"\n",
    "core_mort_9918.to_parquet(out_path, index=False)\n",
    "\n",
    "print(\"Saved:\", out_path, core_mort_9918.shape)\n",
    "print(\"Age non-missing:\", core_mort_9918[\"RIDAGEYR\"].notna().mean().round(3))\n",
    "print(\"Events (%):\", round(100 * core_mort_9918[\"EVENT\"].mean(), 2))\n",
    "print(\"TIME_Y median (y):\", core_mort_9918[\"TIME_Y\"].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "886fe36a-80f9-45a4-afa2-24ca16408f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>SDMVPSU</th>\n",
       "      <th>SDMVSTRA</th>\n",
       "      <th>WTMEC2YR</th>\n",
       "      <th>SMK_STATUS</th>\n",
       "      <th>CIGS_PER_DAY</th>\n",
       "      <th>PACK_YEARS</th>\n",
       "      <th>FORMER_SMOKER</th>\n",
       "      <th>DRINKS_PER_DAY</th>\n",
       "      <th>ALCOHOL_CAT</th>\n",
       "      <th>LTPA_MET_HR_WK</th>\n",
       "      <th>LTPA_IMPUTED_FLAG</th>\n",
       "      <th>BMXWT</th>\n",
       "      <th>BMXHT</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BMI_CLAS</th>\n",
       "      <th>DIABETES</th>\n",
       "      <th>HTN</th>\n",
       "      <th>HIGH_CHOL</th>\n",
       "      <th>CVD</th>\n",
       "      <th>CANCER</th>\n",
       "      <th>SBP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>TCHOL</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>TG</th>\n",
       "      <th>DMDHHSIZ</th>\n",
       "      <th>TIME_Y</th>\n",
       "      <th>EVENT</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28325.384898</td>\n",
       "      <td>NEVER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.789041</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.4</td>\n",
       "      <td>174.0</td>\n",
       "      <td>24.904215</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.666667</td>\n",
       "      <td>56.666667</td>\n",
       "      <td>215.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>99445.065735</td>\n",
       "      <td>FORMER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>HEAVY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.5</td>\n",
       "      <td>178.3</td>\n",
       "      <td>29.096386</td>\n",
       "      <td>OVER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>82.666667</td>\n",
       "      <td>279.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39656.600444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.2</td>\n",
       "      <td>162.0</td>\n",
       "      <td>22.557537</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>114.666667</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>153.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25525.423409</td>\n",
       "      <td>FORMER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8030.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>162.9</td>\n",
       "      <td>29.393577</td>\n",
       "      <td>OVER</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125.333333</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>245.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22445.808572</td>\n",
       "      <td>CURRENT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197260</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.8</td>\n",
       "      <td>190.1</td>\n",
       "      <td>30.936955</td>\n",
       "      <td>OBESE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>145.333333</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>95494.214052</td>\n",
       "      <td>NEVER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857129</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.2</td>\n",
       "      <td>180.0</td>\n",
       "      <td>30.617284</td>\n",
       "      <td>OBESE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>176.666667</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>156.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1843.950828</td>\n",
       "      <td>FORMER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>HEAVY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.6</td>\n",
       "      <td>157.7</td>\n",
       "      <td>25.573710</td>\n",
       "      <td>OVER</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>314.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19486.733790</td>\n",
       "      <td>CURRENT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.5</td>\n",
       "      <td>166.2</td>\n",
       "      <td>27.332850</td>\n",
       "      <td>OVER</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>59.333333</td>\n",
       "      <td>174.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>114519.177908</td>\n",
       "      <td>CURRENT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>HEAVY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.6</td>\n",
       "      <td>174.9</td>\n",
       "      <td>26.675375</td>\n",
       "      <td>OVER</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>68.666667</td>\n",
       "      <td>199.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12565.995924</td>\n",
       "      <td>NEVER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.5</td>\n",
       "      <td>144.2</td>\n",
       "      <td>19.958026</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147.333333</td>\n",
       "      <td>60.666667</td>\n",
       "      <td>164.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEQN  SDDSRVYR  SDMVPSU  SDMVSTRA       WTMEC2YR SMK_STATUS  CIGS_PER_DAY  PACK_YEARS  FORMER_SMOKER  DRINKS_PER_DAY ALCOHOL_CAT  LTPA_MET_HR_WK  LTPA_IMPUTED_FLAG  BMXWT  BMXHT        BMI  \\\n",
       "0   2.0       1.0      3.0       1.0   28325.384898      NEVER           NaN         NaN            0.0        0.789041    MODERATE             NaN                0.0   75.4  174.0  24.904215   \n",
       "1   5.0       1.0      2.0       8.0   99445.065735     FORMER           NaN         NaN            1.0       12.000000       HEAVY             NaN                0.0   92.5  178.3  29.096386   \n",
       "2   6.0       1.0      2.0       2.0   39656.600444        NaN           NaN         NaN            NaN             NaN         NaN             NaN                NaN   59.2  162.0  22.557537   \n",
       "3   7.0       1.0      2.0       4.0   25525.423409     FORMER           NaN      8030.0            1.0             NaN        NONE             NaN                0.0   78.0  162.9  29.393577   \n",
       "4  10.0       1.0      1.0       7.0   22445.808572    CURRENT           1.0         NaN            0.0        0.197260    MODERATE             NaN                0.0  111.8  190.1  30.936955   \n",
       "5  12.0       1.0      2.0       6.0   95494.214052      NEVER           NaN         NaN            0.0        0.857129    MODERATE             NaN                0.0   99.2  180.0  30.617284   \n",
       "6  13.0       1.0      2.0      13.0    1843.950828     FORMER           NaN      1095.0            1.0        2.000000       HEAVY             NaN                0.0   63.6  157.7  25.573710   \n",
       "7  14.0       1.0      1.0      12.0   19486.733790    CURRENT           1.0         NaN            0.0        1.000000    MODERATE             NaN                0.0   75.5  166.2  27.332850   \n",
       "8  15.0       1.0      2.0      11.0  114519.177908    CURRENT           2.0         NaN            0.0        8.000000       HEAVY             NaN                0.0   81.6  174.9  26.675375   \n",
       "9  16.0       1.0      1.0      11.0   12565.995924      NEVER           NaN         NaN            0.0             NaN        NONE             NaN                0.0   41.5  144.2  19.958026   \n",
       "\n",
       "  BMI_CLAS  DIABETES  HTN  HIGH_CHOL  CVD  CANCER         SBP         DBP  TCHOL    HDL    LDL     TG  DMDHHSIZ     TIME_Y  EVENT  RIDAGEYR  \n",
       "0   NORMAL         0    0          0    0       1  100.666667   56.666667  215.0   54.0  136.0  128.0       1.0  14.750000      1      77.0  \n",
       "1     OVER         0    1          1    0       0  122.000000   82.666667  279.0   42.0  168.0  347.0       3.0  20.333333      0      49.0  \n",
       "2   NORMAL         0    0          0    0       0  114.666667   68.000000  153.0   61.0   59.0  181.0       2.0  20.416667      0      19.0  \n",
       "3     OVER         0    0          1    0       0  125.333333   80.000000  245.0  105.0  127.0   62.0       1.0  19.666667      0      59.0  \n",
       "4    OBESE         0    1          0    0       0  145.333333   96.000000  140.0   51.0   80.0   45.0       1.0  19.250000      1      43.0  \n",
       "5    OBESE         0    1          0    0       0  176.666667  102.000000  156.0   38.0   89.0  146.0       4.0  19.666667      0      37.0  \n",
       "6     OVER         1    1          1    0       0  133.333333   70.000000  314.0   49.0  260.0   16.0       2.0   1.333333      1      70.0  \n",
       "7     OVER         0    0          0    0       0  138.000000   59.333333  174.0   40.0  123.0   49.0       1.0  11.333333      1      81.0  \n",
       "8     OVER         0    0          0    0       0  108.000000   68.666667  199.0   58.0  131.0   54.0       2.0  19.250000      0      38.0  \n",
       "9   NORMAL         0    1          0    0       0  147.333333   60.666667  164.0   55.0   73.0  187.0       1.0   5.166667      1      85.0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_mort_9918.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c951427e-bb99-48f7-ac72-b8818b4be732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_mort_9918[\"RIDAGEYR\"].describe()\n",
    "core_mort_9918[\"RIDAGEYR\"].isna().mean().round(3)  # missing rate\n",
    "core_mort_9918.query(\"RIDAGEYR < 0 or RIDAGEYR > 120\").shape  # out-of-range?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dfbf538a-1ce6-42bb-804f-5cfcbe7ce99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    59064.000000\n",
       "mean        47.734119\n",
       "std         19.504749\n",
       "min         18.000000\n",
       "25%         31.000000\n",
       "50%         47.000000\n",
       "75%         64.000000\n",
       "max         85.000000\n",
       "Name: RIDAGEYR, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_mort_9918[\"RIDAGEYR\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6e9a77-0172-449f-8cb6-d94ce5fb1917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "437cffe5-9c2b-4bbf-a4e4-e530e0fe9bb2",
   "metadata": {},
   "source": [
    "<h2>Sanity Checks </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a9688bb-e27b-4b99-8c18-5e5c52e4185d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n_rows                     128809.000000\n",
       "n_unique_seqn              128809.000000\n",
       "missing_bmi_pct                 0.318378\n",
       "missing_alcohol_cat_pct         0.465402\n",
       "missing_smk_status_pct          0.572903\n",
       "has_weights                     1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity checks\n",
    "quick_checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5279902-ca98-425a-9d67-aceaa3031f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMK_STATUS %NA</th>\n",
       "      <th>LTPA_MET_HR_WK %NA</th>\n",
       "      <th>BMI %NA</th>\n",
       "      <th>WTMEC2YR %NA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999–2018</th>\n",
       "      <td>45.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019–2023</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>56.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SMK_STATUS %NA  LTPA_MET_HR_WK %NA  BMI %NA  WTMEC2YR %NA\n",
       "1999–2018            45.7               100.0     13.3           0.0\n",
       "2019–2023           100.0               100.0    100.0          56.6"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missingness by era table\n",
    "missingness_by_era()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c2c7c83-8862-4e32-8647-51f822553018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6815517549239571)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Basic peek\n",
    "core = pd.read_parquet(CONFIG.out_dir / CONFIG.cov_core)\n",
    "core.head(3)\n",
    "\n",
    "# 2) Unique participants and NA overview\n",
    "core[\"SEQN\"].nunique(), core.isna().mean().round(3).sort_values().head(10)\n",
    "\n",
    "# 3) Alcohol category distribution\n",
    "core[\"ALCOHOL_CAT\"].value_counts(dropna=False)\n",
    "\n",
    "# 4) Smoking status distribution\n",
    "core[\"SMK_STATUS\"].value_counts(dropna=False)\n",
    "\n",
    "# 5) Survey design fields present?\n",
    "set([\"SDDSRVYR\",\"SDMVPSU\",\"SDMVSTRA\",\"WTMEC2YR\"]).issubset(core.columns)\n",
    "\n",
    "# 6) BMI sanity (no negatives and in a plausible range)\n",
    "core[\"BMI\"].describe()\n",
    "((core[\"BMI\"] >= 10) & (core[\"BMI\"] <= 80)).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70d8bce1-ed42-4c4b-8fe4-7ea07ba8d600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALCOHOL_CAT\n",
       "NaN         59948\n",
       "NONE        42792\n",
       "MODERATE    14843\n",
       "HEAVY       11226\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Alcohol category distribution\n",
    "core[\"ALCOHOL_CAT\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2e7691b-dbae-41be-9807-3145e1977c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SMK_STATUS\n",
       "NaN        0.573\n",
       "NEVER      0.233\n",
       "FORMER     0.106\n",
       "CURRENT    0.089\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution checks\n",
    "core[\"ALCOHOL_CAT\"].value_counts(dropna=False, normalize=True).round(3)\n",
    "core[\"SMK_STATUS\"].value_counts(dropna=False, normalize=True).round(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b8191bc-afd0-4c27-a64f-a412e2cdee77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7804f8ef-d3e8-4b3f-9ca3-3e22270c5028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
