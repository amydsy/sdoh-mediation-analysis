{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6321aae-088c-49a4-aa8b-0d59f8b12f00",
   "metadata": {},
   "source": [
    "<h1>Demographic</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c2fcda",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2>Install required package and import libraries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "efe6e728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyreadstat in /Users/dengshuyue/amydsy/lib/python3.13/site-packages (1.3.0)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /Users/dengshuyue/amydsy/lib/python3.13/site-packages (from pyreadstat) (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/dengshuyue/amydsy/lib/python3.13/site-packages (from pandas>=1.2.0->pyreadstat) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/dengshuyue/amydsy/lib/python3.13/site-packages (from pandas>=1.2.0->pyreadstat) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/dengshuyue/amydsy/lib/python3.13/site-packages (from pandas>=1.2.0->pyreadstat) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/dengshuyue/amydsy/lib/python3.13/site-packages (from pandas>=1.2.0->pyreadstat) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/dengshuyue/amydsy/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadstat) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# If not already installed, install pyreadstat (used to read .sas7bdat files)\n",
    "!pip install pyreadstat\n",
    "!pip install openpyxl\n",
    "\n",
    "# Import core packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pyreadstat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0095018c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2>Load and preview SAS dataset</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e9a8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your .sas7bdat file\n",
    "file_path = \"/Users/dengshuyue/Desktop/SDOH/analysis/data/demo_i.sas7bdat\"\n",
    "\n",
    "# Load the dataset using pandas (requires pyreadstat)\n",
    "df = pd.read_sas(file_path, format=\"sas7bdat\")\n",
    "\n",
    "# Preview the data\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()\n",
    "\n",
    "# List all column names\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4371d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to your .sas7bdat file\n",
    "file_path = \"/Users/dengshuyue/Desktop/SDOH/analysis/data/gg.sas7bdat\"\n",
    "\n",
    "# Load the dataset using pandas (requires pyreadstat)\n",
    "df = pd.read_sas(file_path, format=\"sas7bdat\")\n",
    "\n",
    "# Preview the data\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()\n",
    "\n",
    "# List all column names\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbfd6ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>marriage</th>\n",
       "      <th>HOD050</th>\n",
       "      <th>HOQ065</th>\n",
       "      <th>EMPLOY</th>\n",
       "      <th>unemployment</th>\n",
       "      <th>ELIGSTAT</th>\n",
       "      <th>MORTSTAT</th>\n",
       "      <th>UCOD_LEADING</th>\n",
       "      <th>DIABETES</th>\n",
       "      <th>HYPERTEN</th>\n",
       "      <th>PERMTH_INT</th>\n",
       "      <th>PERMTH_EXM</th>\n",
       "      <th>Death_heart</th>\n",
       "      <th>Death_cancer</th>\n",
       "      <th>Death_resp</th>\n",
       "      <th>Death_cerev</th>\n",
       "      <th>Death_diabe</th>\n",
       "      <th>Death_other</th>\n",
       "      <th>death_cvd</th>\n",
       "      <th>death_cmd</th>\n",
       "      <th>FSDHH</th>\n",
       "      <th>SNAP</th>\n",
       "      <th>FS</th>\n",
       "      <th>ins</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>INDFMPIR</th>\n",
       "      <th>diabe</th>\n",
       "      <th>smk</th>\n",
       "      <th>smk_avg</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>HEI2015_TOTAL_SCORE</th>\n",
       "      <th>edu</th>\n",
       "      <th>alcg2</th>\n",
       "      <th>DAYS</th>\n",
       "      <th>WTDRD1</th>\n",
       "      <th>DR12DRST</th>\n",
       "      <th>WTDR2D</th>\n",
       "      <th>i_optup</th>\n",
       "      <th>i_FCS</th>\n",
       "      <th>i_HSR</th>\n",
       "      <th>i_nutri</th>\n",
       "      <th>perE_alco</th>\n",
       "      <th>sdmvpsu</th>\n",
       "      <th>sdmvstra</th>\n",
       "      <th>tchol</th>\n",
       "      <th>hdl</th>\n",
       "      <th>ldl</th>\n",
       "      <th>tg</th>\n",
       "      <th>bmi</th>\n",
       "      <th>dm_self</th>\n",
       "      <th>hba1c</th>\n",
       "      <th>cancer</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>dm_rx</th>\n",
       "      <th>chol_rx</th>\n",
       "      <th>angina_rx</th>\n",
       "      <th>CVD</th>\n",
       "      <th>lung_disease</th>\n",
       "      <th>angina</th>\n",
       "      <th>met_hr</th>\n",
       "      <th>wt10</th>\n",
       "      <th>wt</th>\n",
       "      <th>i_FCS_sd</th>\n",
       "      <th>i_Optup_sd</th>\n",
       "      <th>i_nutri_sd</th>\n",
       "      <th>i_HSR_sd</th>\n",
       "      <th>hei2015_sd</th>\n",
       "      <th>Death_inj</th>\n",
       "      <th>Death_alz</th>\n",
       "      <th>Death_infl</th>\n",
       "      <th>Death_kid</th>\n",
       "      <th>death_other1</th>\n",
       "      <th>Death_oth2</th>\n",
       "      <th>death_cmdk</th>\n",
       "      <th>death_cmdkh</th>\n",
       "      <th>death_multi</th>\n",
       "      <th>agesq</th>\n",
       "      <th>py</th>\n",
       "      <th>agestart</th>\n",
       "      <th>ageend</th>\n",
       "      <th>pir</th>\n",
       "      <th>bmic</th>\n",
       "      <th>include</th>\n",
       "      <th>ins2</th>\n",
       "      <th>unemployment2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21009.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>196.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.542908</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56998.593412</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170262.470827</td>\n",
       "      <td>42.652217</td>\n",
       "      <td>25.525713</td>\n",
       "      <td>4.324399</td>\n",
       "      <td>7.838628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>31.26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>5699.859341</td>\n",
       "      <td>21282.808853</td>\n",
       "      <td>2.343959</td>\n",
       "      <td>5.220590</td>\n",
       "      <td>-2.472753</td>\n",
       "      <td>4.281583</td>\n",
       "      <td>3.503301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3025.0</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>55.0</td>\n",
       "      <td>71.250000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.931080</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55313.014168</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75296.121197</td>\n",
       "      <td>44.072913</td>\n",
       "      <td>30.611291</td>\n",
       "      <td>5.652702</td>\n",
       "      <td>4.488967</td>\n",
       "      <td>10.617983</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>25.49</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>5531.301417</td>\n",
       "      <td>9412.015150</td>\n",
       "      <td>2.810954</td>\n",
       "      <td>5.394481</td>\n",
       "      <td>-1.416078</td>\n",
       "      <td>5.596735</td>\n",
       "      <td>3.994698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2704.0</td>\n",
       "      <td>15.083333</td>\n",
       "      <td>52.0</td>\n",
       "      <td>67.083333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21012.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'001'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38.637620</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18966.755482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29690.563714</td>\n",
       "      <td>46.390303</td>\n",
       "      <td>29.339153</td>\n",
       "      <td>4.508485</td>\n",
       "      <td>10.484242</td>\n",
       "      <td>10.935122</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>19.60</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.666667</td>\n",
       "      <td>64.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1896.675548</td>\n",
       "      <td>3711.320464</td>\n",
       "      <td>2.694137</td>\n",
       "      <td>5.678128</td>\n",
       "      <td>-3.307332</td>\n",
       "      <td>4.463846</td>\n",
       "      <td>2.972125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3969.0</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>63.0</td>\n",
       "      <td>73.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'001'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.249329</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16558.465868</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12824.553561</td>\n",
       "      <td>48.060086</td>\n",
       "      <td>40.101046</td>\n",
       "      <td>6.171980</td>\n",
       "      <td>5.366953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>28.32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.666667</td>\n",
       "      <td>1655.846587</td>\n",
       "      <td>1603.069195</td>\n",
       "      <td>3.682373</td>\n",
       "      <td>5.882507</td>\n",
       "      <td>-1.693045</td>\n",
       "      <td>6.110872</td>\n",
       "      <td>5.173025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6889.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>83.0</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>46.395227</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11616.087348</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9651.202301</td>\n",
       "      <td>53.498019</td>\n",
       "      <td>35.075704</td>\n",
       "      <td>6.260343</td>\n",
       "      <td>3.491417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>19.34</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.666667</td>\n",
       "      <td>67.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>1161.608735</td>\n",
       "      <td>1206.400288</td>\n",
       "      <td>3.220909</td>\n",
       "      <td>6.548105</td>\n",
       "      <td>-1.101393</td>\n",
       "      <td>6.198360</td>\n",
       "      <td>3.568864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1369.0</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>53.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SEQN  marriage  HOD050  HOQ065  EMPLOY  unemployment  ELIGSTAT  \\\n",
       "0  21009.0       1.0     6.0     1.0     1.0           0.0       1.0   \n",
       "1  21010.0       1.0     3.0     1.0     2.0           1.0       1.0   \n",
       "2  21012.0       1.0     7.0     1.0     3.0           0.0       1.0   \n",
       "3  21015.0       1.0     6.0     1.0     3.0           0.0       1.0   \n",
       "4  21017.0       1.0     3.0     2.0     1.0           0.0       1.0   \n",
       "\n",
       "   MORTSTAT UCOD_LEADING  DIABETES  HYPERTEN  PERMTH_INT  PERMTH_EXM  \\\n",
       "0       0.0          NaN       NaN       NaN       196.0       195.0   \n",
       "1       0.0          NaN       NaN       NaN       182.0       181.0   \n",
       "2       1.0       b'001'       0.0       0.0       127.0       126.0   \n",
       "3       1.0       b'001'       0.0       0.0        25.0        24.0   \n",
       "4       0.0          NaN       NaN       NaN       202.0       201.0   \n",
       "\n",
       "   Death_heart  Death_cancer  Death_resp  Death_cerev  Death_diabe  \\\n",
       "0          0.0           0.0         0.0          0.0          0.0   \n",
       "1          0.0           0.0         0.0          0.0          0.0   \n",
       "2          1.0           0.0         0.0          0.0          0.0   \n",
       "3          1.0           0.0         0.0          0.0          0.0   \n",
       "4          0.0           0.0         0.0          0.0          0.0   \n",
       "\n",
       "   Death_other  death_cvd  death_cmd  FSDHH  SNAP   FS  ins  RIDAGEYR  \\\n",
       "0          0.0        0.0        0.0    1.0   0.0  1.0  1.0      55.0   \n",
       "1          0.0        0.0        0.0    3.0   2.0  0.0  0.0      52.0   \n",
       "2          0.0        1.0        1.0    1.0   2.0  1.0  0.0      63.0   \n",
       "3          0.0        1.0        1.0    1.0   2.0  1.0  2.0      83.0   \n",
       "4          0.0        0.0        0.0    1.0   2.0  1.0  0.0      37.0   \n",
       "\n",
       "   INDFMPIR  diabe  smk  smk_avg  sex  race  HEI2015_TOTAL_SCORE  edu  alcg2  \\\n",
       "0      3.79    0.0  1.0      0.0  1.0   1.0            45.542908  2.0    1.0   \n",
       "1      1.24    0.0  4.0     20.0  2.0   1.0            51.931080  3.0    3.0   \n",
       "2      0.89    0.0  4.0     20.0  1.0   2.0            38.637620  2.0    4.0   \n",
       "3      1.20    0.0  2.0      0.0  1.0   1.0            67.249329  3.0    1.0   \n",
       "4      0.21    0.0  3.0      3.0  2.0   3.0            46.395227  1.0    1.0   \n",
       "\n",
       "   DAYS        WTDRD1  DR12DRST         WTDR2D    i_optup      i_FCS  \\\n",
       "0   1.0  56998.593412       1.0  170262.470827  42.652217  25.525713   \n",
       "1   1.0  55313.014168       1.0   75296.121197  44.072913  30.611291   \n",
       "2   1.0  18966.755482       1.0   29690.563714  46.390303  29.339153   \n",
       "3   1.0  16558.465868       1.0   12824.553561  48.060086  40.101046   \n",
       "4   1.0  11616.087348       1.0    9651.202301  53.498019  35.075704   \n",
       "\n",
       "      i_HSR    i_nutri  perE_alco  sdmvpsu  sdmvstra  tchol    hdl    ldl  \\\n",
       "0  4.324399   7.838628   0.000000      2.0      31.0  254.0   37.0  176.0   \n",
       "1  5.652702   4.488967  10.617983      1.0      29.0  174.0  119.0   39.0   \n",
       "2  4.508485  10.484242  10.935122      2.0      33.0  191.0   92.0   78.0   \n",
       "3  6.171980   5.366953   0.000000      2.0      33.0  141.0   34.0   94.0   \n",
       "4  6.260343   3.491417   0.000000      2.0      42.0  184.0   77.0   65.0   \n",
       "\n",
       "      tg    bmi  dm_self  hba1c  cancer         sbp        dbp  dm_rx  \\\n",
       "0  198.0  31.26      2.0    5.9     0.0  120.000000  86.000000    0.0   \n",
       "1   86.0  25.49      2.0    5.5     0.0  133.333333  84.000000    0.0   \n",
       "2  111.0  19.60      2.0    4.8     0.0  122.666667  64.666667    0.0   \n",
       "3   60.0  28.32      2.0    5.0     1.0  154.000000  54.000000    0.0   \n",
       "4  222.0  19.34      2.0    5.1     0.0  102.666667  67.333333    0.0   \n",
       "\n",
       "   chol_rx  angina_rx  CVD  lung_disease  angina      met_hr         wt10  \\\n",
       "0      0.0        0.0  0.0           0.0     0.0   16.000000  5699.859341   \n",
       "1      0.0        0.0  0.0           1.0     0.0  130.000000  5531.301417   \n",
       "2      0.0        0.0  0.0           0.0     0.0    0.000000  1896.675548   \n",
       "3      0.0        0.0  1.0           1.0     0.0   38.666667  1655.846587   \n",
       "4      0.0        0.0  0.0           0.0     0.0   11.333333  1161.608735   \n",
       "\n",
       "             wt  i_FCS_sd  i_Optup_sd  i_nutri_sd  i_HSR_sd  hei2015_sd  \\\n",
       "0  21282.808853  2.343959    5.220590   -2.472753  4.281583    3.503301   \n",
       "1   9412.015150  2.810954    5.394481   -1.416078  5.596735    3.994698   \n",
       "2   3711.320464  2.694137    5.678128   -3.307332  4.463846    2.972125   \n",
       "3   1603.069195  3.682373    5.882507   -1.693045  6.110872    5.173025   \n",
       "4   1206.400288  3.220909    6.548105   -1.101393  6.198360    3.568864   \n",
       "\n",
       "   Death_inj  Death_alz  Death_infl  Death_kid  death_other1  Death_oth2  \\\n",
       "0        0.0        0.0         0.0        0.0           0.0         0.0   \n",
       "1        0.0        0.0         0.0        0.0           0.0         0.0   \n",
       "2        0.0        0.0         0.0        0.0           0.0         0.0   \n",
       "3        0.0        0.0         0.0        0.0           0.0         0.0   \n",
       "4        0.0        0.0         0.0        0.0           0.0         0.0   \n",
       "\n",
       "   death_cmdk  death_cmdkh  death_multi   agesq         py  agestart  \\\n",
       "0         0.0          0.0          0.0  3025.0  16.250000      55.0   \n",
       "1         0.0          0.0          0.0  2704.0  15.083333      52.0   \n",
       "2         1.0          1.0          1.0  3969.0  10.500000      63.0   \n",
       "3         1.0          1.0          1.0  6889.0   2.000000      83.0   \n",
       "4         0.0          0.0          0.0  1369.0  16.750000      37.0   \n",
       "\n",
       "      ageend  pir  bmic  include  ins2  unemployment2  \n",
       "0  71.250000  3.0   3.0      1.0   1.0            0.0  \n",
       "1  67.083333  1.0   2.0      1.0   0.0            1.0  \n",
       "2  73.500000  1.0   0.0      1.0   0.0            1.0  \n",
       "3  85.000000  1.0   2.0      1.0   1.0            1.0  \n",
       "4  53.750000  1.0   0.0      1.0   0.0            0.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Path to your .sas7bdat file\n",
    "file_path = \"/Users/dengshuyue/Desktop/SDOH/analysis/data/sodh_diet_mort.sas7bdat\"\n",
    "\n",
    "# Load the dataset using pandas (requires pyreadstat)\n",
    "df = pd.read_sas(file_path, format=\"sas7bdat\")\n",
    "\n",
    "# Preview the data\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()\n",
    "\n",
    "# List all column names\n",
    "# print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ae37456-384b-43ef-a397-231c5e43cf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sample size: 38,900\n",
      "Age range: 20.0 to 85.0 years\n"
     ]
    }
   ],
   "source": [
    "# Display total number of rows (i.e., participants) in the dataset\n",
    "print(f\"Total sample size: {df.shape[0]:,}\")\n",
    "\n",
    "# Check the min and max age\n",
    "min_age = df['RIDAGEYR'].min()\n",
    "max_age = df['RIDAGEYR'].max()\n",
    "print(f\"Age range: {min_age} to {max_age} years\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0354e411-4071-4d2d-b78c-fca5f733ca15",
   "metadata": {},
   "source": [
    "<h2>Merge datasets step-by-step and track sample size</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea763e8-7ab0-4d7e-b17a-5afda4e7847b",
   "metadata": {},
   "source": [
    "<h3>Merge demo</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7fe3423d-97e9-4c13-bcab-ae3de85d819b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total rows: 80312\n",
      "✅ Unique SEQN values: 80312\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Set path\n",
    "folder_path = \"/Users/dengshuyue/Desktop/SDOH/analysis/data\"\n",
    "\n",
    "# Step 2: NHANES demographic files to check\n",
    "demo_files = [\n",
    "    #\"demo\",    # 1999–2000\n",
    "    #\"demo_b\", # 2001–2002\n",
    "    \"demo_c\",  # 2003–2004\n",
    "    \"demo_d\",  # 2005–2006\n",
    "    \"demo_e\",  # 2007–2008\n",
    "    \"demo_f\",  # 2009–2010\n",
    "    \"demo_g\",  # 2011–2012\n",
    "    \"demo_h\",  # 2013–2014\n",
    "    \"demo_i\",  # 2015–2016\n",
    "    \"demo_j\"   # 2017–2018\n",
    "]\n",
    "# Step 3: Load files if they exist\n",
    "demo_dfs = []\n",
    "for f in demo_files:\n",
    "    file_path = os.path.join(folder_path, f\"{f}.sas7bdat\")\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_sas(file_path)\n",
    "        demo_dfs.append(df)\n",
    "    else:\n",
    "        print(f\" File not found: {file_path}\")\n",
    "\n",
    "# Step 4: Combine datasets\n",
    "demoall = pd.concat(demo_dfs, ignore_index=True)\n",
    "demoall = demoall.copy()  # Avoid fragmentation warnings\n",
    "\n",
    "\n",
    "# print(\"📝 Preview of DMDMARTL values:\")\n",
    "# print(demoall[\"DMDMARTL\"].value_counts(dropna=False))\n",
    "\n",
    "\n",
    "# Step 5: Recode marriage from DMDMARTL\n",
    "conditions = [\n",
    "    demoall['DMDMARTL'].isin([1, 6]),\n",
    "    demoall['DMDMARTL'].isin([3, 4]),\n",
    "    demoall['DMDMARTL'] == 2,\n",
    "    demoall['DMDMARTL'] == 5\n",
    "]\n",
    "choices = [1, 2, 3, 4]\n",
    "demoall['marriage'] = np.select(conditions, choices, default=pd.NA)\n",
    "\n",
    "# Step 6: Keep only SEQN and marriage\n",
    "demoall = demoall[['SEQN', 'marriage']]\n",
    "\n",
    "# Step 7: Summary counts\n",
    "total_rows = demoall.shape[0]\n",
    "unique_ids = demoall['SEQN'].nunique()\n",
    "print(f\"✅ Total rows: {total_rows}\")\n",
    "print(f\"✅ Unique SEQN values: {unique_ids}\")\n",
    "\n",
    "# Step 8: Preview\n",
    "# demoall.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb1804b-1f7d-46f5-a98a-19d6534ba831",
   "metadata": {},
   "source": [
    "<h3>Preprocess SDOH</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4bd52bac-c8dd-497b-b42f-fc2d95baa41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Employment data (OCQ) ---\n",
    "ocq = pd.read_sas(f\"{folder_path}/ocq.sas7bdat\")\n",
    "\n",
    "ocq['employ'] = np.nan\n",
    "ocq.loc[ocq['OCD150'] == 1, 'employ'] = 1\n",
    "ocq.loc[(ocq['OCD150'] == 3) | (ocq['OCQ380'] == 5), 'employ'] = 2\n",
    "ocq.loc[ocq['OCQ380'] == 3, 'employ'] = 3\n",
    "ocq.loc[ocq['OCQ380'].isin([4, 6]), 'employ'] = 4\n",
    "ocq.loc[ocq['OCQ380'].isin([1, 2, 7]), 'employ'] = 5\n",
    "ocq['unemployment'] = (ocq['employ'] == 2).astype(int)\n",
    "ocq = ocq[['SEQN', 'employ', 'unemployment']]\n",
    "\n",
    "# --- Housing data (HOQ) ---\n",
    "hoq = pd.read_sas(f\"{folder_path}/hoq.sas7bdat\")\n",
    "hoq.loc[hoq['HOQ065'].isin([7, 9]), 'HOQ065'] = np.nan\n",
    "hoq = hoq[['SEQN', 'HOD050', 'HOQ065']]\n",
    "\n",
    "# --- Health insurance (HIQs) ---\n",
    "hiqs = pd.read_sas(f\"{folder_path}/hiqs.sas7bdat\")\n",
    "ins = pd.DataFrame({'SEQN': hiqs['SEQN']})\n",
    "ins['ins'] = np.nan\n",
    "\n",
    "# Private insurance\n",
    "ins.loc[(hiqs['HIQ031A'] == 14) | (hiqs['HID030A'] == 1), 'ins'] = 1\n",
    "\n",
    "# Medicare\n",
    "ins.loc[\n",
    "    ((hiqs['HIQ031B'] == 15) & (hiqs['HIQ031D'] != 17) & (hiqs['HIQ031E'] != 18)) |\n",
    "    ((hiqs['HID030B'] == 1) & (hiqs['HID030C'] != 1)),\n",
    "    'ins'\n",
    "] = 2\n",
    "\n",
    "# Medicaid\n",
    "ins.loc[\n",
    "    (((hiqs['HIQ031D'] == 17) | (hiqs['HIQ031E'] == 18)) & (hiqs['HIQ031B'] != 15)) |\n",
    "    ((hiqs['HID030B'] != 1) & (hiqs['HID030C'] == 1)),\n",
    "    'ins'\n",
    "] = 3\n",
    "ins.loc[\n",
    "    ((hiqs['HIQ031B'] == 15) & (hiqs['HIQ031D'] == 17)) |\n",
    "    ((hiqs['HID030B'] == 1) & (hiqs['HID030C'] == 1)),\n",
    "    'ins'\n",
    "] = 3\n",
    "\n",
    "# Other insurance\n",
    "ins.loc[\n",
    "    (hiqs[['HIQ031C', 'HIQ031F', 'HIQ031G', 'HIQ031H', 'HIQ031I']].eq(1).any(axis=1)) |\n",
    "    (hiqs['HID030D'] == 1),\n",
    "    'ins'\n",
    "] = 5\n",
    "\n",
    "# No insurance\n",
    "ins.loc[(hiqs['HIQ011'] == 2) | (hiqs['HID010'] == 2), 'ins'] = 0\n",
    "\n",
    "# --- SNAP and Food Security (FSQS) ---\n",
    "fsqs = pd.read_sas(f\"{folder_path}/fsqs.sas7bdat\")\n",
    "snap = pd.DataFrame({'SEQN': fsqs['SEQN'], 'FSDHH': fsqs['FSDHH']})\n",
    "\n",
    "snap['SNAP'] = np.nan\n",
    "snap.loc[fsqs['FSQ165'] == 2, 'SNAP'] = 0\n",
    "snap.loc[fsqs['FSQ012'] == 1, 'SNAP'] = 1\n",
    "snap.loc[fsqs['FSQ012'] == 2, 'SNAP'] = 0\n",
    "snap.loc[fsqs['FSQ171'] == 1, 'SNAP'] = 1\n",
    "snap.loc[fsqs['FSQ171'] == 2, 'SNAP'] = 0\n",
    "snap.loc[fsqs['FSD170N'] >= 1, 'SNAP'] = 1\n",
    "snap.loc[fsqs['FSQ170'] == 1, 'SNAP'] = 1\n",
    "snap.loc[(fsqs['FSQ170'] == 2) & (fsqs['FSD170N'] < 1), 'SNAP'] = 0\n",
    "snap.loc[fsqs['FSD200'] == 1, 'SNAP'] = 1\n",
    "\n",
    "# Food Security\n",
    "snap['FS'] = np.nan\n",
    "snap.loc[fsqs['FSDHH'].isin([1, 2]), 'FS'] = 1\n",
    "snap.loc[fsqs['FSDHH'] > 2, 'FS'] = 0\n",
    "\n",
    "# Keep only final columns\n",
    "snap = snap[['SEQN', 'SNAP', 'FSDHH', 'FS']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0756bd0-74c3-4a01-91be-3e39f65c73f8",
   "metadata": {},
   "source": [
    "<h3>Load and Preprocess Dietary Scores, Covariates, Weights, and Mortality Data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e3b5216a-9d0c-42f2-87d2-e67931c22a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read dietary score data\n",
    "scores = pd.read_excel(os.path.join(folder_path, \"i.scores.xlsx\"), engine=\"openpyxl\")\n",
    "\n",
    "# Rename columns to match desired output\n",
    "scores = scores.rename(columns={\n",
    "    \"seqn\": \"SEQN\",\n",
    "    \"i.FCS\": \"i_FCS\",\n",
    "    \"i.optup\": \"i_optup\",  # keep lowercase here first\n",
    "    \"i.HSR\": \"i_HSR\",\n",
    "    \"i.nutri\": \"i_nutri\"\n",
    "})\n",
    "\n",
    "# Then copy and rename for output\n",
    "scores2 = scores[[\"SEQN\", \"i_FCS\", \"i_optup\", \"i_HSR\", \"i_nutri\"]].copy()\n",
    "scores2 = scores2.rename(columns={\"i_optup\": \"i_Optup\"})\n",
    "scores2 = scores2.sort_values(\"SEQN\")\n",
    "\n",
    "\n",
    "# Step 2: Read covariates from Lu paper\n",
    "covar = pd.read_sas(os.path.join(folder_path, \"covar.sas7bdat\"), format=\"sas7bdat\")\n",
    "covar = covar.rename(columns=str.upper)  # make all column names uppercase to match SAS style\n",
    "# filter available variables only\n",
    "covar_vars = [\"SEQN\", \"RIDAGEYR\", \"SEX\", \"RACE\", \"EDU\", \"INDFMPIR\", \"SMK_AVG\", \"SMK_PAST\",\n",
    "              \"SMK\", \"ALCG2\", \"HEI2015_TOTAL_SCORE\", \"DIABE\"]\n",
    "covar = covar[[col for col in covar_vars if col in covar.columns]].copy()\n",
    "covar = covar.sort_values(\"SEQN\")\n",
    "\n",
    "# Step 3: Read covariates from Meghan paper\n",
    "covariates1_raw = pd.read_csv(os.path.join(folder_path, \"covariates.csv\"))\n",
    "covariates1 = covariates1_raw.rename(columns={\"seqn\": \"SEQN\"})\n",
    "covariates_vars = [\"SEQN\", \"sdmvpsu\", \"sdmvstra\", \"met_hr\", \"perE_alco\", \"dm_self\",\n",
    "                   \"tchol\", \"hdl\", \"ldl\", \"tg\", \"bmi\", \"CVD\", \"dm_rx\", \"chol_rx\",\n",
    "                   \"angina_rx\", \"lung_disease\", \"angina\", \"hba1c\", \"sbp\", \"dbp\", \"cancer\"]\n",
    "covariates1 = covariates1[[col for col in covariates_vars if col in covariates1.columns]].copy()\n",
    "covariates1 = covariates1.sort_values(\"SEQN\")\n",
    "\n",
    "# Step 4: Read dietary weight data (filter DAYS == 1)\n",
    "dietwt = pd.read_sas(os.path.join(folder_path, \"gg.sas7bdat\"), format=\"sas7bdat\")\n",
    "\n",
    "# Check for expected columns\n",
    "required_cols = [\"SEQN\", \"DAYS\", \"WTDRD1\", \"WTDR2D\", \"DR12DRST\"]\n",
    "missing = [col for col in required_cols if col not in dietwt.columns]\n",
    "if missing:\n",
    "    print(f\"Warning: Missing columns from gg.sas7bdat: {missing}\")\n",
    "\n",
    "# Filter and select\n",
    "dietwt = dietwt[dietwt[\"DAYS\"] == 1][[\"SEQN\", \"WTDRD1\", \"WTDR2D\", \"DR12DRST\"]].copy()\n",
    "dietwt = dietwt.sort_values(\"SEQN\")\n",
    "\n",
    "\n",
    "# Step 5: Read mortality data\n",
    "mort = pd.read_sas(os.path.join(folder_path, \"mortality9918.sas7bdat\"), format=\"sas7bdat\")\n",
    "mort = mort.sort_values(\"SEQN\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3a00e673-bb93-4e3f-a581-68a145fb1caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores2:\n",
      "  Rows: 39746\n",
      "  Unique SEQN: 39746\n",
      "----------------------------------------\n",
      "covar:\n",
      "  Rows: 101316\n",
      "  Unique SEQN: 101316\n",
      "----------------------------------------\n",
      "covariates1:\n",
      "  Rows: 39262\n",
      "  Unique SEQN: 39262\n",
      "----------------------------------------\n",
      "dietwt:\n",
      "  Rows: 88413\n",
      "  Unique SEQN: 88413\n",
      "----------------------------------------\n",
      "mort:\n",
      "  Rows: 59064\n",
      "  Unique SEQN: 59064\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def summarize_df(name, df):\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Rows: {df.shape[0]}\")\n",
    "    print(f\"  Unique SEQN: {df['SEQN'].nunique()}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "summarize_df(\"scores2\", scores2)\n",
    "summarize_df(\"covar\", covar)\n",
    "summarize_df(\"covariates1\", covariates1)\n",
    "summarize_df(\"dietwt\", dietwt)\n",
    "summarize_df(\"mort\", mort)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d60ce34-7b66-4a79-bac4-2a1a8aade4b6",
   "metadata": {},
   "source": [
    "<h3>Merging Datasets and \n",
    "    Creating Derived Variables for Mortality and Covariate Analysis<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0d31c071-8484-4653-b70d-fdf8e165d6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all datasets by SEQN\n",
    "from functools import reduce\n",
    "\n",
    "# Put all dataframes into a list\n",
    "merge_list = [demoall, hoq, ocq, mort, snap, ins, covar, dietwt, scores2, covariates1]\n",
    "\n",
    "# Inner merge on SEQN for all (change to outer if needed)\n",
    "score_mort = reduce(lambda left, right: pd.merge(left, right, on=\"SEQN\", how=\"left\"), merge_list)\n",
    "\n",
    "# Variable transformations\n",
    "score_mort[\"wt10\"] = score_mort[\"WTDRD1\"] / 10\n",
    "score_mort[\"wt\"] = score_mort[\"WTDR2D\"] / 8\n",
    "score_mort[\"i_FCS_sd\"] = score_mort[\"i_FCS\"] / 10.89\n",
    "score_mort[\"i_Optup_sd\"] = score_mort[\"i_Optup\"] / 8.17\n",
    "score_mort[\"i_nutri_sd\"] = -score_mort[\"i_nutri\"] / 3.17\n",
    "score_mort[\"i_HSR_sd\"] = score_mort[\"i_HSR\"] / 1.01\n",
    "score_mort[\"hei2015_sd\"] = score_mort[\"HEI2015_TOTAL_SCORE\"] / 13\n",
    "\n",
    "# Recode UCOD_LEADING to create binary death indicators\n",
    "score_mort[\"death_heart\"] = (score_mort[\"UCOD_LEADING\"] == \"001\").astype(int)\n",
    "score_mort[\"death_cancer\"] = (score_mort[\"UCOD_LEADING\"] == \"002\").astype(int)\n",
    "score_mort[\"death_resp\"] = (score_mort[\"UCOD_LEADING\"] == \"003\").astype(int)\n",
    "score_mort[\"Death_inj\"] = (score_mort[\"UCOD_LEADING\"] == \"004\").astype(int)\n",
    "score_mort[\"death_cerev\"] = (score_mort[\"UCOD_LEADING\"] == \"005\").astype(int)\n",
    "score_mort[\"Death_alz\"] = (score_mort[\"UCOD_LEADING\"] == \"006\").astype(int)\n",
    "score_mort[\"death_diabe\"] = (score_mort[\"UCOD_LEADING\"] == \"007\").astype(int)\n",
    "score_mort[\"Death_infl\"] = (score_mort[\"UCOD_LEADING\"] == \"008\").astype(int)\n",
    "score_mort[\"Death_kid\"] = (score_mort[\"UCOD_LEADING\"] == \"009\").astype(int)\n",
    "score_mort[\"death_other1\"] = (score_mort[\"UCOD_LEADING\"] == \"010\").astype(int)\n",
    "\n",
    "# Composite death categories\n",
    "score_mort[\"Death_other\"] = score_mort[[\"death_resp\", \"Death_inj\", \"Death_alz\", \"Death_infl\"]].sum(axis=1).clip(upper=1)\n",
    "score_mort[\"Death_oth2\"] = score_mort[[\"death_resp\", \"Death_inj\", \"Death_alz\", \"Death_infl\", \"death_other1\"]].sum(axis=1).clip(upper=1)\n",
    "\n",
    "# CMD outcomes\n",
    "score_mort[\"death_cvd\"] = score_mort[[\"death_heart\", \"death_cerev\"]].sum(axis=1).clip(upper=1)\n",
    "score_mort[\"death_cmd\"] = score_mort[[\"death_heart\", \"death_cerev\", \"death_diabe\"]].sum(axis=1).clip(upper=1)\n",
    "score_mort[\"death_cmdk\"] = score_mort[[\"death_heart\", \"death_cerev\", \"death_diabe\", \"Death_kid\"]].sum(axis=1).clip(upper=1)\n",
    "\n",
    "# Initialize death_cmdkh\n",
    "score_mort[\"death_cmdkh\"] = score_mort[\"death_cmdk\"]\n",
    "\n",
    "# Overwrite death_cmdkh if diabetes or hypertension is present\n",
    "score_mort.loc[score_mort[\"DIABETES\"] == 1, \"death_cmdkh\"] = 1\n",
    "score_mort.loc[score_mort[\"HYPERTEN\"] == 1, \"death_cmdkh\"] = 1\n",
    "\n",
    "# Fill missing CMD with 0\n",
    "score_mort[\"death_cmd\"] = score_mort[\"death_cmd\"].fillna(0)\n",
    "\n",
    "# Reset other cause flags if CMD present\n",
    "score_mort.loc[score_mort[\"death_cmd\"] == 1, [\"Death_other\", \"Death_oth2\"]] = 0\n",
    "\n",
    "\n",
    "# Multiple cause mortality category\n",
    "score_mort[\"death_multi\"] = score_mort[\"MORTSTAT\"]\n",
    "score_mort.loc[score_mort[\"death_cmd\"] == 1, \"death_multi\"] = 1\n",
    "score_mort.loc[score_mort[\"death_cancer\"] == 1, \"death_multi\"] = 2\n",
    "score_mort.loc[score_mort[\"Death_oth2\"] == 1, \"death_multi\"] = 3\n",
    "\n",
    "# Age squared and time vars\n",
    "score_mort[\"agesq\"] = score_mort[\"RIDAGEYR\"] ** 2\n",
    "score_mort[\"py\"] = score_mort[\"PERMTH_EXM\"] / 12\n",
    "score_mort[\"agestart\"] = score_mort[\"RIDAGEYR\"]\n",
    "score_mort[\"ageend\"] = score_mort[\"RIDAGEYR\"] + score_mort[\"py\"]\n",
    "\n",
    "# Poverty ratio category\n",
    "score_mort[\"pir\"] = 5\n",
    "score_mort.loc[(score_mort[\"INDFMPIR\"] < 1.3) & (score_mort[\"INDFMPIR\"].notna()), \"pir\"] = 1\n",
    "score_mort.loc[(score_mort[\"INDFMPIR\"] >= 1.3), \"pir\"] = 2\n",
    "score_mort.loc[(score_mort[\"INDFMPIR\"] >= 3), \"pir\"] = 3\n",
    "\n",
    "# Recode SNAP for low-income nonparticipants\n",
    "score_mort.loc[(score_mort[\"INDFMPIR\"].between(0, 1.3)) & (score_mort[\"SNAP\"] != 1), \"SNAP\"] = 2\n",
    "\n",
    "# BMI category\n",
    "score_mort[\"bmic\"] = pd.NA\n",
    "score_mort.loc[(score_mort[\"bmi\"] > 0) & (score_mort[\"bmi\"] < 18.5), \"bmic\"] = 1\n",
    "score_mort.loc[(score_mort[\"bmi\"] >= 18.5) & (score_mort[\"bmi\"] < 25), \"bmic\"] = 0\n",
    "score_mort.loc[(score_mort[\"bmi\"] >= 25), \"bmic\"] = 2\n",
    "score_mort.loc[(score_mort[\"bmi\"] >= 30), \"bmic\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6465c46d-fbcd-41b7-8de0-4b2ba06d3a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After ELIGSTAT & MORTSTAT inclusion: {1: 47632, 0: 32680}\n",
      "Dropped at Step 2 (diet data or recall quality): 7950\n",
      "Dropped at Step 3 (missing FS/SNAP or pir=4): 780\n",
      "Dropped at Step 4 (zero or negative WTDRD1): 0\n",
      "📊 Final include flag counts: {1: 38902, 0: 32680, 2: 7950, 3: 780}\n",
      " Final analytic sample size: 38902\n"
     ]
    }
   ],
   "source": [
    "# check drop by step\n",
    "\n",
    "# Step 1: Initial inclusion based on ELIGSTAT and MORTSTAT\n",
    "score_mort[\"include\"] = np.where(\n",
    "    (score_mort[\"ELIGSTAT\"] == 1) & (score_mort[\"MORTSTAT\"].notna()), 1, 0\n",
    ")\n",
    "print(f\"After ELIGSTAT & MORTSTAT inclusion: {score_mort['include'].value_counts().to_dict()}\")\n",
    "\n",
    "# Step 2: Exclude missing HEI, invalid WTDRD1, or DR12DRST > 1\n",
    "step2_cond = (\n",
    "    (score_mort[\"include\"] == 1) &\n",
    "    (\n",
    "        score_mort[\"HEI2015_TOTAL_SCORE\"].isna() |\n",
    "        (score_mort[\"WTDRD1\"] <= 0) |\n",
    "        (score_mort[\"DR12DRST\"] > 1)\n",
    "    )\n",
    ")\n",
    "print(f\"Dropped at Step 2 (diet data or recall quality): {step2_cond.sum()}\")\n",
    "score_mort.loc[step2_cond, \"include\"] = 2\n",
    "\n",
    "# Step 3: Exclude missing FS, SNAP, or pir == 4\n",
    "step3_cond = (\n",
    "    (score_mort[\"include\"] == 1) &\n",
    "    (\n",
    "        score_mort[\"FS\"].isna() |\n",
    "        score_mort[\"SNAP\"].isna() |\n",
    "        (score_mort[\"pir\"] == 4)\n",
    "    )\n",
    ")\n",
    "print(f\"Dropped at Step 3 (missing FS/SNAP or pir=4): {step3_cond.sum()}\")\n",
    "score_mort.loc[step3_cond, \"include\"] = 3\n",
    "\n",
    "# Step 4: Exclude if WTDRD1 <= 0 (redundant with step 2, but following SAS)\n",
    "step4_cond = (score_mort[\"include\"] == 1) & (score_mort[\"WTDRD1\"] <= 0)\n",
    "print(f\"Dropped at Step 4 (zero or negative WTDRD1): {step4_cond.sum()}\")\n",
    "score_mort.loc[step4_cond, \"include\"] = 4\n",
    "\n",
    "# Final count of each inclusion code\n",
    "print(f\"📊 Final include flag counts: {score_mort['include'].value_counts().to_dict()}\")\n",
    "\n",
    "# Apply final filter\n",
    "score_mort = score_mort[score_mort[\"include\"] == 1].copy()\n",
    "print(f\" Final analytic sample size: {score_mort.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d9880c7b-03e9-4aa9-a2b6-72afb7d51d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inclusion flag\n",
    "score_mort[\"include\"] = np.where(\n",
    "    (score_mort[\"ELIGSTAT\"] == 1) & (score_mort[\"MORTSTAT\"].notna()), 1, 0\n",
    ")\n",
    "score_mort.loc[\n",
    "    (score_mort[\"include\"] == 1) &\n",
    "    (\n",
    "        (score_mort[\"HEI2015_TOTAL_SCORE\"].isna()) |\n",
    "        (score_mort[\"WTDRD1\"] <= 0) |\n",
    "        (score_mort[\"DR12DRST\"] > 1)\n",
    "    ),\n",
    "    \"include\"\n",
    "] = 2\n",
    "score_mort.loc[\n",
    "    (score_mort[\"include\"] == 1) &\n",
    "    (\n",
    "        score_mort[\"FS\"].isna() |\n",
    "        score_mort[\"SNAP\"].isna() |\n",
    "        (score_mort[\"pir\"] == 4)\n",
    "    ),\n",
    "    \"include\"\n",
    "] = 3\n",
    "score_mort.loc[\n",
    "    (score_mort[\"include\"] == 1) & (score_mort[\"WTDRD1\"] <= 0),\n",
    "    \"include\"\n",
    "] = 4\n",
    "\n",
    "# Insurance binary\n",
    "score_mort[\"ins2\"] = np.where(score_mort[\"ins\"] == 0, 0, 1)\n",
    "\n",
    "# Unemployment indicator\n",
    "score_mort[\"unemployment2\"] = np.where(score_mort[\"employ\"] > 1, 1, 0)\n",
    "\n",
    "# Final filter to keep only those with include == 1\n",
    "score_mort = score_mort[score_mort[\"include\"] == 1].copy()\n",
    "\n",
    "# Save final dataset\n",
    "score_mort.to_pickle(os.path.join(folder_path, \"SODH_diet_mort.pkl\"))  # You can also use .csv or .parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299cbdb9-9f4f-45ee-9d9a-ac27efde94e1",
   "metadata": {},
   "source": [
    "<h3>check final merged data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8cf05be6-2a0e-4022-909b-d08da3900193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total rows: 38902\n",
      " Unique SEQN values: 38902\n"
     ]
    }
   ],
   "source": [
    "SODH_diet_mort = pd.read_pickle(os.path.join(folder_path, \"SODH_diet_mort.pkl\"))\n",
    "# Number of rows\n",
    "total_rows = SODH_diet_mort.shape[0]\n",
    "\n",
    "# Number of unique SEQN values\n",
    "unique_ids = SODH_diet_mort['SEQN'].nunique()\n",
    "\n",
    "print(f\" Total rows: {total_rows}\")\n",
    "print(f\" Unique SEQN values: {unique_ids}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "bbb9ed4d-66f8-45f5-b203-21551fd964e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Age range: 20.0 to 85.0\n"
     ]
    }
   ],
   "source": [
    "# Check age range\n",
    "min_age = score_mort[\"RIDAGEYR\"].min()\n",
    "max_age = score_mort[\"RIDAGEYR\"].max()\n",
    "\n",
    "print(f\" Age range: {min_age} to {max_age}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9a6928-ddd9-47b1-a751-9688adc470f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63bab96-6045-4562-bc25-ac6aff06a0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b60085-19d6-4273-9e48-498e630c7202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca94725-3dbf-4c0f-9cc9-41fbf49f1b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de9496-7e60-414d-8985-17c00eb4202e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c6adb-c130-40fa-a2b4-ba60cecd8c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9be492-74d7-4489-9878-da7d5c791395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa022767",
   "metadata": {},
   "source": [
    "<h2>🧮 Weighted Summary Statistics for Key Demographics and Health Variables\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "22d3d67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df, meta = pyreadstat.read_sas7bdat(\"/Users/dengshuyue/Desktop/SDOH/analysis/data/sodh_diet_mort.sas7bdat\")\n",
    "\n",
    "# Drop missing weights\n",
    "df = df.dropna(subset=['WTDRD1', 'sdmvstra', 'sdmvpsu'])\n",
    "\n",
    "# Define a simple weighted mean function\n",
    "def weighted_mean(x, w):\n",
    "    return np.sum(x * w) / np.sum(w)\n",
    "\n",
    "# Define a simple weighted proportion function\n",
    "def weighted_prop(var, w, categories=None):\n",
    "    d = df[[var, w]].dropna()\n",
    "    total_weight = d[w].sum()\n",
    "    return (d.groupby(var)[w].sum() / total_weight).sort_index()\n",
    "\n",
    "# Example: weighted mean for age\n",
    "mean_age = weighted_mean(df['RIDAGEYR'], df['WTDRD1'])\n",
    "\n",
    "# Example: weighted proportions for sex\n",
    "sex_props = weighted_prop('sex', 'WTDRD1')\n",
    "race_props = weighted_prop('race', 'WTDRD1')\n",
    "edu_props = weighted_prop('edu', 'WTDRD1')\n",
    "pir_props = weighted_prop('pir', 'WTDRD1')\n",
    "fs_props = weighted_prop('FS', 'WTDRD1')\n",
    "snap_props = weighted_prop('SNAP', 'WTDRD1')\n",
    "smk_props = weighted_prop('smk', 'WTDRD1')\n",
    "alcg2_props = weighted_prop('alcg2', 'WTDRD1')\n",
    "bmic_props = weighted_prop('bmic', 'WTDRD1')\n",
    "\n",
    "# Binary conditions\n",
    "binary_vars = ['DIABETES', 'CVD', 'dm_rx', 'chol_rx', 'angina', 'cancer', 'lung_disease', 'MORTSTAT']\n",
    "binary_means = {var: round(weighted_mean(df[var].fillna(0), df['WTDRD1']) * 100, 1) for var in binary_vars}\n",
    "\n",
    "# Continuous variables\n",
    "cont_vars = ['RIDAGEYR', 'met_hr', 'bmi', 'hba1c', 'sbp', 'dbp', 'hdl', 'ldl', 'tg', 'HEI2015_TOTAL_SCORE']\n",
    "cont_means = {var: round(weighted_mean(df[var], df['WTDRD1']), 2) for var in cont_vars}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167c1fef",
   "metadata": {},
   "source": [
    "<h2>Sample exclusion summary</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "839c3eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample exclusion summary:\n",
      "Total participants: 38420\n",
      "Excluded due to missing mortality data: 0\n",
      "Excluded due to missing dietary recall weight: 0\n",
      "Excluded due to missing family income: 0\n",
      "Excluded due to missing food insecurity status: 0\n",
      "Final analytic sample: 38420\n"
     ]
    }
   ],
   "source": [
    "# === Track exclusion reasons ===\n",
    "\n",
    "total_n = len(df)\n",
    "\n",
    "# 1. Excluded for invalid mortality status\n",
    "exclude_mort = df['MORTSTAT'].isna()\n",
    "n_mort_missing = exclude_mort.sum()\n",
    "\n",
    "# 2. Excluded for fewer than one valid dietary recall\n",
    "exclude_diet = df['WTDRD1'].isna()\n",
    "n_diet_missing = exclude_diet.sum()\n",
    "\n",
    "# 3. Excluded for missing family income (e.g., INDFMPIR or pir)\n",
    "exclude_income = df['pir'].isna()\n",
    "n_income_missing = exclude_income.sum()\n",
    "\n",
    "# 4. Excluded for missing food insecurity status (e.g., FS or FSDHH)\n",
    "exclude_fs = df['FS'].isna()\n",
    "n_fs_missing = exclude_fs.sum()\n",
    "\n",
    "# You can combine all exclusions for final n included if needed\n",
    "excluded_total = exclude_mort | exclude_diet | exclude_income | exclude_fs\n",
    "n_final_included = total_n - excluded_total.sum()\n",
    "\n",
    "# === Print results ===\n",
    "print(\"Sample exclusion summary:\")\n",
    "print(f\"Total participants: {total_n}\")\n",
    "print(f\"Excluded due to missing mortality data: {n_mort_missing}\")\n",
    "print(f\"Excluded due to missing dietary recall weight: {n_diet_missing}\")\n",
    "print(f\"Excluded due to missing family income: {n_income_missing}\")\n",
    "print(f\"Excluded due to missing food insecurity status: {n_fs_missing}\")\n",
    "print(f\"Final analytic sample: {n_final_included}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dfdc65",
   "metadata": {},
   "source": [
    "<h2>Calculate weighted percentage of deceased</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b12bfb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted percentage deceased: 9.1%\n"
     ]
    }
   ],
   "source": [
    "# Clean data: drop rows with missing mortality status or weight\n",
    "mort_df = df[['MORTSTAT', 'WTDRD1']].dropna()\n",
    "\n",
    "# Calculate total weighted sum\n",
    "total_weight = mort_df['WTDRD1'].sum()\n",
    "\n",
    "# Weighted percentage of deceased (MORTSTAT == 1)\n",
    "dead_weight = mort_df.loc[mort_df['MORTSTAT'] == 1, 'WTDRD1'].sum()\n",
    "weighted_pct_dead = (dead_weight / total_weight) * 100\n",
    "\n",
    "print(f\"Weighted percentage deceased: {weighted_pct_dead:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03524dc6",
   "metadata": {},
   "source": [
    "<h2>Generate Weighted Demographic Summary Table</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37c94a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sex</td>\n",
       "      <td>Female</td>\n",
       "      <td>898890154 (52.2%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sex</td>\n",
       "      <td>Male</td>\n",
       "      <td>821475363 (47.8%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>race</td>\n",
       "      <td>Non-Hispanic White</td>\n",
       "      <td>1170666658 (68.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>race</td>\n",
       "      <td>Non-Hispanic Black</td>\n",
       "      <td>192703827 (11.2%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>race</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>231665971 (13.5%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>race</td>\n",
       "      <td>Other</td>\n",
       "      <td>125329062 (7.3%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>edu</td>\n",
       "      <td>Less than high school</td>\n",
       "      <td>273653325 (15.9%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>edu</td>\n",
       "      <td>High school or equivalent</td>\n",
       "      <td>410284219 (23.9%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>edu</td>\n",
       "      <td>Some college</td>\n",
       "      <td>544769320 (31.7%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>edu</td>\n",
       "      <td>College or above</td>\n",
       "      <td>490754264 (28.5%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pir</td>\n",
       "      <td>&lt;1.3</td>\n",
       "      <td>352883685 (20.5%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pir</td>\n",
       "      <td>1.3~2.99</td>\n",
       "      <td>465592751 (27.1%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pir</td>\n",
       "      <td>&gt;=3</td>\n",
       "      <td>809188344 (47.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SNAP</td>\n",
       "      <td>Not participant</td>\n",
       "      <td>1277870183 (74.3%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SNAP</td>\n",
       "      <td>Participant</td>\n",
       "      <td>246720094 (14.3%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SNAP</td>\n",
       "      <td>Income eligible non-participant</td>\n",
       "      <td>195775241 (11.4%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>smk</td>\n",
       "      <td>Nonsmokers</td>\n",
       "      <td>932219796 (54.2%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>smk</td>\n",
       "      <td>Former smokers</td>\n",
       "      <td>429409492 (25.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>smk</td>\n",
       "      <td>&lt;15 cigarettes/day</td>\n",
       "      <td>210303642 (12.2%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>smk</td>\n",
       "      <td>15-24.9 cigarettes/day</td>\n",
       "      <td>109398983 (6.4%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variable                         Category             Overall\n",
       "0       sex                           Female   898890154 (52.2%)\n",
       "1       sex                             Male   821475363 (47.8%)\n",
       "2      race               Non-Hispanic White  1170666658 (68.0%)\n",
       "3      race               Non-Hispanic Black   192703827 (11.2%)\n",
       "4      race                         Hispanic   231665971 (13.5%)\n",
       "5      race                            Other    125329062 (7.3%)\n",
       "6       edu            Less than high school   273653325 (15.9%)\n",
       "7       edu        High school or equivalent   410284219 (23.9%)\n",
       "8       edu                     Some college   544769320 (31.7%)\n",
       "9       edu                 College or above   490754264 (28.5%)\n",
       "10      pir                             <1.3   352883685 (20.5%)\n",
       "11      pir                         1.3~2.99   465592751 (27.1%)\n",
       "12      pir                              >=3   809188344 (47.0%)\n",
       "13     SNAP                  Not participant  1277870183 (74.3%)\n",
       "14     SNAP                      Participant   246720094 (14.3%)\n",
       "15     SNAP  Income eligible non-participant   195775241 (11.4%)\n",
       "16      smk                       Nonsmokers   932219796 (54.2%)\n",
       "17      smk                   Former smokers   429409492 (25.0%)\n",
       "18      smk               <15 cigarettes/day   210303642 (12.2%)\n",
       "19      smk           15-24.9 cigarettes/day    109398983 (6.4%)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try domographic \n",
    "\n",
    "# === Load data ===\n",
    "df, meta = pyreadstat.read_sas7bdat(\"/Users/dengshuyue/Desktop/SDOH/analysis/data/sodh_diet_mort.sas7bdat\")\n",
    "df = df.dropna(subset=['WTDRD1', 'sdmvstra', 'sdmvpsu'])  # drop missing survey vars\n",
    "\n",
    "# === Define helper functions ===\n",
    "def weighted_mean(x, w):\n",
    "    d = pd.DataFrame({'x': x, 'w': w}).dropna()\n",
    "    return np.sum(d.x * d.w) / np.sum(d.w)\n",
    "\n",
    "def weighted_props(df, var, weight):\n",
    "    d = df[[var, weight]].dropna()\n",
    "    total_weight = d[weight].sum()\n",
    "    counts = d.groupby(var)[weight].sum()\n",
    "    proportions = (counts / total_weight).round(3)\n",
    "    return counts.round(0).astype(int), (proportions * 100).round(1)\n",
    "\n",
    "# === Categorical variables ===\n",
    "cat_vars = {\n",
    "    'sex': {2: 'Female', 1: 'Male'},\n",
    "    'race': {\n",
    "        1: 'Non-Hispanic White',\n",
    "        2: 'Non-Hispanic Black',\n",
    "        3: 'Hispanic',\n",
    "        4: 'Other'\n",
    "    },\n",
    "    'edu': {\n",
    "        1: 'Less than high school',\n",
    "        2: 'High school or equivalent',\n",
    "        3: 'Some college',\n",
    "        4: 'College or above'\n",
    "    },\n",
    "    'pir': {\n",
    "        1: '<1.3',\n",
    "        2: '1.3~2.99',\n",
    "        3: '>=3'\n",
    "    },\n",
    "    'SNAP': {\n",
    "        0: 'Not participant',\n",
    "        1: 'Participant',\n",
    "        2: 'Income eligible non-participant'\n",
    "    },\n",
    "    'smk': {\n",
    "        1: 'Nonsmokers',\n",
    "        2: 'Former smokers',\n",
    "        3: '<15 cigarettes/day',\n",
    "        4: '15-24.9 cigarettes/day',\n",
    "        5: '≥ 25 cigarettes/day'\n",
    "    },\n",
    "    'alcg2': {\n",
    "        1: 'Nondrinkers',\n",
    "        2: 'Moderate drinker',\n",
    "        3: 'Heavy drinker',\n",
    "        4: 'Missing'\n",
    "    },\n",
    "    'bmic': {\n",
    "        1: 'BMI <18.5',\n",
    "        2: '18-24.9',\n",
    "        3: '25-29.9',\n",
    "        4: 'BMI ≥30'\n",
    "    }\n",
    "}\n",
    "\n",
    "cat_rows = []\n",
    "for var, labels in cat_vars.items():\n",
    "    counts, props = weighted_props(df, var, 'WTDRD1')\n",
    "    for code, label in labels.items():\n",
    "        if code in counts.index:\n",
    "            cat_rows.append({\n",
    "                'Variable': var,\n",
    "                'Category': label,\n",
    "                'Overall': f\"{counts[code]} ({props[code]}%)\"\n",
    "            })\n",
    "\n",
    "# === Binary prevalence variables (as % only) ===\n",
    "binary_vars = ['DIABETES', 'CVD', 'dm_rx', 'chol_rx', 'angina', 'cancer', 'lung_disease', 'MORTSTAT']\n",
    "for var in binary_vars:\n",
    "    prevalence = weighted_mean(df[var].fillna(0), df['WTDRD1']) * 100\n",
    "    cat_rows.append({\n",
    "        'Variable': var,\n",
    "        'Category': '1',\n",
    "        'Overall': f\"{round(prevalence, 1)}%\"\n",
    "    })\n",
    "\n",
    "# === Continuous variables (means) ===\n",
    "cont_vars = ['RIDAGEYR', 'met_hr', 'bmi', 'hba1c', 'sbp', 'dbp', 'hdl', 'ldl', 'tg', 'HEI2015_TOTAL_SCORE']\n",
    "for var in cont_vars:\n",
    "    mean_val = weighted_mean(df[var], df['WTDRD1'])\n",
    "    cat_rows.append({\n",
    "        'Variable': var,\n",
    "        'Category': '',\n",
    "        'Overall': f\"{round(mean_val, 2)}\"\n",
    "    })\n",
    "\n",
    "# === Final demographic summary table ===\n",
    "demo_table = pd.DataFrame(cat_rows)\n",
    "\n",
    "# Show the first few rows of the demographic summary table\n",
    "demo_table.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eae26a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male: 18845 (48.4%)\n",
      "Female: 20055 (51.6%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38420"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define unweighted counts and proportions\n",
    "def unweighted_props(df, var):\n",
    "    counts = df[var].value_counts(dropna=False).sort_index()\n",
    "    props = counts / counts.sum() * 100\n",
    "    return counts, props.round(1)\n",
    "\n",
    "# Now use it for 'sex'\n",
    "counts, props = unweighted_props(df, 'sex')\n",
    "\n",
    "# Optionally map codes to labels\n",
    "sex_labels = {1: 'Male', 2: 'Female'}\n",
    "for val in counts.index:\n",
    "    label = sex_labels.get(val, val)\n",
    "    print(f\"{label}: {counts[val]} ({props[val]}%)\")\n",
    "18530+19890\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9eae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "##merge be-careful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c1062d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63741b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ed50c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531b7645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2440f2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/dengshuyue/Desktop/SDOH/analysis/code/Ref/2.Prepare data_master.sas', 'r', encoding='latin1') as f:\n",
    "    sas_code = f.read()\n",
    "\n",
    "print(sas_code[:20000])  # Preview the first X,000 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e5a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/dengshuyue/Desktop/SDOH/analysis/code/Ref/2.1_Prepare data_covariates.sas', 'r', encoding='latin1') as f:\n",
    "    sas_code = f.read()\n",
    "\n",
    "print(sas_code[:20000])  # Preview the first X,000 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1742324",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/dengshuyue/Desktop/SDOH/analysis/code/Descriptions_1.sas', 'r', encoding='latin1') as f:\n",
    "    sas_code = f.read()\n",
    "\n",
    "print(sas_code[:20000])  # Preview the first 15,000 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9704426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diabetes Identification Note:\n",
    "# The final diabetes indicator variable used in the analysis is 'diabe2'.\n",
    "# This composite variable identifies diabetes based on the following criteria:\n",
    "# - Self-reported physician diagnosis (DIQ010), current insulin use (DIQ050), or oral medication use (DIQ070)\n",
    "# - Prescription drug data indicating diabetes treatment (dm_rx2)\n",
    "# - Fasting glucose ≥ 126 mg/dL (glu_dm)\n",
    "# - OGTT ≥ 200 mg/dL (ogtt_dm)\n",
    "# - HbA1c ≥ 6.5% (hb_dm)\n",
    "# Any one of these criteria being met will set 'diabe2' = 1, otherwise 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4508de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/dengshuyue/Desktop/SDOH/analysis/Analysis1_COX_allcause_bysub.sas', 'r', encoding='latin1') as f:\n",
    "    sas_code = f.read()\n",
    "\n",
    "print(sas_code[:10000])  # Preview the first 15,000 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bcc94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/dengshuyue/Desktop/SDOH/analysis/Analysis1_dataprep.sas', 'r', encoding='latin1') as f:\n",
    "    sas_code = f.read()\n",
    "\n",
    "print(sas_code[:20000])  # Preview the first 15,000 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58be0118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab19022e-5d46-4163-88b5-58f23781e962",
   "metadata": {},
   "source": [
    "<h1>SDOH score</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e7542aa-9952-439b-afe6-f53d66af6b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOQ065</th>\n",
       "      <th>HOD050</th>\n",
       "      <th>EMPLOY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38895</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38896</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38897</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38898</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38899</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38900 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HOQ065  HOD050  EMPLOY\n",
       "0         1.0     6.0     1.0\n",
       "1         1.0     3.0     2.0\n",
       "2         1.0     7.0     3.0\n",
       "3         1.0     6.0     3.0\n",
       "4         2.0     3.0     1.0\n",
       "...       ...     ...     ...\n",
       "38895     3.0     8.0     1.0\n",
       "38896     1.0     6.0     3.0\n",
       "38897     2.0     1.0     1.0\n",
       "38898     2.0     8.0     2.0\n",
       "38899     1.0     9.0     4.0\n",
       "\n",
       "[38900 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see housing and employ\n",
    "df[['HOQ065', 'HOD050', 'EMPLOY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "508bb06c-1993-4a1f-ad30-df81712d139c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== HOQ065 Summary ===\n",
      "Value counts:\n",
      "HOQ065\n",
      "1.0    24162\n",
      "2.0    13779\n",
      "3.0      907\n",
      "NaN       52\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Proportions:\n",
      "HOQ065\n",
      "1.0    62.11\n",
      "2.0    35.42\n",
      "3.0     2.33\n",
      "NaN     0.13\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Missing values: 52\n",
      "\n",
      "=== HOD050 Summary ===\n",
      "Value counts:\n",
      "HOD050\n",
      "5.0      8034\n",
      "6.0      7469\n",
      "4.0      6416\n",
      "7.0      5175\n",
      "8.0      3352\n",
      "3.0      3193\n",
      "9.0      1908\n",
      "10.0     1122\n",
      "2.0       820\n",
      "11.0      476\n",
      "12.0      285\n",
      "1.0       281\n",
      "13.0      260\n",
      "999.0      43\n",
      "777.0      39\n",
      "NaN        27\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Proportions:\n",
      "HOD050\n",
      "5.0      20.65\n",
      "6.0      19.20\n",
      "4.0      16.49\n",
      "7.0      13.30\n",
      "8.0       8.62\n",
      "3.0       8.21\n",
      "9.0       4.90\n",
      "10.0      2.88\n",
      "2.0       2.11\n",
      "11.0      1.22\n",
      "12.0      0.73\n",
      "1.0       0.72\n",
      "13.0      0.67\n",
      "999.0     0.11\n",
      "777.0     0.10\n",
      "NaN       0.07\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Missing values: 27\n",
      "\n",
      "=== EMPLOY Summary ===\n",
      "Value counts:\n",
      "EMPLOY\n",
      "1.0    20703\n",
      "3.0     7765\n",
      "5.0     4323\n",
      "4.0     3634\n",
      "2.0     1594\n",
      "NaN      881\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Proportions:\n",
      "EMPLOY\n",
      "1.0    53.22\n",
      "3.0    19.96\n",
      "5.0    11.11\n",
      "4.0     9.34\n",
      "2.0     4.10\n",
      "NaN     2.26\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Missing values: 881\n"
     ]
    }
   ],
   "source": [
    "# List of selected SDOH-related variables\n",
    "selected_cols = ['HOQ065', 'HOD050', 'MOR']\n",
    "\n",
    "# Summary function for each variable\n",
    "for col in selected_cols:\n",
    "    print(f\"\\n=== {col} Summary ===\")\n",
    "    print(\"Value counts:\")\n",
    "    print(df[col].value_counts(dropna=False))\n",
    "    print(\"\\nProportions:\")\n",
    "    print((df[col].value_counts(normalize=True, dropna=False) * 100).round(2))\n",
    "    print(f\"\\nMissing values: {df[col].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97dc217-6b45-4c00-b48f-d933c0aab82f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
