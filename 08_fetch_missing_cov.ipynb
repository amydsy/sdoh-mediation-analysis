{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f44d125-4718-416c-af05-b56401ea0847",
   "metadata": {},
   "source": [
    "# backfill missing cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c404742-724f-4e9c-8a7e-e903882716b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check before start work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "191cd2ba-67b0-4da5-a527-c13092f4b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close any open plots and free memory\n",
    "import gc\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.close('all')\n",
    "except Exception:\n",
    "    pass\n",
    "gc.collect()\n",
    "\n",
    "# Clear the interactive output area\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=True)\n",
    "\n",
    "# Wipe user variables (keeps imported modules loaded)\n",
    "%reset -f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b127aa65-abf5-494f-aeb0-fb40dc4a12e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive namespace is empty.\n"
     ]
    }
   ],
   "source": [
    "%who  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c2e7ed-93ee-4ce0-99a0-0ad84d81aef5",
   "metadata": {},
   "source": [
    "## Load previous cov file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fe849e2b-5a95-4df0-ac6d-d1e02fad0704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded cov_concise_99_23: (128809, 51)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "OUT = Path(\"/Users/dengshuyue/Desktop/SDOH/analysis/output\")\n",
    "src = OUT / \"cov_concise_99_23.parquet\"\n",
    "\n",
    "df_my_cov_aligned_short = pd.read_parquet(src)\n",
    "df_my_cov_aligned_short[\"SEQN\"] = pd.to_numeric(df_my_cov_aligned_short[\"SEQN\"], errors=\"coerce\").astype(\"Int64\")\n",
    "df_my_cov_aligned_short[\"SDDSRVYR\"] = pd.to_numeric(df_my_cov_aligned_short[\"SDDSRVYR\"], errors=\"coerce\")\n",
    "if \"SNAP\" not in df_my_cov_aligned_short.columns:\n",
    "    df_my_cov_aligned_short[\"SNAP\"] = pd.Series(pd.NA, index=df_my_cov_aligned_short.index, dtype=\"Int64\")\n",
    "\n",
    "print(\"✓ Loaded cov_concise_99_23:\", df_my_cov_aligned_short.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "998e7efd-2195-4d28-9e03-6192954df3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      UNDER\n",
       "1     NORMAL\n",
       "2      UNDER\n",
       "3       <NA>\n",
       "4       OVER\n",
       "5     NORMAL\n",
       "6       OVER\n",
       "7      UNDER\n",
       "8      UNDER\n",
       "9      OBESE\n",
       "10    NORMAL\n",
       "11     OBESE\n",
       "12      OVER\n",
       "13      OVER\n",
       "14      OVER\n",
       "15    NORMAL\n",
       "16     UNDER\n",
       "17      <NA>\n",
       "18      <NA>\n",
       "19    NORMAL\n",
       "Name: bmic, dtype: string"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_my_cov_aligned_short[\"bmic\"].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13ef75e-6f45-4ccc-be57-ace56810e942",
   "metadata": {},
   "source": [
    "## SNAP pre2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "97ca83b7-77e6-4f25-82a0-2d789afc9faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SNAP coverage by cycle (% non-missing) — BEFORE\n",
      " SDDSRVYR\n",
      "1.0      4.8\n",
      "2.0      4.2\n",
      "3.0     48.9\n",
      "4.0     47.5\n",
      "5.0     57.9\n",
      "6.0     58.3\n",
      "7.0     56.5\n",
      "8.0     55.9\n",
      "9.0     55.0\n",
      "10.0    56.2\n",
      "12.0     0.0\n",
      "66.0    54.5\n",
      "Name: SNAP, dtype: float64\n",
      "\n",
      "Filled cycles 1–2 | rows with SNAP non-missing: 53193 → 55371\n",
      "\n",
      "SNAP coverage by cycle (% non-missing) — AFTER\n",
      " SDDSRVYR\n",
      "1.0     15.1\n",
      "2.0     14.6\n",
      "3.0     48.9\n",
      "4.0     47.5\n",
      "5.0     57.9\n",
      "6.0     58.3\n",
      "7.0     56.5\n",
      "8.0     55.9\n",
      "9.0     55.0\n",
      "10.0    56.2\n",
      "12.0     0.0\n",
      "66.0    54.5\n",
      "Name: SNAP, dtype: float64\n",
      "\n",
      "SNAP source counts (cycles 1–2):\n",
      " SDDSRVYR  SNAP_src  \n",
      "1.0       FSD170N_HH      8\n",
      "          FSD180        948\n",
      "          FSD200        548\n",
      "2.0       FSD180        893\n",
      "          FSD200        716\n",
      "Name: SEQN, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "# 08_snap_backfill: Fill SNAP in 1999–2002 and re-check coverage\n",
    "# - Load FSQ (1999) / FSQ_B (2001)\n",
    "# - Hierarchy: FSD200 (current) → FSD180 (past yr) → HH proxy FSD170N (promote if HH size==1)\n",
    "# - Overwrite only cycles 1 & 2, keep provenance in SNAP_src\n",
    "# - Build SNAP_bin (0/1/NA) and print audits\n",
    "\n",
    "import pandas as pd, numpy as np, io, requests\n",
    "from typing import Optional\n",
    "\n",
    "# ---------- fetch helper (fix early-cycle year folders) ----------\n",
    "_YEARFOLDER_FIX = {\"1999-2000\": \"1999\", \"2001-2002\": \"2001\"}\n",
    "\n",
    "def fetch_xpt(year_folder: str, filebase: str) -> pd.DataFrame:\n",
    "    yf = _YEARFOLDER_FIX.get(year_folder, year_folder)\n",
    "    url = f\"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/{yf}/DataFiles/{filebase}.xpt\"\n",
    "    r = requests.get(url); r.raise_for_status()\n",
    "    df = pd.read_sas(io.BytesIO(r.content), format=\"xport\", encoding=\"latin1\")\n",
    "    df.columns = [c.upper() for c in df.columns]\n",
    "    df[\"SEQN\"] = pd.to_numeric(df[\"SEQN\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    return df\n",
    "\n",
    "# ---------- pull SNAP-relevant columns from FSQ ----------\n",
    "def load_fsq_for_cycle(year_folder: str, filebase: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns FSQ subset indexed by SEQN with SNAP candidates + household size.\n",
    "    Columns (when present): FSD200, FSD180, FSD170N, DMDHHSIZ\n",
    "    \"\"\"\n",
    "    fsq = fetch_xpt(year_folder, filebase).set_index(\"SEQN\")\n",
    "    keep = [c for c in [\"FSD200\",\"FSD180\",\"FSD170N\",\"DMDHHSIZ\"] if c in fsq.columns]\n",
    "    return fsq[keep].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "def fill_snap_hierarchy(df: pd.DataFrame, fsq: pd.DataFrame, cycle_code: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For SDDSRVYR == cycle_code:\n",
    "      1) FSD200: 1→1, 2→0\n",
    "      2) FSD180: 1→1, 2→0 (fill remaining)\n",
    "      3) FSD170N (HH proxy): >0→1, ==0→0 (fill remaining); mark as HH proxy\n",
    "         Promote HH proxy to individual if DMDHHSIZ==1.\n",
    "    Writes SNAP (Int64 0/1/NA) and SNAP_src (string).\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "    m = out[\"SDDSRVYR\"].eq(float(cycle_code))\n",
    "    if not m.any():\n",
    "        return out\n",
    "\n",
    "    seqn = out.loc[m, \"SEQN\"].astype(\"Int64\")\n",
    "    sub = fsq.reindex(seqn.values)\n",
    "\n",
    "    snap = pd.Series(pd.NA, index=sub.index, dtype=\"Int64\")\n",
    "    src  = pd.Series(pd.NA, index=sub.index, dtype=\"string\")\n",
    "\n",
    "    # 1) Current authorization\n",
    "    if \"FSD200\" in sub.columns:\n",
    "        s = sub[\"FSD200\"]\n",
    "        snap.loc[s.eq(1)] = 1; src.loc[s.eq(1)] = \"FSD200\"\n",
    "        snap.loc[s.eq(2)] = 0; src.loc[s.eq(2)] = \"FSD200\"\n",
    "\n",
    "    # 2) Past-year authorization\n",
    "    need = snap.isna()\n",
    "    if \"FSD180\" in sub.columns:\n",
    "        s = sub[\"FSD180\"]\n",
    "        snap.loc[need & s.eq(1)] = 1; src.loc[need & s.eq(1)] = \"FSD180\"\n",
    "        snap.loc[need & s.eq(2)] = 0; src.loc[need & s.eq(2)] = \"FSD180\"\n",
    "\n",
    "    # 3) HH proxy (any authorized in HH)\n",
    "    need = snap.isna()\n",
    "    if \"FSD170N\" in sub.columns:\n",
    "        h = sub[\"FSD170N\"]\n",
    "        snap.loc[need & (h > 0)] = 1; src.loc[need & (h > 0)] = \"FSD170N_HH\"\n",
    "        snap.loc[need & (h == 0)] = 0; src.loc[need & (h == 0)] = \"FSD170N_HH\"\n",
    "\n",
    "        # Promote to individual if household size==1\n",
    "        if \"DMDHHSIZ\" in sub.columns:\n",
    "            promote = src.eq(\"FSD170N_HH\") & sub[\"DMDHHSIZ\"].eq(1)\n",
    "            src.loc[promote] = \"FSD170N_HH_singleton\"\n",
    "\n",
    "    # ensure cols exist\n",
    "    if \"SNAP\" not in out.columns:\n",
    "        out[\"SNAP\"] = pd.Series(pd.NA, index=out.index, dtype=\"Int64\")\n",
    "    if \"SNAP_src\" not in out.columns:\n",
    "        out[\"SNAP_src\"] = pd.Series(pd.NA, index=out.index, dtype=\"string\")\n",
    "\n",
    "    out.loc[m, \"SNAP\"] = snap.values\n",
    "    out.loc[m, \"SNAP_src\"] = src.values\n",
    "    return out\n",
    "\n",
    "# ---------- PRE audit ----------\n",
    "def print_coverage(df: pd.DataFrame, col: str, title: str):\n",
    "    cov = (df.groupby(\"SDDSRVYR\", observed=True)[col]\n",
    "             .apply(lambda s: s.notna().mean()*100, include_groups=False)\n",
    "             .round(1))\n",
    "    print(f\"\\n{title}\\n\", cov)\n",
    "\n",
    "print_coverage(df_my_cov_aligned_short, \"SNAP\", \"SNAP coverage by cycle (% non-missing) — BEFORE\")\n",
    "\n",
    "# ---------- apply to cycles 1 & 2 ----------\n",
    "fsq_9900 = load_fsq_for_cycle(\"1999-2000\", \"FSQ\")\n",
    "fsq_0102 = load_fsq_for_cycle(\"2001-2002\", \"FSQ_B\")\n",
    "\n",
    "before1 = df_my_cov_aligned_short[\"SNAP\"].notna().sum()\n",
    "df_my_cov_aligned_short = fill_snap_hierarchy(df_my_cov_aligned_short, fsq_9900, 1)\n",
    "df_my_cov_aligned_short = fill_snap_hierarchy(df_my_cov_aligned_short, fsq_0102, 2)\n",
    "after1  = df_my_cov_aligned_short[\"SNAP\"].notna().sum()\n",
    "print(f\"\\nFilled cycles 1–2 | rows with SNAP non-missing: {before1} → {after1}\")\n",
    "\n",
    "# ---------- binarize & audits ----------\n",
    "# SNAP is already 0/1/NA; keep a dedicated binary column for clarity\n",
    "df_my_cov_aligned_short[\"SNAP_bin\"] = df_my_cov_aligned_short[\"SNAP\"].astype(\"Int64\")\n",
    "\n",
    "print_coverage(df_my_cov_aligned_short, \"SNAP\", \"SNAP coverage by cycle (% non-missing) — AFTER\")\n",
    "\n",
    "# source breakdown for early cycles\n",
    "src_counts = (df_my_cov_aligned_short\n",
    "    .loc[df_my_cov_aligned_short[\"SDDSRVYR\"].isin([1.0, 2.0])]\n",
    "    .groupby([\"SDDSRVYR\", \"SNAP_src\"], observed=True)[\"SEQN\"]\n",
    "    .count()\n",
    "    .sort_index())\n",
    "print(\"\\nSNAP source counts (cycles 1–2):\\n\", src_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d869b31c-7c43-4410-899d-4c19fc612d7e",
   "metadata": {},
   "source": [
    "#### check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "146174bb-f006-4862-a80f-850803708652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adult SNAP participation rates by cycle (% among non-missing):\n",
      "           SNAP_bin_rate  indiv_only_rate  indiv+singleton_rate\n",
      "SDDSRVYR                                                      \n",
      "1.0               48.73            48.17                 48.17\n",
      "2.0               54.66            54.66                 54.66\n",
      "3.0               12.72              NaN                   NaN\n",
      "4.0               11.10              NaN                   NaN\n",
      "5.0               15.68              NaN                   NaN\n",
      "6.0               19.82              NaN                   NaN\n",
      "7.0               23.63              NaN                   NaN\n",
      "8.0               22.37              NaN                   NaN\n",
      "9.0               25.86              NaN                   NaN\n",
      "10.0              23.67              NaN                   NaN\n",
      "12.0                NaN              NaN                   NaN\n",
      "66.0              24.46              NaN                   NaN\n"
     ]
    }
   ],
   "source": [
    "# --- Guardrails: ensure ONLY cycles 1–2 changed ---\n",
    "_changed = (\n",
    "    df_my_cov_aligned_short[\"SNAP_src\"].notna()\n",
    "    & ~df_my_cov_aligned_short[\"SDDSRVYR\"].isin([1.0, 2.0])\n",
    ")\n",
    "assert not _changed.any(), \"SNAP was modified outside cycles 1–2 unexpectedly.\"\n",
    "\n",
    "# --- Provenance-aware flags (nullable Int64-safe) ---\n",
    "src_rank = {\n",
    "    \"FSD200\": 3,                    # current, individual\n",
    "    \"FSD180\": 2,                    # past 12m, individual\n",
    "    \"FSD170N_HH_singleton\": 2,      # HH proxy but singleton household\n",
    "    \"FSD170N_HH\": 1                 # HH proxy (multi-person)\n",
    "}\n",
    "df_my_cov_aligned_short[\"SNAP_src_rank\"] = (\n",
    "    df_my_cov_aligned_short[\"SNAP_src\"].map(src_rank).astype(\"Int64\")\n",
    ")\n",
    "\n",
    "# --- Sensitivity variants (build as Pandas Series, not NumPy arrays) ---\n",
    "mask_indiv = df_my_cov_aligned_short[\"SNAP_src\"].isin([\"FSD200\", \"FSD180\"])\n",
    "mask_indiv_or_single = df_my_cov_aligned_short[\"SNAP_src\"].isin(\n",
    "    [\"FSD200\", \"FSD180\", \"FSD170N_HH_singleton\"]\n",
    ")\n",
    "\n",
    "# Start as all NA (nullable Int64), then fill by mask\n",
    "df_my_cov_aligned_short[\"SNAP_indiv_only\"] = pd.Series(\n",
    "    pd.NA, index=df_my_cov_aligned_short.index, dtype=\"Int64\"\n",
    ")\n",
    "df_my_cov_aligned_short.loc[mask_indiv, \"SNAP_indiv_only\"] = (\n",
    "    pd.to_numeric(df_my_cov_aligned_short.loc[mask_indiv, \"SNAP\"], errors=\"coerce\")\n",
    "      .astype(\"Int64\")\n",
    ")\n",
    "\n",
    "df_my_cov_aligned_short[\"SNAP_indiv_plus_singleton\"] = pd.Series(\n",
    "    pd.NA, index=df_my_cov_aligned_short.index, dtype=\"Int64\"\n",
    ")\n",
    "df_my_cov_aligned_short.loc[mask_indiv_or_single, \"SNAP_indiv_plus_singleton\"] = (\n",
    "    pd.to_numeric(df_my_cov_aligned_short.loc[mask_indiv_or_single, \"SNAP\"], errors=\"coerce\")\n",
    "      .astype(\"Int64\")\n",
    ")\n",
    "\n",
    "# Ensure the main binary is tidy nullable Int64 too\n",
    "df_my_cov_aligned_short[\"SNAP_bin\"] = pd.to_numeric(\n",
    "    df_my_cov_aligned_short[\"SNAP\"], errors=\"coerce\"\n",
    ").astype(\"Int64\")\n",
    "\n",
    "# --- Quick QC: adult participation rates by cycle (no save) ---\n",
    "adults = df_my_cov_aligned_short.loc[df_my_cov_aligned_short[\"RIDAGEYR\"] >= 18]\n",
    "\n",
    "def _rate(s: pd.Series) -> float:\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    denom = s.notna().sum()\n",
    "    return float((s.eq(1)).sum() / denom * 100) if denom else float(\"nan\")\n",
    "\n",
    "qc = pd.DataFrame({\n",
    "    \"SNAP_bin_rate\": adults.groupby(\"SDDSRVYR\", observed=True)[\"SNAP_bin\"].apply(_rate),\n",
    "    \"indiv_only_rate\": adults.groupby(\"SDDSRVYR\", observed=True)[\"SNAP_indiv_only\"].apply(_rate),\n",
    "    \"indiv+singleton_rate\": adults.groupby(\"SDDSRVYR\", observed=True)[\"SNAP_indiv_plus_singleton\"].apply(_rate),\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\nAdult SNAP participation rates by cycle (% among non-missing):\\n\", qc)\n",
    "\n",
    "# Optional: free memory if not reusing FSQ pulls\n",
    "# del fsq_9900, fsq_0102\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eace92-3b3c-4330-a4df-1f558c2e65af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b73db995-3175-4fc3-9f53-482123374abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SEQN', 'SDDSRVYR', 'sdmvpsu', 'sdmvstra', 'RIDAGEYR', 'SEX', 'RACE',\n",
       "       'household_size', 'EDU', 'pir', 'SMK_AVG', 'SMK', 'ALCG2', 'met_hr',\n",
       "       'SMK_STATUS', 'CIGS_PER_DAY', 'PACK_YEARS', 'FORMER_SMOKER',\n",
       "       'DRINKS_PER_DAY', 'ALCOHOL_CAT', 'bmic', 'DIABE', 'HYPERTEN', 'chol_rx',\n",
       "       'CVD', 'cancer', 'probable_depression', 'ahei_total', 'unemployment2',\n",
       "       'sdoh_access', 'ins', 'HOQ065', 'marriage', 'SNAP', 'FS', 'WTINT2YR',\n",
       "       'WTMEC2YR', 'WTSAF2YR', 'WTINT4YR', 'WTMEC4YR', 'WTINTPRP', 'WTMECPRP',\n",
       "       'WTSAFPRP', 'wt_int', 'wt_mec', 'wt_fasting', 'wt_phlebotomy',\n",
       "       'WTPH2YR', 'marriage_prev', 'marriage_label', 'marriage3', 'SNAP_src',\n",
       "       'SNAP_bin', 'SNAP_src_rank', 'SNAP_indiv_only',\n",
       "       'SNAP_indiv_plus_singleton'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_my_cov_aligned_short.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b1c016-5106-4483-a2a5-01c717a3771a",
   "metadata": {},
   "source": [
    "## check major missingness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6385ac9-94e7-40ae-ba89-7619b07e2aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 by OVERALL *effective* % missing (weights handled as subsamples):\n",
      " CIGS_PER_DAY      79.4\n",
      "SMK_AVG           79.4\n",
      "PACK_YEARS        77.9\n",
      "DRINKS_PER_DAY    71.7\n",
      "ahei_total        54.4\n",
      "SNAP_bin          52.6\n",
      "FS                46.9\n",
      "HOQ065            46.7\n",
      "ALCOHOL_CAT       46.5\n",
      "ALCG2             46.5\n",
      "sdoh_access       46.1\n",
      "SMK_STATUS        45.7\n",
      "SMK               45.7\n",
      "FORMER_SMOKER     45.6\n",
      "unemployment2     44.0\n",
      "met_hr            43.5\n",
      "marriage3         39.0\n",
      "ins               38.4\n",
      "wt_phlebotomy     32.4\n",
      "wt_fasting        24.1\n",
      "Name: OVERALL_effective_%miss, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIGS_PER_DAY</th>\n",
       "      <th>SMK_AVG</th>\n",
       "      <th>PACK_YEARS</th>\n",
       "      <th>DRINKS_PER_DAY</th>\n",
       "      <th>ahei_total</th>\n",
       "      <th>SNAP_bin</th>\n",
       "      <th>FS</th>\n",
       "      <th>HOQ065</th>\n",
       "      <th>ALCOHOL_CAT</th>\n",
       "      <th>ALCG2</th>\n",
       "      <th>sdoh_access</th>\n",
       "      <th>SMK_STATUS</th>\n",
       "      <th>SMK</th>\n",
       "      <th>FORMER_SMOKER</th>\n",
       "      <th>unemployment2</th>\n",
       "      <th>met_hr</th>\n",
       "      <th>marriage3</th>\n",
       "      <th>ins</th>\n",
       "      <th>wt_phlebotomy</th>\n",
       "      <th>wt_fasting</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79.5</td>\n",
       "      <td>79.5</td>\n",
       "      <td>76.4</td>\n",
       "      <td>75.7</td>\n",
       "      <td>19.0</td>\n",
       "      <td>84.9</td>\n",
       "      <td>52.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>55.4</td>\n",
       "      <td>55.4</td>\n",
       "      <td>51.9</td>\n",
       "      <td>51.2</td>\n",
       "      <td>51.2</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>39.2</td>\n",
       "      <td>52.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.3</td>\n",
       "      <td>78.3</td>\n",
       "      <td>76.9</td>\n",
       "      <td>75.4</td>\n",
       "      <td>18.2</td>\n",
       "      <td>85.4</td>\n",
       "      <td>54.2</td>\n",
       "      <td>51.9</td>\n",
       "      <td>54.5</td>\n",
       "      <td>54.5</td>\n",
       "      <td>51.8</td>\n",
       "      <td>51.1</td>\n",
       "      <td>51.1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>34.3</td>\n",
       "      <td>52.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77.8</td>\n",
       "      <td>77.8</td>\n",
       "      <td>75.7</td>\n",
       "      <td>75.5</td>\n",
       "      <td>24.5</td>\n",
       "      <td>51.1</td>\n",
       "      <td>52.4</td>\n",
       "      <td>50.8</td>\n",
       "      <td>53.2</td>\n",
       "      <td>53.2</td>\n",
       "      <td>50.8</td>\n",
       "      <td>50.3</td>\n",
       "      <td>50.3</td>\n",
       "      <td>50.2</td>\n",
       "      <td>50.2</td>\n",
       "      <td>50.2</td>\n",
       "      <td>33.2</td>\n",
       "      <td>51.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.3</td>\n",
       "      <td>78.3</td>\n",
       "      <td>77.7</td>\n",
       "      <td>75.4</td>\n",
       "      <td>69.5</td>\n",
       "      <td>52.5</td>\n",
       "      <td>52.4</td>\n",
       "      <td>52.4</td>\n",
       "      <td>53.9</td>\n",
       "      <td>53.9</td>\n",
       "      <td>52.3</td>\n",
       "      <td>51.9</td>\n",
       "      <td>51.9</td>\n",
       "      <td>51.9</td>\n",
       "      <td>51.9</td>\n",
       "      <td>51.9</td>\n",
       "      <td>35.4</td>\n",
       "      <td>54.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>77.9</td>\n",
       "      <td>77.9</td>\n",
       "      <td>77.3</td>\n",
       "      <td>70.1</td>\n",
       "      <td>68.9</td>\n",
       "      <td>42.1</td>\n",
       "      <td>42.1</td>\n",
       "      <td>42.1</td>\n",
       "      <td>43.8</td>\n",
       "      <td>43.8</td>\n",
       "      <td>42.1</td>\n",
       "      <td>41.6</td>\n",
       "      <td>41.6</td>\n",
       "      <td>41.5</td>\n",
       "      <td>41.5</td>\n",
       "      <td>41.5</td>\n",
       "      <td>41.6</td>\n",
       "      <td>44.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>78.5</td>\n",
       "      <td>78.5</td>\n",
       "      <td>78.0</td>\n",
       "      <td>68.7</td>\n",
       "      <td>67.1</td>\n",
       "      <td>41.7</td>\n",
       "      <td>41.7</td>\n",
       "      <td>41.4</td>\n",
       "      <td>42.5</td>\n",
       "      <td>42.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80.3</td>\n",
       "      <td>80.3</td>\n",
       "      <td>79.9</td>\n",
       "      <td>68.7</td>\n",
       "      <td>69.5</td>\n",
       "      <td>43.5</td>\n",
       "      <td>43.3</td>\n",
       "      <td>43.4</td>\n",
       "      <td>42.4</td>\n",
       "      <td>42.4</td>\n",
       "      <td>43.3</td>\n",
       "      <td>43.1</td>\n",
       "      <td>43.1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>46.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>79.6</td>\n",
       "      <td>79.6</td>\n",
       "      <td>79.4</td>\n",
       "      <td>66.9</td>\n",
       "      <td>70.1</td>\n",
       "      <td>44.1</td>\n",
       "      <td>44.1</td>\n",
       "      <td>44.1</td>\n",
       "      <td>41.8</td>\n",
       "      <td>41.8</td>\n",
       "      <td>44.0</td>\n",
       "      <td>43.3</td>\n",
       "      <td>43.3</td>\n",
       "      <td>43.3</td>\n",
       "      <td>43.3</td>\n",
       "      <td>43.3</td>\n",
       "      <td>43.3</td>\n",
       "      <td>46.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>81.6</td>\n",
       "      <td>81.6</td>\n",
       "      <td>79.6</td>\n",
       "      <td>68.4</td>\n",
       "      <td>71.3</td>\n",
       "      <td>45.0</td>\n",
       "      <td>44.7</td>\n",
       "      <td>44.8</td>\n",
       "      <td>42.5</td>\n",
       "      <td>42.5</td>\n",
       "      <td>44.6</td>\n",
       "      <td>42.8</td>\n",
       "      <td>42.8</td>\n",
       "      <td>42.6</td>\n",
       "      <td>42.6</td>\n",
       "      <td>42.6</td>\n",
       "      <td>42.7</td>\n",
       "      <td>48.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>82.2</td>\n",
       "      <td>82.2</td>\n",
       "      <td>77.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.1</td>\n",
       "      <td>43.8</td>\n",
       "      <td>43.3</td>\n",
       "      <td>43.3</td>\n",
       "      <td>40.2</td>\n",
       "      <td>40.2</td>\n",
       "      <td>43.2</td>\n",
       "      <td>39.8</td>\n",
       "      <td>39.8</td>\n",
       "      <td>39.8</td>\n",
       "      <td>39.8</td>\n",
       "      <td>39.8</td>\n",
       "      <td>39.9</td>\n",
       "      <td>44.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.9</td>\n",
       "      <td>46.9</td>\n",
       "      <td>41.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.6</td>\n",
       "      <td>32.4</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>32.4</td>\n",
       "      <td>66.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.5</td>\n",
       "      <td>45.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.4</td>\n",
       "      <td>42.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.7</td>\n",
       "      <td>37.8</td>\n",
       "      <td>40.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CIGS_PER_DAY  SMK_AVG  PACK_YEARS  DRINKS_PER_DAY  ahei_total  \\\n",
       "SDDSRVYR                                                                  \n",
       "1                 79.5     79.5        76.4            75.7        19.0   \n",
       "2                 78.3     78.3        76.9            75.4        18.2   \n",
       "3                 77.8     77.8        75.7            75.5        24.5   \n",
       "4                 78.3     78.3        77.7            75.4        69.5   \n",
       "5                 77.9     77.9        77.3            70.1        68.9   \n",
       "6                 78.5     78.5        78.0            68.7        67.1   \n",
       "7                 80.3     80.3        79.9            68.7        69.5   \n",
       "8                 79.6     79.6        79.4            66.9        70.1   \n",
       "9                 81.6     81.6        79.6            68.4        71.3   \n",
       "10                82.2     82.2        77.8             NaN        70.1   \n",
       "12                 NaN      NaN         NaN             NaN         NaN   \n",
       "66                 NaN      NaN         NaN             NaN         NaN   \n",
       "\n",
       "          SNAP_bin    FS  HOQ065  ALCOHOL_CAT  ALCG2  sdoh_access  SMK_STATUS  \\\n",
       "SDDSRVYR                                                                        \n",
       "1             84.9  52.4    52.0         55.4   55.4         51.9        51.2   \n",
       "2             85.4  54.2    51.9         54.5   54.5         51.8        51.1   \n",
       "3             51.1  52.4    50.8         53.2   53.2         50.8        50.3   \n",
       "4             52.5  52.4    52.4         53.9   53.9         52.3        51.9   \n",
       "5             42.1  42.1    42.1         43.8   43.8         42.1        41.6   \n",
       "6             41.7  41.7    41.4         42.5   42.5         41.3        41.0   \n",
       "7             43.5  43.3    43.4         42.4   42.4         43.3        43.1   \n",
       "8             44.1  44.1    44.1         41.8   41.8         44.0        43.3   \n",
       "9             45.0  44.7    44.8         42.5   42.5         44.6        42.8   \n",
       "10            43.8  43.3    43.3         40.2   40.2         43.2        39.8   \n",
       "12             NaN   NaN     NaN         46.9   46.9         41.3         NaN   \n",
       "66            45.5  45.1     NaN         42.4   42.4          NaN         NaN   \n",
       "\n",
       "           SMK  FORMER_SMOKER  unemployment2  met_hr  marriage3   ins  \\\n",
       "SDDSRVYR                                                                \n",
       "1         51.2           51.0           51.0    51.0       39.2  52.4   \n",
       "2         51.1           51.0           51.0    51.0       34.3  52.3   \n",
       "3         50.3           50.2           50.2    50.2       33.2  51.0   \n",
       "4         51.9           51.9           51.9    51.9       35.4  54.6   \n",
       "5         41.6           41.5           41.5    41.5       41.6  44.5   \n",
       "6         41.0           41.0           41.0    41.0       41.0  44.6   \n",
       "7         43.1           43.0           43.0    43.0       43.1  46.7   \n",
       "8         43.3           43.3           43.3    43.3       43.3  46.9   \n",
       "9         42.8           42.6           42.6    42.6       42.7  48.7   \n",
       "10        39.8           39.8           39.8    39.8       39.9  44.7   \n",
       "12         NaN            NaN           34.6    32.4       34.8   0.5   \n",
       "66         NaN            NaN           40.7    37.8       40.7   0.2   \n",
       "\n",
       "          wt_phlebotomy  wt_fasting  \n",
       "SDDSRVYR                             \n",
       "1                   NaN        13.6  \n",
       "2                   NaN        11.8  \n",
       "3                   NaN        11.8  \n",
       "4                   NaN        13.0  \n",
       "5                   NaN        13.8  \n",
       "6                   NaN        12.3  \n",
       "7                   NaN        11.9  \n",
       "8                   NaN        12.1  \n",
       "9                   NaN        12.9  \n",
       "10                  NaN        12.0  \n",
       "12                 32.4        66.5  \n",
       "66                  NaN        67.3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = df_my_cov_aligned_short\n",
    "\n",
    "# --- keep only SNAP_bin & marriage3; drop helpers ---\n",
    "snap_drop = {\"SNAP\",\"SNAP_prev\",\"SNAP_src\",\"SNAP_src_rank\",\"SNAP_indiv_only\",\"SNAP_indiv_plus_singleton\"}\n",
    "marriage_drop = {\"marriage\",\"marriage_prev\",\"marriage_label\"}\n",
    "cols = [c for c in df.columns if c not in snap_drop | marriage_drop]\n",
    "for must in [\"SNAP_bin\",\"marriage3\"]:\n",
    "    if must in df.columns and must not in cols:\n",
    "        cols.append(must)\n",
    "\n",
    "# -------- eligibility masks --------\n",
    "def smokers_mask(d):\n",
    "    if \"SMK_STATUS\" in d.columns:        # 1=never, 2=former, 3=current (adjust if different)\n",
    "        return d[\"SMK_STATUS\"].notna() & (d[\"SMK_STATUS\"] != 1)\n",
    "    m1 = d[\"FORMER_SMOKER\"].eq(1) if \"FORMER_SMOKER\" in d.columns else False\n",
    "    m2 = d[\"SMK\"].eq(1) if \"SMK\" in d.columns else False\n",
    "    return (m1 | m2).fillna(False)\n",
    "\n",
    "def adults_mask(d):\n",
    "    return pd.to_numeric(d[\"RIDAGEYR\"], errors=\"coerce\").ge(18).fillna(False)\n",
    "\n",
    "def fasting_mask(d):  # prefer an actual fasting lab variable if present\n",
    "    for cand in [\"P_GLU\",\"LBXGLU\",\"fasting_glucose\",\"glucose_fasting\",\"wt_fasting\"]:\n",
    "        if cand in d.columns:\n",
    "            return d[cand].notna()\n",
    "    # fallback: very conservative (no rows)\n",
    "    return pd.Series(False, index=d.index)\n",
    "\n",
    "def phleb_mask(d):\n",
    "    if \"wt_phlebotomy\" in d.columns:\n",
    "        return d[\"wt_phlebotomy\"].notna()\n",
    "    # fallback: very conservative\n",
    "    return pd.Series(False, index=d.index)\n",
    "\n",
    "# Per-variable eligibility (row-level denominator)\n",
    "eligibility = {\n",
    "    \"CIGS_PER_DAY\": smokers_mask,\n",
    "    \"PACK_YEARS\": smokers_mask,\n",
    "    \"SMK_AVG\": smokers_mask,\n",
    "    \"probable_depression\": adults_mask,\n",
    "    # weights: compute missingness only where applicable to the sub-sample\n",
    "    \"WTSAFPRP\": fasting_mask,            # fasting subsample (e.g., P_GLU universe)\n",
    "    \"WTPH2YR\": phleb_mask,               # phlebotomy subsample\n",
    "}\n",
    "\n",
    "# Cycle-level applicability helper (exclude cycles where a var basically doesn't exist)\n",
    "def applicable_cycles(d, col, thresh=0.10):\n",
    "    by_cyc = d.groupby(\"SDDSRVYR\", observed=True)[col].apply(lambda s: s.notna().mean())\n",
    "    return set(by_cyc[by_cyc > thresh].index.tolist())\n",
    "\n",
    "# Some weights are intended only for specific cycles (override presence heuristic)\n",
    "cycle_overrides = {\n",
    "    \"WTINTPRP\": {66.0},   # pre-pandemic combined cycle\n",
    "    \"WTMECPRP\": {66.0},\n",
    "    # Add any others you use with known cycle scopes\n",
    "    # \"WTINT4YR\": {9.0, 10.0},  # example if you want to pin 4-year weights\n",
    "    # \"WTMEC4YR\": {9.0, 10.0},\n",
    "}\n",
    "\n",
    "# -------- compute effective missingness --------\n",
    "cycles = sorted(df[\"SDDSRVYR\"].dropna().unique().tolist())\n",
    "eff_miss = pd.DataFrame(index=[int(c) for c in cycles], columns=[])\n",
    "overall_eff = {}\n",
    "\n",
    "for col in cols:\n",
    "    # 1) row-level eligibility\n",
    "    elig = eligibility.get(col, lambda d: pd.Series(True, index=d.index))(df)\n",
    "\n",
    "    # 2) cycle applicability\n",
    "    if col in cycle_overrides:\n",
    "        apps = cycle_overrides[col]\n",
    "    else:\n",
    "        apps = applicable_cycles(df, col, thresh=0.10)  # empirical presence\n",
    "\n",
    "    cyc_mask = df[\"SDDSRVYR\"].isin(list(apps)) if apps else pd.Series(False, index=df.index)\n",
    "    use = elig & cyc_mask\n",
    "\n",
    "    # per-cycle effective missingness\n",
    "    per_cyc = []\n",
    "    for cyc in cycles:\n",
    "        m = use & df[\"SDDSRVYR\"].eq(cyc)\n",
    "        denom = m.sum()\n",
    "        per_cyc.append(np.nan if denom == 0 else round(df.loc[m, col].isna().mean()*100, 1))\n",
    "    eff_miss[col] = per_cyc\n",
    "\n",
    "    # overall effective missingness\n",
    "    denom_all = use.sum()\n",
    "    overall_eff[col] = np.nan if denom_all == 0 else round(df.loc[use, col].isna().mean()*100, 1)\n",
    "\n",
    "eff_miss.index.name = \"SDDSRVYR\"\n",
    "eff_miss = eff_miss.sort_index()\n",
    "overall_eff = pd.Series(overall_eff, name=\"OVERALL_effective_%miss\").sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 20 by OVERALL *effective* % missing (weights handled as subsamples):\\n\",\n",
    "      overall_eff.head(20))\n",
    "\n",
    "top20_cols = overall_eff.head(20).index.tolist()\n",
    "display(eff_miss[top20_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3da0d12-f8e3-46fd-ac1a-8e9f5ca74994",
   "metadata": {},
   "source": [
    "## check focus on pre18 missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ccaa023-a77b-4bad-84fc-42bbb7f559f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-2018 major-missing check (non-missing < 20.0% in any cycle):\n",
      "Flagged variables: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_nonmiss_%</th>\n",
       "      <th>max_nonmiss_%</th>\n",
       "      <th>cycles_below_thresh</th>\n",
       "      <th>cycles_triggering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wt_phlebotomy</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probable_depression</th>\n",
       "      <td>6.8</td>\n",
       "      <td>60.4</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNAP_bin</th>\n",
       "      <td>14.6</td>\n",
       "      <td>58.3</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     min_nonmiss_%  max_nonmiss_%  cycles_below_thresh  \\\n",
       "wt_phlebotomy                  0.0            0.0                   10   \n",
       "probable_depression            6.8           60.4                    3   \n",
       "SNAP_bin                      14.6           58.3                    2   \n",
       "\n",
       "                                   cycles_triggering  \n",
       "wt_phlebotomy        [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  \n",
       "probable_depression                        [1, 2, 3]  \n",
       "SNAP_bin                                      [1, 2]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-cycle non-missingness (%) for flagged variables (rows = cycles 1..10):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probable_depression</th>\n",
       "      <th>wt_phlebotomy</th>\n",
       "      <th>SNAP_bin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>51.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>59.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>60.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>57.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>58.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>57.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>59.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          probable_depression  wt_phlebotomy  SNAP_bin\n",
       "SDDSRVYR                                              \n",
       "1.0                       7.2            0.0      15.1\n",
       "2.0                       7.4            0.0      14.6\n",
       "3.0                       6.8            0.0      48.9\n",
       "4.0                      51.5            0.0      47.5\n",
       "5.0                      59.1            0.0      57.9\n",
       "6.0                      60.4            0.0      58.3\n",
       "7.0                      57.6            0.0      56.5\n",
       "8.0                      58.2            0.0      55.9\n",
       "9.0                      57.5            0.0      55.0\n",
       "10.0                     59.8            0.0      56.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = df_my_cov_aligned_short\n",
    "\n",
    "# ---------- config ----------\n",
    "PRE2018_CYCLES = list(range(1, 11))          # cycles 1..10\n",
    "THRESH = 20.0                                 # non-missingness (%)\n",
    "IGNORE_VARS = {\"CIGS_PER_DAY\",\"SMK_AVG\",\"PACK_YEARS\",\"DRINKS_PER_DAY\"}  # your expected-missing set\n",
    "SNAP_HELPERS = {\"SNAP\",\"SNAP_prev\",\"SNAP_src\",\"SNAP_src_rank\",\"SNAP_indiv_only\",\"SNAP_indiv_plus_singleton\"}\n",
    "MARRIAGE_HELPERS = {\"marriage\",\"marriage_prev\",\"marriage_label\"}\n",
    "ID_VARS = {\"SEQN\",\"SDDSRVYR\"}\n",
    "\n",
    "# keep only SNAP_bin & marriage3 for those topics\n",
    "cols = []\n",
    "for c in df.columns:\n",
    "    if c in ID_VARS:                         # we won't audit these here\n",
    "        continue\n",
    "    if c in SNAP_HELPERS or c in MARRIAGE_HELPERS:\n",
    "        continue\n",
    "    if c in IGNORE_VARS:                     # skip your “expected missing” vars\n",
    "        continue\n",
    "    if c.startswith(\"WT\"):                   # skip structural weight columns (e.g., WTSAFPRP, WTMECPRP...)\n",
    "        continue\n",
    "    cols.append(c)\n",
    "\n",
    "# ensure main signals present if available\n",
    "for must in [\"SNAP_bin\",\"marriage3\"]:\n",
    "    if must in df.columns and must not in cols:\n",
    "        cols.append(must)\n",
    "\n",
    "# subset to pre-2018 cycles\n",
    "pre_mask = df[\"SDDSRVYR\"].isin(PRE2018_CYCLES)\n",
    "pre = df.loc[pre_mask, cols + [\"SDDSRVYR\"]].copy()\n",
    "\n",
    "# non-missingness (%) by cycle\n",
    "nonmiss = pre.groupby(\"SDDSRVYR\", observed=True)[cols].apply(\n",
    "    lambda x: x.notna().mean() * 100, include_groups=False\n",
    ").round(1).sort_index()\n",
    "\n",
    "# find columns with any cycle < THRESH\n",
    "flag_mask = nonmiss.lt(THRESH)\n",
    "flagged_cols = flag_mask.any(axis=0)\n",
    "flagged = nonmiss.loc[:, flagged_cols]\n",
    "\n",
    "# summary table\n",
    "summary = pd.DataFrame({\n",
    "    \"min_nonmiss_%\": flagged.min(axis=0),\n",
    "    \"max_nonmiss_%\": flagged.max(axis=0),\n",
    "    \"cycles_below_thresh\": flag_mask.loc[:, flagged_cols].sum(axis=0).astype(int),\n",
    "    \"cycles_triggering\": flag_mask.loc[:, flagged_cols].apply(lambda s: [int(c) for c in s.index[s].tolist()], axis=0)\n",
    "}).sort_values([\"cycles_below_thresh\",\"min_nonmiss_%\"], ascending=[False, True])\n",
    "\n",
    "print(f\"Pre-2018 major-missing check (non-missing < {THRESH}% in any cycle):\")\n",
    "print(f\"Flagged variables: {len(summary)}\")\n",
    "display(summary)\n",
    "\n",
    "print(\"\\nPer-cycle non-missingness (%) for flagged variables (rows = cycles 1..10):\")\n",
    "display(flagged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631cef44-e75c-4a7a-b462-021c33ce784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "######  wt_phlebotomy expected missing, as only one  cycle 21-23 have it\n",
    "######  probable_depression expected missing for cycle 1-3 as only a small subsample tested (cidi used)\n",
    "######  SNAP_bin expected, questionary on those question have lots missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cd66c60-5d44-4b0e-9bc5-3d73ac4e31b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SEQN', 'SDDSRVYR', 'sdmvpsu', 'sdmvstra', 'RIDAGEYR', 'SEX', 'RACE',\n",
       "       'household_size', 'EDU', 'pir', 'SMK_AVG', 'SMK', 'ALCG2', 'met_hr',\n",
       "       'SMK_STATUS', 'CIGS_PER_DAY', 'PACK_YEARS', 'FORMER_SMOKER',\n",
       "       'DRINKS_PER_DAY', 'ALCOHOL_CAT', 'bmic', 'DIABE', 'HYPERTEN', 'chol_rx',\n",
       "       'CVD', 'cancer', 'probable_depression', 'ahei_total', 'unemployment2',\n",
       "       'sdoh_access', 'ins', 'HOQ065', 'marriage', 'SNAP', 'FS', 'WTINT2YR',\n",
       "       'WTMEC2YR', 'WTSAF2YR', 'WTINT4YR', 'WTMEC4YR', 'WTINTPRP', 'WTMECPRP',\n",
       "       'WTSAFPRP', 'wt_int', 'wt_mec', 'wt_fasting', 'wt_phlebotomy',\n",
       "       'WTPH2YR', 'marriage_prev', 'marriage_label', 'marriage3', 'SNAP_src',\n",
       "       'SNAP_bin', 'SNAP_src_rank', 'SNAP_indiv_only',\n",
       "       'SNAP_indiv_plus_singleton'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_my_cov_aligned_short.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499793e8-7327-484d-a38e-4a56ffb571c9",
   "metadata": {},
   "source": [
    "## Keep fetch/work on post 18 missing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa04d1f3-93da-4d2a-9774-6df1494881e3",
   "metadata": {},
   "source": [
    "#### first check what is still missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3e6e6014-810c-446a-aa04-09f9f4fc8d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST-2018 missingness (% by cycle):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sdmvpsu</th>\n",
       "      <th>sdmvstra</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RACE</th>\n",
       "      <th>household_size</th>\n",
       "      <th>EDU</th>\n",
       "      <th>pir</th>\n",
       "      <th>SMK</th>\n",
       "      <th>ALCG2</th>\n",
       "      <th>...</th>\n",
       "      <th>cancer</th>\n",
       "      <th>probable_depression</th>\n",
       "      <th>ahei_total</th>\n",
       "      <th>unemployment2</th>\n",
       "      <th>sdoh_access</th>\n",
       "      <th>ins</th>\n",
       "      <th>HOQ065</th>\n",
       "      <th>FS</th>\n",
       "      <th>marriage3</th>\n",
       "      <th>SNAP_bin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.7</td>\n",
       "      <td>17.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>46.9</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>46.9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>34.6</td>\n",
       "      <td>41.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>34.8</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>40.7</td>\n",
       "      <td>14.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>42.4</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>42.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>40.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>45.1</td>\n",
       "      <td>40.7</td>\n",
       "      <td>45.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sdmvpsu  sdmvstra  RIDAGEYR  SEX   RACE  household_size   EDU   pir  \\\n",
       "SDDSRVYR                                                                        \n",
       "12.0          0.0       0.0       0.0  0.0  100.0             0.0  34.7  17.1   \n",
       "66.0          0.0       0.0       0.0  0.0  100.0           100.0  40.7  14.1   \n",
       "\n",
       "            SMK  ALCG2  ...  cancer  probable_depression  ahei_total  \\\n",
       "SDDSRVYR                ...                                            \n",
       "12.0      100.0   46.9  ...   100.0                 46.9       100.0   \n",
       "66.0      100.0   42.4  ...   100.0                 42.4       100.0   \n",
       "\n",
       "          unemployment2  sdoh_access  ins  HOQ065     FS  marriage3  SNAP_bin  \n",
       "SDDSRVYR                                                                       \n",
       "12.0               34.6         41.3  0.5   100.0  100.0       34.8     100.0  \n",
       "66.0               40.7        100.0  0.2   100.0   45.1       40.7      45.5  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HIGH missing (>50% in either 66 or 12): 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RACE</th>\n",
       "      <th>household_size</th>\n",
       "      <th>SMK</th>\n",
       "      <th>SMK_STATUS</th>\n",
       "      <th>FORMER_SMOKER</th>\n",
       "      <th>bmic</th>\n",
       "      <th>DIABE</th>\n",
       "      <th>HYPERTEN</th>\n",
       "      <th>chol_rx</th>\n",
       "      <th>CVD</th>\n",
       "      <th>cancer</th>\n",
       "      <th>ahei_total</th>\n",
       "      <th>sdoh_access</th>\n",
       "      <th>HOQ065</th>\n",
       "      <th>FS</th>\n",
       "      <th>SNAP_bin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>41.3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66.0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>45.1</td>\n",
       "      <td>45.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           RACE  household_size    SMK  SMK_STATUS  FORMER_SMOKER   bmic  \\\n",
       "SDDSRVYR                                                                   \n",
       "12.0      100.0             0.0  100.0       100.0          100.0  100.0   \n",
       "66.0      100.0           100.0  100.0       100.0          100.0  100.0   \n",
       "\n",
       "          DIABE  HYPERTEN  chol_rx    CVD  cancer  ahei_total  sdoh_access  \\\n",
       "SDDSRVYR                                                                     \n",
       "12.0      100.0     100.0    100.0  100.0   100.0       100.0         41.3   \n",
       "66.0      100.0     100.0    100.0  100.0   100.0       100.0        100.0   \n",
       "\n",
       "          HOQ065     FS  SNAP_bin  \n",
       "SDDSRVYR                           \n",
       "12.0       100.0  100.0     100.0  \n",
       "66.0       100.0   45.1      45.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Worst % (either cycle):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RACE              100.0\n",
       "household_size    100.0\n",
       "SMK               100.0\n",
       "SMK_STATUS        100.0\n",
       "FORMER_SMOKER     100.0\n",
       "bmic              100.0\n",
       "DIABE             100.0\n",
       "HYPERTEN          100.0\n",
       "chol_rx           100.0\n",
       "CVD               100.0\n",
       "cancer            100.0\n",
       "ahei_total        100.0\n",
       "sdoh_access       100.0\n",
       "HOQ065            100.0\n",
       "FS                100.0\n",
       "SNAP_bin          100.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEDIUM missing (20–50% in either 66 or 12): 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALCG2</th>\n",
       "      <th>ALCOHOL_CAT</th>\n",
       "      <th>probable_depression</th>\n",
       "      <th>EDU</th>\n",
       "      <th>unemployment2</th>\n",
       "      <th>marriage3</th>\n",
       "      <th>met_hr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>46.9</td>\n",
       "      <td>46.9</td>\n",
       "      <td>46.9</td>\n",
       "      <td>34.7</td>\n",
       "      <td>34.6</td>\n",
       "      <td>34.8</td>\n",
       "      <td>32.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66.0</th>\n",
       "      <td>42.4</td>\n",
       "      <td>42.4</td>\n",
       "      <td>42.4</td>\n",
       "      <td>40.7</td>\n",
       "      <td>40.7</td>\n",
       "      <td>40.7</td>\n",
       "      <td>37.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ALCG2  ALCOHOL_CAT  probable_depression   EDU  unemployment2  \\\n",
       "SDDSRVYR                                                                 \n",
       "12.0       46.9         46.9                 46.9  34.7           34.6   \n",
       "66.0       42.4         42.4                 42.4  40.7           40.7   \n",
       "\n",
       "          marriage3  met_hr  \n",
       "SDDSRVYR                     \n",
       "12.0           34.8    32.4  \n",
       "66.0           40.7    37.8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Worst % (either cycle):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ALCG2                  46.9\n",
       "ALCOHOL_CAT            46.9\n",
       "probable_depression    46.9\n",
       "EDU                    40.7\n",
       "unemployment2          40.7\n",
       "marriage3              40.7\n",
       "met_hr                 37.8\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, io, requests\n",
    "\n",
    "df = df_my_cov_aligned_short\n",
    "\n",
    "# ---------------- config ----------------\n",
    "POST2018_CYCLES = [66.0, 12.0]\n",
    "IGNORE_EXPECTED = {\"CIGS_PER_DAY\",\"SMK_AVG\",\"PACK_YEARS\",\"DRINKS_PER_DAY\"}  # your expected-missing vars\n",
    "SNAP_HELPERS = {\"SNAP\",\"SNAP_prev\",\"SNAP_src\",\"SNAP_src_rank\",\"SNAP_indiv_only\",\"SNAP_indiv_plus_singleton\"}\n",
    "MARRIAGE_HELPERS = {\"marriage\",\"marriage_prev\",\"marriage_label\"}\n",
    "ID_VARS = {\"SEQN\",\"SDDSRVYR\"}\n",
    "# ignore structural weights (both WT* and your wt_* flags)\n",
    "def is_weight_col(c: str) -> bool:\n",
    "    return c.startswith(\"WT\") or c.startswith(\"wt_\")\n",
    "\n",
    "# build column list to audit\n",
    "cols = []\n",
    "for c in df.columns:\n",
    "    if c in ID_VARS: continue\n",
    "    if c in IGNORE_EXPECTED: continue\n",
    "    if c in SNAP_HELPERS or c in MARRIAGE_HELPERS: continue\n",
    "    if is_weight_col(c): continue  # structural\n",
    "    cols.append(c)\n",
    "\n",
    "# ensure main signals are included\n",
    "for must in [\"SNAP_bin\",\"marriage3\"]:\n",
    "    if must in df.columns and must not in cols:\n",
    "        cols.append(must)\n",
    "\n",
    "# subset post-2018\n",
    "post_mask = df[\"SDDSRVYR\"].isin(POST2018_CYCLES)\n",
    "post = df.loc[post_mask, cols + [\"SDDSRVYR\"]].copy()\n",
    "\n",
    "# missingness by cycle\n",
    "miss = (post.groupby(\"SDDSRVYR\", observed=True)[cols]\n",
    "            .apply(lambda x: x.isna().mean()*100, include_groups=False)\n",
    "            .round(1)\n",
    "            .sort_index())\n",
    "\n",
    "# classify\n",
    "HIGH_T = 50.0\n",
    "MID_T  = 20.0\n",
    "\n",
    "high_any = miss.gt(HIGH_T).any(axis=0)\n",
    "mid_any  = miss.gt(MID_T).any(axis=0) & ~high_any\n",
    "\n",
    "high_tbl = miss.loc[:, high_any].copy()\n",
    "mid_tbl  = miss.loc[:, mid_any].copy()\n",
    "\n",
    "# ordered lists by worst cycle value\n",
    "def worst_order(tbl: pd.DataFrame):\n",
    "    if tbl.empty: return []\n",
    "    worst = tbl.max(axis=0).sort_values(ascending=False)\n",
    "    return worst.index.tolist(), worst\n",
    "\n",
    "high_vars, high_worst = worst_order(high_tbl)\n",
    "mid_vars,  mid_worst  = worst_order(mid_tbl)\n",
    "\n",
    "print(\"POST-2018 missingness (% by cycle):\")\n",
    "display(miss)\n",
    "\n",
    "print(\"\\nHIGH missing (>50% in either 66 or 12):\", len(high_vars))\n",
    "if high_vars:\n",
    "    display(high_tbl[high_vars])\n",
    "    print(\"\\nWorst % (either cycle):\")\n",
    "    display(high_worst)\n",
    "\n",
    "print(\"\\nMEDIUM missing (20–50% in either 66 or 12):\", len(mid_vars))\n",
    "if mid_vars:\n",
    "    display(mid_tbl[mid_vars])\n",
    "    print(\"\\nWorst % (either cycle):\")\n",
    "    display(mid_worst)\n",
    "\n",
    "# ---------------- OPTIONAL: source scanner to help pick modules/cols next ----------------\n",
    "_YEARFOLDER_FIX = {\"1999-2000\":\"1999\",\"2001-2002\":\"2001\"}  # kept for reuse\n",
    "\n",
    "def _cycle_to_year_suffix(cyc: int):\n",
    "    # 66 → (\"2017\",\"P_*\"), 12 → (\"2021\",\"*_L\")\n",
    "    if cyc == 66:\n",
    "        return \"2017\", \"P\", \"{mod}\"\n",
    "    elif cyc == 12:\n",
    "        return \"2021\", \"L\", \"{mod}_{suf}\"\n",
    "    else:\n",
    "        raise ValueError(\"Only cycles 66 and 12 supported here.\")\n",
    "\n",
    "def fetch_xpt(year_folder: str, filebase: str) -> pd.DataFrame:\n",
    "    url = f\"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/{year_folder}/DataFiles/{filebase}.xpt\"\n",
    "    r = requests.get(url); r.raise_for_status()\n",
    "    df2 = pd.read_sas(io.BytesIO(r.content), format=\"xport\", encoding=\"latin1\")\n",
    "    df2.columns = [c.upper() for c in df2.columns]\n",
    "    return df2\n",
    "\n",
    "def scan_modules_for_patterns(cycle_code: int, modules=(\"DEMO\",\"HIQ\",\"HUQ\",\"HOQ\",\"INQ\",\"FSQ\",\"OCQ\",\"ALQ\",\"DBQ\",\"DPQ\",\"SMQ\",\"PAQ\",\"MCQ\"),\n",
    "                              patterns=(r\".*\",)):\n",
    "    year, suf, fmt = _cycle_to_year_suffix(int(cycle_code))\n",
    "    hits = []\n",
    "    for mod in modules:\n",
    "        filebase = (f\"P_{fmt.format(mod=mod)}\" if suf==\"P\" else fmt.format(mod=mod, suf=suf)).upper()\n",
    "        try:\n",
    "            dfm = fetch_xpt(year, filebase)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        upcols = {c:c.upper() for c in dfm.columns}\n",
    "        for pat in patterns:\n",
    "            rx = re.compile(pat, flags=re.I)\n",
    "            for c, cu in upcols.items():\n",
    "                if rx.search(cu):\n",
    "                    hits.append((mod, filebase, c))\n",
    "    return hits\n",
    "\n",
    "# Example: when you're ready to backfill a variable, try scanning like:\n",
    "# hits66 = scan_modules_for_patterns(66, patterns=[r\"^HIQ0*11$\", r\"HEALTH.?INS\", r\"INSUR\"])  # insurance\n",
    "# hits12 = scan_modules_for_patterns(12, patterns=[r\"^HIQ0*11$\", r\"HEALTH.?INS\", r\"INSUR\"])\n",
    "# print(\"Cycle 66 hits:\", hits66[:10]); print(\"Cycle 12 hits:\", hits12[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8247643-1615-448c-991f-229c66b196f4",
   "metadata": {},
   "source": [
    "#### systematic fetch try for post 2018 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc37bac-4c7b-4cde-b944-c067502a9fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5eec7146-91d4-409e-a46b-7c656ed2a194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEMO 66] filled RACE from 2017/P_DEMO:RIDRETH3 (n_src_nonnull=15560, wrote=0)\n",
      "[DEMO 66] DMDHHSIZ missing in P_DEMO.xpt, fell back to DEMO_J.xpt\n",
      "[DEMO 66] filled household_size from 2017/P_DEMO:DMDHHSIZ (n_src_nonnull=9254, wrote=0)\n",
      "[BMX 66] filled bmic from 2017/P_BMX:BMXBMI (n_src_nonnull=13137, wrote=0)\n",
      "[HIQ 66] filled ins from 2017/P_HIQ:HIQ011 (n_src_nonnull=15523, wrote=0)\n",
      "[DIQ 66] filled DIABE from 2017/P_DIQ:DIQ010 (n_src_nonnull=14694, wrote=0)\n",
      "[BPQ 66] filled HYPERTEN from 2017/P_BPQ:BPQ020 (n_src_nonnull=10183, wrote=0)\n",
      "[BPQ 66] BPQ101D not in P_BPQ.xpt nor BPQ_J.xpt — skipped\n",
      "[MCQ 66] filled cancer from 2017/P_MCQ:MCQ220 (n_src_nonnull=9228, wrote=0)\n",
      "[MCQ 66] derived CVD from ['MCQ160B', 'MCQ160C', 'MCQ160D', 'MCQ160E', 'MCQ160F']\n",
      "[SMQ 66] derived SMK trio + attempted CIGS_PER_DAY, PACK_YEARS\n",
      "[DEMO 12] filled RACE from 2021/DEMO_L:RIDRETH3 (n_src_nonnull=11933, wrote=0)\n",
      "[DEMO 12] filled household_size from 2021/DEMO_L:DMDHHSIZ (n_src_nonnull=11933, wrote=0)\n",
      "[BMX 12] filled bmic from 2021/BMX_L:BMXBMI (n_src_nonnull=8471, wrote=0)\n",
      "[HIQ 12] filled ins from 2021/HIQ_L:HIQ011 (n_src_nonnull=11871, wrote=0)\n",
      "[DIQ 12] filled DIABE from 2021/DIQ_L:DIQ010 (n_src_nonnull=11452, wrote=0)\n",
      "[BPQ 12] filled HYPERTEN from 2021/BPQ_L:BPQ020 (n_src_nonnull=8487, wrote=0)\n",
      "[BPQ 12] filled chol_rx from 2021/BPQ_L:BPQ101D (n_src_nonnull=8465, wrote=0)\n",
      "[MCQ 12] filled cancer from 2021/MCQ_L:MCQ220 (n_src_nonnull=7800, wrote=0)\n",
      "[MCQ 12] derived CVD from ['MCQ160B', 'MCQ160C', 'MCQ160D', 'MCQ160E', 'MCQ160F']\n",
      "[SMQ 12] derived SMK trio + attempted CIGS_PER_DAY, PACK_YEARS\n",
      "[HOQ 66] tenure HOQ065 not available publicly — marked structural missing\n",
      "[HOQ 12] tenure HOQ065 not available publicly — marked structural missing\n",
      "\n",
      "SMK non-missing % by cycle:\n",
      "SDDSRVYR\n",
      "1.0     48.8\n",
      "2.0     48.9\n",
      "3.0     49.7\n",
      "4.0     48.1\n",
      "5.0     58.4\n",
      "6.0     59.0\n",
      "7.0     56.9\n",
      "8.0     56.7\n",
      "9.0     57.2\n",
      "10.0    60.2\n",
      "12.0    68.1\n",
      "66.0    62.3\n",
      "\n",
      "bmic non-missing % by cycle:\n",
      "SDDSRVYR\n",
      "1.0      0.0\n",
      "2.0      0.0\n",
      "3.0      0.0\n",
      "4.0      0.0\n",
      "5.0      0.0\n",
      "6.0      0.0\n",
      "7.0      0.0\n",
      "8.0      0.0\n",
      "9.0      0.0\n",
      "10.0     0.0\n",
      "12.0    71.0\n",
      "66.0    84.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, io, requests\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# =========================\n",
    "# Fetch & file mapping\n",
    "# =========================\n",
    "_YEARFOLDER_FIX = {\"1999-2000\": \"1999\", \"2001-2002\": \"2001\"}  # early-cycle folder quirk\n",
    "\n",
    "def fetch_xpt(year_folder: str, filebase: str) -> pd.DataFrame:\n",
    "    yf = _YEARFOLDER_FIX.get(year_folder, year_folder)\n",
    "    url = f\"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/{yf}/DataFiles/{filebase}.xpt\"\n",
    "    r = requests.get(url); r.raise_for_status()\n",
    "    df = pd.read_sas(io.BytesIO(r.content), format=\"xport\", encoding=\"latin1\")\n",
    "    df.columns = [c.upper() for c in df.columns]\n",
    "    if \"SEQN\" in df.columns:\n",
    "        df[\"SEQN\"] = pd.to_numeric(df[\"SEQN\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    return df\n",
    "\n",
    "def file_for(module: str, cycle: int) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Returns (year_folder, filebase) for cycles 66 and 12.\n",
    "    - 66 (2017–Mar 2020): P_<MODULE> under '2017' (EXCEPT HOQ → HOQ_J)\n",
    "    - 12 (Aug 2021–Aug 2023): <MODULE>_L under '2021' (HOQ → HOQ_L)\n",
    "    \"\"\"\n",
    "    m = module.upper()\n",
    "    if m == \"HOQ\":\n",
    "        return (\"2017\", \"HOQ_J\") if cycle == 66 else (\"2021\", \"HOQ_L\")\n",
    "    if cycle == 66:\n",
    "        return (\"2017\", f\"P_{m}\")\n",
    "    elif cycle == 12:\n",
    "        return (\"2021\", f\"{m}_L\")\n",
    "    else:\n",
    "        raise ValueError(\"This helper is scoped to cycles 66 and 12 only.\")\n",
    "\n",
    "# =========================\n",
    "# Dtype helpers\n",
    "# =========================\n",
    "def ensure_col_dtype(df: pd.DataFrame, col: str, desired: str) -> None:\n",
    "    \"\"\"\n",
    "    Ensure df[col] exists and has dtype `desired`\n",
    "      desired ∈ {'Int64','float64','string','boolean'}\n",
    "    If categorical/incompatible, coerce the whole column.\n",
    "    NOTE: Use this for columns that are safe to coerce globally.\n",
    "          For smoking columns, use the safe-assign helpers below instead.\n",
    "    \"\"\"\n",
    "    if col not in df.columns:\n",
    "        if desired == \"boolean\":\n",
    "            df[col] = pd.Series(False, index=df.index, dtype=\"boolean\")\n",
    "        else:\n",
    "            df[col] = pd.Series(pd.NA, index=df.index, dtype=desired)\n",
    "        return\n",
    "    try:\n",
    "        df[col] = df[col].astype(desired)\n",
    "    except Exception:\n",
    "        if isinstance(df[col].dtype, CategoricalDtype):\n",
    "            df[col] = df[col].astype(object)  # drop categories\n",
    "        if desired == \"Int64\":\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\").astype(\"Int64\")\n",
    "        elif desired == \"float64\":\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\").astype(\"float64\")\n",
    "        elif desired == \"boolean\":\n",
    "            df[col] = df[col].astype(\"boolean\")\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"string\")\n",
    "\n",
    "def map_yes_no_codes(s: pd.Series) -> pd.Series:\n",
    "    x = pd.to_numeric(s, errors=\"coerce\")\n",
    "    out = pd.Series(pd.NA, index=x.index, dtype=\"Int64\")\n",
    "    out.loc[x.eq(1)] = 1\n",
    "    out.loc[x.eq(2)] = 0\n",
    "    return out\n",
    "\n",
    "# =========================\n",
    "# Assign helpers (protect older cycles)\n",
    "# =========================\n",
    "def _ensure_col_exists(df: pd.DataFrame, col: str, desired: str) -> None:\n",
    "    \"\"\"Create df[col] if missing; don't coerce if it already exists.\"\"\"\n",
    "    if col not in df.columns:\n",
    "        if desired == \"boolean\":\n",
    "            df[col] = pd.Series(False, index=df.index, dtype=\"boolean\")\n",
    "        else:\n",
    "            df[col] = pd.Series(pd.NA, index=df.index, dtype=desired)\n",
    "\n",
    "def _safe_cycle_assign(df: pd.DataFrame, col: str, idx: pd.Index, values: np.ndarray) -> None:\n",
    "    \"\"\"\n",
    "    Assign only on `idx` without disturbing other rows/dtypes.\n",
    "    If the column is categorical, temporarily drop categories (to 'object') to avoid mass NA.\n",
    "    \"\"\"\n",
    "    if col not in df.columns:\n",
    "        # create as object for maximal permissiveness; we only write the slice\n",
    "        df[col] = pd.Series(pd.NA, index=df.index, dtype=\"object\")\n",
    "    if isinstance(df[col].dtype, CategoricalDtype):\n",
    "        df[col] = df[col].astype(object)\n",
    "    df.loc[idx, col] = values\n",
    "\n",
    "# =========================\n",
    "# Utility\n",
    "# =========================\n",
    "def _mask_from_map(seq: pd.Series, truthy_indexlike) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Map SEQN -> boolean, cast to pandas nullable boolean, fill NA=False, then numpy.\n",
    "    `truthy_indexlike` may be a boolean Series indexed by SEQN, or an Index of True rows.\n",
    "    \"\"\"\n",
    "    if isinstance(truthy_indexlike, (pd.Series, pd.DataFrame)):\n",
    "        mapped = seq.map(truthy_indexlike).astype(\"boolean\")\n",
    "    else:\n",
    "        truth = pd.Series(True, index=pd.Index(truthy_indexlike, name=\"SEQN\"))\n",
    "        mapped = seq.map(truth).astype(\"boolean\")\n",
    "    return mapped.fillna(False).to_numpy()\n",
    "\n",
    "# =========================\n",
    "# Backfill: generic (with 66 fallback)\n",
    "# =========================\n",
    "    \"\"\"\n",
    "def backfill_simple(df: pd.DataFrame, target_col: str, cycle: int, module: str, src_col: str,\n",
    "                    mapper=lambda s: pd.to_numeric(s, errors=\"coerce\")) -> pd.DataFrame:\n",
    "    y, f = file_for(module, cycle)\n",
    "    try:\n",
    "        src = fetch_xpt(y, f).set_index(\"SEQN\")\n",
    "    except Exception as e:\n",
    "        print(f\"[{module} {cycle}] fetch {y}/{f}.xpt failed ({e}) — skipped\")\n",
    "        return df\n",
    "\n",
    "    # If unified P_* (cycle 66) is missing the variable, try module_J named file\n",
    "    if src_col not in src.columns and cycle == 66 and f.startswith(\"P_\"):\n",
    "        alt_file = f\"{module.upper()}_J\"\n",
    "        try:\n",
    "            alt = fetch_xpt(\"2017\", alt_file).set_index(\"SEQN\")\n",
    "            if src_col in alt.columns:\n",
    "                src = alt\n",
    "                print(f\"[{module} {cycle}] {src_col} missing in {f}.xpt, fell back to {alt_file}.xpt\")\n",
    "            else:\n",
    "                print(f\"[{module} {cycle}] {src_col} not in {f}.xpt nor {alt_file}.xpt — skipped\")\n",
    "                return df\n",
    "        except Exception as e:\n",
    "            print(f\"[{module} {cycle}] fallback 2017/{alt_file}.xpt failed ({e}) — skipped\")\n",
    "            return df\n",
    "    elif src_col not in src.columns:\n",
    "        print(f\"[{module} {cycle}] {src_col} not in file {f}.xpt — skipped\")\n",
    "        return df\n",
    "\n",
    "    # Map & align\n",
    "    s_mapped = mapper(src[src_col])\n",
    "    s_mapped.name = target_col\n",
    "\n",
    "    m   = df[\"SDDSRVYR\"].eq(float(cycle))\n",
    "    idx = df.index[m]\n",
    "    seq = df.loc[idx, \"SEQN\"].astype(\"Int64\")\n",
    "\n",
    "    mapped = seq.map(s_mapped)\n",
    "\n",
    "    # decide desired dtype from the mapped series\n",
    "    if pd.api.types.is_integer_dtype(s_mapped.dtype):\n",
    "        desired_dtype = \"Int64\"\n",
    "        mapped = mapped.astype(\"Int64\")\n",
    "    elif pd.api.types.is_numeric_dtype(s_mapped.dtype):\n",
    "        desired_dtype = \"float64\"\n",
    "        mapped = pd.to_numeric(mapped, errors=\"coerce\").astype(\"float64\")\n",
    "    else:\n",
    "        desired_dtype = \"string\"\n",
    "        mapped = mapped.astype(\"string\")\n",
    "\n",
    "    # this is safe for non-smoking columns\n",
    "    ensure_col_dtype(df, target_col, desired_dtype)\n",
    "    df.loc[idx, target_col] = mapped.values\n",
    "    print(f\"[{module} {cycle}] filled {target_col} from {y}/{f}:{src_col} (n={s_mapped.notna().sum()})\")\n",
    "    return df\n",
    "    \"\"\"\n",
    "\n",
    "# ------------------------- generic backfill (cycle-scoped, snapshot/restore) -------------------------\n",
    "def _preserve_outside_cycle(df: pd.DataFrame, col: str, m_cycle: pd.Series):\n",
    "    \"\"\"\n",
    "    Return a Series snapshot of df[col] for rows NOT in the cycle mask (to restore after writes).\n",
    "    If column doesn't exist yet, return None.\n",
    "    \"\"\"\n",
    "    if col in df.columns:\n",
    "        return df.loc[~m_cycle, col].copy()\n",
    "    return None\n",
    "\n",
    "def backfill_simple(df: pd.DataFrame, target_col: str, cycle: int, module: str, src_col: str,\n",
    "                    mapper=lambda s: pd.to_numeric(s, errors=\"coerce\")) -> pd.DataFrame:\n",
    "    y, f = file_for(module, cycle)\n",
    "    try:\n",
    "        src = fetch_xpt(y, f).set_index(\"SEQN\")\n",
    "    except Exception as e:\n",
    "        print(f\"[{module} {cycle}] fetch {y}/{f}.xpt failed ({e}) — skipped\")\n",
    "        return df\n",
    "\n",
    "    # unified P_* bundle sometimes lacks vars in 66 → try MODULE_J\n",
    "    if src_col not in src.columns and cycle == 66 and f.startswith(\"P_\"):\n",
    "        alt_file = f\"{module.upper()}_J\"\n",
    "        try:\n",
    "            alt = fetch_xpt(\"2017\", alt_file).set_index(\"SEQN\")\n",
    "            if src_col in alt.columns:\n",
    "                src = alt\n",
    "                print(f\"[{module} {cycle}] {src_col} missing in {f}.xpt, fell back to {alt_file}.xpt\")\n",
    "            else:\n",
    "                print(f\"[{module} {cycle}] {src_col} not in {f}.xpt nor {alt_file}.xpt — skipped\")\n",
    "                return df\n",
    "        except Exception as e:\n",
    "            print(f\"[{module} {cycle}] fallback 2017/{alt_file}.xpt failed ({e}) — skipped\")\n",
    "            return df\n",
    "    elif src_col not in src.columns:\n",
    "        print(f\"[{module} {cycle}] {src_col} not in file {f}.xpt — skipped\")\n",
    "        return df\n",
    "\n",
    "    # map & align\n",
    "    s_mapped = mapper(src[src_col])\n",
    "    s_mapped.name = target_col\n",
    "\n",
    "    m_cycle = df[\"SDDSRVYR\"].eq(float(cycle))\n",
    "    idx = df.index[m_cycle]\n",
    "    if len(idx) == 0:\n",
    "        print(f\"[{module} {cycle}] no rows in frame — skipped\")\n",
    "        return df\n",
    "\n",
    "    seq    = df.loc[idx, \"SEQN\"].astype(\"Int64\")\n",
    "    mapped = seq.map(s_mapped)\n",
    "\n",
    "    # choose a dtype for *new* columns only (do NOT coerce existing columns)\n",
    "    if pd.api.types.is_integer_dtype(s_mapped.dtype):\n",
    "        desired_dtype = \"Int64\";   mapped = mapped.astype(\"Int64\")\n",
    "    elif pd.api.types.is_numeric_dtype(s_mapped.dtype):\n",
    "        desired_dtype = \"float64\"; mapped = pd.to_numeric(mapped, errors=\"coerce\").astype(\"float64\")\n",
    "    else:\n",
    "        desired_dtype = \"string\";  mapped = mapped.astype(\"string\")\n",
    "\n",
    "    # snapshot everything outside the cycle to guarantee no collateral changes\n",
    "    snapshot = _preserve_outside_cycle(df, target_col, m_cycle)\n",
    "\n",
    "    # create column if missing (don’t coerce if it exists)\n",
    "    if target_col not in df.columns:\n",
    "        if desired_dtype == \"boolean\":\n",
    "            df[target_col] = pd.Series(False, index=df.index, dtype=\"boolean\")\n",
    "        else:\n",
    "            df[target_col] = pd.Series(pd.NA, index=df.index, dtype=desired_dtype)\n",
    "\n",
    "    # inside-cycle, fill only where currently NA and we have a mapped value\n",
    "    cur_slice = df.loc[idx, target_col]\n",
    "    fill_mask = cur_slice.isna() & mapped.notna()\n",
    "    # write only the needed rows\n",
    "    df.loc[idx[fill_mask], target_col] = mapped[fill_mask].values\n",
    "\n",
    "    # restore everything outside the cycle exactly as it was\n",
    "    if snapshot is not None:\n",
    "        df.loc[~m_cycle, target_col] = snapshot\n",
    "\n",
    "    wrote = int(fill_mask.sum())\n",
    "    print(f\"[{module} {cycle}] filled {target_col} from {y}/{f}:{src_col} (n_src_nonnull={s_mapped.notna().sum()}, wrote={wrote})\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Backfill: Smoking (safe per-cycle assigns)\n",
    "# =========================\n",
    "def backfill_smoking(df: pd.DataFrame, cycle: int) -> pd.DataFrame:\n",
    "    y, f = file_for(\"SMQ\", cycle)\n",
    "    try:\n",
    "        smq = fetch_xpt(y, f).set_index(\"SEQN\")\n",
    "    except Exception as e:\n",
    "        print(f\"[SMQ {cycle}] fetch failed ({e}) — skipped\")\n",
    "        return df\n",
    "    if not {\"SMQ020\",\"SMQ040\"}.issubset(smq.columns):\n",
    "        print(f\"[SMQ {cycle}] needed vars missing — skipped\")\n",
    "        return df\n",
    "\n",
    "    ever = pd.to_numeric(smq[\"SMQ020\"], errors=\"coerce\")  # 1 yes, 2 no\n",
    "    now  = pd.to_numeric(smq[\"SMQ040\"], errors=\"coerce\")  # 1 every day, 2 some days, 3 not at all\n",
    "\n",
    "    current = (ever.eq(1)) & (now.isin([1,2]))\n",
    "    former  = (ever.eq(1)) & (now.eq(3))\n",
    "    never   =  ever.eq(2)\n",
    "\n",
    "    m   = df[\"SDDSRVYR\"].eq(float(cycle))\n",
    "    idx = df.index[m]\n",
    "    if len(idx) == 0:\n",
    "        print(f\"[SMQ {cycle}] no rows in frame — skipped\")\n",
    "        return df\n",
    "\n",
    "    seq = df.loc[idx, \"SEQN\"].astype(\"Int64\")\n",
    "\n",
    "    mask_curr  = _mask_from_map(seq, current)\n",
    "    mask_form  = _mask_from_map(seq, former)\n",
    "    mask_never = _mask_from_map(seq, never)\n",
    "\n",
    "    # Create-only (do NOT coerce entire column)\n",
    "    for col, dtype in [(\"SMK\",\"Int64\"), (\"SMK_STATUS\",\"Int64\"),\n",
    "                       (\"FORMER_SMOKER\",\"Int64\"), (\"CIGS_PER_DAY\",\"float64\"),\n",
    "                       (\"PACK_YEARS\",\"float64\")]:\n",
    "        _ensure_col_exists(df, col, dtype)\n",
    "\n",
    "    # Build values for this cycle only\n",
    "    smk = pd.Series(pd.NA, index=idx, dtype=\"Int64\")\n",
    "    smk.loc[idx[mask_curr]] = 1\n",
    "    smk.loc[idx[~mask_curr & (mask_form | mask_never)]] = 0\n",
    "\n",
    "    status = pd.Series(pd.NA, index=idx, dtype=\"Int64\")\n",
    "    status.loc[idx[mask_curr]] = 1\n",
    "    status.loc[idx[~mask_curr & mask_form]] = 2\n",
    "    status.loc[idx[~mask_curr & ~mask_form & mask_never]] = 3\n",
    "\n",
    "    fs = pd.Series(pd.NA, index=idx, dtype=\"Int64\")\n",
    "    fs.loc[idx[mask_form]] = 1\n",
    "    fs.loc[idx[~mask_form & (mask_curr | mask_never)]] = 0\n",
    "\n",
    "    # Safe per-cycle assigns (won't disturb other cycles or categories)\n",
    "    _safe_cycle_assign(df, \"SMK\",           idx, smk.values)\n",
    "    _safe_cycle_assign(df, \"SMK_STATUS\",    idx, status.values)\n",
    "    _safe_cycle_assign(df, \"FORMER_SMOKER\", idx, fs.values)\n",
    "\n",
    "    # ----- Extras (best effort, may be sparse) -----\n",
    "    cigs_vars = [v for v in [\"SMD650\",\"SMQ051\"] if v in smq.columns]  # avg cigs/day past 30 days, etc.\n",
    "    if cigs_vars:\n",
    "        cigs = pd.to_numeric(smq[cigs_vars[0]], errors=\"coerce\")\n",
    "        cigs_slice = seq.map(cigs).astype(\"float64\")\n",
    "        _safe_cycle_assign(df, \"CIGS_PER_DAY\", idx, cigs_slice.values)\n",
    "\n",
    "    yrs_vars = [v for v in [\"SMD641\",\"SMD030Y\",\"SMQ050Q\"] if v in smq.columns]  # years proxy (often weak)\n",
    "    if yrs_vars and cigs_vars:\n",
    "        yrs  = pd.to_numeric(smq[yrs_vars[0]], errors=\"coerce\")\n",
    "        cigs = pd.to_numeric(smq[cigs_vars[0]], errors=\"coerce\")\n",
    "        packs_slice = (cigs / 20.0) * yrs\n",
    "        packs_slice = seq.map(packs_slice).astype(\"float64\")\n",
    "        _safe_cycle_assign(df, \"PACK_YEARS\", idx, packs_slice.values)\n",
    "\n",
    "    print(f\"[SMQ {cycle}] derived SMK trio + attempted CIGS_PER_DAY, PACK_YEARS\")\n",
    "    return df\n",
    "\n",
    "# =========================\n",
    "# Backfill: CVD\n",
    "# =========================\n",
    "def backfill_cvd(df: pd.DataFrame, cycle: int) -> pd.DataFrame:\n",
    "    y, f = file_for(\"MCQ\", cycle)\n",
    "    try:\n",
    "        mcq = fetch_xpt(y, f).set_index(\"SEQN\")\n",
    "    except Exception as e:\n",
    "        print(f\"[MCQ {cycle}] fetch failed ({e}) — skipped\")\n",
    "        return df\n",
    "    cols = [c for c in [\"MCQ160B\",\"MCQ160C\",\"MCQ160D\",\"MCQ160E\",\"MCQ160F\"] if c in mcq.columns]\n",
    "    if not cols:\n",
    "        print(f\"[MCQ {cycle}] CVD items not found — skipped\")\n",
    "        return df\n",
    "\n",
    "    x = mcq[cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    any_yes = (x == 1).any(axis=1)  # SEQN index\n",
    "    all_no  = (x == 2).all(axis=1)\n",
    "\n",
    "    m   = df[\"SDDSRVYR\"].eq(float(cycle))\n",
    "    idx = df.index[m]\n",
    "    seq = df.loc[idx, \"SEQN\"].astype(\"Int64\")\n",
    "\n",
    "    mask_any_yes = _mask_from_map(seq, any_yes)\n",
    "    mask_all_no  = _mask_from_map(seq, all_no)\n",
    "\n",
    "    ensure_col_dtype(df, \"CVD\", \"Int64\")  # safe globally\n",
    "    cvd = pd.Series(pd.NA, index=idx, dtype=\"Int64\")\n",
    "    cvd.loc[idx[mask_any_yes]] = 1\n",
    "    cvd.loc[idx[mask_all_no & ~mask_any_yes]] = 0\n",
    "\n",
    "    df.loc[idx, \"CVD\"] = cvd.values\n",
    "    print(f\"[MCQ {cycle}] derived CVD from {cols}\")\n",
    "    return df\n",
    "\n",
    "# =========================\n",
    "# HOQ065 (tenure unavailable 66 & 12)\n",
    "# =========================\n",
    "def backfill_hoq65_with_structural(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Tenure (HOQ065) availability per our checks:\n",
    "      - Cycle 66 (2017–Mar 2020): public HOQ_J does not cover your 66 SEQNs.\n",
    "      - Cycle 12 (2021–2023): HOQ_L released but has no HOQ065.\n",
    "    Mark HOQ065 as structural-missing for both cycles.\n",
    "    \"\"\"\n",
    "    ensure_col_dtype(df, \"HOQ065\", \"Int64\")\n",
    "    ensure_col_dtype(df, \"HOQ065_structural_missing\", \"boolean\")\n",
    "\n",
    "    for cyc in (66.0, 12.0):\n",
    "        m = df[\"SDDSRVYR\"].eq(cyc)\n",
    "        df.loc[m, \"HOQ065\"] = pd.NA\n",
    "        df.loc[m, \"HOQ065_structural_missing\"] = True\n",
    "        print(f\"[HOQ {int(cyc)}] tenure HOQ065 not available publicly — marked structural missing\")\n",
    "    return df\n",
    "\n",
    "# =========================\n",
    "# APPLY: cycles 66 & 12\n",
    "# =========================\n",
    "for cyc in (66, 12):\n",
    "    # DEMO\n",
    "    df_my_cov_aligned_short = backfill_simple(\n",
    "        df_my_cov_aligned_short, \"RACE\", cyc, \"DEMO\", \"RIDRETH3\",\n",
    "        mapper=lambda s: pd.to_numeric(s, errors=\"coerce\").astype(\"Int64\")\n",
    "    )\n",
    "    df_my_cov_aligned_short = backfill_simple(\n",
    "        df_my_cov_aligned_short, \"household_size\", cyc, \"DEMO\", \"DMDHHSIZ\",\n",
    "        mapper=lambda s: pd.to_numeric(s, errors=\"coerce\").astype(\"Int64\")\n",
    "    )\n",
    "\n",
    "    # BMX\n",
    "    df_my_cov_aligned_short = backfill_simple(\n",
    "        df_my_cov_aligned_short, \"bmic\", cyc, \"BMX\", \"BMXBMI\",\n",
    "        mapper=lambda s: pd.to_numeric(s, errors=\"coerce\")\n",
    "    )\n",
    "\n",
    "    # HIQ / DIQ / BPQ\n",
    "    df_my_cov_aligned_short = backfill_simple(df_my_cov_aligned_short, \"ins\",      cyc, \"HIQ\", \"HIQ011\",  mapper=map_yes_no_codes)\n",
    "    df_my_cov_aligned_short = backfill_simple(df_my_cov_aligned_short, \"DIABE\",    cyc, \"DIQ\", \"DIQ010\",  mapper=map_yes_no_codes)\n",
    "    df_my_cov_aligned_short = backfill_simple(df_my_cov_aligned_short, \"HYPERTEN\", cyc, \"BPQ\", \"BPQ020\",  mapper=map_yes_no_codes)\n",
    "    df_my_cov_aligned_short = backfill_simple(df_my_cov_aligned_short, \"chol_rx\",  cyc, \"BPQ\", \"BPQ101D\", mapper=map_yes_no_codes)\n",
    "\n",
    "    # MCQ (cancer + CVD)\n",
    "    df_my_cov_aligned_short = backfill_simple(df_my_cov_aligned_short, \"cancer\", cyc, \"MCQ\", \"MCQ220\", mapper=map_yes_no_codes)\n",
    "    df_my_cov_aligned_short = backfill_cvd(df_my_cov_aligned_short, cyc)\n",
    "\n",
    "    # Smoking (safe assigns; will not disturb pre-2018 values)\n",
    "    df_my_cov_aligned_short = backfill_smoking(df_my_cov_aligned_short, cyc)\n",
    "\n",
    "# HOQ065 (structural)\n",
    "df_my_cov_aligned_short = backfill_hoq65_with_structural(df_my_cov_aligned_short)\n",
    "\n",
    "# =========================\n",
    "# (Optional) quick sanity\n",
    "# =========================\n",
    "def _pct_nonmissing(s): return (1 - s.isna().mean())*100\n",
    "if \"SMK\" in df_my_cov_aligned_short.columns:\n",
    "    smk_pct = (df_my_cov_aligned_short.groupby(\"SDDSRVYR\")[\"SMK\"]\n",
    "               .apply(lambda s: _pct_nonmissing(s).round(1)))\n",
    "    print(\"\\nSMK non-missing % by cycle:\")\n",
    "    print(smk_pct.to_string())\n",
    "\n",
    "def _pct_nonmissing(s): return (1 - s.isna().mean())*100\n",
    "if \"SMK\" in df_my_cov_aligned_short.columns:\n",
    "    smk_pct = (df_my_cov_aligned_short.groupby(\"SDDSRVYR\")[\"bmic\"]\n",
    "               .apply(lambda s: _pct_nonmissing(s).round(1)))\n",
    "    print(\"\\nbmic non-missing % by cycle:\")\n",
    "    print(smk_pct.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ba11c526-aa62-4242-abef-f8c1468fe029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEMO 66] filled RACE from 2017/P_DEMO:RIDRETH3 (n_src_nonnull=15560, wrote=15560)\n",
      "[DEMO 66] DMDHHSIZ missing in P_DEMO.xpt, fell back to DEMO_J.xpt\n",
      "[DEMO 66] filled household_size from 2017/P_DEMO:DMDHHSIZ (n_src_nonnull=9254, wrote=0)\n",
      "[BMX 66] filled bmi from 2017/P_BMX:BMXBMI (n_src_nonnull=13137, wrote=13137)\n",
      "[HIQ 66] filled ins from 2017/P_HIQ:HIQ011 (n_src_nonnull=15523, wrote=0)\n",
      "[DIQ 66] filled DIABE from 2017/P_DIQ:DIQ010 (n_src_nonnull=14694, wrote=14694)\n",
      "[BPQ 66] filled HYPERTEN from 2017/P_BPQ:BPQ020 (n_src_nonnull=10183, wrote=10183)\n",
      "[BPQ 66] BPQ101D not in P_BPQ.xpt nor BPQ_J.xpt — skipped\n",
      "[MCQ 66] filled cancer from 2017/P_MCQ:MCQ220 (n_src_nonnull=9228, wrote=9228)\n",
      "[MCQ 66] derived CVD from ['MCQ160B', 'MCQ160C', 'MCQ160D', 'MCQ160E', 'MCQ160F']\n",
      "[SMQ 66] derived SMK trio + attempted CIGS_PER_DAY, PACK_YEARS\n",
      "[DEMO 12] filled RACE from 2021/DEMO_L:RIDRETH3 (n_src_nonnull=11933, wrote=11933)\n",
      "[DEMO 12] filled household_size from 2021/DEMO_L:DMDHHSIZ (n_src_nonnull=11933, wrote=0)\n",
      "[BMX 12] filled bmi from 2021/BMX_L:BMXBMI (n_src_nonnull=8471, wrote=8471)\n",
      "[HIQ 12] filled ins from 2021/HIQ_L:HIQ011 (n_src_nonnull=11871, wrote=0)\n",
      "[DIQ 12] filled DIABE from 2021/DIQ_L:DIQ010 (n_src_nonnull=11452, wrote=11452)\n",
      "[BPQ 12] filled HYPERTEN from 2021/BPQ_L:BPQ020 (n_src_nonnull=8487, wrote=8487)\n",
      "[BPQ 12] filled chol_rx from 2021/BPQ_L:BPQ101D (n_src_nonnull=8465, wrote=8465)\n",
      "[MCQ 12] filled cancer from 2021/MCQ_L:MCQ220 (n_src_nonnull=7800, wrote=7800)\n",
      "[MCQ 12] derived CVD from ['MCQ160B', 'MCQ160C', 'MCQ160D', 'MCQ160E', 'MCQ160F']\n",
      "[SMQ 12] derived SMK trio + attempted CIGS_PER_DAY, PACK_YEARS\n",
      "[HOQ 66] tenure HOQ065 not available publicly — marked structural missing\n",
      "[HOQ 12] tenure HOQ065 not available publicly — marked structural missing\n",
      "\n",
      "SMK non-missing % by cycle:\n",
      "SDDSRVYR\n",
      "1.0     48.8\n",
      "2.0     48.9\n",
      "3.0     49.7\n",
      "4.0     48.1\n",
      "5.0     58.4\n",
      "6.0     59.0\n",
      "7.0     56.9\n",
      "8.0     56.7\n",
      "9.0     57.2\n",
      "10.0    60.2\n",
      "12.0    68.1\n",
      "66.0    62.3\n",
      "\n",
      "BMI (numeric) non-missing % by cycle:\n",
      "SDDSRVYR\n",
      "1.0      0.0\n",
      "2.0      0.0\n",
      "3.0      0.0\n",
      "4.0      0.0\n",
      "5.0      0.0\n",
      "6.0      0.0\n",
      "7.0      0.0\n",
      "8.0      0.0\n",
      "9.0      0.0\n",
      "10.0     0.0\n",
      "12.0    71.0\n",
      "66.0    84.4\n",
      "\n",
      "BMI (categorical, bmi_cat) non-missing % by cycle:\n",
      "SDDSRVYR\n",
      "1.0     84.9\n",
      "2.0     81.6\n",
      "3.0     85.8\n",
      "4.0     86.5\n",
      "5.0     87.3\n",
      "6.0     89.3\n",
      "7.0     88.2\n",
      "8.0     89.0\n",
      "9.0     87.8\n",
      "10.0    86.5\n",
      "12.0    71.0\n",
      "66.0    84.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, io, requests\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# =========================\n",
    "# Fetch & file mapping\n",
    "# =========================\n",
    "_YEARFOLDER_FIX = {\"1999-2000\": \"1999\", \"2001-2002\": \"2001\"}  # early-cycle folder quirk\n",
    "\n",
    "def fetch_xpt(year_folder: str, filebase: str) -> pd.DataFrame:\n",
    "    yf = _YEARFOLDER_FIX.get(year_folder, year_folder)\n",
    "    url = f\"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/{yf}/DataFiles/{filebase}.xpt\"\n",
    "    r = requests.get(url); r.raise_for_status()\n",
    "    df = pd.read_sas(io.BytesIO(r.content), format=\"xport\", encoding=\"latin1\")\n",
    "    df.columns = [c.upper() for c in df.columns]\n",
    "    if \"SEQN\" in df.columns:\n",
    "        df[\"SEQN\"] = pd.to_numeric(df[\"SEQN\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    return df\n",
    "\n",
    "def file_for(module: str, cycle: int) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Returns (year_folder, filebase) for cycles 66 and 12.\n",
    "    - 66 (2017–Mar 2020): P_<MODULE> under '2017' (EXCEPT HOQ → HOQ_J)\n",
    "    - 12 (Aug 2021–Aug 2023): <MODULE>_L under '2021' (HOQ → HOQ_L)\n",
    "    \"\"\"\n",
    "    m = module.upper()\n",
    "    if m == \"HOQ\":\n",
    "        return (\"2017\", \"HOQ_J\") if cycle == 66 else (\"2021\", \"HOQ_L\")\n",
    "    if cycle == 66:\n",
    "        return (\"2017\", f\"P_{m}\")\n",
    "    elif cycle == 12:\n",
    "        return (\"2021\", f\"{m}_L\")\n",
    "    else:\n",
    "        raise ValueError(\"This helper is scoped to cycles 66 and 12 only.\")\n",
    "\n",
    "# =========================\n",
    "# Dtype helpers\n",
    "# =========================\n",
    "def ensure_col_dtype(df: pd.DataFrame, col: str, desired: str) -> None:\n",
    "    \"\"\"\n",
    "    Ensure df[col] exists and has dtype `desired`\n",
    "      desired ∈ {'Int64','float64','string','boolean'}\n",
    "    If categorical/incompatible, coerce the whole column.\n",
    "    NOTE: Use this for columns that are safe to coerce globally.\n",
    "          For smoking columns, use the safe-assign helpers below instead.\n",
    "    \"\"\"\n",
    "    if col not in df.columns:\n",
    "        if desired == \"boolean\":\n",
    "            df[col] = pd.Series(False, index=df.index, dtype=\"boolean\")\n",
    "        elif desired == \"float64\":\n",
    "            df[col] = pd.Series(np.nan, index=df.index, dtype=\"float64\")  # use np.nan for float64\n",
    "        else:\n",
    "            df[col] = pd.Series(pd.NA, index=df.index, dtype=desired)\n",
    "        return\n",
    "    try:\n",
    "        df[col] = df[col].astype(desired)\n",
    "    except Exception:\n",
    "        if isinstance(df[col].dtype, CategoricalDtype):\n",
    "            df[col] = df[col].astype(object)  # drop categories\n",
    "        if desired == \"Int64\":\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\").astype(\"Int64\")\n",
    "        elif desired == \"float64\":\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\").astype(\"float64\")\n",
    "        elif desired == \"boolean\":\n",
    "            df[col] = df[col].astype(\"boolean\")\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"string\")\n",
    "\n",
    "def map_yes_no_codes(s: pd.Series) -> pd.Series:\n",
    "    x = pd.to_numeric(s, errors=\"coerce\")\n",
    "    out = pd.Series(pd.NA, index=x.index, dtype=\"Int64\")\n",
    "    out.loc[x.eq(1)] = 1\n",
    "    out.loc[x.eq(2)] = 0\n",
    "    return out\n",
    "\n",
    "# =========================\n",
    "# Assign helpers (protect older cycles)\n",
    "# =========================\n",
    "def _ensure_col_exists(df: pd.DataFrame, col: str, desired: str) -> None:\n",
    "    \"\"\"Create df[col] if missing; don't coerce if it already exists.\"\"\"\n",
    "    if col not in df.columns:\n",
    "        if desired == \"boolean\":\n",
    "            df[col] = pd.Series(False, index=df.index, dtype=\"boolean\")\n",
    "        elif desired == \"float64\":\n",
    "            df[col] = pd.Series(np.nan, index=df.index, dtype=\"float64\")  # use np.nan for float64\n",
    "        else:\n",
    "            df[col] = pd.Series(pd.NA, index=df.index, dtype=desired)\n",
    "\n",
    "def _safe_cycle_assign(df: pd.DataFrame, col: str, idx: pd.Index, values: np.ndarray) -> None:\n",
    "    \"\"\"\n",
    "    Assign only on `idx` without disturbing other rows/dtypes.\n",
    "    If the column is categorical, temporarily drop categories (to 'object') to avoid mass NA.\n",
    "    \"\"\"\n",
    "    if col not in df.columns:\n",
    "        df[col] = pd.Series(pd.NA, index=df.index, dtype=\"object\")\n",
    "    if isinstance(df[col].dtype, CategoricalDtype):\n",
    "        df[col] = df[col].astype(object)\n",
    "    df.loc[idx, col] = values\n",
    "\n",
    "# =========================\n",
    "# Utility\n",
    "# =========================\n",
    "def _mask_from_map(seq: pd.Series, truthy_indexlike) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Map SEQN -> boolean, cast to pandas nullable boolean, fill NA=False, then numpy.\n",
    "    `truthy_indexlike` may be a boolean Series indexed by SEQN, or an Index of True rows.\n",
    "    \"\"\"\n",
    "    if isinstance(truthy_indexlike, (pd.Series, pd.DataFrame)):\n",
    "        mapped = seq.map(truthy_indexlike).astype(\"boolean\")\n",
    "    else:\n",
    "        truth = pd.Series(True, index=pd.Index(truthy_indexlike, name=\"SEQN\"))\n",
    "        mapped = seq.map(truth).astype(\"boolean\")\n",
    "    return mapped.fillna(False).to_numpy()\n",
    "\n",
    "# =========================\n",
    "# Preserve cat BMI; set up numeric BMI\n",
    "# =========================\n",
    "def _is_stringlike_or_categorical(s: pd.Series) -> bool:\n",
    "    return (pd.api.types.is_string_dtype(s.dtype) or isinstance(s.dtype, CategoricalDtype))\n",
    "\n",
    "def preserve_bmi_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    If existing 'bmic' is categorical/string (older labels), preserve it as 'bmi_cat'.\n",
    "    Always ensure a numeric 'bmi' column exists for numeric BMI backfill.\n",
    "    \"\"\"\n",
    "    if \"bmic\" in df.columns and _is_stringlike_or_categorical(df[\"bmic\"]):\n",
    "        if \"bmi_cat\" not in df.columns:\n",
    "            df = df.rename(columns={\"bmic\": \"bmi_cat\"})\n",
    "        # else: keep both; don't touch existing\n",
    "    if \"bmi\" not in df.columns:\n",
    "        df[\"bmi\"] = pd.Series(np.nan, index=df.index, dtype=\"float64\")  # float-safe creation\n",
    "    return df\n",
    "\n",
    "def ensure_bmi_cat_from_numeric(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fill bmi_cat ONLY where missing and numeric bmi exists.\n",
    "    Categories: UNDER (<18.5), NORMAL [18.5,25), OVER [25,30), OBESE [30,∞)\n",
    "    \"\"\"\n",
    "    if \"bmi_cat\" not in df.columns:\n",
    "        df[\"bmi_cat\"] = pd.Series(pd.NA, index=df.index, dtype=\"string\")\n",
    "    need = df[\"bmi_cat\"].isna() & df[\"bmi\"].notna()\n",
    "    if need.any():\n",
    "        bins   = [-np.inf, 18.5, 25.0, 30.0, np.inf]\n",
    "        labels = [\"UNDER\", \"NORMAL\", \"OVER\", \"OBESE\"]\n",
    "        df.loc[need, \"bmi_cat\"] = pd.cut(\n",
    "            df.loc[need, \"bmi\"], bins=bins, labels=labels, right=False\n",
    "        ).astype(\"string\").values\n",
    "    return df\n",
    "\n",
    "# =========================\n",
    "# Backfill: generic (with 66 fallback), NA-only within-cycle, preserves outside\n",
    "# =========================\n",
    "def _preserve_outside_cycle(df: pd.DataFrame, col: str, m_cycle: pd.Series):\n",
    "    \"\"\"\n",
    "    Return a Series snapshot of df[col] for rows NOT in the cycle mask (to restore after writes).\n",
    "    If column doesn't exist yet, return None.\n",
    "    \"\"\"\n",
    "    if col in df.columns:\n",
    "        return df.loc[~m_cycle, col].copy()\n",
    "    return None\n",
    "\n",
    "def backfill_simple(df: pd.DataFrame, target_col: str, cycle: int, module: str, src_col: str,\n",
    "                    mapper=lambda s: pd.to_numeric(s, errors=\"coerce\")) -> pd.DataFrame:\n",
    "    y, f = file_for(module, cycle)\n",
    "    try:\n",
    "        src = fetch_xpt(y, f).set_index(\"SEQN\")\n",
    "    except Exception as e:\n",
    "        print(f\"[{module} {cycle}] fetch {y}/{f}.xpt failed ({e}) — skipped\")\n",
    "        return df\n",
    "\n",
    "    # unified P_* bundle sometimes lacks vars in 66 → try MODULE_J\n",
    "    if src_col not in src.columns and cycle == 66 and f.startswith(\"P_\"):\n",
    "        alt_file = f\"{module.upper()}_J\"\n",
    "        try:\n",
    "            alt = fetch_xpt(\"2017\", alt_file).set_index(\"SEQN\")\n",
    "            if src_col in alt.columns:\n",
    "                src = alt\n",
    "                print(f\"[{module} {cycle}] {src_col} missing in {f}.xpt, fell back to {alt_file}.xpt\")\n",
    "            else:\n",
    "                print(f\"[{module} {cycle}] {src_col} not in {f}.xpt nor {alt_file}.xpt — skipped\")\n",
    "                return df\n",
    "        except Exception as e:\n",
    "            print(f\"[{module} {cycle}] fallback 2017/{alt_file}.xpt failed ({e}) — skipped\")\n",
    "            return df\n",
    "    elif src_col not in src.columns:\n",
    "        print(f\"[{module} {cycle}] {src_col} not in file {f}.xpt — skipped\")\n",
    "        return df\n",
    "\n",
    "    # map & align\n",
    "    s_mapped = mapper(src[src_col])\n",
    "    s_mapped.name = target_col\n",
    "\n",
    "    m_cycle = df[\"SDDSRVYR\"].eq(float(cycle))\n",
    "    idx = df.index[m_cycle]\n",
    "    if len(idx) == 0:\n",
    "        print(f\"[{module} {cycle}] no rows in frame — skipped\")\n",
    "        return df\n",
    "\n",
    "    seq    = df.loc[idx, \"SEQN\"].astype(\"Int64\")\n",
    "    mapped = seq.map(s_mapped)\n",
    "\n",
    "    # choose dtype for new columns only (do NOT coerce existing columns)\n",
    "    if pd.api.types.is_integer_dtype(s_mapped.dtype):\n",
    "        desired_dtype = \"Int64\";   mapped = mapped.astype(\"Int64\")\n",
    "    elif pd.api.types.is_numeric_dtype(s_mapped.dtype):\n",
    "        desired_dtype = \"float64\"; mapped = pd.to_numeric(mapped, errors=\"coerce\").astype(\"float64\")\n",
    "    else:\n",
    "        desired_dtype = \"string\";  mapped = mapped.astype(\"string\")\n",
    "\n",
    "    # snapshot outside-cycle values to guarantee no collateral changes\n",
    "    snapshot = _preserve_outside_cycle(df, target_col, m_cycle)\n",
    "\n",
    "    # create column if missing (don’t coerce if it exists)\n",
    "    if target_col not in df.columns:\n",
    "        if desired_dtype == \"boolean\":\n",
    "            df[target_col] = pd.Series(False, index=df.index, dtype=\"boolean\")\n",
    "        elif desired_dtype == \"float64\":\n",
    "            df[target_col] = pd.Series(np.nan, index=df.index, dtype=\"float64\")  # float-safe creation\n",
    "        else:\n",
    "            df[target_col] = pd.Series(pd.NA, index=df.index, dtype=desired_dtype)\n",
    "\n",
    "    # inside-cycle, fill only where currently NA and we have a mapped value\n",
    "    cur_slice = df.loc[idx, target_col]\n",
    "    fill_mask = cur_slice.isna() & mapped.notna()\n",
    "    df.loc[idx[fill_mask], target_col] = mapped[fill_mask].values\n",
    "\n",
    "    # restore everything outside the cycle exactly as it was\n",
    "    if snapshot is not None:\n",
    "        df.loc[~m_cycle, target_col] = snapshot\n",
    "\n",
    "    wrote = int(fill_mask.sum())\n",
    "    print(f\"[{module} {cycle}] filled {target_col} from {y}/{f}:{src_col} (n_src_nonnull={s_mapped.notna().sum()}, wrote={wrote})\")\n",
    "    return df\n",
    "\n",
    "# =========================\n",
    "# Backfill: Smoking (safe per-cycle assigns)\n",
    "# =========================\n",
    "def backfill_smoking(df: pd.DataFrame, cycle: int) -> pd.DataFrame:\n",
    "    y, f = file_for(\"SMQ\", cycle)\n",
    "    try:\n",
    "        smq = fetch_xpt(y, f).set_index(\"SEQN\")\n",
    "    except Exception as e:\n",
    "        print(f\"[SMQ {cycle}] fetch failed ({e}) — skipped\")\n",
    "        return df\n",
    "    if not {\"SMQ020\",\"SMQ040\"}.issubset(smq.columns):\n",
    "        print(f\"[SMQ {cycle}] needed vars missing — skipped\")\n",
    "        return df\n",
    "\n",
    "    ever = pd.to_numeric(smq[\"SMQ020\"], errors=\"coerce\")  # 1 yes, 2 no\n",
    "    now  = pd.to_numeric(smq[\"SMQ040\"], errors=\"coerce\")  # 1 every day, 2 some days, 3 not at all\n",
    "\n",
    "    current = (ever.eq(1)) & (now.isin([1,2]))\n",
    "    former  = (ever.eq(1)) & (now.eq(3))\n",
    "    never   =  ever.eq(2)\n",
    "\n",
    "    m   = df[\"SDDSRVYR\"].eq(float(cycle))\n",
    "    idx = df.index[m]\n",
    "    if len(idx) == 0:\n",
    "        print(f\"[SMQ {cycle}] no rows in frame — skipped\")\n",
    "        return df\n",
    "\n",
    "    seq = df.loc[idx, \"SEQN\"].astype(\"Int64\")\n",
    "\n",
    "    mask_curr  = _mask_from_map(seq, current)\n",
    "    mask_form  = _mask_from_map(seq, former)\n",
    "    mask_never = _mask_from_map(seq, never)\n",
    "\n",
    "    # Create-only (do NOT coerce entire column)\n",
    "    for col, dtype in [(\"SMK\",\"Int64\"), (\"SMK_STATUS\",\"Int64\"),\n",
    "                       (\"FORMER_SMOKER\",\"Int64\"), (\"CIGS_PER_DAY\",\"float64\"),\n",
    "                       (\"PACK_YEARS\",\"float64\")]:\n",
    "        _ensure_col_exists(df, col, dtype)\n",
    "\n",
    "    # Build values for this cycle only\n",
    "    smk = pd.Series(pd.NA, index=idx, dtype=\"Int64\")\n",
    "    smk.loc[idx[mask_curr]] = 1\n",
    "    smk.loc[idx[~mask_curr & (mask_form | mask_never)]] = 0\n",
    "\n",
    "    status = pd.Series(pd.NA, index=idx, dtype=\"Int64\")\n",
    "    status.loc[idx[mask_curr]] = 1\n",
    "    status.loc[idx[~mask_curr & mask_form]] = 2\n",
    "    status.loc[idx[~mask_curr & ~mask_form & mask_never]] = 3\n",
    "\n",
    "    fs = pd.Series(pd.NA, index=idx, dtype=\"Int64\")\n",
    "    fs.loc[idx[mask_form]] = 1\n",
    "    fs.loc[idx[~mask_form & (mask_curr | mask_never)]] = 0\n",
    "\n",
    "    # Safe per-cycle assigns (won't disturb other cycles or categories)\n",
    "    _safe_cycle_assign(df, \"SMK\",           idx, smk.values)\n",
    "    _safe_cycle_assign(df, \"SMK_STATUS\",    idx, status.values)\n",
    "    _safe_cycle_assign(df, \"FORMER_SMOKER\", idx, fs.values)\n",
    "\n",
    "    # Extras (best effort)\n",
    "    cigs_vars = [v for v in [\"SMD650\",\"SMQ051\"] if v in smq.columns]\n",
    "    if cigs_vars:\n",
    "        cigs = pd.to_numeric(smq[cigs_vars[0]], errors=\"coerce\")\n",
    "        cigs_slice = seq.map(cigs).astype(\"float64\")\n",
    "        _safe_cycle_assign(df, \"CIGS_PER_DAY\", idx, cigs_slice.values)\n",
    "\n",
    "    yrs_vars = [v for v in [\"SMD641\",\"SMD030Y\",\"SMQ050Q\"] if v in smq.columns]\n",
    "    if yrs_vars and cigs_vars:\n",
    "        yrs  = pd.to_numeric(smq[yrs_vars[0]], errors=\"coerce\")\n",
    "        cigs = pd.to_numeric(smq[cigs_vars[0]], errors=\"coerce\")\n",
    "        packs_slice = (cigs / 20.0) * yrs\n",
    "        packs_slice = seq.map(packs_slice).astype(\"float64\")\n",
    "        _safe_cycle_assign(df, \"PACK_YEARS\", idx, packs_slice.values)\n",
    "\n",
    "    print(f\"[SMQ {cycle}] derived SMK trio + attempted CIGS_PER_DAY, PACK_YEARS\")\n",
    "    return df\n",
    "\n",
    "# =========================\n",
    "# Backfill: CVD\n",
    "# =========================\n",
    "def backfill_cvd(df: pd.DataFrame, cycle: int) -> pd.DataFrame:\n",
    "    y, f = file_for(\"MCQ\", cycle)\n",
    "    try:\n",
    "        mcq = fetch_xpt(y, f).set_index(\"SEQN\")\n",
    "    except Exception as e:\n",
    "        print(f\"[MCQ {cycle}] fetch failed ({e}) — skipped\")\n",
    "        return df\n",
    "    cols = [c for c in [\"MCQ160B\",\"MCQ160C\",\"MCQ160D\",\"MCQ160E\",\"MCQ160F\"] if c in mcq.columns]\n",
    "    if not cols:\n",
    "        print(f\"[MCQ {cycle}] CVD items not found — skipped\")\n",
    "        return df\n",
    "\n",
    "    x = mcq[cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    any_yes = (x == 1).any(axis=1)  # SEQN index\n",
    "    all_no  = (x == 2).all(axis=1)\n",
    "\n",
    "    m   = df[\"SDDSRVYR\"].eq(float(cycle))\n",
    "    idx = df.index[m]\n",
    "    seq = df.loc[idx, \"SEQN\"].astype(\"Int64\")\n",
    "\n",
    "    mask_any_yes = _mask_from_map(seq, any_yes)\n",
    "    mask_all_no  = _mask_from_map(seq, all_no)\n",
    "\n",
    "    ensure_col_dtype(df, \"CVD\", \"Int64\")\n",
    "    cvd = pd.Series(pd.NA, index=idx, dtype=\"Int64\")\n",
    "    cvd.loc[idx[mask_any_yes]] = 1\n",
    "    cvd.loc[idx[mask_all_no & ~mask_any_yes]] = 0\n",
    "\n",
    "    df.loc[idx, \"CVD\"] = cvd.values\n",
    "    print(f\"[MCQ {cycle}] derived CVD from {cols}\")\n",
    "    return df\n",
    "\n",
    "# =========================\n",
    "# HOQ065 (tenure unavailable 66 & 12)\n",
    "# =========================\n",
    "def backfill_hoq65_with_structural(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Tenure (HOQ065) availability per our checks:\n",
    "      - Cycle 66 (2017–Mar 2020): public HOQ_J does not cover your 66 SEQNs.\n",
    "      - Cycle 12 (2021–2023): HOQ_L released but has no HOQ065.\n",
    "    Mark HOQ065 as structural-missing for both cycles.\n",
    "    \"\"\"\n",
    "    ensure_col_dtype(df, \"HOQ065\", \"Int64\")\n",
    "    ensure_col_dtype(df, \"HOQ065_structural_missing\", \"boolean\")\n",
    "\n",
    "    for cyc in (66.0, 12.0):\n",
    "        m = df[\"SDDSRVYR\"].eq(cyc)\n",
    "        df.loc[m, \"HOQ065\"] = pd.NA\n",
    "        df.loc[m, \"HOQ065_structural_missing\"] = True\n",
    "        print(f\"[HOQ {int(cyc)}] tenure HOQ065 not available publicly — marked structural missing\")\n",
    "    return df\n",
    "\n",
    "# =========================\n",
    "# APPLY: cycles 66 & 12\n",
    "# =========================\n",
    "# IMPORTANT: call preserve_bmi_columns() once before any BMX writes\n",
    "df_my_cov_aligned_short = preserve_bmi_columns(df_my_cov_aligned_short)\n",
    "\n",
    "for cyc in (66, 12):\n",
    "    # DEMO\n",
    "    df_my_cov_aligned_short = backfill_simple(\n",
    "        df_my_cov_aligned_short, \"RACE\", cyc, \"DEMO\", \"RIDRETH3\",\n",
    "        mapper=lambda s: pd.to_numeric(s, errors=\"coerce\").astype(\"Int64\")\n",
    "    )\n",
    "    df_my_cov_aligned_short = backfill_simple(\n",
    "        df_my_cov_aligned_short, \"household_size\", cyc, \"DEMO\", \"DMDHHSIZ\",\n",
    "        mapper=lambda s: pd.to_numeric(s, errors=\"coerce\").astype(\"Int64\")\n",
    "    )\n",
    "\n",
    "    # BMX → write numeric BMI to 'bmi' (preserves your old categorical bmic → bmi_cat)\n",
    "    df_my_cov_aligned_short = backfill_simple(\n",
    "        df_my_cov_aligned_short, \"bmi\", cyc, \"BMX\", \"BMXBMI\",\n",
    "        mapper=lambda s: pd.to_numeric(s, errors=\"coerce\")\n",
    "    )\n",
    "\n",
    "    # HIQ / DIQ / BPQ\n",
    "    df_my_cov_aligned_short = backfill_simple(df_my_cov_aligned_short, \"ins\",      cyc, \"HIQ\", \"HIQ011\",  mapper=map_yes_no_codes)\n",
    "    df_my_cov_aligned_short = backfill_simple(df_my_cov_aligned_short, \"DIABE\",    cyc, \"DIQ\", \"DIQ010\",  mapper=map_yes_no_codes)\n",
    "    df_my_cov_aligned_short = backfill_simple(df_my_cov_aligned_short, \"HYPERTEN\", cyc, \"BPQ\", \"BPQ020\",  mapper=map_yes_no_codes)\n",
    "    df_my_cov_aligned_short = backfill_simple(df_my_cov_aligned_short, \"chol_rx\",  cyc, \"BPQ\", \"BPQ101D\", mapper=map_yes_no_codes)\n",
    "\n",
    "    # MCQ (cancer + CVD)\n",
    "    df_my_cov_aligned_short = backfill_simple(df_my_cov_aligned_short, \"cancer\", cyc, \"MCQ\", \"MCQ220\", mapper=map_yes_no_codes)\n",
    "    df_my_cov_aligned_short = backfill_cvd(df_my_cov_aligned_short, cyc)\n",
    "\n",
    "    # Smoking (safe assigns; will not disturb pre-2018 values)\n",
    "    df_my_cov_aligned_short = backfill_smoking(df_my_cov_aligned_short, cyc)\n",
    "\n",
    "# HOQ065 (structural)\n",
    "df_my_cov_aligned_short = backfill_hoq65_with_structural(df_my_cov_aligned_short)\n",
    "\n",
    "# (Optional) build missing labels from numeric BMI WITHOUT overwriting your originals\n",
    "df_my_cov_aligned_short = ensure_bmi_cat_from_numeric(df_my_cov_aligned_short)\n",
    "\n",
    "# =========================\n",
    "# Quick sanity\n",
    "# =========================\n",
    "def _pct_nonmissing(s): return (1 - s.isna().mean())*100\n",
    "\n",
    "if \"SMK\" in df_my_cov_aligned_short.columns:\n",
    "    smk_pct = (df_my_cov_aligned_short.groupby(\"SDDSRVYR\")[\"SMK\"]\n",
    "               .apply(lambda s: _pct_nonmissing(s).round(1)))\n",
    "    print(\"\\nSMK non-missing % by cycle:\")\n",
    "    print(smk_pct.to_string())\n",
    "\n",
    "if \"bmi\" in df_my_cov_aligned_short.columns:\n",
    "    bmi_pct = (df_my_cov_aligned_short.groupby(\"SDDSRVYR\")[\"bmi\"]\n",
    "               .apply(lambda s: _pct_nonmissing(s).round(1)))\n",
    "    print(\"\\nBMI (numeric) non-missing % by cycle:\")\n",
    "    print(bmi_pct.to_string())\n",
    "\n",
    "if \"bmi_cat\" in df_my_cov_aligned_short.columns:\n",
    "    bmi_cat_pct = (df_my_cov_aligned_short.groupby(\"SDDSRVYR\")[\"bmi_cat\"]\n",
    "                   .apply(lambda s: _pct_nonmissing(s).round(1)))\n",
    "    print(\"\\nBMI (categorical, bmi_cat) non-missing % by cycle:\")\n",
    "    print(bmi_cat_pct.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a6805e-6652-4105-88af-a01286d17c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a3cf55d9-e29e-401f-bb72-25709b1ee522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     UNDER\n",
       "1    NORMAL\n",
       "2     UNDER\n",
       "3      <NA>\n",
       "4      OVER\n",
       "5    NORMAL\n",
       "6      OVER\n",
       "7     UNDER\n",
       "8     UNDER\n",
       "9     OBESE\n",
       "Name: bmi_cat, dtype: string"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_my_cov_aligned_short[\"bmi_cat\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c3980134-e6f5-4d36-b82c-0af0d7e976cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[structural] Marked household_size and chol_rx as structural missing for cycle 66\n"
     ]
    }
   ],
   "source": [
    "# Mark structural-missing for items not obtainable in public 2017–Mar 2020 (cycle 66)\n",
    "def mark_structural_missing_66(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ensure_col_dtype(df, \"household_size\", \"Int64\")\n",
    "    ensure_col_dtype(df, \"household_size_structural_missing\", \"boolean\")\n",
    "    ensure_col_dtype(df, \"chol_rx\", \"Int64\")\n",
    "    ensure_col_dtype(df, \"chol_rx_structural_missing\", \"boolean\")\n",
    "\n",
    "    m66 = df[\"SDDSRVYR\"].eq(66.0)\n",
    "\n",
    "    # DMDHHSIZ not available for your 66 SEQNs (no overlap with DEMO_J; no DEMO_K)\n",
    "    df.loc[m66, \"household_size\"] = pd.NA\n",
    "    df.loc[m66, \"household_size_structural_missing\"] = True\n",
    "\n",
    "    # BPQ101D not present in BPQ_J; no BPQ_K\n",
    "    df.loc[m66, \"chol_rx\"] = pd.NA\n",
    "    df.loc[m66, \"chol_rx_structural_missing\"] = True\n",
    "\n",
    "    print(\"[structural] Marked household_size and chol_rx as structural missing for cycle 66\")\n",
    "    return df\n",
    "\n",
    "# call it\n",
    "df_my_cov_aligned_short = mark_structural_missing_66(df_my_cov_aligned_short)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9c20e8-422b-43cf-8f3a-0e3efdd30033",
   "metadata": {},
   "source": [
    "#### sanity check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "13f8c7d6-fc92-4dda-9e83-8b711c2e6d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_my_cov_aligned_short[[\"CIGS_PER_DAY\", \"PACK_YEARS\"]].tail(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1c070166-cae9-474f-8b99-a43e752a7ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOTAL missing (%):\n",
      "SDDSRVYR         12.0   66.0\n",
      "var                         \n",
      "CIGS_PER_DAY     90.1   89.2\n",
      "CVD              34.9   41.0\n",
      "DIABE             4.0    5.6\n",
      "FORMER_SMOKER    31.9   37.7\n",
      "HOQ065          100.0  100.0\n",
      "HYPERTEN         28.9   34.6\n",
      "PACK_YEARS       97.9   89.2\n",
      "RACE              0.0    0.0\n",
      "SMK              31.9   37.7\n",
      "SMK_STATUS       31.9   37.7\n",
      "bmic             29.0   15.6\n",
      "cancer           34.6   40.7\n",
      "chol_rx          29.1  100.0\n",
      "household_size    0.0  100.0\n",
      "ins               0.5    0.2\n",
      "\n",
      "STRUCTURAL missing (%):\n",
      "SDDSRVYR         12.0   66.0\n",
      "var                         \n",
      "CIGS_PER_DAY      0.0    0.0\n",
      "CVD               0.0    0.0\n",
      "DIABE             0.0    0.0\n",
      "FORMER_SMOKER     0.0    0.0\n",
      "HOQ065          100.0  100.0\n",
      "HYPERTEN          0.0    0.0\n",
      "PACK_YEARS        0.0    0.0\n",
      "RACE              0.0    0.0\n",
      "SMK               0.0    0.0\n",
      "SMK_STATUS        0.0    0.0\n",
      "bmic              0.0    0.0\n",
      "cancer            0.0    0.0\n",
      "chol_rx           0.0  100.0\n",
      "household_size    0.0  100.0\n",
      "ins               0.0    0.0\n",
      "\n",
      "NON-STRUCTURAL missing (%):\n",
      "SDDSRVYR        12.0  66.0\n",
      "var                       \n",
      "CIGS_PER_DAY    90.1  89.2\n",
      "CVD             34.9  41.0\n",
      "DIABE            4.0   5.6\n",
      "FORMER_SMOKER   31.9  37.7\n",
      "HOQ065           0.0   0.0\n",
      "HYPERTEN        28.9  34.6\n",
      "PACK_YEARS      97.9  89.2\n",
      "RACE             0.0   0.0\n",
      "SMK             31.9  37.7\n",
      "SMK_STATUS      31.9  37.7\n",
      "bmic            29.0  15.6\n",
      "cancer          34.6  40.7\n",
      "chol_rx         29.1   0.0\n",
      "household_size   0.0   0.0\n",
      "ins              0.5   0.2\n"
     ]
    }
   ],
   "source": [
    "# 1) Post-2018 audit by cycle (missing %)\n",
    "\n",
    "# ---------- Post-2018 audit: missing vs structural missing ----------\n",
    "audit_cols = [\n",
    "    \"RACE\",\"household_size\",\"bmic\",\"ins\",\"DIABE\",\"HYPERTEN\",\"chol_rx\",\n",
    "    \"CVD\",\"cancer\",\"SMK\",\"SMK_STATUS\",\"FORMER_SMOKER\",\"CIGS_PER_DAY\",\n",
    "    \"PACK_YEARS\",\"HOQ065\"\n",
    "]\n",
    "\n",
    "# Map variables -> their structural-missing flags if you maintain them\n",
    "structural_map = {\n",
    "    \"HOQ065\": \"HOQ065_structural_missing\",\n",
    "    \"household_size\": \"household_size_structural_missing\",\n",
    "    \"chol_rx\": \"chol_rx_structural_missing\",\n",
    "    \"PACK_YEARS\": \"PACK_YEARS_structural_missing\",  # only if you created it\n",
    "    \"SNAP\": \"SNAP_structural_missing\",               # only if you added SNAP later\n",
    "}\n",
    "\n",
    "# We’ll show cycles 66 & 12 only\n",
    "mask = df_my_cov_aligned_short[\"SDDSRVYR\"].isin([66.0, 12.0])\n",
    "sub  = df_my_cov_aligned_short.loc[mask, audit_cols + [\"SDDSRVYR\"]].copy()\n",
    "\n",
    "# 1) Total missing (%)\n",
    "miss_long = (\n",
    "    sub.assign(_row=1)\n",
    "       .melt(id_vars=[\"SDDSRVYR\",\"_row\"], var_name=\"var\", value_name=\"val\")\n",
    "       .assign(missing=lambda d: d[\"val\"].isna())\n",
    "       .groupby([\"SDDSRVYR\",\"var\"], as_index=False)\n",
    "       .agg(pct_missing=(\"missing\",\"mean\"))\n",
    ")\n",
    "miss_long[\"pct_missing\"] = (miss_long[\"pct_missing\"]*100).round(1)\n",
    "\n",
    "# 2) Structural missing (%) — pull from *_structural_missing flags if present\n",
    "rows = []\n",
    "for var in audit_cols:\n",
    "    flag = structural_map.get(var, None)\n",
    "    if flag and flag in df_my_cov_aligned_short.columns:\n",
    "        g = (\n",
    "            df_my_cov_aligned_short.loc[mask, [\"SDDSRVYR\", flag]]\n",
    "            .groupby(\"SDDSRVYR\")[flag].mean()  # mean(True) = share structural\n",
    "            .mul(100).round(1)\n",
    "        )\n",
    "        for cyc, val in g.items():\n",
    "            rows.append({\"SDDSRVYR\": cyc, \"var\": var, \"pct_structural\": val})\n",
    "\n",
    "struct_long = pd.DataFrame(rows)\n",
    "if struct_long.empty:\n",
    "    struct_long = miss_long[[\"SDDSRVYR\",\"var\"]].assign(pct_structural=0.0)\n",
    "\n",
    "# 3) Combine & compute non-structural missing = total - structural (clipped at 0)\n",
    "audit_all = miss_long.merge(struct_long, on=[\"SDDSRVYR\",\"var\"], how=\"left\")\n",
    "audit_all[\"pct_structural\"] = audit_all[\"pct_structural\"].fillna(0.0)\n",
    "audit_all[\"pct_nonstructural_missing\"] = (audit_all[\"pct_missing\"] - audit_all[\"pct_structural\"]).clip(lower=0).round(1)\n",
    "\n",
    "# 4) Pretty pivots\n",
    "print(\"\\nTOTAL missing (%):\")\n",
    "print(audit_all.pivot(index=\"var\", columns=\"SDDSRVYR\", values=\"pct_missing\").fillna(0).sort_index())\n",
    "\n",
    "print(\"\\nSTRUCTURAL missing (%):\")\n",
    "print(audit_all.pivot(index=\"var\", columns=\"SDDSRVYR\", values=\"pct_structural\").fillna(0).sort_index())\n",
    "\n",
    "print(\"\\nNON-STRUCTURAL missing (%):\")\n",
    "print(audit_all.pivot(index=\"var\", columns=\"SDDSRVYR\", values=\"pct_nonstructural_missing\").fillna(0).sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "67068297-b848-47c1-a0ba-73900941b940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDDSRVYR\n",
      "66.0    15560\n",
      "12.0    11933\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2) Composition: how many rows in each post-2018 cycle?\n",
    "print(df_my_cov_aligned_short.loc[df_my_cov_aligned_short[\"SDDSRVYR\"].isin([66.0, 12.0]), \"SDDSRVYR\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "42c44905-614f-498d-a6fc-667c9e7a5bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           HOQ_has\n",
      "SDDSRVYR          \n",
      "1.0       0.480482\n",
      "2.0       0.481294\n",
      "3.0       0.492096\n",
      "4.0       0.476421\n",
      "5.0       0.578579\n",
      "6.0       0.585840\n",
      "7.0       0.566216\n",
      "8.0       0.558821\n",
      "9.0       0.552101\n",
      "10.0      0.566890\n",
      "12.0      0.000000\n",
      "66.0      0.000000\n"
     ]
    }
   ],
   "source": [
    "# 3) HOQ coverage per cycle (share non-missing)\n",
    "print(\n",
    "    df_my_cov_aligned_short\n",
    "      .assign(HOQ_has = df_my_cov_aligned_short[\"HOQ065\"].notna())\n",
    "      .pivot_table(index=\"SDDSRVYR\", values=\"HOQ_has\", aggfunc=\"mean\")\n",
    "      .sort_index()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3445a766-df1b-4e31-ac3c-75b13ea96648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle 66 HOQ overlap: 0 of 15560\n"
     ]
    }
   ],
   "source": [
    "# 4) SEQN overlap check for HOQ 66 (sanity that mapping keys aligned)\n",
    "y,f = file_for(\"HOQ\", 66)\n",
    "hoq66 = fetch_xpt(y,f).set_index(\"SEQN\")\n",
    "m66 = df_my_cov_aligned_short[\"SDDSRVYR\"].eq(66.0)\n",
    "\n",
    "seq_df = set(df_my_cov_aligned_short.loc[m66, \"SEQN\"].dropna().astype(int))\n",
    "seq_hoq = set(hoq66.index.dropna().astype(int))\n",
    "print(\"Cycle 66 HOQ overlap:\", len(seq_df & seq_hoq), \"of\", len(seq_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5c2daa34-a97a-4837-9b71-ba98f8672f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle 66 SEQNs: 15560  |  in HOQ_J: 0  |  share: 0.000\n"
     ]
    }
   ],
   "source": [
    "# Overlap between your cycle-66 SEQNs and HOQ_J\n",
    "m66 = df_my_cov_aligned_short[\"SDDSRVYR\"].eq(66.0)\n",
    "seq66 = set(df_my_cov_aligned_short.loc[m66, \"SEQN\"].dropna().astype(int))\n",
    "\n",
    "hoq_j = fetch_xpt(\"2017\",\"HOQ_J\")\n",
    "seq_j = set(hoq_j[\"SEQN\"].dropna().astype(int))\n",
    "\n",
    "over = len(seq66 & seq_j)\n",
    "print(f\"Cycle 66 SEQNs: {len(seq66)}  |  in HOQ_J: {over}  |  share: {over/len(seq66):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "16f77c27-b8cc-4a18-95de-a589a402dd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66∩10 SEQN overlap: 0\n"
     ]
    }
   ],
   "source": [
    "m10 = df_my_cov_aligned_short[\"SDDSRVYR\"].eq(10.0)\n",
    "seq10 = set(df_my_cov_aligned_short.loc[m10, \"SEQN\"].dropna().astype(int))\n",
    "\n",
    "print(\"66∩10 SEQN overlap:\", len(seq66 & seq10))  # expect 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe19597-36e7-431b-9869-ae54feb868f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "335c4da2-61cd-461b-9b14-db6ae6744596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_DEMO.xpt has DMDHHSIZ? False\n",
      "DEMO_J.xpt has DMDHHSIZ? True\n",
      "P_BPQ.xpt has BPQ101D? False\n",
      "BPQ_J.xpt has BPQ101D? False\n"
     ]
    }
   ],
   "source": [
    "# 5) Specific variables that used the 66→_J fallback (optional peek)\n",
    "for mod, col in [(\"DEMO\",\"DMDHHSIZ\"), (\"BPQ\",\"BPQ101D\")]:\n",
    "    y, f = file_for(mod, 66)\n",
    "    try:\n",
    "        psrc = fetch_xpt(y, f)\n",
    "        print(f\"{f}.xpt has {col}?\", col in psrc.columns)\n",
    "    except Exception as e:\n",
    "        print(f\"{f}.xpt fetch failed: {e}\")\n",
    "    try:\n",
    "        jsrc = fetch_xpt(\"2017\", f\"{mod}_J\")\n",
    "        print(f\"{mod}_J.xpt has {col}?\", col in jsrc.columns)\n",
    "    except Exception as e:\n",
    "        print(f\"{mod}_J.xpt fetch failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f3c1aa-65e6-449e-a2ec-6df4f35815f8",
   "metadata": {},
   "source": [
    "#### check DMDHHSIZ fallabck "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "16cd3e35-cb2e-4cb6-98d9-360418e31714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEMO 66] DMDHHSIZ missing in P_DEMO.xpt, fell back to DEMO_J.xpt\n",
      "[DEMO 66] filled household_size from 2017/P_DEMO:DMDHHSIZ (n=9254)\n",
      "[BPQ 66] BPQ101D not in P_BPQ.xpt nor BPQ_J.xpt — skipped\n"
     ]
    }
   ],
   "source": [
    "df_my_cov_aligned_short = backfill_simple(\n",
    "    df_my_cov_aligned_short, \"household_size\", 66, \"DEMO\", \"DMDHHSIZ\",\n",
    "    mapper=lambda s: pd.to_numeric(s, errors=\"coerce\").astype(\"Int64\")\n",
    ")\n",
    "df_my_cov_aligned_short = backfill_simple(\n",
    "    df_my_cov_aligned_short, \"chol_rx\", 66, \"BPQ\", \"BPQ101D\",\n",
    "    mapper=lambda s: pd.to_numeric(s, errors=\"coerce\").astype(\"Int64\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e51dd94c-eec9-4073-942d-e29b3241a658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle 66 SEQNs: 15560\n",
      "[info] 2017/DEMO_K.xpt not available (404 Client Error: Not Found for url: https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/DEMO_K.xpt)\n",
      "DEMO_J has DMDHHSIZ? True\n",
      "DEMO_K has DMDHHSIZ? False\n",
      "66 ∩ (DEMO_J∪K) SEQNs: 0 of 15560\n",
      "[info] 2017/BPQ_K.xpt not available (404 Client Error: Not Found for url: https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/BPQ_K.xpt)\n",
      "BPQ_J has BPQ101D? False\n",
      "BPQ_K has BPQ101D? False\n",
      "66 ∩ (BPQ_J∪K) SEQNs: 0 of 15560\n"
     ]
    }
   ],
   "source": [
    "# --- helpers ---\n",
    "def _fetch_or_none(year: str, filebase: str):\n",
    "    try:\n",
    "        return fetch_xpt(year, filebase)\n",
    "    except Exception as e:\n",
    "        print(f\"[info] {year}/{filebase}.xpt not available ({e})\")\n",
    "        return None\n",
    "\n",
    "def _seqn_set(df):\n",
    "    if df is None or \"SEQN\" not in df.columns:\n",
    "        return set()\n",
    "    return set(pd.to_numeric(df[\"SEQN\"], errors=\"coerce\").dropna().astype(int))\n",
    "\n",
    "# Cycle-66 SEQNs from your frame\n",
    "m66   = df_my_cov_aligned_short[\"SDDSRVYR\"].eq(66.0)\n",
    "seq66 = set(df_my_cov_aligned_short.loc[m66, \"SEQN\"].dropna().astype(int))\n",
    "print(\"Cycle 66 SEQNs:\", len(seq66))\n",
    "\n",
    "# ---- DEMO: DMDHHSIZ lives in DEMO_J (K may not exist) ----\n",
    "demo_j = _fetch_or_none(\"2017\", \"DEMO_J\")\n",
    "demo_k = _fetch_or_none(\"2017\", \"DEMO_K\")  # may 404; that's fine\n",
    "\n",
    "print(\"DEMO_J has DMDHHSIZ?\", (demo_j is not None) and (\"DMDHHSIZ\" in demo_j.columns))\n",
    "print(\"DEMO_K has DMDHHSIZ?\", (demo_k is not None) and (\"DMDHHSIZ\" in getattr(demo_k, \"columns\", [])))\n",
    "\n",
    "seq_demo = _seqn_set(demo_j) | _seqn_set(demo_k)\n",
    "print(\"66 ∩ (DEMO_J∪K) SEQNs:\", len(seq66 & seq_demo), \"of\", len(seq66))\n",
    "\n",
    "# ---- BPQ: BPQ101D lives in BPQ_J (K may not exist) ----\n",
    "bpq_j = _fetch_or_none(\"2017\", \"BPQ_J\")\n",
    "bpq_k = _fetch_or_none(\"2017\", \"BPQ_K\")    # may 404; that's fine\n",
    "\n",
    "print(\"BPQ_J has BPQ101D?\", (bpq_j is not None) and (\"BPQ101D\" in bpq_j.columns))\n",
    "print(\"BPQ_K has BPQ101D?\", (bpq_k is not None) and (\"BPQ101D\" in getattr(bpq_k, \"columns\", [])))\n",
    "\n",
    "seq_bpq = _seqn_set(bpq_j) | _seqn_set(bpq_k)\n",
    "print(\"66 ∩ (BPQ_J∪K) SEQNs:\", len(seq66 & seq_bpq), \"of\", len(seq66))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0bfe66-b165-48db-8953-1d025e0072bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6c29aa8-2056-42a9-afc0-2bc86f7fc7fd",
   "metadata": {},
   "source": [
    "## check missingness after systematic fetch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "081fc8f8-d51d-479e-a2c4-bf132b874cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_my_cov_aligned_short[[\"marriage3\", \"marriage_prev\"]].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "59b8fd87-0ff9-4a1f-abd8-3f6865b2eead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vars with <20% non-missing in at least one applicable cycle:\n",
      "SDDSRVYR                     1.0    2.0    3.0    4.0    5.0    6.0    7.0    8.0    9.0   10.0   12.0  66.0\n",
      "var                                                                                                         \n",
      "SNAP_indiv_plus_singleton   15.0   14.6    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0\n",
      "household_size             100.0  100.0  100.0  100.0  100.0  100.0  100.0  100.0  100.0  100.0  100.0   0.0\n",
      "chol_rx                    100.0  100.0  100.0  100.0  100.0  100.0  100.0  100.0  100.0  100.0   70.9   0.0\n",
      "bmi                          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   71.0  84.4\n",
      "ahei_total                  81.0   81.8   75.5   30.5   31.1   32.9   30.5   29.9   28.7   29.9    0.0   0.0\n",
      "WTPH2YR                      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0             \n",
      "SNAP_src_rank               15.1   14.6    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0\n",
      "SNAP_src                    15.1   14.6    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0\n",
      "sdoh_access                 48.1   48.2   49.2   47.7   57.9   58.7   56.7   56.0   55.4   56.8   58.7   0.0\n",
      "wt_phlebotomy                0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   67.6   0.0\n",
      "SNAP_bin                    15.1   14.6   48.9   47.5   57.9   58.3   56.5   55.9   55.0   56.2    0.0  54.5\n",
      "SNAP                        15.1   14.6   48.9   47.5   57.9   58.3   56.5   55.9   55.0   56.2    0.0  54.5\n",
      "SMK_AVG                     10.0   10.6   11.0   10.4   12.9   12.7   11.2   11.6   10.6   10.7    0.0   0.0\n",
      "HOQ065                      48.0   48.1   49.2   47.6   57.9   58.6   56.6   55.9   55.2   56.7    0.0   0.0\n",
      "FS                          47.6   45.8   47.6   47.6   57.9   58.3   56.7   55.9   55.3   56.7    0.0  54.9\n",
      "DRINKS_PER_DAY              24.3   24.6   24.5   24.6   29.9   31.3   31.3   33.1   31.6    0.0    0.0   0.0\n",
      "SNAP_indiv_only             15.0   14.6    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0\n",
      "PACK_YEARS                  11.5   11.3   12.1   10.7   13.2   13.0   11.4   11.7   11.7   13.4    2.1  10.8\n",
      "probable_depression          7.2    7.4    6.8   51.5   59.1   60.4   57.6   58.2   57.5   59.8   53.1  57.6\n",
      "CIGS_PER_DAY                10.0   10.6   11.0   10.4   12.9   12.7   11.2   11.6   10.6   10.7    9.9  10.8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "THRESH = 20.0\n",
    "ID_COLS = {\"SEQN\", \"SDDSRVYR\"}\n",
    "FLAG_SUFFIX = \"_structural_missing\"\n",
    "\n",
    "# Hide cosmetic / redundant columns here\n",
    "ALWAYS_EXCLUDE = {\n",
    "    \"marriage_label\", \"marriage_prev\",\n",
    "}\n",
    "\n",
    "# ✅ Applicability map (your correction applied: 4YR weights → cycle 66)\n",
    "WEIGHT_CYCLE_MAP = {\n",
    "    # classic 2-yr weights (pre-2017 cycles)\n",
    "    \"WTINT2YR\": {1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0},\n",
    "    \"WTMEC2YR\": {1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0},\n",
    "\n",
    "    # pre-pandemic combined (2017–Mar 2020)\n",
    "    \"WTINTPRP\": {66.0},\n",
    "    \"WTMECPRP\": {66.0},\n",
    "    \"WTSAFPRP\": {66.0},\n",
    "    \"WTINT4YR\": {66.0},   # ⬅ updated\n",
    "    \"WTMEC4YR\": {66.0},   # ⬅ updated\n",
    "\n",
    "    # fasting / phlebotomy 2-yr (legacy)\n",
    "    \"WTPH2YR\":  {1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0},\n",
    "    \"WTSAF2YR\": {1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0},\n",
    "}\n",
    "\n",
    "df = df_my_cov_aligned_short.copy()\n",
    "\n",
    "def _applicable(var: str, cyc: float) -> bool:\n",
    "    if var in ALWAYS_EXCLUDE:\n",
    "        return False\n",
    "    if var in WEIGHT_CYCLE_MAP:\n",
    "        return cyc in WEIGHT_CYCLE_MAP[var]\n",
    "    return True  # default: applicable\n",
    "\n",
    "# columns to audit\n",
    "value_cols = [c for c in df.columns if c not in ID_COLS and not c.endswith(FLAG_SUFFIX)]\n",
    "\n",
    "# long form and applicability\n",
    "long = df[[\"SDDSRVYR\"] + value_cols].melt(\"SDDSRVYR\", var_name=\"var\", value_name=\"val\")\n",
    "long[\"applicable\"] = long.apply(lambda r: _applicable(r[\"var\"], r[\"SDDSRVYR\"]), axis=1)\n",
    "\n",
    "# compute non-missing% only where applicable\n",
    "app = long[long[\"applicable\"]].copy()\n",
    "summ = (app.groupby([\"SDDSRVYR\",\"var\"], as_index=False)\n",
    "          .agg(nonmissing_pct=(\"val\", lambda x: (1 - x.isna().mean())*100)))\n",
    "summ[\"nonmissing_pct\"] = summ[\"nonmissing_pct\"].round(1)\n",
    "\n",
    "# keep vars with < THRESH non-missing in any applicable cycle\n",
    "low_vars = (summ.groupby(\"var\")[\"nonmissing_pct\"].min()\n",
    "                 .reset_index().query(\"nonmissing_pct < @THRESH\")[\"var\"].tolist())\n",
    "summ_low = summ[summ[\"var\"].isin(low_vars)]\n",
    "\n",
    "# pivot; leave non-applicable blank (NaN) instead of 0\n",
    "pivot = summ_low.pivot(index=\"var\", columns=\"SDDSRVYR\", values=\"nonmissing_pct\")\n",
    "pivot[\"_min\"] = pivot.min(axis=1, skipna=True)\n",
    "pivot = pivot.sort_values(\"_min\", ascending=True).drop(columns=\"_min\")\n",
    "\n",
    "print(f\"\\nVars with <{THRESH:.0f}% non-missing in at least one applicable cycle:\")\n",
    "print(pivot.to_string(na_rep=\"\"))  # blanks for not-applicable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bc5ee4-7918-4904-9aa6-69dca06add2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4b65b464-be71-42c0-8ad8-586f7c0430d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vars with <20% non-missing in at least one applicable cycle (SNAP removed):\n",
      "SDDSRVYR          1.0    2.0    3.0    4.0    5.0    6.0    7.0    8.0    9.0   10.0   12.0  66.0\n",
      "var                                                                                              \n",
      "DRINKS_PER_DAY   24.3   24.6   24.5   24.6   29.9   31.3   31.3   33.1   31.6    0.0    0.0   0.0\n",
      "HOQ065           48.0   48.1   49.2   47.6   57.9   58.6   56.6   55.9   55.2   56.7    0.0   0.0\n",
      "ahei_total       81.0   81.8   75.5   30.5   31.1   32.9   30.5   29.9   28.7   29.9    0.0   0.0\n",
      "chol_rx         100.0  100.0  100.0  100.0  100.0  100.0  100.0  100.0  100.0  100.0   70.9   0.0\n",
      "household_size  100.0  100.0  100.0  100.0  100.0  100.0  100.0  100.0  100.0  100.0  100.0   0.0\n",
      "sdoh_access      48.1   48.2   49.2   47.7   57.9   58.7   56.7   56.0   55.4   56.8   58.7   0.0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "THRESH = 20.0\n",
    "ID_COLS = {\"SEQN\", \"SDDSRVYR\"}\n",
    "FLAG_SUFFIX = \"_structural_missing\"\n",
    "\n",
    "# Columns we always hide (labels, prev flags, etc.)\n",
    "ALWAYS_EXCLUDE = {\n",
    "    \"marriage_label\", \"marriage_prev\",\n",
    "    \"probable_depression\",\n",
    "}\n",
    "\n",
    "# If a more complete/derived sibling exists, skip the base\n",
    "DERIVED_BETTER = {\n",
    "    \"BMI\": {\"BMI_CLAS\", \"BMI_CAT\", \"bmic\", \"bmi_cat\"},\n",
    "}\n",
    "\n",
    "# ✅ Regex rules: ignore families where missingness is expected/OK\n",
    "\n",
    "IGNORE_REGEXES = [\n",
    "    r\"(^|_)SNAP(\\b|_)\",          # all SNAP\n",
    "    r\"^(FS|FSDHH)\\b\",            # food security families\n",
    "    r\"^(SMK|CIGS?|PACK)\",        # smoking families\n",
    "    r\".*_label$\",                # cosmetic\n",
    "    r\".*_prev$\",                 # lag flags\n",
    "    r\"phlebotom|phleb\",          # any phlebotomy-related names\n",
    "]\n",
    "\n",
    "IGNORE_EXACT = {\n",
    "    # SNAP variants you’ve seen\n",
    "    \"SNAP\", \"SNAP_bin\", \"SNAP_indiv_only\", \"SNAP_indiv_plus_singleton\",\n",
    "    \"SNAP_src\", \"SNAP_src_rank\",\n",
    "    # explicitly ignore these two\n",
    "    \"WTPH2YR\", \"wt_phlebotomy\",\n",
    "}\n",
    "\n",
    "\n",
    "# ✅ Applicability map (4YR weights → cycle 66)\n",
    "WEIGHT_CYCLE_MAP = {\n",
    "    \"WTINT2YR\": {1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0},\n",
    "    \"WTMEC2YR\": {1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0},\n",
    "    \"WTINTPRP\": {66.0},\n",
    "    \"WTMECPRP\": {66.0},\n",
    "    \"WTSAFPRP\": {66.0},\n",
    "    \"WTINT4YR\": {66.0},\n",
    "    \"WTMEC4YR\": {66.0},\n",
    "    \"WTPH2YR\":  {1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0},\n",
    "    \"WTSAF2YR\": {1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0},\n",
    "}\n",
    "\n",
    "def _is_ignored(col: str, cols_lower: set[str]) -> bool:\n",
    "    c0 = col\n",
    "    if c0 in ALWAYS_EXCLUDE or c0 in IGNORE_EXACT:\n",
    "        return True\n",
    "    for pat in IGNORE_REGEXES:\n",
    "        if re.search(pat, c0, flags=re.IGNORECASE):\n",
    "            return True\n",
    "    # numeric vs categorical “better” siblings\n",
    "    base = c0.upper()\n",
    "    if base in DERIVED_BETTER:\n",
    "        alts = DERIVED_BETTER[base]\n",
    "        if any(alt.lower() in cols_lower for alt in alts):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def _applicable(var: str, cyc: float) -> bool:\n",
    "    v = var.upper()\n",
    "    if var in ALWAYS_EXCLUDE or var in IGNORE_EXACT:\n",
    "        return False\n",
    "    if v in WEIGHT_CYCLE_MAP:\n",
    "        return cyc in WEIGHT_CYCLE_MAP[v]\n",
    "    return True\n",
    "\n",
    "df = df_my_cov_aligned_short.copy()\n",
    "\n",
    "# Build filtered column list\n",
    "cols_lower = {c.lower() for c in df.columns}\n",
    "value_cols = []\n",
    "for c in df.columns:\n",
    "    if c in ID_COLS or c.endswith(FLAG_SUFFIX):\n",
    "        continue\n",
    "    if _is_ignored(c, cols_lower):\n",
    "        continue\n",
    "    value_cols.append(c)\n",
    "\n",
    "# Long/applicability → summary\n",
    "long = df[[\"SDDSRVYR\"] + value_cols].melt(\"SDDSRVYR\", var_name=\"var\", value_name=\"val\")\n",
    "long[\"applicable\"] = long.apply(lambda r: _applicable(r[\"var\"], r[\"SDDSRVYR\"]), axis=1)\n",
    "\n",
    "app = long[long[\"applicable\"]].copy()\n",
    "summ = (app.groupby([\"SDDSRVYR\",\"var\"], as_index=False)\n",
    "          .agg(nonmissing_pct=(\"val\", lambda x: (1 - x.isna().mean())*100)))\n",
    "summ[\"nonmissing_pct\"] = summ[\"nonmissing_pct\"].round(1)\n",
    "\n",
    "low_vars = (summ.groupby(\"var\")[\"nonmissing_pct\"].min()\n",
    "                 .reset_index().query(\"nonmissing_pct < @THRESH\")[\"var\"].tolist())\n",
    "summ_low = summ[summ[\"var\"].isin(low_vars)]\n",
    "\n",
    "pivot = summ_low.pivot(index=\"var\", columns=\"SDDSRVYR\", values=\"nonmissing_pct\")\n",
    "pivot[\"_min\"] = pivot.min(axis=1, skipna=True)\n",
    "pivot = pivot.sort_values(\"_min\", ascending=True).drop(columns=\"_min\")\n",
    "\n",
    "print(f\"\\nVars with <{THRESH:.0f}% non-missing in at least one applicable cycle (SNAP removed):\")\n",
    "print(pivot.to_string(na_rep=\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf56335-1b8c-4ef9-9104-a5af6c23e266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f9360e6c-187c-441f-b2e9-14e00dc6c43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SEQN', 'SDDSRVYR', 'sdmvpsu', 'sdmvstra', 'RIDAGEYR', 'SEX', 'RACE',\n",
       "       'household_size', 'EDU', 'pir', 'SMK_AVG', 'SMK', 'ALCG2', 'met_hr',\n",
       "       'SMK_STATUS', 'CIGS_PER_DAY', 'PACK_YEARS', 'FORMER_SMOKER',\n",
       "       'DRINKS_PER_DAY', 'ALCOHOL_CAT', 'bmi_cat', 'DIABE', 'HYPERTEN',\n",
       "       'chol_rx', 'CVD', 'cancer', 'probable_depression', 'ahei_total',\n",
       "       'unemployment2', 'sdoh_access', 'ins', 'HOQ065', 'marriage', 'SNAP',\n",
       "       'FS', 'WTINT2YR', 'WTMEC2YR', 'WTSAF2YR', 'WTINT4YR', 'WTMEC4YR',\n",
       "       'WTINTPRP', 'WTMECPRP', 'WTSAFPRP', 'wt_int', 'wt_mec', 'wt_fasting',\n",
       "       'wt_phlebotomy', 'WTPH2YR', 'marriage_prev', 'marriage_label',\n",
       "       'marriage3', 'SNAP_src', 'SNAP_bin', 'SNAP_src_rank', 'SNAP_indiv_only',\n",
       "       'SNAP_indiv_plus_singleton', 'bmi', 'HOQ065_structural_missing',\n",
       "       'household_size_structural_missing', 'chol_rx_structural_missing'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_my_cov_aligned_short.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ba39e3dc-a019-4f31-99af-0e6f136a7fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128709    0\n",
       "128710    0\n",
       "128711    0\n",
       "128712    0\n",
       "128713    1\n",
       "         ..\n",
       "128804    0\n",
       "128805    1\n",
       "128806    0\n",
       "128807    0\n",
       "128808    0\n",
       "Name: DIABE, Length: 100, dtype: Int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_my_cov_aligned_short[\"DIABE\"].tail(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d8024d-23a3-44f4-b758-7358ce912810",
   "metadata": {},
   "source": [
    "## save, pre 2018 complete, post 2018 almost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e5ba35e1-5afc-41d6-ac60-7669076418ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved: /Users/dengshuyue/Desktop/SDOH/analysis/output/cov_addv2_99_23.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "OUT = Path(\"/Users/dengshuyue/Desktop/SDOH/analysis/output\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df = df_my_cov_aligned_short.copy()\n",
    "for c in df.select_dtypes(include=\"object\"):\n",
    "    df[c] = df[c].apply(lambda x: x.decode(\"utf-8\",\"ignore\") if isinstance(x,(bytes,bytearray)) else x).astype(\"string\")\n",
    "\n",
    "handoff = OUT / \"cov_addv2_99_23.parquet\"\n",
    "df.to_parquet(handoff, index=False)\n",
    "print(\"✓ Saved:\", handoff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8729a535-61f2-49ff-834f-afa45c3695ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
