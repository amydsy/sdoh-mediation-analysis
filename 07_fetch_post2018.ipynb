{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d3f2050-e263-48c8-ace0-48b75e929269",
   "metadata": {},
   "source": [
    "## set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3e39b36e-3c61-4228-8725-98d36a4373c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mine: (128809, 82) | lu: (101316, 75)\n",
      "Loaded: /Users/dengshuyue/Desktop/SDOH/analysis/output/demo_mt_cov_dp_sdoh.parquet\n",
      "Loaded: /Users/dengshuyue/Desktop/SDOH/analysis/data/cov/nhanes_primary_anal_full_singleimputation_v2.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = Path(\"/Users/dengshuyue/Desktop/SDOH/analysis\")\n",
    "OUT  = ROOT / \"output\"\n",
    "\n",
    "MY_PATH = OUT / \"demo_mt_cov_dp_sdoh.parquet\"\n",
    "LU_PATH = ROOT / \"data/cov/nhanes_primary_anal_full_singleimputation_v2.csv\"\n",
    "\n",
    "df_my_cov_1999_2023 = pd.read_parquet(MY_PATH)\n",
    "df_lu_cov_1999_2018 = pd.read_csv(LU_PATH)\n",
    "\n",
    "print(\"mine:\", df_my_cov_1999_2023.shape, \"| lu:\", df_lu_cov_1999_2018.shape)\n",
    "print(\"Loaded:\", MY_PATH)\n",
    "print(\"Loaded:\", LU_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f801de9a-af35-467e-b2c5-b964fe5ce35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>SDMVPSU</th>\n",
       "      <th>SDMVSTRA</th>\n",
       "      <th>WTMEC2YR</th>\n",
       "      <th>AGE_YR</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>SEX</th>\n",
       "      <th>FEMALE</th>\n",
       "      <th>SMK_STATUS</th>\n",
       "      <th>...</th>\n",
       "      <th>FS_HH</th>\n",
       "      <th>FS_ADULT</th>\n",
       "      <th>FS_FINAL</th>\n",
       "      <th>HHFDSEC</th>\n",
       "      <th>ADFDSEC</th>\n",
       "      <th>FS_HH4</th>\n",
       "      <th>FS_ADULT4</th>\n",
       "      <th>FS_SOURCE_HH</th>\n",
       "      <th>FS_SOURCE_FINAL</th>\n",
       "      <th>SNAP_SOURCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10982.898896</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28325.384898</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>NEVER</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>HHFDSEC</td>\n",
       "      <td>household</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>46192.256945</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10251.260020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>99445.065735</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>FORMER</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>HHFDSEC</td>\n",
       "      <td>household</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39656.600444</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25525.423409</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>FORMER</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>31510.587866</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7575.870247</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22445.808572</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>CURRENT</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEQN  SDDSRVYR  SDMVPSU  SDMVSTRA      WTMEC2YR  AGE_YR  RIAGENDR SEX  \\\n",
       "0     1       1.0      1.0       5.0  10982.898896     2.0         2   F   \n",
       "1     2       1.0      3.0       1.0  28325.384898    77.0         1   M   \n",
       "2     3       1.0      2.0       7.0  46192.256945    10.0         2   F   \n",
       "3     4       1.0      1.0       2.0  10251.260020     1.0         1   M   \n",
       "4     5       1.0      2.0       8.0  99445.065735    49.0         1   M   \n",
       "5     6       1.0      2.0       2.0  39656.600444    19.0         2   F   \n",
       "6     7       1.0      2.0       4.0  25525.423409    59.0         2   F   \n",
       "7     8       1.0      1.0       6.0  31510.587866    13.0         1   M   \n",
       "8     9       1.0      2.0       9.0   7575.870247    11.0         2   F   \n",
       "9    10       1.0      1.0       7.0  22445.808572    43.0         1   M   \n",
       "\n",
       "   FEMALE SMK_STATUS  ...  FS_HH  FS_ADULT  FS_FINAL  HHFDSEC ADFDSEC  FS_HH4  \\\n",
       "0       1        NaN  ...   <NA>      <NA>      <NA>     <NA>    <NA>    <NA>   \n",
       "1       0      NEVER  ...      0         0         0        1       1       1   \n",
       "2       1        NaN  ...   <NA>      <NA>      <NA>     <NA>    <NA>    <NA>   \n",
       "3       0        NaN  ...   <NA>      <NA>      <NA>     <NA>    <NA>    <NA>   \n",
       "4       0     FORMER  ...      0         0         0        1       1       1   \n",
       "5       1        NaN  ...   <NA>      <NA>      <NA>     <NA>    <NA>    <NA>   \n",
       "6       1     FORMER  ...   <NA>      <NA>      <NA>     <NA>    <NA>    <NA>   \n",
       "7       0        NaN  ...   <NA>      <NA>      <NA>     <NA>    <NA>    <NA>   \n",
       "8       1        NaN  ...   <NA>      <NA>      <NA>     <NA>    <NA>    <NA>   \n",
       "9       0    CURRENT  ...   <NA>      <NA>      <NA>     <NA>    <NA>    <NA>   \n",
       "\n",
       "   FS_ADULT4  FS_SOURCE_HH  FS_SOURCE_FINAL  SNAP_SOURCE  \n",
       "0       <NA>          <NA>             <NA>         <NA>  \n",
       "1          1       HHFDSEC        household         <NA>  \n",
       "2       <NA>          <NA>             <NA>         <NA>  \n",
       "3       <NA>          <NA>             <NA>         <NA>  \n",
       "4          1       HHFDSEC        household         <NA>  \n",
       "5       <NA>          <NA>             <NA>         <NA>  \n",
       "6       <NA>          <NA>             <NA>         <NA>  \n",
       "7       <NA>          <NA>             <NA>         <NA>  \n",
       "8       <NA>          <NA>             <NA>         <NA>  \n",
       "9       <NA>          <NA>             <NA>         <NA>  \n",
       "\n",
       "[10 rows x 82 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_my_cov_1999_2023.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f9e039-fde5-4a1e-9282-a4937ea3fc0e",
   "metadata": {},
   "source": [
    "#### Helpers (used later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f735d0c5-a7c0-482f-abfd-3375b3cec0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) HELPERS (robust + imports np)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _norm_str_col(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Lowercase + strip + turn 'nan' into actual NaN.\"\"\"\n",
    "    s = series.astype(str).str.strip().str.lower()\n",
    "    return s.replace({\"nan\": np.nan})\n",
    "\n",
    "def _num_summary(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"Lightweight numeric summary for a set of columns.\"\"\"\n",
    "    rows = []\n",
    "    for c in cols:\n",
    "        s = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "        rows.append({\n",
    "            \"column\": c,\n",
    "            \"n\": len(s),\n",
    "            \"na_rate\": float(s.isna().mean()),\n",
    "            \"min\": np.nanmin(s.values),\n",
    "            \"p25\": np.nanpercentile(s.values, 25),\n",
    "            \"median\": np.nanmedian(s.values),\n",
    "            \"p75\": np.nanpercentile(s.values, 75),\n",
    "            \"max\": np.nanmax(s.values),\n",
    "            \"mean\": np.nanmean(s.values),\n",
    "            \"std\": np.nanstd(s.values),\n",
    "            \"unique_non_na\": int(s.nunique(dropna=True)),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def _binary_sig(series: pd.Series) -> str | None:\n",
    "    \"\"\"Detect common binary encodings.\"\"\"\n",
    "    vals = set(_norm_str_col(series).dropna().unique())\n",
    "    if vals <= {\"0\",\"1\"}: return \"0/1\"\n",
    "    if vals <= {\"yes\",\"no\"}: return \"yes/no\"\n",
    "    if vals <= {\"true\",\"false\"}: return \"true/false\"\n",
    "    if vals <= {\"male\",\"female\"}: return \"male/female\"\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c72ac48-4459-436b-8b33-47a79e540bdb",
   "metadata": {},
   "source": [
    "#### Column set differences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "bbaacf23-26c4-4d58-85ee-ecc295b2bd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Columns] only_in_lu: 69 | only_in_my: 76 | in_both: 6\n",
      "• only_in_lu (first 20): ['MetS', 'MetS_bp', 'MetS_count', 'MetS_fpg', 'MetS_hdl', 'MetS_triglycerides', 'MetS_wc', 'WTINT2YR', 'WTSAF2YR', 'X', 'adiposity_pri', 'adiposity_sec', 'age', 'age_cat', 'angina', 'angina_rx', 'asthma', 'bmi', 'bp_pri', 'bp_sec']\n",
      "• only_in_my (first 20): ['ADFDSEC', 'AGE_YR', 'ALCOHOL_CAT', 'BMI', 'BMI_CLAS', 'BMXHT', 'BMXWT', 'CANCER', 'CENSORED', 'CIDI_12M_MDE', 'CIDI_SCORE_RAW', 'CIGS_PER_DAY', 'DBP', 'DEP_HARMONIZED', 'DEP_IMP', 'DEP_SOURCE', 'DIABETES', 'DMDHHSIZ', 'DPQ_CAT', 'DRINKS_PER_DAY']\n"
     ]
    }
   ],
   "source": [
    "# 2) COLUMN SET DIFFERENCES (a)\n",
    "\n",
    "cols_my = set(df_my_cov_1999_2023.columns)\n",
    "cols_lu = set(df_lu_cov_1999_2018.columns)\n",
    "\n",
    "audit_only_in_lu = sorted(cols_lu - cols_my)\n",
    "audit_only_in_my = sorted(cols_my - cols_lu)\n",
    "audit_in_both    = sorted(cols_my & cols_lu)\n",
    "\n",
    "print(f\"[Columns] only_in_lu: {len(audit_only_in_lu)} | only_in_my: {len(audit_only_in_my)} | in_both: {len(audit_in_both)}\")\n",
    "print(\"• only_in_lu (first 20):\", audit_only_in_lu[:20])\n",
    "print(\"• only_in_my (first 20):\", audit_only_in_my[:20])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "67beccc1-932f-43f6-a166-1ed8867afbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 columns\n",
      "['SEQN', 'SDDSRVYR', 'SDMVPSU', 'SDMVSTRA', 'WTMEC2YR', 'AGE_YR', 'RIAGENDR', 'SEX', 'FEMALE', 'SMK_STATUS', 'CIGS_PER_DAY', 'PACK_YEARS', 'FORMER_SMOKER', 'DRINKS_PER_DAY', 'ALCOHOL_CAT', 'LTPA', 'METSCORE', 'IMP', 'BMXWT', 'BMXHT', 'BMI', 'BMI_CLAS', 'DIABETES', 'HTN', 'HIGH_CHOL', 'CVD', 'CANCER', 'SBP', 'DBP', 'TCHOL', 'HDL', 'LDL', 'TG', 'DMDHHSIZ', 'ELIGSTAT', 'MORTSTAT', 'PERMTH_EXM', 'PERMTH_INT', 'UCOD_LEADING', 'IS_POST2018', 'IS_ADULT', 'MORTALITY_COVERED', 'EVENT', 'CENSORED', 'FU_YRS_EXM', 'FU_YRS_INT', 'UCOD_LABEL', 'PHQ9', 'PHQ9_GE10', 'DPQ_CAT', 'DEP_IMP', 'CIDI_SCORE_RAW', 'CIDI_12M_MDE', 'WTSCI2YR', 'DEP_HARMONIZED', 'DEP_SOURCE', 'PIR', 'PIR_CAT', 'INDFMINC', 'EDU', 'EDU_CAT', 'RACE_ETH', 'MARITAL', 'MARITAL_CAT', 'EMPLOY', 'UNEMPLOYMENT', 'HOD050', 'HOQ065', 'INS', 'SNAP', 'FSDHH', 'FS', 'FS_HH', 'FS_ADULT', 'FS_FINAL', 'HHFDSEC', 'ADFDSEC', 'FS_HH4', 'FS_ADULT4', 'FS_SOURCE_HH', 'FS_SOURCE_FINAL', 'SNAP_SOURCE']\n",
      "75 columns\n",
      "['X', 'SEQN', 'SDDSRVYR', 'WTINT2YR', 'WTMEC2YR', 'WTSAF2YR', 'SDMVPSU', 'SDMVSTRA', 'age', 'sex', 're', 'edu', 'pir', 'tchol', 'hdl', 'ldl', 'tg', 'wc', 'bmi', 'dm_self', 'hba1c', 'fpg', 'chf', 'chd', 'mi', 'stroke', 'cancer', 'emphysema', 'bronchitis', 'asthma', 're2', 'copd', 'sbp', 'dbp', 'dm_rx', 'chol_rx', 'angina_rx', 'htn_rx', 'roseQ', 'no_na', 'age_cat', 'pir_cat', 'edu2', 'CVD', 'lung_disease', 'diabetes', 'tchol_hdl', 'angina', 'lipid_pri', 'adiposity_pri', 'bp_pri', 'glucose_pri', 'cvd_pri', 'lipid_sec', 'adiposity_sec', 'bp_sec', 'glucose_sec', 'cvd_sec', 'optimal_pri_count', 'intermediate_pri_count', 'poor_pri_count', 'optimal_sec_count', 'intermediate_sec_count', 'poor_sec_count', 'optimal_all', 'poor_all', 'optimal_all_sec', 'poor_all_sec', 'MetS_hdl', 'MetS_triglycerides', 'MetS_bp', 'MetS_wc', 'MetS_fpg', 'MetS_count', 'MetS']\n"
     ]
    }
   ],
   "source": [
    "# mine\n",
    "print(len(df_my_cov_1999_2023.columns), \"columns\")\n",
    "print(df_my_cov_1999_2023.columns.tolist())\n",
    "\n",
    "# lu\n",
    "print(len(df_lu_cov_1999_2018.columns), \"columns\")\n",
    "print(df_lu_cov_1999_2018.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34575e49-2360-4d48-912e-0fea2df49d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "7bfad80d-91ca-4d43-9bf0-5bc1efc110d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %whos DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "678b5491-1541-4e55-a8c0-7f25b7788af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_my_cov_1999_2023[['MORTALITY_COVERED', 'EVENT', \"UCOD_LABEL\", \"CANCER\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe75417-424d-40b0-843a-61fdb05e689b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e31c2cc-a3de-4aa4-b520-32a3ef182a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a4a1f-76d6-46fc-b9af-ab27acadd403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b9d2ee-8cb1-4bca-8041-28b411616d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dbeec05-2a00-401b-bf34-a9962ef84005",
   "metadata": {},
   "source": [
    "## Align column same as lu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8363147b-a244-46dc-ae0d-74f24846e2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed 15 columns automatically.\n",
      "Examples: [('AGE_YR', 'age'), ('BMI', 'bmi'), ('CANCER', 'cancer'), ('DBP', 'dbp'), ('DIABETES', 'diabetes'), ('EDU', 'edu'), ('HDL', 'hdl'), ('LDL', 'ldl'), ('PIR', 'pir'), ('PIR_CAT', 'pir_cat')]\n",
      "Still missing from your data (present in Lu): ['X', 'WTINT2YR', 'WTSAF2YR', 'wc', 'dm_self', 'hba1c', 'fpg', 'chf', 'chd', 'mi', 'stroke', 'emphysema', 'bronchitis', 'asthma', 're2', 'copd', 'dm_rx', 'chol_rx', 'angina_rx', 'htn_rx', 'roseQ', 'no_na', 'age_cat', 'edu2', 'lung_disease', 'tchol_hdl', 'angina', 'lipid_pri', 'adiposity_pri', 'bp_pri', 'glucose_pri', 'cvd_pri', 'lipid_sec', 'adiposity_sec', 'bp_sec', 'glucose_sec', 'cvd_sec', 'optimal_pri_count', 'intermediate_pri_count', 'poor_pri_count', 'optimal_sec_count', 'intermediate_sec_count', 'poor_sec_count', 'optimal_all', 'poor_all', 'optimal_all_sec', 'poor_all_sec', 'MetS_hdl', 'MetS_triglycerides', 'MetS_bp', 'MetS_wc', 'MetS_fpg', 'MetS_count', 'MetS']\n",
      "Final order starts with: ['SEQN', 'SDDSRVYR', 'WTMEC2YR', 'SDMVPSU', 'SDMVSTRA', 'age', 'sex', 're', 'edu', 'pir', 'tchol', 'hdl', 'ldl', 'tg', 'bmi']\n"
     ]
    }
   ],
   "source": [
    "import re, difflib\n",
    "import pandas as pd\n",
    "\n",
    "# === Inputs (your two originals) ===\n",
    "mine = df_my_cov_1999_2023.copy()\n",
    "lu   = df_lu_cov_1999_2018.copy()\n",
    "\n",
    "lu_cols = list(lu.columns)\n",
    "mine_cols = list(mine.columns)\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def norm(s: str) -> str:\n",
    "    # Lower, drop non-alnum (so AGE_YR -> ageyr; RACE_ETH -> raceeth)\n",
    "    return re.sub(r'[^0-9a-z]+', '', s.lower()) if isinstance(s, str) else s\n",
    "\n",
    "lu_norm_to_name = {}\n",
    "for c in lu_cols:\n",
    "    lu_norm_to_name.setdefault(norm(c), c)  # keep first occurrence\n",
    "\n",
    "# Minimal synonyms (expand as needed if you see mismatches)\n",
    "# YOUR column name -> Lu column name\n",
    "synonyms = {\n",
    "    'AGE_YR':'age',\n",
    "    'SEX':'sex',\n",
    "    'RACE_ETH':'re',\n",
    "    'EDU':'edu',\n",
    "    'PIR':'pir',\n",
    "    'TCHOL':'tchol',\n",
    "    'HDL':'hdl',\n",
    "    'LDL':'ldl',\n",
    "    'TG':'tg',\n",
    "    'WC':'wc',\n",
    "    'BMI':'bmi',\n",
    "    'SBP':'sbp',\n",
    "    'DBP':'dbp',\n",
    "    'DIABETES':'diabetes',\n",
    "    'CVD':'CVD',          # Lu uses uppercase \"CVD\" in your list\n",
    "    'CANCER':'cancer',\n",
    "    'DM_RX':'dm_rx',\n",
    "    'CHOL_RX':'chol_rx',\n",
    "    'HTN_RX':'htn_rx',\n",
    "    'ANGINA_RX':'angina_rx',\n",
    "    'ANGINA':'angina',\n",
    "    'AGE_CAT':'age_cat',\n",
    "    'PIR_CAT':'pir_cat',\n",
    "    'EDU2':'edu2',\n",
    "    'METS_HDL':'MetS_hdl',\n",
    "    'METS_TRIGLYCERIDES':'MetS_triglycerides',\n",
    "    'METS_BP':'MetS_bp',\n",
    "    'METS_WC':'MetS_wc',\n",
    "    'METS_FPG':'MetS_fpg',\n",
    "    'METS_COUNT':'MetS_count',\n",
    "    'ROSEQ':'roseQ',\n",
    "    'NO_NA':'no_na',\n",
    "    'LUNG_DISEASE':'lung_disease',\n",
    "    'BP_PRI':'bp_pri',\n",
    "    'GLUCOSE_PRI':'glucose_pri',\n",
    "    'LIPID_PRI':'lipid_pri',\n",
    "    'ADIPOSITY_PRI':'adiposity_pri',\n",
    "    'CVD_PRI':'cvd_pri',\n",
    "    'BP_SEC':'bp_sec',\n",
    "    'GLUCOSE_SEC':'glucose_sec',\n",
    "    'LIPID_SEC':'lipid_sec',\n",
    "    'ADIPOSITY_SEC':'adiposity_sec',\n",
    "    'CVD_SEC':'cvd_sec',\n",
    "    # Common admin/weight vars:\n",
    "    'WTMEC2YR':'WTMEC2YR',\n",
    "    'SDDSRVYR':'SDDSRVYR',\n",
    "    'SDMVPSU':'SDMVPSU',\n",
    "    'SDMVSTRA':'SDMVSTRA',\n",
    "}\n",
    "\n",
    "# Columns we should **never** rename (IDs/keys that already match)\n",
    "protect_exact = set(['SEQN','SDDSRVYR','SDMVPSU','SDMVSTRA','WTMEC2YR'])\n",
    "\n",
    "# ---------- Build mapping (your -> lu) ----------\n",
    "mapping = {}          # final mapping to apply\n",
    "used_targets = set()  # to avoid collisions (two src -> one dst)\n",
    "\n",
    "for src in mine_cols:\n",
    "    if src in protect_exact or src.endswith('_lu'):\n",
    "        continue\n",
    "\n",
    "    # 1) If exact Lu name already, keep as-is\n",
    "    if src in lu_cols:\n",
    "        continue\n",
    "\n",
    "    # 2) Synonym override\n",
    "    if src in synonyms and synonyms[src] in lu_cols and synonyms[src] not in used_targets and synonyms[src] not in mine_cols:\n",
    "        mapping[src] = synonyms[src]\n",
    "        used_targets.add(synonyms[src])\n",
    "        continue\n",
    "\n",
    "    # 3) Case-insensitive exact\n",
    "    ci = next((dst for dst in lu_cols if isinstance(dst, str) and dst.lower() == src.lower()), None)\n",
    "    if ci and ci not in used_targets and ci not in mine_cols:\n",
    "        mapping[src] = ci\n",
    "        used_targets.add(ci)\n",
    "        continue\n",
    "\n",
    "    # 4) Normalized name match\n",
    "    nsrc = norm(src)\n",
    "    if nsrc in lu_norm_to_name:\n",
    "        dst = lu_norm_to_name[nsrc]\n",
    "        if dst not in used_targets and dst not in mine_cols:\n",
    "            mapping[src] = dst\n",
    "            used_targets.add(dst)\n",
    "            continue\n",
    "\n",
    "    # 5) Fuzzy match for stragglers (safe threshold)\n",
    "    # Only attempt for alphas; ignore obviously different admin columns you don't want changed\n",
    "    candidates = difflib.get_close_matches(src, lu_cols, n=1, cutoff=0.92)\n",
    "    if candidates:\n",
    "        dst = candidates[0]\n",
    "        if dst not in used_targets and dst not in mine_cols:\n",
    "            mapping[src] = dst\n",
    "            used_targets.add(dst)\n",
    "            continue\n",
    "\n",
    "# ---------- Apply rename ----------\n",
    "mine_renamed = mine.rename(columns=mapping).copy()\n",
    "\n",
    "# ---------- Reorder to Lu’s order (extras at end; keep *_lu at very end) ----------\n",
    "ordered = [c for c in lu_cols if c in mine_renamed.columns]\n",
    "extras  = [c for c in mine_renamed.columns if c not in ordered and not c.endswith('_lu')]\n",
    "audit   = [c for c in mine_renamed.columns if c.endswith('_lu')]\n",
    "\n",
    "df_my_cov_aligned = mine_renamed[ordered + extras + audit].copy()\n",
    "\n",
    "# ---------- Report ----------\n",
    "renamed_pairs = sorted(mapping.items(), key=lambda x: x[0].lower())\n",
    "missing_in_mine = [c for c in lu_cols if c not in df_my_cov_aligned.columns]\n",
    "\n",
    "print(f\"Renamed {len(renamed_pairs)} columns automatically.\")\n",
    "print(\"Examples:\", renamed_pairs[:10])\n",
    "print(\"Still missing from your data (present in Lu):\", missing_in_mine)\n",
    "print(\"Final order starts with:\", df_my_cov_aligned.columns[:15].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e97df4b-008b-4040-bd01-36bde77cd0a9",
   "metadata": {},
   "source": [
    "#### Adding missing column merge from lu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a1a71025-28dc-4f8d-a728-5d304affe7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-renamed 15 columns to Lu names.\n",
      "Filled from Lu (newly added): ['X', 'WTINT2YR', 'WTSAF2YR', 'wc', 'dm_self', 'hba1c', 'fpg', 'chf', 'chd', 'mi', 'stroke', 'emphysema', 'bronchitis', 'asthma', 're2', 'copd', 'dm_rx', 'chol_rx', 'angina_rx', 'htn_rx'] ...\n",
      "Still missing Lu cols: []\n",
      "Final starts with: ['X', 'SEQN', 'SDDSRVYR', 'WTINT2YR', 'WTMEC2YR', 'WTSAF2YR', 'SDMVPSU', 'SDMVSTRA', 'age', 'sex', 're', 'edu', 'pir', 'tchol', 'hdl']\n"
     ]
    }
   ],
   "source": [
    "import re, pandas as pd\n",
    "\n",
    "# === 0) Start from the two originals ===\n",
    "mine = df_my_cov_1999_2023.copy()\n",
    "lu   = df_lu_cov_1999_2018.copy()\n",
    "\n",
    "# === 1) Auto-rename YOUR columns to Lu's names (case/underscore-insensitive + synonyms) ===\n",
    "def norm(s: str) -> str:\n",
    "    return re.sub(r'[^0-9a-z]+', '', s.lower()) if isinstance(s, str) else s\n",
    "\n",
    "lu_cols = list(lu.columns)\n",
    "mine_cols = list(mine.columns)\n",
    "\n",
    "# First pass: normalized name index for Lu\n",
    "lu_norm_to_name = {}\n",
    "for c in lu_cols:\n",
    "    lu_norm_to_name.setdefault(norm(c), c)\n",
    "\n",
    "# Synonyms (YOUR -> Lu)\n",
    "synonyms = {\n",
    "    'AGE_YR':'age','SEX':'sex','RACE_ETH':'re','EDU':'edu','PIR':'pir',\n",
    "    'TCHOL':'tchol','HDL':'hdl','LDL':'ldl','TG':'tg',\n",
    "    'WC':'wc','BMI':'bmi','SBP':'sbp','DBP':'dbp',\n",
    "    'DIABETES':'diabetes','CVD':'CVD','CANCER':'cancer',\n",
    "    'DM_RX':'dm_rx','CHOL_RX':'chol_rx','HTN_RX':'htn_rx','ANGINA_RX':'angina_rx','ANGINA':'angina',\n",
    "    'AGE_CAT':'age_cat','PIR_CAT':'pir_cat','EDU2':'edu2',\n",
    "    'METS_HDL':'MetS_hdl','METS_TRIGLYCERIDES':'MetS_triglycerides','METS_BP':'MetS_bp',\n",
    "    'METS_WC':'MetS_wc','METS_FPG':'MetS_fpg','METS_COUNT':'MetS_count',\n",
    "    'ROSEQ':'roseQ','NO_NA':'no_na','LUNG_DISEASE':'lung_disease',\n",
    "    'BP_PRI':'bp_pri','GLUCOSE_PRI':'glucose_pri','LIPID_PRI':'lipid_pri','ADIPOSITY_PRI':'adiposity_pri',\n",
    "    'CVD_PRI':'cvd_pri','BP_SEC':'bp_sec','GLUCOSE_SEC':'glucose_sec','LIPID_SEC':'lipid_sec',\n",
    "    'ADIPOSITY_SEC':'adiposity_sec','CVD_SEC':'cvd_sec',\n",
    "    # admin/weights that already match:\n",
    "    'WTMEC2YR':'WTMEC2YR','SDDSRVYR':'SDDSRVYR','SDMVPSU':'SDMVPSU','SDMVSTRA':'SDMVSTRA'\n",
    "}\n",
    "\n",
    "protect_exact = {'SEQN','SDDSRVYR','SDMVPSU','SDMVSTRA','WTMEC2YR'}\n",
    "\n",
    "mapping = {}\n",
    "used_targets = set()\n",
    "for src in mine_cols:\n",
    "    if src in protect_exact or src.endswith('_lu'):\n",
    "        continue\n",
    "    if src in lu_cols:\n",
    "        continue\n",
    "    # synonyms first\n",
    "    if src in synonyms and synonyms[src] in lu_cols and synonyms[src] not in used_targets and synonyms[src] not in mine.columns:\n",
    "        mapping[src] = synonyms[src]; used_targets.add(synonyms[src]); continue\n",
    "    # case-insensitive exact\n",
    "    ci = next((dst for dst in lu_cols if isinstance(dst, str) and dst.lower()==src.lower()), None)\n",
    "    if ci and ci not in used_targets and ci not in mine.columns:\n",
    "        mapping[src] = ci; used_targets.add(ci); continue\n",
    "    # normalized match\n",
    "    nc = norm(src)\n",
    "    if nc in lu_norm_to_name:\n",
    "        dst = lu_norm_to_name[nc]\n",
    "        if dst not in used_targets and dst not in mine.columns:\n",
    "            mapping[src] = dst; used_targets.add(dst); continue\n",
    "\n",
    "mine = mine.rename(columns=mapping)\n",
    "\n",
    "# === 2) Identify Lu columns you still lack, and merge ONLY those in ===\n",
    "missing = [c for c in lu_cols if c not in mine.columns]\n",
    "# keys must exist in both:\n",
    "for k in ['SEQN','SDDSRVYR']:\n",
    "    if k not in mine.columns or k not in lu.columns:\n",
    "        raise KeyError(f\"Key {k} missing in one of the frames\")\n",
    "\n",
    "# subset Lu to keys + missing, drop dup keys, then merge\n",
    "lu_sub = lu[['SEQN','SDDSRVYR'] + missing].copy()\n",
    "dup_ct = lu_sub.duplicated(['SEQN','SDDSRVYR']).sum()\n",
    "if dup_ct:\n",
    "    print(f\"[warn] Dropping {dup_ct} duplicate rows on keys in Lu subset\")\n",
    "    lu_sub = lu_sub.drop_duplicates(['SEQN','SDDSRVYR'], keep='first')\n",
    "\n",
    "# Merge (no suffix needed—these cols are missing in 'mine')\n",
    "aligned = mine.merge(lu_sub, on=['SEQN','SDDSRVYR'], how='left')\n",
    "\n",
    "# === 3) Reorder to Lu order first, then any extras ===\n",
    "order = [c for c in lu_cols if c in aligned.columns]\n",
    "extras = [c for c in aligned.columns if c not in order]\n",
    "df_my_cov_aligned = aligned[order + extras].copy()\n",
    "\n",
    "# === 4) Quick report\n",
    "print(f\"Auto-renamed {len(mapping)} columns to Lu names.\")\n",
    "print(\"Filled from Lu (newly added):\", missing[:20], \"...\" if len(missing)>20 else \"\")\n",
    "still_missing = [c for c in lu_cols if c not in df_my_cov_aligned.columns]  # should be empty\n",
    "print(\"Still missing Lu cols:\", still_missing)\n",
    "print(\"Final starts with:\", df_my_cov_aligned.columns[:15].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a387281-7882-4c51-ba81-c3900f687368",
   "metadata": {},
   "source": [
    "#### clean and check merged file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "08296f13-4ec7-45fd-b717-6b71de8c01f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X' in df_my_cov_aligned.columns:\n",
    "    df_my_cov_aligned = df_my_cov_aligned.drop(columns=['X'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "d3eef66a-68ac-49ee-9d7e-a540b2df4565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# binary flags\n",
    "bin_cols = ['dm_self','chf','chd','mi','stroke','emphysema','bronchitis','asthma',\n",
    "            'copd','dm_rx','chol_rx','angina_rx','htn_rx','angina']\n",
    "for c in df_my_cov_aligned.columns.intersection(bin_cols):\n",
    "    df_my_cov_aligned[c] = pd.to_numeric(df_my_cov_aligned[c], errors='coerce').astype('Int8')\n",
    "\n",
    "# labs/metrics\n",
    "num_cols = ['wc','hba1c','fpg','tchol_hdl','MetS_hdl','MetS_triglycerides',\n",
    "            'MetS_bp','MetS_wc','MetS_fpg','MetS_count']\n",
    "for c in df_my_cov_aligned.columns.intersection(num_cols):\n",
    "    df_my_cov_aligned[c] = pd.to_numeric(df_my_cov_aligned[c], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "7dd60df9-88e2-4fc9-850d-e2123eb130db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>WTINT2YR</th>\n",
       "      <th>WTMEC2YR</th>\n",
       "      <th>WTSAF2YR</th>\n",
       "      <th>SDMVPSU</th>\n",
       "      <th>SDMVSTRA</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>re</th>\n",
       "      <th>...</th>\n",
       "      <th>FS_HH</th>\n",
       "      <th>FS_ADULT</th>\n",
       "      <th>FS_FINAL</th>\n",
       "      <th>HHFDSEC</th>\n",
       "      <th>ADFDSEC</th>\n",
       "      <th>FS_HH4</th>\n",
       "      <th>FS_ADULT4</th>\n",
       "      <th>FS_SOURCE_HH</th>\n",
       "      <th>FS_SOURCE_FINAL</th>\n",
       "      <th>SNAP_SOURCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9727.078709</td>\n",
       "      <td>10982.898896</td>\n",
       "      <td>75131.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26678.636376</td>\n",
       "      <td>28325.384898</td>\n",
       "      <td>60586.147294</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>HHFDSEC</td>\n",
       "      <td>household</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43621.680548</td>\n",
       "      <td>46192.256945</td>\n",
       "      <td>121969.841152</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10346.119327</td>\n",
       "      <td>10251.260020</td>\n",
       "      <td>4624.687273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91050.846620</td>\n",
       "      <td>99445.065735</td>\n",
       "      <td>234895.205650</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>HHFDSEC</td>\n",
       "      <td>household</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36508.250375</td>\n",
       "      <td>39656.600444</td>\n",
       "      <td>13379.800000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>F</td>\n",
       "      <td>NH Black</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22352.088620</td>\n",
       "      <td>25525.423409</td>\n",
       "      <td>57661.621988</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31600.089655</td>\n",
       "      <td>31510.587866</td>\n",
       "      <td>76026.438279</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7529.435502</td>\n",
       "      <td>7575.870247</td>\n",
       "      <td>14694.924957</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21071.164059</td>\n",
       "      <td>22445.808572</td>\n",
       "      <td>60202.416895</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEQN  SDDSRVYR      WTINT2YR      WTMEC2YR       WTSAF2YR  SDMVPSU  \\\n",
       "0     1       1.0   9727.078709  10982.898896   75131.200000      1.0   \n",
       "1     2       1.0  26678.636376  28325.384898   60586.147294      3.0   \n",
       "2     3       1.0  43621.680548  46192.256945  121969.841152      2.0   \n",
       "3     4       1.0  10346.119327  10251.260020    4624.687273      1.0   \n",
       "4     5       1.0  91050.846620  99445.065735  234895.205650      2.0   \n",
       "5     6       1.0  36508.250375  39656.600444   13379.800000      2.0   \n",
       "6     7       1.0  22352.088620  25525.423409   57661.621988      2.0   \n",
       "7     8       1.0  31600.089655  31510.587866   76026.438279      1.0   \n",
       "8     9       1.0   7529.435502   7575.870247   14694.924957      2.0   \n",
       "9    10       1.0  21071.164059  22445.808572   60202.416895      1.0   \n",
       "\n",
       "   SDMVSTRA   age sex                re  ...  FS_HH  FS_ADULT  FS_FINAL  \\\n",
       "0       5.0   2.0   F    Other Hispanic  ...   <NA>      <NA>      <NA>   \n",
       "1       1.0  77.0   M  Mexican American  ...      0         0         0   \n",
       "2       7.0  10.0   F  Mexican American  ...   <NA>      <NA>      <NA>   \n",
       "3       2.0   1.0   M    Other Hispanic  ...   <NA>      <NA>      <NA>   \n",
       "4       8.0  49.0   M  Mexican American  ...      0         0         0   \n",
       "5       2.0  19.0   F          NH Black  ...   <NA>      <NA>      <NA>   \n",
       "6       4.0  59.0   F    Other Hispanic  ...   <NA>      <NA>      <NA>   \n",
       "7       6.0  13.0   M  Mexican American  ...   <NA>      <NA>      <NA>   \n",
       "8       9.0  11.0   F    Other Hispanic  ...   <NA>      <NA>      <NA>   \n",
       "9       7.0  43.0   M    Other Hispanic  ...   <NA>      <NA>      <NA>   \n",
       "\n",
       "   HHFDSEC  ADFDSEC  FS_HH4  FS_ADULT4  FS_SOURCE_HH  FS_SOURCE_FINAL  \\\n",
       "0     <NA>     <NA>    <NA>       <NA>          <NA>             <NA>   \n",
       "1        1        1       1          1       HHFDSEC        household   \n",
       "2     <NA>     <NA>    <NA>       <NA>          <NA>             <NA>   \n",
       "3     <NA>     <NA>    <NA>       <NA>          <NA>             <NA>   \n",
       "4        1        1       1          1       HHFDSEC        household   \n",
       "5     <NA>     <NA>    <NA>       <NA>          <NA>             <NA>   \n",
       "6     <NA>     <NA>    <NA>       <NA>          <NA>             <NA>   \n",
       "7     <NA>     <NA>    <NA>       <NA>          <NA>             <NA>   \n",
       "8     <NA>     <NA>    <NA>       <NA>          <NA>             <NA>   \n",
       "9     <NA>     <NA>    <NA>       <NA>          <NA>             <NA>   \n",
       "\n",
       "   SNAP_SOURCE  \n",
       "0         <NA>  \n",
       "1         <NA>  \n",
       "2         <NA>  \n",
       "3         <NA>  \n",
       "4         <NA>  \n",
       "5         <NA>  \n",
       "6         <NA>  \n",
       "7         <NA>  \n",
       "8         <NA>  \n",
       "9         <NA>  \n",
       "\n",
       "[10 rows x 135 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check \n",
    "df_my_cov_aligned.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b3ff89-2d9c-473f-8b17-b938772b085a",
   "metadata": {},
   "source": [
    "## Keep important column for this analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "38f8d560-375d-4307-978e-027714e5e36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping 19 columns; missing 26:\n",
      "Missing: ['RIDAGEYR', 'SEX', 'RACE', 'household_size', 'SMK_AVG', 'SMK', 'ALCG2', 'met_hr', 'bmic', 'DIABE', 'HYPERTEN', 'probable_depression', 'sdoh_score', 'ahei_total', 'unemployment2', 'EDU', 'sdoh_access', 'ins', 'marriage', 'BPQ020', 'BPQ050A', 'sdmvpsu', 'sdmvstra', 'wt', 'wt10', 'SNAP3']\n",
      "df_desc shape: (128809, 19)\n",
      "NA rates (top 10):\n",
      "SNAP            0.587\n",
      "HOQ065          0.581\n",
      "MORTSTAT        0.541\n",
      "FS              0.518\n",
      "chol_rx         0.213\n",
      "dm_rx           0.213\n",
      "ldl             0.213\n",
      "hdl             0.213\n",
      "hba1c           0.213\n",
      "lung_disease    0.213\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = df_my_cov_aligned.copy()\n",
    "\n",
    "needed_core = [\n",
    "    # final table / missing checks\n",
    "    \"RIDAGEYR\",\"SEX\",\"RACE\",\"household_size\",\n",
    "    \"SMK_AVG\",\"SMK\",\"ALCG2\",\"met_hr\",\n",
    "    \"bmic\",\"DIABE\",\"HYPERTEN\",\"chol_rx\",\"CVD\",\"cancer\",\n",
    "    \"probable_depression\",\"sdoh_score\",\"ahei_total\",\n",
    "]\n",
    "\n",
    "needed_build = [\n",
    "    # for sdoh_score\n",
    "    \"unemployment2\",\"pir\",\"SNAP\",\"EDU\",\"sdoh_access\",\"ins\",\"HOQ065\",\"marriage\",\n",
    "    # for HYPERTEN\n",
    "    \"BPQ020\",\"BPQ050A\",\"sbp\",\"dbp\",\n",
    "]\n",
    "\n",
    "needed_survey = [\"sdmvpsu\",\"sdmvstra\",\"wt\", \"wt10\"]  # keep wt10 if you still reference it\n",
    "needed_keys   = [\"SEQN\",\"SDDSRVYR\"]\n",
    "\n",
    "needed_optional = [\n",
    "    \"FS\",\"SNAP3\",\"dm_rx\",\"angina\",\"lung_disease\",\"MORTSTAT\",\n",
    "    \"hba1c\",\"hdl\",\"ldl\",\"tg\"\n",
    "]\n",
    "\n",
    "NEEDED = needed_core + needed_build + needed_survey + needed_keys + needed_optional\n",
    "\n",
    "# Only keep those present; report what's missing\n",
    "present = [c for c in NEEDED if c in df.columns]\n",
    "missing = [c for c in NEEDED if c not in df.columns]\n",
    "\n",
    "print(f\"Keeping {len(present)} columns; missing {len(missing)}:\")\n",
    "print(\"Missing:\", missing)\n",
    "\n",
    "df_desc = df[present].copy()\n",
    "\n",
    "# (Optional) sanity peek\n",
    "print(\"df_desc shape:\", df_desc.shape)\n",
    "print(\"NA rates (top 10):\")\n",
    "print(df_desc.isna().mean().sort_values(ascending=False).head(10).round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a93ca235-ba14-472e-bcdc-76446f8ceee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 columns:\n",
      " ['SEQN', 'SDDSRVYR', 'WTINT2YR', 'WTMEC2YR', 'WTSAF2YR', 'SDMVPSU', 'SDMVSTRA', 'age', 'sex', 're', 'edu', 'pir', 'tchol', 'hdl', 'ldl', 'tg', 'wc', 'bmi', 'dm_self', 'hba1c', 'fpg', 'chf', 'chd', 'mi', 'stroke', 'cancer', 'emphysema', 'bronchitis', 'asthma', 're2', 'copd', 'sbp', 'dbp', 'dm_rx', 'chol_rx', 'angina_rx', 'htn_rx', 'roseQ', 'no_na', 'age_cat', 'pir_cat', 'edu2', 'CVD', 'lung_disease', 'diabetes', 'tchol_hdl', 'angina', 'lipid_pri', 'adiposity_pri', 'bp_pri', 'glucose_pri', 'cvd_pri', 'lipid_sec', 'adiposity_sec', 'bp_sec', 'glucose_sec', 'cvd_sec', 'optimal_pri_count', 'intermediate_pri_count', 'poor_pri_count', 'optimal_sec_count', 'intermediate_sec_count', 'poor_sec_count', 'optimal_all', 'poor_all', 'optimal_all_sec', 'poor_all_sec', 'MetS_hdl', 'MetS_triglycerides', 'MetS_bp', 'MetS_wc', 'MetS_fpg', 'MetS_count', 'MetS', 'RIAGENDR', 'FEMALE', 'SMK_STATUS', 'CIGS_PER_DAY', 'PACK_YEARS', 'FORMER_SMOKER', 'DRINKS_PER_DAY', 'ALCOHOL_CAT', 'LTPA', 'METSCORE', 'IMP', 'BMXWT', 'BMXHT', 'BMI_CLAS', 'HTN', 'HIGH_CHOL', 'DMDHHSIZ', 'ELIGSTAT', 'MORTSTAT', 'PERMTH_EXM', 'PERMTH_INT', 'UCOD_LEADING', 'IS_POST2018', 'IS_ADULT', 'MORTALITY_COVERED', 'EVENT', 'CENSORED', 'FU_YRS_EXM', 'FU_YRS_INT', 'UCOD_LABEL', 'PHQ9', 'PHQ9_GE10', 'DPQ_CAT', 'DEP_IMP', 'CIDI_SCORE_RAW', 'CIDI_12M_MDE', 'WTSCI2YR', 'DEP_HARMONIZED', 'DEP_SOURCE', 'INDFMINC', 'EDU_CAT', 'MARITAL', 'MARITAL_CAT', 'EMPLOY', 'UNEMPLOYMENT', 'HOD050', 'HOQ065', 'INS', 'SNAP', 'FSDHH', 'FS', 'FS_HH', 'FS_ADULT', 'FS_FINAL', 'HHFDSEC', 'ADFDSEC', 'FS_HH4', 'FS_ADULT4', 'FS_SOURCE_HH', 'FS_SOURCE_FINAL', 'SNAP_SOURCE']\n"
     ]
    }
   ],
   "source": [
    "# 1) Plain list (sorted)\n",
    "cols = (df_my_cov_aligned.columns.tolist())\n",
    "print(f\"{len(cols)} columns:\\n\", cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe24ac2b-d69d-4fac-9911-5dc438a04ab5",
   "metadata": {},
   "source": [
    "#### adjust column name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "e46cfaa5-9eae-4a09-ad4b-ef15dac83fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aliases/derivations created: {'RIDAGEYR': 'age', 'SEX': 'sex', 'RACE': 're', 'household_size': 'DMDHHSIZ', 'sdmvpsu': 'SDMVPSU', 'sdmvstra': 'SDMVSTRA', 'wt': 'WTMEC2YR', 'wt10': 'WTMEC2YR', 'SMK_AVG': 'CIGS_PER_DAY', 'SMK': 'FORMER_SMOKER', 'ALCG2': 'ALCOHOL_CAT', 'met_hr': 'METSCORE', 'bmic': 'BMI_CLAS', 'DIABE': 'diabetes', 'probable_depression': 'DEP_HARMONIZED', 'unemployment2': 'UNEMPLOYMENT', 'EDU': 'edu', 'ins': 'INS', 'marriage': 'MARITAL', 'SNAP3': 'SNAP'}\n",
      "df_desc columns kept: 40\n",
      "Still missing (not found in df): ['sdoh_score', 'ahei_total', 'sdoh_access', 'BPQ020', 'BPQ050A']\n",
      "Smoking-related kept: ['SMK_STATUS', 'SMK', 'SMK_AVG', 'FORMER_SMOKER', 'CIGS_PER_DAY']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = df_my_cov_aligned.copy()\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def ci_pick(*names):\n",
    "    \"\"\"case-insensitive column pick: returns first match or None\"\"\"\n",
    "    lowmap = {c.lower(): c for c in df.columns}\n",
    "    for n in names:\n",
    "        if n in df.columns: return n\n",
    "        if n.lower() in lowmap: return lowmap[n.lower()]\n",
    "    return None\n",
    "\n",
    "def pick_best(cands):\n",
    "    cols = []\n",
    "    for c in cands:\n",
    "        col = ci_pick(c)\n",
    "        if col: cols.append(col)\n",
    "    if not cols: return None\n",
    "    cov = {c: df[c].notna().mean() for c in cols}\n",
    "    return max(cov, key=cov.get)  # highest coverage\n",
    "\n",
    "created = {}\n",
    "\n",
    "# ---------- 1) alias to canonical (adds BPQ+MM fallbacks, AHEI fallbacks) ----------\n",
    "aliases = {\n",
    "    # IDs / survey\n",
    "    \"RIDAGEYR\": [\"RIDAGEYR\",\"AGE_YR\",\"age\"],\n",
    "    \"SEX\":      [\"SEX\",\"sex\",\"RIAGENDR\"],\n",
    "    \"RACE\":     [\"RACE\",\"re2\",\"re\"],\n",
    "    \"household_size\": [\"household_size\",\"DMDHHSIZ\"],\n",
    "    \"sdmvpsu\":  [\"sdmvpsu\",\"SDMVPSU\"],\n",
    "    \"sdmvstra\": [\"sdmvstra\",\"SDMVSTRA\"],\n",
    "    \"wt\":       [\"wt\",\"WTMEC2YR\"],\n",
    "    \"wt10\":     [\"wt10\",\"WTMEC2YR\"],\n",
    "\n",
    "    # behavior\n",
    "    \"SMK_AVG\":  [\"SMK_AVG\",\"CIGS_PER_DAY\"],\n",
    "    \"SMK\":      [\"SMK\",\"FORMER_SMOKER\",\"SMK_STATUS\"],\n",
    "    \"ALCG2\":    [\"ALCG2\",\"ALCOHOL_CAT\"],\n",
    "    \"met_hr\":   [\"met_hr\",\"METSCORE\",\"LTPA\"],\n",
    "\n",
    "    # clinical\n",
    "    \"bmic\":     [\"bmic\",\"BMI_CLAS\"],\n",
    "    \"DIABE\":    [\"DIABE\",\"DIABETES\",\"diabetes\"],\n",
    "    \"chol_rx\":  [\"chol_rx\"],\n",
    "    \"CVD\":      [\"CVD\"],\n",
    "    \"cancer\":   [\"cancer\"],\n",
    "\n",
    "    # outcomes / scores\n",
    "    \"probable_depression\": [\"probable_depression\",\"DEP_HARMONIZED\",\"PHQ9_GE10\",\"DEP_IMP\"],\n",
    "    \"sdoh_score\": [\"sdoh_score\"],\n",
    "    \"ahei_total\": [\"ahei_total\",\"AHEI\",\"ahei\",\"HEI2015_TOTAL_SCORE\",\"HEI2015_TOTAL\"],\n",
    "\n",
    "    # building blocks (for possible compute later)\n",
    "    \"unemployment2\": [\"unemployment2\",\"UNEMPLOYMENT\",\"EMPLOY\"],\n",
    "    \"pir\":           [\"pir\"],\n",
    "    \"SNAP\":          [\"SNAP\"],\n",
    "    \"EDU\":           [\"EDU\",\"EDU_CAT\",\"edu\",\"edu2\"],\n",
    "    \"sdoh_access\":   [\"sdoh_access\",\"HUQ_ACCESS\",\"huq_access\"],\n",
    "    \"ins\":           [\"ins\",\"INS\"],\n",
    "    \"HOQ065\":        [\"HOQ065\"],\n",
    "    \"marriage\":      [\"marriage\",\"MARITAL\",\"MARITAL_CAT\"],\n",
    "\n",
    "    # HTN components (case-insensitive)\n",
    "    \"BPQ020\":        [\"BPQ020\",\"bpq020\"],\n",
    "    \"BPQ050A\":       [\"BPQ050A\",\"bpq050a\"],\n",
    "    \"sbp\":           [\"sbp\",\"SBP\"],\n",
    "    \"dbp\":           [\"dbp\",\"DBP\"],\n",
    "\n",
    "    # SNAP3 label variant\n",
    "    \"SNAP3\":         [\"SNAP3\",\"SNAP\"],\n",
    "}\n",
    "\n",
    "for target, cands in aliases.items():\n",
    "    src = pick_best(cands)\n",
    "    if src:\n",
    "        if target != src:\n",
    "            df[target] = df[src]\n",
    "            created[target] = src\n",
    "\n",
    "# Normalize SEX if it came from RIAGENDR (1/2)\n",
    "if \"SEX\" in df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df[\"SEX\"]):\n",
    "        df[\"SEX\"] = df[\"SEX\"].map({1: \"Male\", 2: \"Female\"}).fillna(df[\"SEX\"])\n",
    "    else:\n",
    "        df[\"SEX\"] = df[\"SEX\"].astype(str).str.strip().str.capitalize()\n",
    "\n",
    "# HYPERTEN compute if missing (your R rule)\n",
    "if \"HYPERTEN\" not in df.columns:\n",
    "    bpq020 = df[ci_pick(\"BPQ020\",\"bpq020\")] if ci_pick(\"BPQ020\",\"bpq020\") else pd.Series(np.nan, index=df.index)\n",
    "    bpq050a= df[ci_pick(\"BPQ050A\",\"bpq050a\")] if ci_pick(\"BPQ050A\",\"bpq050a\") else pd.Series(np.nan, index=df.index)\n",
    "    sbp = df[ci_pick(\"sbp\",\"SBP\")] if ci_pick(\"sbp\",\"SBP\") else pd.Series(np.nan, index=df.index)\n",
    "    dbp = df[ci_pick(\"dbp\",\"DBP\")] if ci_pick(\"dbp\",\"DBP\") else pd.Series(np.nan, index=df.index)\n",
    "    df[\"HYPERTEN\"] = np.where(((bpq020==1) | (bpq050a==1) | (sbp>=130) | (dbp>=85)), 1,\n",
    "                              np.where(bpq020.notna() | bpq050a.notna() | sbp.notna() | dbp.notna(), 0, np.nan))\n",
    "\n",
    "# ---------- 2) keep BOTH canonical + source columns ----------\n",
    "# Define source groups to retain alongside canonical\n",
    "source_groups = {\n",
    "    \"SMK_AVG\": [\"CIGS_PER_DAY\"],\n",
    "    \"SMK\":     [\"FORMER_SMOKER\",\"SMK_STATUS\"],\n",
    "    \"ALCG2\":   [\"ALCOHOL_CAT\"],\n",
    "    \"met_hr\":  [\"METSCORE\",\"LTPA\"],\n",
    "    \"bmic\":    [\"BMI_CLAS\",\"BMI\"],        # keep BMI if you like for context\n",
    "    \"DIABE\":   [\"DIABETES\",\"diabetes\"],\n",
    "    \"sbp\":     [\"SBP\"],\n",
    "    \"dbp\":     [\"DBP\"],\n",
    "    \"ahei_total\": [\"AHEI\",\"ahei\",\"HEI2015_TOTAL_SCORE\",\"HEI2015_TOTAL\"],\n",
    "}\n",
    "\n",
    "# Core variables your R script needs\n",
    "needed_core = [\n",
    "  \"RIDAGEYR\",\"SEX\",\"RACE\",\"household_size\",\n",
    "  \"SMK_AVG\",\"SMK\",\"ALCG2\",\"met_hr\",\n",
    "  \"bmic\",\"DIABE\",\"HYPERTEN\",\"chol_rx\",\"CVD\",\"cancer\",\n",
    "  \"probable_depression\",\"sdoh_score\",\"ahei_total\",\n",
    "  \"unemployment2\",\"pir\",\"SNAP\",\"EDU\",\"sdoh_access\",\"ins\",\"HOQ065\",\"marriage\",\n",
    "  \"BPQ020\",\"BPQ050A\",\"sdmvpsu\",\"sdmvstra\",\"wt\",\"wt10\",\"SNAP3\",\n",
    "  \"SEQN\",\"SDDSRVYR\"\n",
    "]\n",
    "\n",
    "retain = set()\n",
    "# always keep canonicals that exist\n",
    "retain.update([c for c in needed_core if c in df.columns])\n",
    "# also keep sources if present\n",
    "for canon, sources in source_groups.items():\n",
    "    if canon in df.columns:\n",
    "        for s in sources:\n",
    "            s_real = ci_pick(s)\n",
    "            if s_real: retain.add(s_real)\n",
    "\n",
    "df_desc = df[list(retain)].copy()\n",
    "\n",
    "# ---------- 3) report ----------\n",
    "still_missing = [c for c in needed_core if c not in df_desc.columns]\n",
    "print(\"Aliases/derivations created:\", created)\n",
    "print(f\"df_desc columns kept: {len(df_desc.columns)}\")\n",
    "print(\"Still missing (not found in df):\", still_missing)\n",
    "print(\"Smoking-related kept:\",\n",
    "      [c for c in df_desc.columns if c.upper() in {\"SMK_AVG\",\"CIGS_PER_DAY\",\"SMK\",\"FORMER_SMOKER\",\"SMK_STATUS\"}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "431eadb8-e96a-4c70-b4c5-781748c35742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aliases/derivations created: {'RIDAGEYR': 'age', 'SEX': 'sex', 'RACE': 're', 'household_size': 'DMDHHSIZ', 'sdmvpsu': 'SDMVPSU', 'sdmvstra': 'SDMVSTRA', 'SMK_AVG': 'CIGS_PER_DAY', 'SMK': 'FORMER_SMOKER', 'ALCG2': 'ALCOHOL_CAT', 'met_hr': 'METSCORE', 'bmic': 'BMI_CLAS', 'DIABE': 'diabetes', 'probable_depression': 'DEP_HARMONIZED', 'unemployment2': 'UNEMPLOYMENT', 'EDU': 'edu', 'ins': 'INS', 'marriage': 'MARITAL', 'SNAP3': 'SNAP'}\n",
      "df_desc columns kept: 40\n",
      "Still missing (not found in df): ['sdoh_score', 'ahei_total', 'sdoh_access', 'BPQ020', 'BPQ050A', 'WTDRD1', 'WTDR2D', 'wt', 'wt10', 'WTINT4YR', 'WTMEC4YR']\n",
      "Weights present in df_desc: ['WTINT2YR', 'WTMEC2YR', 'WTSAF2YR']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = df_my_cov_aligned.copy()\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def ci_pick(*names):\n",
    "    lowmap = {c.lower(): c for c in df.columns}\n",
    "    for n in names:\n",
    "        if n in df.columns: return n\n",
    "        if n.lower() in lowmap: return lowmap[n.lower()]\n",
    "    return None\n",
    "\n",
    "def pick_best(cands):\n",
    "    cols = []\n",
    "    for c in cands:\n",
    "        col = ci_pick(c)\n",
    "        if col: cols.append(col)\n",
    "    if not cols: return None\n",
    "    cov = {c: df[c].notna().mean() for c in cols}\n",
    "    return max(cov, key=cov.get)\n",
    "\n",
    "created = {}\n",
    "\n",
    "# ---------- 1) alias to canonical (NO coalescing of weights) ----------\n",
    "aliases = {\n",
    "    # IDs / survey\n",
    "    \"RIDAGEYR\": [\"RIDAGEYR\",\"AGE_YR\",\"age\"],\n",
    "    \"SEX\":      [\"SEX\",\"sex\",\"RIAGENDR\"],\n",
    "    \"RACE\":     [\"RACE\",\"re2\",\"re\"],\n",
    "    \"household_size\": [\"household_size\",\"DMDHHSIZ\"],\n",
    "    \"sdmvpsu\":  [\"sdmvpsu\",\"SDMVPSU\"],\n",
    "    \"sdmvstra\": [\"sdmvstra\",\"SDMVSTRA\"],\n",
    "    # keep user's wt/wt10 AS-IS if present\n",
    "    \"wt\":       [\"wt\"],\n",
    "    \"wt10\":     [\"wt10\"],\n",
    "    # keep ALL NHANES weights separately (standardize casing only)\n",
    "    \"WTINT2YR\": [\"WTINT2YR\",\"wtint2yr\"],\n",
    "    \"WTMEC2YR\": [\"WTMEC2YR\",\"wtmec2yr\"],\n",
    "    \"WTSAF2YR\": [\"WTSAF2YR\",\"wtsaf2yr\"],\n",
    "    \"WTDRD1\":   [\"WTDRD1\",\"wtdrd1\",\"wtdrd1d\"],\n",
    "    \"WTDR2D\":   [\"WTDR2D\",\"wtdr2d\"],\n",
    "\n",
    "    # behavior\n",
    "    \"SMK_AVG\":  [\"SMK_AVG\",\"CIGS_PER_DAY\"],\n",
    "    \"SMK\":      [\"SMK\",\"FORMER_SMOKER\",\"SMK_STATUS\"],\n",
    "    \"ALCG2\":    [\"ALCG2\",\"ALCOHOL_CAT\"],\n",
    "    \"met_hr\":   [\"met_hr\",\"METSCORE\",\"LTPA\"],\n",
    "\n",
    "    # clinical\n",
    "    \"bmic\":     [\"bmic\",\"BMI_CLAS\"],\n",
    "    \"DIABE\":    [\"DIABE\",\"DIABETES\",\"diabetes\"],\n",
    "    \"chol_rx\":  [\"chol_rx\"],\n",
    "    \"CVD\":      [\"CVD\"],\n",
    "    \"cancer\":   [\"cancer\"],\n",
    "\n",
    "    # outcomes / scores\n",
    "    \"probable_depression\": [\"probable_depression\",\"DEP_HARMONIZED\",\"PHQ9_GE10\",\"DEP_IMP\"],\n",
    "    \"sdoh_score\": [\"sdoh_score\"],\n",
    "    \"ahei_total\": [\"ahei_total\",\"AHEI\",\"ahei\",\"HEI2015_TOTAL_SCORE\",\"HEI2015_TOTAL\"],\n",
    "\n",
    "    # building blocks\n",
    "    \"unemployment2\": [\"unemployment2\",\"UNEMPLOYMENT\",\"EMPLOY\"],\n",
    "    \"pir\":           [\"pir\"],\n",
    "    \"SNAP\":          [\"SNAP\"],\n",
    "    \"EDU\":           [\"EDU\",\"EDU_CAT\",\"edu\",\"edu2\"],\n",
    "    \"sdoh_access\":   [\"sdoh_access\",\"HUQ_ACCESS\",\"huq_access\"],\n",
    "    \"ins\":           [\"ins\",\"INS\"],\n",
    "    \"HOQ065\":        [\"HOQ065\"],\n",
    "    \"marriage\":      [\"marriage\",\"MARITAL\",\"MARITAL_CAT\"],\n",
    "\n",
    "    # HTN components (case-insensitive)\n",
    "    \"BPQ020\":        [\"BPQ020\",\"bpq020\"],\n",
    "    \"BPQ050A\":       [\"BPQ050A\",\"bpq050a\"],\n",
    "    \"sbp\":           [\"sbp\",\"SBP\"],\n",
    "    \"dbp\":           [\"dbp\",\"DBP\"],\n",
    "\n",
    "    # SNAP3 alias\n",
    "    \"SNAP3\":         [\"SNAP3\",\"SNAP\"],\n",
    "}\n",
    "\n",
    "for target, cands in aliases.items():\n",
    "    src = pick_best(cands)\n",
    "    if src:\n",
    "        if target != src:\n",
    "            df[target] = df[src]\n",
    "            created[target] = src\n",
    "\n",
    "# Normalize SEX if it came from RIAGENDR (1/2)\n",
    "if \"SEX\" in df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df[\"SEX\"]):\n",
    "        df[\"SEX\"] = df[\"SEX\"].map({1: \"Male\", 2: \"Female\"}).fillna(df[\"SEX\"])\n",
    "    else:\n",
    "        df[\"SEX\"] = df[\"SEX\"].astype(str).str.strip().str.capitalize()\n",
    "\n",
    "# HYPERTEN compute if missing (same rule)\n",
    "if \"HYPERTEN\" not in df.columns:\n",
    "    bpq020 = df[ci_pick(\"BPQ020\",\"bpq020\")] if ci_pick(\"BPQ020\",\"bpq020\") else pd.Series(np.nan, index=df.index)\n",
    "    bpq050a= df[ci_pick(\"BPQ050A\",\"bpq050a\")] if ci_pick(\"BPQ050A\",\"bpq050a\") else pd.Series(np.nan, index=df.index)\n",
    "    sbp = df[ci_pick(\"sbp\",\"SBP\")] if ci_pick(\"sbp\",\"SBP\") else pd.Series(np.nan, index=df.index)\n",
    "    dbp = df[ci_pick(\"dbp\",\"DBP\")] if ci_pick(\"dbp\",\"DBP\") else pd.Series(np.nan, index=df.index)\n",
    "    df[\"HYPERTEN\"] = np.where(((bpq020==1) | (bpq050a==1) | (sbp>=130) | (dbp>=85)), 1,\n",
    "                              np.where(bpq020.notna() | bpq050a.notna() | sbp.notna() | dbp.notna(), 0, np.nan))\n",
    "\n",
    "# ---------- 2) keep BOTH canonical + source columns ----------\n",
    "source_groups = {\n",
    "    \"SMK_AVG\":   [\"CIGS_PER_DAY\"],\n",
    "    \"SMK\":       [\"FORMER_SMOKER\",\"SMK_STATUS\"],\n",
    "    \"ALCG2\":     [\"ALCOHOL_CAT\"],\n",
    "    \"met_hr\":    [\"METSCORE\",\"LTPA\"],\n",
    "    \"bmic\":      [\"BMI_CLAS\",\"BMI\"],\n",
    "    \"DIABE\":     [\"DIABETES\",\"diabetes\"],\n",
    "    \"sbp\":       [\"SBP\"],\n",
    "    \"dbp\":       [\"DBP\"],\n",
    "    \"ahei_total\":[\"AHEI\",\"ahei\",\"HEI2015_TOTAL_SCORE\",\"HEI2015_TOTAL\"],\n",
    "    # weights: keep raw variants too if present\n",
    "    \"WTINT2YR\":  [\"wtint2yr\"],\n",
    "    \"WTMEC2YR\":  [\"wtmec2yr\",\"wt\",\"wt10\"],  # keep user's wt/wt10 alongside\n",
    "    \"WTSAF2YR\":  [\"wtsaf2yr\"],\n",
    "    \"WTDRD1\":    [\"wtdrd1\",\"wtdrd1d\"],\n",
    "    \"WTDR2D\":    [\"wtdr2d\"],\n",
    "}\n",
    "\n",
    "# Core variables your R script needs + all distinct weights\n",
    "needed_core = [\n",
    "  \"RIDAGEYR\",\"SEX\",\"RACE\",\"household_size\",\n",
    "  \"SMK_AVG\",\"SMK\",\"ALCG2\",\"met_hr\",\n",
    "  \"bmic\",\"DIABE\",\"HYPERTEN\",\"chol_rx\",\"CVD\",\"cancer\",\n",
    "  \"probable_depression\",\"sdoh_score\",\"ahei_total\",\n",
    "  \"unemployment2\",\"pir\",\"SNAP\",\"EDU\",\"sdoh_access\",\"ins\",\"HOQ065\",\"marriage\",\n",
    "  \"BPQ020\",\"BPQ050A\",\"sdmvpsu\",\"sdmvstra\",\"SEQN\",\"SDDSRVYR\",\n",
    "  # weights (keep all if present)\n",
    "  \"WTINT2YR\",\"WTMEC2YR\",\"WTSAF2YR\",\"WTDRD1\",\"WTDR2D\",\"wt\",\"wt10\",\"WTINT4YR\",\"WTMEC4YR\"\n",
    "]\n",
    "\n",
    "retain = set()\n",
    "retain.update([c for c in needed_core if c in df.columns])\n",
    "for canon, sources in source_groups.items():\n",
    "    if canon in df.columns:\n",
    "        for s in sources:\n",
    "            s_real = ci_pick(s)\n",
    "            if s_real: retain.add(s_real)\n",
    "\n",
    "df_desc = df[list(retain)].copy()\n",
    "\n",
    "# ---------- 3) report ----------\n",
    "still_missing = [c for c in needed_core if c not in df_desc.columns]\n",
    "print(\"Aliases/derivations created:\", created)\n",
    "print(f\"df_desc columns kept: {len(df_desc.columns)}\")\n",
    "print(\"Still missing (not found in df):\", still_missing)\n",
    "\n",
    "# quick peek at which weights you have\n",
    "weight_cols = [c for c in [\"WTINT2YR\",\"WTMEC2YR\",\"WTSAF2YR\",\"WTDRD1\",\"WTDR2D\",\"wt\",\"wt10\",\"WTINT4YR\",\"WTMEC4YR\"] if c in df_desc.columns]\n",
    "print(\"Weights present in df_desc:\", weight_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82803bd-cc3d-47d4-adeb-48934b0490e0",
   "metadata": {},
   "source": [
    "#### add 2017-2020 special weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "71ad6aab-6d82-40f8-a8bc-b33c1f0ee7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added/updated: ['WTINT4YR', 'WTMEC4YR', 'SDMVPSU', 'SDMVSTRA']\n",
      "Non-missing rates: {'WTINT4YR': 0.12079901249136318, 'WTMEC4YR': 0.12079901249136318, 'SDMVPSU': 1.0, 'SDMVSTRA': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Base DF\n",
    "df = df_my_cov_aligned.copy()\n",
    "\n",
    "# NHANES P_DEMO (2017–Mar 2020 pre-pandemic)\n",
    "urls = [\n",
    "    \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/P_DEMO.xpt\",\n",
    "    \"https://wwwn.cdc.gov/Nchs/Nhanes/2017-2020/P_DEMO.XPT\",\n",
    "]\n",
    "\n",
    "demo = None\n",
    "for u in urls:\n",
    "    try:\n",
    "        demo = pd.read_sas(u, format=\"xport\", encoding=\"utf-8\")\n",
    "        break\n",
    "    except Exception:\n",
    "        pass\n",
    "if demo is None:\n",
    "    raise RuntimeError(\"Failed to download P_DEMO.xpt from both URLs.\")\n",
    "\n",
    "# Keep + standardize\n",
    "keep = [\"SEQN\", \"WTINTPRP\", \"WTMECPRP\", \"SDMVPSU\", \"SDMVSTRA\", \"SDDSRVYR\"]\n",
    "demo = demo[keep].copy()\n",
    "\n",
    "# Optional sanity check: SDDSRVYR==66 for this file\n",
    "# assert demo[\"SDDSRVYR\"].dropna().eq(66).all()\n",
    "\n",
    "# Map to your 4-year convention\n",
    "demo = demo.rename(columns={\n",
    "    \"WTINTPRP\": \"WTINT4YR\",\n",
    "    \"WTMECPRP\": \"WTMEC4YR\",\n",
    "})\n",
    "\n",
    "# Ensure target cols exist pre-merge (so we can suffix the right-hand side)\n",
    "for col in [\"WTINT4YR\", \"WTMEC4YR\", \"SDMVPSU\", \"SDMVSTRA\"]:\n",
    "    if col not in df.columns:\n",
    "        df[col] = pd.NA\n",
    "\n",
    "# Merge (right-hand columns get *_src)\n",
    "df = df.merge(demo, on=[\"SEQN\"], how=\"left\", suffixes=(\"\", \"_src\"))\n",
    "\n",
    "# Fill only missing (mask assignment avoids FutureWarning), then drop *_src\n",
    "for col in [\"WTINT4YR\", \"WTMEC4YR\", \"SDMVPSU\", \"SDMVSTRA\"]:\n",
    "    src = f\"{col}_src\"\n",
    "    if src in df.columns:\n",
    "        mask = df[col].isna() & df[src].notna()\n",
    "        if mask.any():\n",
    "            df.loc[mask, col] = df.loc[mask, src]\n",
    "        df.drop(columns=[src], inplace=True)\n",
    "\n",
    "# Dtypes: weights as float; PSU/STRATA as nullable int\n",
    "for col in [\"WTINT4YR\", \"WTMEC4YR\", \"WTINT2YR\", \"WTMEC2YR\", \"WTSAF2YR\", \"WTDRD1\", \"WTDR2D\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")  # float\n",
    "\n",
    "for col in [\"SDMVPSU\", \"SDMVSTRA\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Quick audit\n",
    "have = [c for c in [\"WTINT4YR\",\"WTMEC4YR\",\"SDMVPSU\",\"SDMVSTRA\"] if c in df.columns]\n",
    "print(\"Added/updated:\", have)\n",
    "print(\"Non-missing rates:\", {c: float(df[c].notna().mean()) for c in have})\n",
    "\n",
    "df_my_cov_aligned = df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177a03d1-bb42-4206-8a9b-7ff02ba9d7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd421f27-dab7-4f6b-b54e-bda162f2eafb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b59012-ce19-431c-b003-3d9a18e9074f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e063f55-9342-4043-a112-32a7e3a73f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70567b4d-34d5-41cb-ab4f-c3dec601042a",
   "metadata": {},
   "source": [
    "#### Add ahei score build in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "baabfb8f-5a35-42d1-90de-0e6e17c44935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ahei_total merged from ahei_1999_2018_combined.csv. Non-missing: 46169 (added 46169).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA = Path(\"/Users/dengshuyue/Desktop/SDOH/analysis/output\")\n",
    "cand = [DATA/\"ahei_1999_2018_combined.csv\", DATA/\"ahei_9904_wjfrt_ssbfix.csv\"]\n",
    "\n",
    "ahei_path = next((p for p in cand if p.exists()), None)\n",
    "if ahei_path is None:\n",
    "    raise FileNotFoundError(\"No AHEI combined file found. Please write ahei_1999_2018_combined.csv in R.\")\n",
    "\n",
    "# --- read header only to discover exact column names (case-insensitive) ---\n",
    "hdr = pd.read_csv(ahei_path, nrows=0, low_memory=False)\n",
    "lower_map = {c.lower(): c for c in hdr.columns}\n",
    "\n",
    "seqn_col = lower_map.get(\"seqn\")\n",
    "tot_col = next((lower_map[k] for k in [\"ahei_all\",\"ahei_all_recomp\"] if k in lower_map), None)\n",
    "if not seqn_col or not tot_col:\n",
    "    raise ValueError(f\"Couldn’t find SEQN or AHEI total in {ahei_path.name}. \"\n",
    "                     f\"Columns present include: {list(hdr.columns)[:12]} ...\")\n",
    "\n",
    "# --- now read ONLY what we need, with dtypes set → no DtypeWarning ---\n",
    "try:\n",
    "    # use pyarrow if available (fast, no type guessing); falls back if not installed\n",
    "    ahei = pd.read_csv(ahei_path, usecols=[seqn_col, tot_col],\n",
    "                       dtype={seqn_col: \"Int64\"}, engine=\"pyarrow\")\n",
    "except Exception:\n",
    "    ahei = pd.read_csv(ahei_path, usecols=[seqn_col, tot_col],\n",
    "                       dtype={seqn_col: \"Int64\"}, low_memory=False)\n",
    "\n",
    "ahei = ahei.rename(columns={seqn_col: \"SEQN\", tot_col: \"ahei_total\"})\n",
    "ahei[\"ahei_total\"] = pd.to_numeric(ahei[\"ahei_total\"], errors=\"coerce\")\n",
    "ahei = ahei.dropna(subset=[\"SEQN\"]).drop_duplicates(\"SEQN\", keep=\"last\")\n",
    "\n",
    "# --- merge into your frame ---\n",
    "df = df_my_cov_aligned.copy()\n",
    "df[\"SEQN\"] = pd.to_numeric(df[\"SEQN\"], errors=\"coerce\")\n",
    "pre = df[\"ahei_total\"].notna().sum() if \"ahei_total\" in df.columns else 0\n",
    "\n",
    "df = df.merge(ahei, on=\"SEQN\", how=\"left\", suffixes=(\"\", \"_ahei\"))\n",
    "if \"ahei_total_ahei\" in df.columns:\n",
    "    df[\"ahei_total\"] = df[\"ahei_total\"].where(df[\"ahei_total\"].notna(), df[\"ahei_total_ahei\"])\n",
    "    df.drop(columns=[\"ahei_total_ahei\"], inplace=True)\n",
    "\n",
    "post = df[\"ahei_total\"].notna().sum()\n",
    "print(f\"✓ ahei_total merged from {ahei_path.name}. Non-missing: {post} (added {post-pre}).\")\n",
    "\n",
    "df_my_cov_aligned = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898fe3f9-035a-4ce8-a5a1-b0922b1cb29d",
   "metadata": {},
   "source": [
    "#### check again what is missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "cbc1b9f4-a835-42f9-9e4e-e5acceb62b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Present: 14 Missing: 22\n",
      "Still missing: ['RIDAGEYR', 'SEX', 'RACE', 'household_size', 'SMK_AVG', 'SMK', 'ALCG2', 'met_hr', 'bmic', 'DIABE', 'HYPERTEN', 'probable_depression', 'sdoh_score', 'unemployment2', 'EDU', 'sdoh_access', 'ins', 'marriage', 'sdmvpsu', 'sdmvstra', 'WTDRD1', 'WTDR2D']\n",
      "NHANES weights present: ['WTINT2YR', 'WTMEC2YR', 'WTSAF2YR', 'WTINT4YR', 'WTMEC4YR']\n"
     ]
    }
   ],
   "source": [
    "# Start from your earlier needed_core and trim\n",
    "needed_core = [\n",
    "  \"RIDAGEYR\",\"SEX\",\"RACE\",\"household_size\",\n",
    "  \"SMK_AVG\",\"SMK\",\"ALCG2\",\"met_hr\",\n",
    "  \"bmic\",\"DIABE\",\"HYPERTEN\",\"chol_rx\",\"CVD\",\"cancer\",\n",
    "  \"probable_depression\",\"sdoh_score\",\"ahei_total\",\n",
    "  \"unemployment2\",\"pir\",\"SNAP\",\"EDU\",\"sdoh_access\",\"ins\",\"HOQ065\",\"marriage\",\n",
    "  \"sdmvpsu\",\"sdmvstra\",\"SEQN\",\"SDDSRVYR\",\n",
    "  # weights (NHANES only)\n",
    "  \"WTINT2YR\",\"WTMEC2YR\",\"WTSAF2YR\",\"WTDRD1\",\"WTDR2D\",\"WTINT4YR\",\"WTMEC4YR\"\n",
    "]\n",
    "\n",
    "# Check what's still missing\n",
    "present = [c for c in needed_core if c in df_my_cov_aligned.columns]\n",
    "missing = [c for c in needed_core if c not in df_my_cov_aligned.columns]\n",
    "weights_present = [c for c in [\"WTINT2YR\",\"WTMEC2YR\",\"WTSAF2YR\",\"WTDRD1\",\"WTDR2D\",\"WTINT4YR\",\"WTMEC4YR\"]\n",
    "                   if c in df_my_cov_aligned.columns]\n",
    "\n",
    "print(\"Present:\", len(present), \"Missing:\", len(missing))\n",
    "print(\"Still missing:\", missing)\n",
    "print(\"NHANES weights present:\", weights_present)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b5e31984-5ded-4751-bad9-06622ff3dd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEQN, SDDSRVYR, WTINT2YR, WTMEC2YR, WTSAF2YR, SDMVPSU, SDMVSTRA, age, sex, re, edu, pir, tchol, hdl,\n",
      "ldl, tg, wc, bmi, dm_self, hba1c, fpg, chf, chd, mi, stroke, cancer, emphysema, bronchitis, asthma,\n",
      "re2, copd, sbp, dbp, dm_rx, chol_rx, angina_rx, htn_rx, roseQ, no_na, age_cat, pir_cat, edu2, CVD,\n",
      "lung_disease, diabetes, tchol_hdl, angina, lipid_pri, adiposity_pri, bp_pri, glucose_pri, cvd_pri,\n",
      "lipid_sec, adiposity_sec, bp_sec, glucose_sec, cvd_sec, optimal_pri_count, intermediate_pri_count,\n",
      "poor_pri_count, optimal_sec_count, intermediate_sec_count, poor_sec_count, optimal_all, poor_all,\n",
      "optimal_all_sec, poor_all_sec, MetS_hdl, MetS_triglycerides, MetS_bp, MetS_wc, MetS_fpg, MetS_count,\n",
      "MetS, RIAGENDR, FEMALE, SMK_STATUS, CIGS_PER_DAY, PACK_YEARS, FORMER_SMOKER, DRINKS_PER_DAY,\n",
      "ALCOHOL_CAT, LTPA, METSCORE, IMP, BMXWT, BMXHT, BMI_CLAS, HTN, HIGH_CHOL, DMDHHSIZ, ELIGSTAT,\n",
      "MORTSTAT, PERMTH_EXM, PERMTH_INT, UCOD_LEADING, IS_POST2018, IS_ADULT, MORTALITY_COVERED, EVENT,\n",
      "CENSORED, FU_YRS_EXM, FU_YRS_INT, UCOD_LABEL, PHQ9, PHQ9_GE10, DPQ_CAT, DEP_IMP, CIDI_SCORE_RAW,\n",
      "CIDI_12M_MDE, WTSCI2YR, DEP_HARMONIZED, DEP_SOURCE, INDFMINC, EDU_CAT, MARITAL, MARITAL_CAT, EMPLOY,\n",
      "UNEMPLOYMENT, HOD050, HOQ065, INS, SNAP, FSDHH, FS, FS_HH, FS_ADULT, FS_FINAL, HHFDSEC, ADFDSEC,\n",
      "FS_HH4, FS_ADULT4, FS_SOURCE_HH, FS_SOURCE_FINAL, SNAP_SOURCE, WTINT4YR, WTMEC4YR, SDDSRVYR_src,\n",
      "ahei_total\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "print(textwrap.fill(\", \".join(map(str, df_my_cov_aligned.columns)), width=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8610376-2edf-483b-9654-1f6afa4db4dc",
   "metadata": {},
   "source": [
    "#### adjust column name and check missingness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "52b25cd1-a4c8-4f6c-8a92-750163fc712e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Present: 33  Missing: 3\n",
      "Aliased (canonical ← source): {'RIDAGEYR': 'age', 'SEX': 'sex', 'RACE': 're2', 'household_size': 'DMDHHSIZ', 'SMK_AVG': 'CIGS_PER_DAY', 'SMK': 'SMK_STATUS', 'ALCG2': 'ALCOHOL_CAT', 'met_hr': 'METSCORE', 'bmic': 'BMI_CLAS', 'DIABE': 'diabetes', 'HYPERTEN': 'HTN', 'probable_depression': 'DEP_HARMONIZED', 'unemployment2': 'UNEMPLOYMENT', 'EDU': 'edu', 'sdoh_access': 'HOD050', 'ins': 'INS', 'marriage': 'MARITAL', 'sdmvpsu': 'SDMVPSU', 'sdmvstra': 'SDMVSTRA'}\n",
      "Still missing: ['sdoh_score', 'WTDRD1', 'WTDR2D']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Canonical set (HTN stays; BPQ020/050A removed per your earlier choice)\n",
    "needed_core = [\n",
    "  \"RIDAGEYR\",\"SEX\",\"RACE\",\"household_size\",\n",
    "  \"SMK_AVG\",\"SMK\",\"ALCG2\",\"met_hr\",\n",
    "  \"bmic\",\"DIABE\",\"HYPERTEN\",\"chol_rx\",\"CVD\",\"cancer\",\n",
    "  \"probable_depression\",\"sdoh_score\",\"ahei_total\",\n",
    "  \"unemployment2\",\"pir\",\"SNAP\",\"EDU\",\"sdoh_access\",\"ins\",\"HOQ065\",\"marriage\",\n",
    "  \"sdmvpsu\",\"sdmvstra\",\"SEQN\",\"SDDSRVYR\",\n",
    "  \"WTINT2YR\",\"WTMEC2YR\",\"WTSAF2YR\",\"WTDRD1\",\"WTDR2D\",\"WTINT4YR\",\"WTMEC4YR\"\n",
    "]\n",
    "\n",
    "# Map your existing columns → canonical (no coalescing; just alias-by-best)\n",
    "aliases = {\n",
    "    \"RIDAGEYR\": [\"RIDAGEYR\",\"age\"],\n",
    "    \"SEX\":      [\"SEX\",\"RIAGENDR\",\"sex\"],\n",
    "    \"RACE\":     [\"RACE\",\"re2\",\"re\"],\n",
    "    \"household_size\": [\"household_size\",\"DMDHHSIZ\"],\n",
    "    \"SMK_AVG\":  [\"SMK_AVG\",\"CIGS_PER_DAY\"],\n",
    "    \"SMK\":      [\"SMK\",\"SMK_STATUS\",\"FORMER_SMOKER\"],\n",
    "    \"ALCG2\":    [\"ALCG2\",\"ALCOHOL_CAT\"],\n",
    "    \"met_hr\":   [\"met_hr\",\"METSCORE\",\"LTPA\"],\n",
    "    \"bmic\":     [\"bmic\",\"BMI_CLAS\",\"bmi\"],\n",
    "    \"DIABE\":    [\"DIABE\",\"diabetes\",\"DIABETES\",\"dm_self\"],\n",
    "    \"HYPERTEN\": [\"HYPERTEN\",\"HTN\"],\n",
    "    \"chol_rx\":  [\"chol_rx\"],\n",
    "    \"CVD\":      [\"CVD\"],\n",
    "    \"cancer\":   [\"cancer\"],\n",
    "    \"probable_depression\": [\"probable_depression\",\"DEP_HARMONIZED\",\"PHQ9_GE10\",\"DEP_IMP\"],\n",
    "    \"sdoh_score\": [\"sdoh_score\"],  # likely missing\n",
    "    \"ahei_total\": [\"ahei_total\",\"AHEI\",\"HEI2015_TOTAL_SCORE\",\"HEI2015_TOTAL\"],\n",
    "    \"unemployment2\": [\"unemployment2\",\"UNEMPLOYMENT\",\"EMPLOY\"],\n",
    "    \"pir\":      [\"pir\"],\n",
    "    \"SNAP\":     [\"SNAP\"],\n",
    "    \"EDU\":      [\"EDU\",\"edu\",\"edu2\",\"EDU_CAT\"],\n",
    "    \"sdoh_access\": [\"sdoh_access\",\"HOD050\",\"HOQ065\"],  # if you treat these as access proxies\n",
    "    \"ins\":      [\"ins\",\"INS\"],\n",
    "    \"HOQ065\":   [\"HOQ065\"],\n",
    "    \"marriage\": [\"marriage\",\"MARITAL\",\"MARITAL_CAT\"],\n",
    "    \"sdmvpsu\":  [\"sdmvpsu\",\"SDMVPSU\"],\n",
    "    \"sdmvstra\": [\"sdmvstra\",\"SDMVSTRA\"],\n",
    "    \"SEQN\":     [\"SEQN\"],\n",
    "    \"SDDSRVYR\": [\"SDDSRVYR\"],\n",
    "    # weights\n",
    "    \"WTINT2YR\": [\"WTINT2YR\"],\n",
    "    \"WTMEC2YR\": [\"WTMEC2YR\"],\n",
    "    \"WTSAF2YR\": [\"WTSAF2YR\",\"WTSCI2YR\"],  # your frame has WTSCI2YR (safety)\n",
    "    \"WTDRD1\":   [\"WTDRD1\"],               # likely missing\n",
    "    \"WTDR2D\":   [\"WTDR2D\"],               # likely missing\n",
    "    \"WTINT4YR\": [\"WTINT4YR\",\"WTINTPRP\"],\n",
    "    \"WTMEC4YR\": [\"WTMEC4YR\",\"WTMECPRP\"],\n",
    "}\n",
    "\n",
    "def ci_pick(df, names):\n",
    "    low = {c.lower(): c for c in df.columns}\n",
    "    for n in names:\n",
    "        if n in df.columns: return n\n",
    "        if n.lower() in low: return low[n.lower()]\n",
    "    return None\n",
    "\n",
    "created = {}\n",
    "for target, cands in aliases.items():\n",
    "    src = ci_pick(df_my_cov_aligned, cands)\n",
    "    if src and target not in df_my_cov_aligned.columns:\n",
    "        df_my_cov_aligned[target] = df_my_cov_aligned[src]\n",
    "        created[target] = src\n",
    "\n",
    "present = [c for c in needed_core if c in df_my_cov_aligned.columns]\n",
    "missing = [c for c in needed_core if c not in df_my_cov_aligned.columns]\n",
    "\n",
    "print(f\"Present: {len(present)}  Missing: {len(missing)}\")\n",
    "print(\"Aliased (canonical ← source):\", {k:v for k,v in created.items()})\n",
    "print(\"Still missing:\", missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "eaa5caf3-f138-4cc7-b4b2-80f02a4ca989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCQ → present: ['EMPLOY', 'UNEMPLOYMENT'] | missing: []\n",
      "HOQ → present: ['HOD050', 'HOQ065'] | missing: []\n",
      "HIQ → present: ['INS'] | missing: []\n",
      "FSQ → present: ['FSDHH', 'HHFDSEC', 'ADFDSEC', 'FS_HH4', 'FS_ADULT4', 'FS_HH', 'FS_ADULT', 'FS_FINAL', 'FS_SOURCE_HH', 'FS_SOURCE_FINAL', 'SNAP'] | missing: []\n"
     ]
    }
   ],
   "source": [
    "blocks = {\n",
    "    \"OCQ\": [\"EMPLOY\",\"UNEMPLOYMENT\"],\n",
    "    \"HOQ\": [\"HOD050\",\"HOQ065\"],\n",
    "    \"HIQ\": [\"INS\"],\n",
    "    \"FSQ\": [\"FSDHH\",\"HHFDSEC\",\"ADFDSEC\",\"FS_HH4\",\"FS_ADULT4\",\"FS_HH\",\"FS_ADULT\",\"FS_FINAL\",\"FS_SOURCE_HH\",\"FS_SOURCE_FINAL\",\"SNAP\"],\n",
    "}\n",
    "\n",
    "for name, cols in blocks.items():\n",
    "    present = [c for c in cols if c in df_my_cov_aligned.columns]\n",
    "    missing = [c for c in cols if c not in df_my_cov_aligned.columns]\n",
    "    print(f\"{name} → present: {present} | missing: {missing}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "b4298441-7e20-4db0-a25b-8d9b2062a754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>WTINT2YR</th>\n",
       "      <th>WTMEC2YR</th>\n",
       "      <th>WTSAF2YR</th>\n",
       "      <th>SDMVPSU</th>\n",
       "      <th>SDMVSTRA</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>re</th>\n",
       "      <th>...</th>\n",
       "      <th>DIABE</th>\n",
       "      <th>HYPERTEN</th>\n",
       "      <th>probable_depression</th>\n",
       "      <th>unemployment2</th>\n",
       "      <th>EDU</th>\n",
       "      <th>sdoh_access</th>\n",
       "      <th>ins</th>\n",
       "      <th>marriage</th>\n",
       "      <th>sdmvpsu</th>\n",
       "      <th>sdmvstra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9727.078709</td>\n",
       "      <td>10982.898896</td>\n",
       "      <td>75131.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26678.636376</td>\n",
       "      <td>28325.384898</td>\n",
       "      <td>60586.147294</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>77.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43621.680548</td>\n",
       "      <td>46192.256945</td>\n",
       "      <td>121969.841152</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10346.119327</td>\n",
       "      <td>10251.260020</td>\n",
       "      <td>4624.687273</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91050.846620</td>\n",
       "      <td>99445.065735</td>\n",
       "      <td>234895.205650</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>49.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36508.250375</td>\n",
       "      <td>39656.600444</td>\n",
       "      <td>13379.800000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>F</td>\n",
       "      <td>NH Black</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22352.088620</td>\n",
       "      <td>25525.423409</td>\n",
       "      <td>57661.621988</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>59.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31600.089655</td>\n",
       "      <td>31510.587866</td>\n",
       "      <td>76026.438279</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7529.435502</td>\n",
       "      <td>7575.870247</td>\n",
       "      <td>14694.924957</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21071.164059</td>\n",
       "      <td>22445.808572</td>\n",
       "      <td>60202.416895</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>43.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEQN  SDDSRVYR      WTINT2YR      WTMEC2YR       WTSAF2YR  SDMVPSU  \\\n",
       "0     1       1.0   9727.078709  10982.898896   75131.200000        1   \n",
       "1     2       1.0  26678.636376  28325.384898   60586.147294        3   \n",
       "2     3       1.0  43621.680548  46192.256945  121969.841152        2   \n",
       "3     4       1.0  10346.119327  10251.260020    4624.687273        1   \n",
       "4     5       1.0  91050.846620  99445.065735  234895.205650        2   \n",
       "5     6       1.0  36508.250375  39656.600444   13379.800000        2   \n",
       "6     7       1.0  22352.088620  25525.423409   57661.621988        2   \n",
       "7     8       1.0  31600.089655  31510.587866   76026.438279        1   \n",
       "8     9       1.0   7529.435502   7575.870247   14694.924957        2   \n",
       "9    10       1.0  21071.164059  22445.808572   60202.416895        1   \n",
       "\n",
       "   SDMVSTRA   age sex                re  ...  DIABE  HYPERTEN  \\\n",
       "0         5   2.0   F    Other Hispanic  ...      0         0   \n",
       "1         1  77.0   M  Mexican American  ...      0         0   \n",
       "2         7  10.0   F  Mexican American  ...      0         0   \n",
       "3         2   1.0   M    Other Hispanic  ...      0         0   \n",
       "4         8  49.0   M  Mexican American  ...      0         1   \n",
       "5         2  19.0   F          NH Black  ...      0         0   \n",
       "6         4  59.0   F    Other Hispanic  ...      0         0   \n",
       "7         6  13.0   M  Mexican American  ...      0         0   \n",
       "8         9  11.0   F    Other Hispanic  ...      0         0   \n",
       "9         7  43.0   M    Other Hispanic  ...      0         1   \n",
       "\n",
       "   probable_depression  unemployment2   EDU  sdoh_access   ins  marriage  \\\n",
       "0                 <NA>           <NA>  <NA>          NaN  <NA>      <NA>   \n",
       "1                 <NA>              0     5          2.0     1      <NA>   \n",
       "2                 <NA>           <NA>     3          NaN  <NA>      <NA>   \n",
       "3                 <NA>           <NA>  <NA>          NaN  <NA>      <NA>   \n",
       "4                 <NA>              0     5          7.0     1         1   \n",
       "5                 <NA>           <NA>    15          NaN  <NA>         5   \n",
       "6                 <NA>              0     2          NaN  <NA>         1   \n",
       "7                 <NA>           <NA>     5          NaN  <NA>      <NA>   \n",
       "8                 <NA>           <NA>     5          NaN  <NA>      <NA>   \n",
       "9                 <NA>              0     3          4.0     2         4   \n",
       "\n",
       "   sdmvpsu  sdmvstra  \n",
       "0        1         5  \n",
       "1        3         1  \n",
       "2        2         7  \n",
       "3        1         2  \n",
       "4        2         8  \n",
       "5        2         2  \n",
       "6        2         4  \n",
       "7        1         6  \n",
       "8        2         9  \n",
       "9        1         7  \n",
       "\n",
       "[10 rows x 158 columns]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_my_cov_aligned.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89651525-84a7-4042-b62e-3cea6ec66bba",
   "metadata": {},
   "source": [
    "#### Keep important column and name it df_my_cov_aligned_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "4856d43e-10cc-47e0-b509-120cef75b7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_my_cov_aligned_short shape: (128809, 40)\n",
      "Created (canonical ← source): {'SEQN': 'SEQN', 'SDDSRVYR': 'SDDSRVYR', 'sdmvpsu': 'sdmvpsu', 'sdmvstra': 'sdmvstra', 'RIDAGEYR': 'RIDAGEYR', 'SEX': 'SEX', 'RACE': 'RACE', 'household_size': 'household_size', 'EDU': 'EDU', 'pir': 'pir', 'SMK_AVG': 'SMK_AVG', 'SMK': 'SMK', 'ALCG2': 'ALCG2', 'met_hr': 'met_hr', 'SMK_STATUS': 'SMK_STATUS', 'CIGS_PER_DAY': 'CIGS_PER_DAY', 'PACK_YEARS': 'PACK_YEARS', 'FORMER_SMOKER': 'FORMER_SMOKER', 'DRINKS_PER_DAY': 'DRINKS_PER_DAY', 'ALCOHOL_CAT': 'ALCOHOL_CAT', 'bmic': 'bmic', 'DIABE': 'DIABE', 'HYPERTEN': 'HYPERTEN', 'chol_rx': 'chol_rx', 'CVD': 'CVD', 'cancer': 'cancer', 'probable_depression': 'probable_depression', 'ahei_total': 'ahei_total', 'unemployment2': 'unemployment2', 'sdoh_access': 'sdoh_access', 'ins': 'ins', 'HOQ065': 'HOQ065', 'marriage': 'marriage', 'SNAP': 'SNAP', 'FS': 'FS_FINAL', 'WTINT2YR': 'WTINT2YR', 'WTMEC2YR': 'WTMEC2YR', 'WTSAF2YR': 'WTSAF2YR', 'WTINT4YR': 'WTINT4YR', 'WTMEC4YR': 'WTMEC4YR'}\n",
      "Still missing after aliasing: ['sdoh_score']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "src = df_my_cov_aligned.copy()\n",
    "\n",
    "# ---- 1) Canonical columns to keep (core + key derived + requested raw fields) ----\n",
    "canonical_order = [\n",
    "    # IDs / survey design\n",
    "    \"SEQN\",\"SDDSRVYR\",\"sdmvpsu\",\"sdmvstra\",\n",
    "    # demographics\n",
    "    \"RIDAGEYR\",\"SEX\",\"RACE\",\"household_size\",\"EDU\",\"pir\",\n",
    "    # behavior (canonical)\n",
    "    \"SMK_AVG\",\"SMK\",\"ALCG2\",\"met_hr\",\n",
    "    # behavior (raw fields to keep)\n",
    "    \"SMK_STATUS\",\"CIGS_PER_DAY\",\"PACK_YEARS\",\"FORMER_SMOKER\",\"DRINKS_PER_DAY\",\"ALCOHOL_CAT\",\n",
    "    # clinical\n",
    "    \"bmic\",\"DIABE\",\"HYPERTEN\",\"chol_rx\",\"CVD\",\"cancer\",\n",
    "    # scores/outcomes\n",
    "    \"probable_depression\",\"sdoh_score\",\"ahei_total\",\n",
    "    # SDOH / access / insurance / marital / SNAP / FS\n",
    "    \"unemployment2\",\"sdoh_access\",\"ins\",\"HOQ065\",\"marriage\",\"SNAP\",\"FS\",\n",
    "    # weights (interview/exam + pre-pandemic 4-yr + safety)\n",
    "    \"WTINT2YR\",\"WTMEC2YR\",\"WTSAF2YR\",\"WTINT4YR\",\"WTMEC4YR\",\n",
    "]\n",
    "\n",
    "# ---- 2) Alias map: canonical -> possible sources in your frame ----\n",
    "aliases = {\n",
    "    \"SEQN\": [\"SEQN\"],\n",
    "    \"SDDSRVYR\": [\"SDDSRVYR\",\"SDDSRVYR_src\"],\n",
    "\n",
    "    \"sdmvpsu\": [\"sdmvpsu\",\"SDMVPSU\"],\n",
    "    \"sdmvstra\":[\"sdmvstra\",\"SDMVSTRA\"],\n",
    "\n",
    "    \"RIDAGEYR\": [\"RIDAGEYR\",\"age\"],\n",
    "    \"SEX\": [\"SEX\",\"RIAGENDR\",\"sex\"],\n",
    "    \"RACE\": [\"RACE\",\"re2\",\"re\"],\n",
    "    \"household_size\": [\"household_size\",\"DMDHHSIZ\"],\n",
    "    \"EDU\": [\"EDU\",\"edu\",\"edu2\",\"EDU_CAT\"],\n",
    "    \"pir\": [\"pir\"],\n",
    "\n",
    "    # canonical behavior\n",
    "    \"SMK_AVG\": [\"SMK_AVG\",\"CIGS_PER_DAY\"],\n",
    "    \"SMK\": [\"SMK\",\"SMK_STATUS\",\"FORMER_SMOKER\"],\n",
    "    \"ALCG2\": [\"ALCG2\",\"ALCOHOL_CAT\"],\n",
    "    \"met_hr\": [\"met_hr\",\"METSCORE\",\"LTPA\"],\n",
    "\n",
    "    # raw behavior fields (keep as-is)\n",
    "    \"SMK_STATUS\": [\"SMK_STATUS\"],\n",
    "    \"CIGS_PER_DAY\": [\"CIGS_PER_DAY\"],\n",
    "    \"PACK_YEARS\": [\"PACK_YEARS\"],\n",
    "    \"FORMER_SMOKER\": [\"FORMER_SMOKER\"],\n",
    "    \"DRINKS_PER_DAY\": [\"DRINKS_PER_DAY\"],\n",
    "    \"ALCOHOL_CAT\": [\"ALCOHOL_CAT\"],\n",
    "\n",
    "    # clinical\n",
    "    \"bmic\": [\"bmic\",\"BMI_CLAS\",\"bmi\"],\n",
    "    \"DIABE\": [\"DIABE\",\"diabetes\",\"DIABETES\",\"dm_self\"],\n",
    "    \"HYPERTEN\": [\"HYPERTEN\",\"HTN\"],\n",
    "    \"chol_rx\": [\"chol_rx\"],\n",
    "    \"CVD\": [\"CVD\"],\n",
    "    \"cancer\": [\"cancer\"],\n",
    "\n",
    "    # outcomes/scores\n",
    "    \"probable_depression\": [\"probable_depression\",\"DEP_HARMONIZED\",\"PHQ9_GE10\",\"DEP_IMP\"],\n",
    "    \"sdoh_score\": [\"sdoh_score\"],\n",
    "    \"ahei_total\": [\"ahei_total\",\"AHEI\",\"HEI2015_TOTAL_SCORE\",\"HEI2015_TOTAL\"],\n",
    "\n",
    "    # SDOH etc.\n",
    "    \"unemployment2\": [\"unemployment2\",\"UNEMPLOYMENT\",\"EMPLOY\"],\n",
    "    \"sdoh_access\": [\"sdoh_access\"],\n",
    "    \"ins\": [\"ins\",\"INS\"],\n",
    "    \"HOQ065\": [\"HOQ065\"],\n",
    "    \"marriage\": [\"marriage\",\"MARITAL\",\"MARITAL_CAT\"],\n",
    "\n",
    "    \"SNAP\": [\"SNAP\"],\n",
    "    \"FS\": [\"FS_FINAL\",\"FS\"],  # prefer your final FS binary\n",
    "\n",
    "    # weights\n",
    "    \"WTINT2YR\": [\"WTINT2YR\"],\n",
    "    \"WTMEC2YR\": [\"WTMEC2YR\"],\n",
    "    \"WTSAF2YR\": [\"WTSAF2YR\",\"WTSCI2YR\"],\n",
    "    \"WTINT4YR\": [\"WTINT4YR\",\"WTINTPRP\"],\n",
    "    \"WTMEC4YR\": [\"WTMEC4YR\",\"WTMECPRP\"],\n",
    "}\n",
    "\n",
    "def ci_pick(df, names):\n",
    "    low = {c.lower(): c for c in df.columns}\n",
    "    for n in names:\n",
    "        if n in df.columns: return n\n",
    "        if n.lower() in low: return low[n.lower()]\n",
    "    return None\n",
    "\n",
    "# ---- 3) Build df_short with canonical names, copying from the best source ----\n",
    "short_cols = {}\n",
    "created_from = {}\n",
    "for canon, cands in aliases.items():\n",
    "    src_col = ci_pick(src, cands)\n",
    "    if src_col is not None:\n",
    "        short_cols[canon] = src[src_col]\n",
    "        created_from[canon] = src_col\n",
    "\n",
    "df_my_cov_aligned_short = pd.DataFrame(short_cols)\n",
    "\n",
    "# ---- 4) Light harmonization / typing ----\n",
    "# SEX\n",
    "if \"SEX\" in df_my_cov_aligned_short.columns:\n",
    "    s = df_my_cov_aligned_short[\"SEX\"]\n",
    "    if pd.api.types.is_numeric_dtype(s):\n",
    "        df_my_cov_aligned_short[\"SEX\"] = s.map({1:\"Male\", 2:\"Female\"}).astype(\"string\")\n",
    "    else:\n",
    "        df_my_cov_aligned_short[\"SEX\"] = s.astype(str).str.strip().str.capitalize()\n",
    "\n",
    "# Binary-ish ints\n",
    "for col_bin in [\"DIABE\",\"HYPERTEN\",\"CVD\",\"cancer\",\"SNAP\",\"FS\",\"unemployment2\",\"FORMER_SMOKER\"]:\n",
    "    if col_bin in df_my_cov_aligned_short.columns:\n",
    "        df_my_cov_aligned_short[col_bin] = pd.to_numeric(df_my_cov_aligned_short[col_bin], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Continuous behavior\n",
    "for col_num in [\"CIGS_PER_DAY\",\"PACK_YEARS\",\"DRINKS_PER_DAY\",\"SMK_AVG\",\"met_hr\",\"pir\"]:\n",
    "    if col_num in df_my_cov_aligned_short.columns:\n",
    "        df_my_cov_aligned_short[col_num] = pd.to_numeric(df_my_cov_aligned_short[col_num], errors=\"coerce\")\n",
    "\n",
    "# PSU/STRATA → nullable ints; weights → float\n",
    "for col in [\"sdmvpsu\",\"sdmvstra\"]:\n",
    "    if col in df_my_cov_aligned_short.columns:\n",
    "        df_my_cov_aligned_short[col] = pd.to_numeric(df_my_cov_aligned_short[col], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "for col in [\"WTINT2YR\",\"WTMEC2YR\",\"WTSAF2YR\",\"WTINT4YR\",\"WTMEC4YR\"]:\n",
    "    if col in df_my_cov_aligned_short.columns:\n",
    "        df_my_cov_aligned_short[col] = pd.to_numeric(df_my_cov_aligned_short[col], errors=\"coerce\")\n",
    "\n",
    "# Keep final column order (only those that exist)\n",
    "cols_final = [c for c in canonical_order if c in df_my_cov_aligned_short.columns]\n",
    "df_my_cov_aligned_short = df_my_cov_aligned_short[cols_final].copy()\n",
    "\n",
    "# ---- 5) Report coverage ----\n",
    "missing_after = [c for c in canonical_order if c not in df_my_cov_aligned_short.columns]\n",
    "print(\"df_my_cov_aligned_short shape:\", df_my_cov_aligned_short.shape)\n",
    "print(\"Created (canonical ← source):\", created_from)\n",
    "print(\"Still missing after aliasing:\", missing_after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "79b42464-c65b-4b31-a616-27394ff18d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Checked why SMK_AVG etc missing \n",
    "## Pre-2018 cycles have ~10–13% non-missing (expected: only current smokers report cigs/day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd25fb-0bca-42cd-a7d3-e1bb614a84fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce647ff8-8946-4011-b2e6-e6f469f86204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce88a305-711c-49c4-8fc2-de471bb6e39d",
   "metadata": {},
   "source": [
    "## Check what column missing post 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "dd77d87b-f737-4b27-8595-02fe562ec2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DMDHHSIZ</th>\n",
       "      <th>probable_depression</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>CIDI_12M_MDE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9945</th>\n",
       "      <td>3.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>22.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9946</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9947</th>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9948</th>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>39.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9949</th>\n",
       "      <td>3.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>14.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9950</th>\n",
       "      <td>6.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>15.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9951</th>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>23.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952</th>\n",
       "      <td>7.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>14.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9953</th>\n",
       "      <td>5.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>36.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9954</th>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>37.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9955</th>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>46.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9956</th>\n",
       "      <td>6.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>16.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9957</th>\n",
       "      <td>6.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>43.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9958</th>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9959</th>\n",
       "      <td>3.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>85.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9960</th>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>36.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9961</th>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9962</th>\n",
       "      <td>3.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>18.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9963</th>\n",
       "      <td>3.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>11.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9964</th>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>84.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DMDHHSIZ  probable_depression  RIDAGEYR  CIDI_12M_MDE\n",
       "9945       3.0                 <NA>      22.0          <NA>\n",
       "9946       7.0                    0      35.0             0\n",
       "9947       4.0                 <NA>       2.0          <NA>\n",
       "9948       4.0                 <NA>      39.0          <NA>\n",
       "9949       3.0                 <NA>      14.0          <NA>\n",
       "9950       6.0                 <NA>      15.0          <NA>\n",
       "9951       1.0                 <NA>      23.0          <NA>\n",
       "9952       7.0                 <NA>      14.0          <NA>\n",
       "9953       5.0                 <NA>      36.0          <NA>\n",
       "9954       4.0                 <NA>      37.0          <NA>\n",
       "9955       4.0                 <NA>      46.0          <NA>\n",
       "9956       6.0                 <NA>      16.0          <NA>\n",
       "9957       6.0                 <NA>      43.0          <NA>\n",
       "9958       4.0                 <NA>       0.0          <NA>\n",
       "9959       3.0                 <NA>      85.0          <NA>\n",
       "9960       4.0                 <NA>      36.0          <NA>\n",
       "9961       4.0                 <NA>       4.0          <NA>\n",
       "9962       3.0                 <NA>      18.0          <NA>\n",
       "9963       3.0                 <NA>      11.0          <NA>\n",
       "9964       1.0                 <NA>      84.0          <NA>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df_my_cov_aligned.loc[df_my_cov_aligned[\"SDDSRVYR\"].eq(1), [\"DMDHHSIZ\",\"probable_depression\",\"RIDAGEYR\", \"CIDI_12M_MDE\"]].tail(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "c720b760-0644-418d-a3e4-6c684ab4b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_my_cov_aligned.loc[df_my_cov_aligned[\"SDDSRVYR\"].eq(66), [\"DMDHHSIZ\",\"WTINT4YR\",\"WTMEC4YR\"]].tail(9000)\n",
    "# df_my_cov_aligned[[\"DMDHHSIZ\",'WTINT4YR', 'WTMEC4YR']].tail(20)\n",
    "# df_my_cov_aligned[[\"DMDHHSIZ\", \"household_size\", \"HOQ065\"]].tail(10) \n",
    "\n",
    "# df_lu_cov_1999_2018[[  'WTINT2YR', 'WTMEC2YR', 'WTSAF2YR']].head(10) \n",
    "# 'SEQN','SDDSRVYR', 'SDMVPSU', 'SDMVSTRA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "97667301-77db-43a4-b6d1-c9836a41bbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct cycles present (SDDSRVYR): [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 12.0, 66.0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>10122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>10537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>9756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>9254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12.0</td>\n",
       "      <td>11933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>66.0</td>\n",
       "      <td>15560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SDDSRVYR      n\n",
       "0        1.0   9965\n",
       "1        2.0  11039\n",
       "2        3.0  10122\n",
       "3        4.0  10348\n",
       "4        5.0  10149\n",
       "5        6.0  10537\n",
       "6        7.0   9756\n",
       "7        8.0  10175\n",
       "8        9.0   9971\n",
       "9       10.0   9254\n",
       "10      12.0  11933\n",
       "11      66.0  15560"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average non-missing rate per block (by cycle):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>block</th>\n",
       "      <th>behav</th>\n",
       "      <th>clin</th>\n",
       "      <th>demo</th>\n",
       "      <th>design</th>\n",
       "      <th>scores</th>\n",
       "      <th>sdoh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>37.6</td>\n",
       "      <td>97.5</td>\n",
       "      <td>94.9</td>\n",
       "      <td>71.4</td>\n",
       "      <td>44.1</td>\n",
       "      <td>43.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>37.9</td>\n",
       "      <td>96.9</td>\n",
       "      <td>95.9</td>\n",
       "      <td>71.4</td>\n",
       "      <td>44.6</td>\n",
       "      <td>44.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>38.6</td>\n",
       "      <td>97.6</td>\n",
       "      <td>96.2</td>\n",
       "      <td>71.4</td>\n",
       "      <td>41.2</td>\n",
       "      <td>51.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>37.6</td>\n",
       "      <td>97.7</td>\n",
       "      <td>96.0</td>\n",
       "      <td>71.4</td>\n",
       "      <td>41.0</td>\n",
       "      <td>49.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>45.7</td>\n",
       "      <td>97.9</td>\n",
       "      <td>95.7</td>\n",
       "      <td>71.4</td>\n",
       "      <td>45.1</td>\n",
       "      <td>57.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>46.4</td>\n",
       "      <td>98.2</td>\n",
       "      <td>95.7</td>\n",
       "      <td>71.4</td>\n",
       "      <td>46.6</td>\n",
       "      <td>58.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>45.2</td>\n",
       "      <td>98.0</td>\n",
       "      <td>95.8</td>\n",
       "      <td>71.4</td>\n",
       "      <td>44.0</td>\n",
       "      <td>56.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>45.5</td>\n",
       "      <td>98.2</td>\n",
       "      <td>96.1</td>\n",
       "      <td>71.4</td>\n",
       "      <td>44.0</td>\n",
       "      <td>55.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>45.3</td>\n",
       "      <td>98.0</td>\n",
       "      <td>95.6</td>\n",
       "      <td>71.4</td>\n",
       "      <td>43.1</td>\n",
       "      <td>55.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>41.8</td>\n",
       "      <td>97.8</td>\n",
       "      <td>95.3</td>\n",
       "      <td>71.4</td>\n",
       "      <td>44.8</td>\n",
       "      <td>57.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>20.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.7</td>\n",
       "      <td>42.9</td>\n",
       "      <td>26.6</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.5</td>\n",
       "      <td>57.1</td>\n",
       "      <td>28.8</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "block     behav  clin  demo  design  scores  sdoh\n",
       "SDDSRVYR                                         \n",
       "1.0        37.6  97.5  94.9    71.4    44.1  43.7\n",
       "2.0        37.9  96.9  95.9    71.4    44.6  44.1\n",
       "3.0        38.6  97.6  96.2    71.4    41.2  51.5\n",
       "4.0        37.6  97.7  96.0    71.4    41.0  49.8\n",
       "5.0        45.7  97.9  95.7    71.4    45.1  57.7\n",
       "6.0        46.4  98.2  95.7    71.4    46.6  58.2\n",
       "7.0        45.2  98.0  95.8    71.4    44.0  56.3\n",
       "8.0        45.5  98.2  96.1    71.4    44.0  55.7\n",
       "9.0        45.3  98.0  95.6    71.4    43.1  55.3\n",
       "10.0       41.8  97.8  95.3    71.4    44.8  57.4\n",
       "12.0       20.1   0.0  74.7    42.9    26.6  18.5\n",
       "66.0       20.0   0.0  57.5    57.1    28.8  25.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentinel column non-missing rates (by cycle):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WTMEC2YR_nonmiss</th>\n",
       "      <th>WTMEC4YR_nonmiss</th>\n",
       "      <th>FS_nonmiss</th>\n",
       "      <th>SNAP_nonmiss</th>\n",
       "      <th>probable_depression_nonmiss</th>\n",
       "      <th>ahei_total_nonmiss</th>\n",
       "      <th>met_hr_nonmiss</th>\n",
       "      <th>EDU_nonmiss</th>\n",
       "      <th>ins_nonmiss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>81.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>84.3</td>\n",
       "      <td>47.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.8</td>\n",
       "      <td>4.2</td>\n",
       "      <td>7.4</td>\n",
       "      <td>81.8</td>\n",
       "      <td>49.0</td>\n",
       "      <td>82.8</td>\n",
       "      <td>47.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.6</td>\n",
       "      <td>48.9</td>\n",
       "      <td>6.8</td>\n",
       "      <td>75.5</td>\n",
       "      <td>49.8</td>\n",
       "      <td>82.8</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.6</td>\n",
       "      <td>47.5</td>\n",
       "      <td>51.5</td>\n",
       "      <td>30.5</td>\n",
       "      <td>48.1</td>\n",
       "      <td>81.3</td>\n",
       "      <td>45.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.9</td>\n",
       "      <td>57.9</td>\n",
       "      <td>59.1</td>\n",
       "      <td>31.1</td>\n",
       "      <td>58.5</td>\n",
       "      <td>83.1</td>\n",
       "      <td>55.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.3</td>\n",
       "      <td>58.3</td>\n",
       "      <td>60.4</td>\n",
       "      <td>32.9</td>\n",
       "      <td>59.0</td>\n",
       "      <td>83.6</td>\n",
       "      <td>55.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.7</td>\n",
       "      <td>56.5</td>\n",
       "      <td>57.6</td>\n",
       "      <td>30.5</td>\n",
       "      <td>57.0</td>\n",
       "      <td>83.6</td>\n",
       "      <td>53.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.9</td>\n",
       "      <td>55.9</td>\n",
       "      <td>58.2</td>\n",
       "      <td>29.9</td>\n",
       "      <td>56.7</td>\n",
       "      <td>84.2</td>\n",
       "      <td>53.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.3</td>\n",
       "      <td>55.0</td>\n",
       "      <td>57.5</td>\n",
       "      <td>28.7</td>\n",
       "      <td>57.4</td>\n",
       "      <td>83.9</td>\n",
       "      <td>51.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.7</td>\n",
       "      <td>56.2</td>\n",
       "      <td>59.8</td>\n",
       "      <td>29.9</td>\n",
       "      <td>60.2</td>\n",
       "      <td>85.1</td>\n",
       "      <td>55.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.6</td>\n",
       "      <td>65.3</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>54.9</td>\n",
       "      <td>54.5</td>\n",
       "      <td>57.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.2</td>\n",
       "      <td>59.3</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          WTMEC2YR_nonmiss  WTMEC4YR_nonmiss  FS_nonmiss  SNAP_nonmiss  \\\n",
       "SDDSRVYR                                                                 \n",
       "1.0                  100.0               0.0        47.6           4.8   \n",
       "2.0                  100.0               0.0        45.8           4.2   \n",
       "3.0                  100.0               0.0        47.6          48.9   \n",
       "4.0                  100.0               0.0        47.6          47.5   \n",
       "5.0                  100.0               0.0        57.9          57.9   \n",
       "6.0                  100.0               0.0        58.3          58.3   \n",
       "7.0                  100.0               0.0        56.7          56.5   \n",
       "8.0                  100.0               0.0        55.9          55.9   \n",
       "9.0                  100.0               0.0        55.3          55.0   \n",
       "10.0                 100.0               0.0        56.7          56.2   \n",
       "12.0                 100.0               0.0         0.0           0.0   \n",
       "66.0                   0.0             100.0        54.9          54.5   \n",
       "\n",
       "          probable_depression_nonmiss  ahei_total_nonmiss  met_hr_nonmiss  \\\n",
       "SDDSRVYR                                                                    \n",
       "1.0                               7.2                81.0            49.0   \n",
       "2.0                               7.4                81.8            49.0   \n",
       "3.0                               6.8                75.5            49.8   \n",
       "4.0                              51.5                30.5            48.1   \n",
       "5.0                              59.1                31.1            58.5   \n",
       "6.0                              60.4                32.9            59.0   \n",
       "7.0                              57.6                30.5            57.0   \n",
       "8.0                              58.2                29.9            56.7   \n",
       "9.0                              57.5                28.7            57.4   \n",
       "10.0                             59.8                29.9            60.2   \n",
       "12.0                             53.1                 0.0            67.6   \n",
       "66.0                             57.6                 0.0            62.2   \n",
       "\n",
       "          EDU_nonmiss  ins_nonmiss  \n",
       "SDDSRVYR                            \n",
       "1.0              84.3         47.6  \n",
       "2.0              82.8         47.7  \n",
       "3.0              82.8         49.0  \n",
       "4.0              81.3         45.4  \n",
       "5.0              83.1         55.5  \n",
       "6.0              83.6         55.4  \n",
       "7.0              83.6         53.3  \n",
       "8.0              84.2         53.1  \n",
       "9.0              83.9         51.3  \n",
       "10.0             85.1         55.3  \n",
       "12.0             65.3          5.6  \n",
       "66.0             59.3          9.4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = df_my_cov_aligned_short.copy()\n",
    "df['SDDSRVYR'] = pd.to_numeric(df['SDDSRVYR'], errors='coerce')\n",
    "\n",
    "# 1) Cycle counts\n",
    "cycle_counts = (df.groupby('SDDSRVYR', dropna=False).size()\n",
    "                  .rename('n').reset_index().sort_values('SDDSRVYR'))\n",
    "print(\"Distinct cycles present (SDDSRVYR):\", cycle_counts['SDDSRVYR'].tolist())\n",
    "display(cycle_counts)\n",
    "\n",
    "# 2) Block coverage (non-missing rates)\n",
    "key_groups = {\n",
    "    \"design\": [\"sdmvpsu\",\"sdmvstra\",\"WTINT2YR\",\"WTMEC2YR\",\"WTSAF2YR\",\"WTINT4YR\",\"WTMEC4YR\"],\n",
    "    \"demo\":   [\"RIDAGEYR\",\"SEX\",\"RACE\",\"household_size\",\"EDU\",\"pir\"],\n",
    "    \"behav\":  [\"SMK\",\"ALCG2\",\"met_hr\",\"SMK_STATUS\",\"CIGS_PER_DAY\",\"DRINKS_PER_DAY\"],\n",
    "    \"clin\":   [\"bmic\",\"DIABE\",\"HYPERTEN\",\"chol_rx\",\"CVD\",\"cancer\"],\n",
    "    \"scores\": [\"probable_depression\",\"ahei_total\"],  # sdoh_score later\n",
    "    \"sdoh\":   [\"unemployment2\",\"sdoh_access\",\"ins\",\"HOQ065\",\"marriage\",\"SNAP\",\"FS\"],\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for block, cols in key_groups.items():\n",
    "    cols_present = [c for c in cols if c in df.columns]\n",
    "    if not cols_present:\n",
    "        continue\n",
    "    # non-missing rate per column per cycle\n",
    "    nm = (df.groupby('SDDSRVYR', dropna=False)[cols_present]\n",
    "            .agg(lambda s: s.notna().mean()))\n",
    "    nm['block_mean'] = nm.mean(axis=1)  # average within the block\n",
    "    nm = nm.reset_index()\n",
    "    nm.insert(1, 'block', block)\n",
    "    rows.append(nm)\n",
    "\n",
    "coverage = pd.concat(rows, ignore_index=True)\n",
    "\n",
    "# 2a) Wide summary: average non-missing per block per cycle\n",
    "block_wide = (coverage.pivot(index='SDDSRVYR', columns='block', values='block_mean')\n",
    "                        .sort_index())\n",
    "print(\"\\nAverage non-missing rate per block (by cycle):\")\n",
    "display((block_wide*100).round(1))\n",
    "\n",
    "# 3) Sentinel columns\n",
    "sentinel_cols = [\"WTMEC2YR\",\"WTMEC4YR\",\"FS\",\"SNAP\",\"probable_depression\",\"ahei_total\",\"met_hr\",\"EDU\",\"ins\"]\n",
    "sentinel_cols = [c for c in sentinel_cols if c in df.columns]\n",
    "if sentinel_cols:\n",
    "    sentinel = (df.groupby('SDDSRVYR', dropna=False)[sentinel_cols]\n",
    "                  .agg(lambda s: s.notna().mean())\n",
    "                  .rename(columns=lambda c: f\"{c}_nonmiss\")\n",
    "                  .reset_index()\n",
    "                  .sort_values('SDDSRVYR'))\n",
    "    print(\"\\nSentinel column non-missing rates (by cycle):\")\n",
    "    display((sentinel.set_index('SDDSRVYR')*100).round(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1b419b-cec6-4f17-b4c2-ae50de378596",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: From 1999–2004, NHANES used a CIDI subsample (adults 20–39y), so depression data appear ~90% missing overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f718f768-1e06-4360-a30b-c4622a2a816a",
   "metadata": {},
   "source": [
    "#### 1) check missingness for all column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "68ce671c-8b78-4056-8077-52f82a9e571b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          sdmvpsu  sdmvstra  RIDAGEYR    SEX   RACE  household_size   EDU  \\\n",
      "SDDSRVYR                                                                    \n",
      "1.0         100.0     100.0     100.0  100.0  100.0           100.0  84.3   \n",
      "2.0         100.0     100.0     100.0  100.0  100.0           100.0  82.8   \n",
      "3.0         100.0     100.0     100.0  100.0  100.0           100.0  82.8   \n",
      "4.0         100.0     100.0     100.0  100.0  100.0           100.0  81.3   \n",
      "5.0         100.0     100.0     100.0  100.0  100.0           100.0  83.1   \n",
      "\n",
      "           pir  SMK_AVG   SMK  ...   ins  HOQ065  marriage  SNAP    FS  \\\n",
      "SDDSRVYR                       ...                                       \n",
      "1.0       85.1     10.0  48.8  ...  47.6    48.0      60.9   4.8  47.6   \n",
      "2.0       92.8     10.6  48.9  ...  47.7    48.1      65.7   4.2  45.8   \n",
      "3.0       94.2     11.0  49.7  ...  49.0    49.2      66.8  48.9  47.6   \n",
      "4.0       94.8     10.4  48.1  ...  45.4    47.6      64.7  47.5  47.6   \n",
      "5.0       91.2     12.9  58.4  ...  55.5    57.9      58.5  57.9  57.9   \n",
      "\n",
      "          WTINT2YR  WTMEC2YR  WTSAF2YR  WTINT4YR  WTMEC4YR  \n",
      "SDDSRVYR                                                    \n",
      "1.0          100.0     100.0     100.0       0.0       0.0  \n",
      "2.0          100.0     100.0     100.0       0.0       0.0  \n",
      "3.0          100.0     100.0     100.0       0.0       0.0  \n",
      "4.0          100.0     100.0     100.0       0.0       0.0  \n",
      "5.0          100.0     100.0     100.0       0.0       0.0  \n",
      "\n",
      "[5 rows x 38 columns]\n",
      "     SDDSRVYR               column  pct_nonmiss\n",
      "432       1.0             WTINT4YR          0.0\n",
      "444       1.0             WTMEC4YR          0.0\n",
      "372       1.0                 SNAP          4.8\n",
      "288       1.0  probable_depression          7.2\n",
      "156       1.0         CIGS_PER_DAY         10.0\n"
     ]
    }
   ],
   "source": [
    "df = df_my_cov_aligned_short.copy()\n",
    "\n",
    "# exclude identifier-like columns from audit\n",
    "IGNORE = {\"SEQN\", \"SDDSRVYR\"}   # <- add SDDSRVYR here\n",
    "cols_all = [c for c in df.columns if c not in IGNORE]\n",
    "\n",
    "# WIDE: % non-missing per cycle × column\n",
    "rate_wide = (\n",
    "    df.groupby(\"SDDSRVYR\")[cols_all]\n",
    "      .apply(lambda g: g.notna().mean().mul(100))\n",
    "      .round(1)\n",
    "      .sort_index()\n",
    ")\n",
    "\n",
    "# LONG: safe melt\n",
    "rate_long = (\n",
    "    rate_wide\n",
    "      .reset_index()                         # now SDDSRVYR is only in the index, not in columns\n",
    "      .melt(id_vars=\"SDDSRVYR\", var_name=\"column\", value_name=\"pct_nonmiss\")\n",
    "      .sort_values([\"SDDSRVYR\",\"pct_nonmiss\",\"column\"])\n",
    ")\n",
    "\n",
    "print(rate_wide.head())\n",
    "print(rate_long.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41b67b1-c59d-43ee-9987-760eb33a40cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 2) first focus on post 2018 missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "d9e62cff-f13c-4680-ade0-6634c8a474fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_my_cov_aligned_short.copy()\n",
    "POST = {12.0, 66.0}              # 2017–Mar 2020, 2021–2022\n",
    "df_post = df[df['SDDSRVYR'].isin(POST)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "c2240eb9-e817-4f80-bd84-36c14eaa7089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          sdmvpsu  sdmvstra  RIDAGEYR    SEX  RACE  household_size   EDU  \\\n",
      "SDDSRVYR                                                                   \n",
      "12.0        100.0     100.0     100.0  100.0   0.0           100.0  65.3   \n",
      "66.0        100.0     100.0     100.0  100.0   0.0             0.0  59.3   \n",
      "\n",
      "           pir  SMK_AVG  SMK  ...  ins  HOQ065  marriage  SNAP    FS  \\\n",
      "SDDSRVYR                      ...                                      \n",
      "12.0      82.9      0.0  0.0  ...  5.6     0.0       0.0   0.0   0.0   \n",
      "66.0      85.9      0.0  0.0  ...  9.4     0.0       0.0  54.5  54.9   \n",
      "\n",
      "          WTINT2YR  WTMEC2YR  WTSAF2YR  WTINT4YR  WTMEC4YR  \n",
      "SDDSRVYR                                                    \n",
      "12.0           0.0     100.0       0.0       0.0       0.0  \n",
      "66.0           0.0       0.0       0.0     100.0     100.0  \n",
      "\n",
      "[2 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "IGNORE = {'SEQN','SDDSRVYR'}\n",
    "cols_all = [c for c in df_post.columns if c not in IGNORE]\n",
    "\n",
    "rate_wide_post = (\n",
    "    df_post.groupby('SDDSRVYR')[cols_all]\n",
    "           .apply(lambda g: g.notna().mean().mul(100))\n",
    "           .round(1)\n",
    "           .sort_index()\n",
    ")\n",
    "print(rate_wide_post.head())   # wide table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "630884eb-aa5b-4905-89fa-57d0f0b85c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with 0% non-missing by cycle:\n",
      " SDDSRVYR         12.0   66.0\n",
      "RACE             True   True\n",
      "household_size  False   True\n",
      "SMK_AVG          True   True\n",
      "SMK              True   True\n",
      "SMK_STATUS       True   True\n",
      "CIGS_PER_DAY     True   True\n",
      "PACK_YEARS       True   True\n",
      "FORMER_SMOKER    True   True\n",
      "DRINKS_PER_DAY   True   True\n",
      "bmic             True   True\n",
      "DIABE            True   True\n",
      "HYPERTEN         True   True\n",
      "chol_rx          True   True\n",
      "CVD              True   True\n",
      "cancer           True   True\n",
      "ahei_total       True   True\n",
      "sdoh_access     False   True\n",
      "HOQ065           True   True\n",
      "marriage         True   True\n",
      "SNAP             True  False\n",
      "FS               True  False\n",
      "WTINT2YR         True   True\n",
      "WTMEC2YR        False   True\n",
      "WTSAF2YR         True   True\n",
      "WTINT4YR         True  False\n",
      "WTMEC4YR         True  False\n",
      "\n",
      "Consistently 0% (both 12 & 66):\n",
      " ['RACE', 'SMK_AVG', 'SMK', 'SMK_STATUS', 'CIGS_PER_DAY', 'PACK_YEARS', 'FORMER_SMOKER', 'DRINKS_PER_DAY', 'bmic', 'DIABE', 'HYPERTEN', 'chol_rx', 'CVD', 'cancer', 'ahei_total', 'HOQ065', 'marriage', 'WTINT2YR', 'WTSAF2YR']\n",
      "\n",
      "Columns <10% non-missing by cycle:\n",
      " SDDSRVYR         12.0   66.0\n",
      "RACE             True   True\n",
      "household_size  False   True\n",
      "SMK_AVG          True   True\n",
      "SMK              True   True\n",
      "SMK_STATUS       True   True\n",
      "CIGS_PER_DAY     True   True\n",
      "PACK_YEARS       True   True\n",
      "FORMER_SMOKER    True   True\n",
      "DRINKS_PER_DAY   True   True\n",
      "bmic             True   True\n",
      "DIABE            True   True\n",
      "HYPERTEN         True   True\n",
      "chol_rx          True   True\n",
      "CVD              True   True\n",
      "cancer           True   True\n",
      "ahei_total       True   True\n",
      "sdoh_access     False   True\n",
      "ins              True   True\n",
      "HOQ065           True   True\n",
      "marriage         True   True\n",
      "SNAP             True  False\n",
      "FS               True  False\n",
      "WTINT2YR         True   True\n",
      "WTMEC2YR        False   True\n",
      "WTSAF2YR         True   True\n",
      "WTINT4YR         True  False\n",
      "WTMEC4YR         True  False\n",
      "\n",
      "Consistently <10% (both 12 & 66):\n",
      " ['RACE', 'SMK_AVG', 'SMK', 'SMK_STATUS', 'CIGS_PER_DAY', 'PACK_YEARS', 'FORMER_SMOKER', 'DRINKS_PER_DAY', 'bmic', 'DIABE', 'HYPERTEN', 'chol_rx', 'CVD', 'cancer', 'ahei_total', 'ins', 'HOQ065', 'marriage', 'WTINT2YR', 'WTSAF2YR']\n"
     ]
    }
   ],
   "source": [
    "# 0% non-missing per cycle\n",
    "zero_mask = rate_wide_post.eq(0.0)\n",
    "print(\"Columns with 0% non-missing by cycle:\\n\", zero_mask.loc[:, zero_mask.any()].T)\n",
    "\n",
    "# Consistently 0% across ALL post-2018 cycles\n",
    "consistently_zero = zero_mask.all(axis=0)\n",
    "print(\"\\nConsistently 0% (both 12 & 66):\\n\", consistently_zero[consistently_zero].index.tolist())\n",
    "\n",
    "# Low coverage threshold (tune as needed)\n",
    "THRESH = 10.0\n",
    "low_mask = rate_wide_post.lt(THRESH)\n",
    "print(\"\\nColumns <10% non-missing by cycle:\\n\", low_mask.loc[:, low_mask.any()].T)\n",
    "\n",
    "# Consistently low across ALL post-2018 cycles\n",
    "consistently_low = low_mask.all(axis=0)\n",
    "print(\"\\nConsistently <10% (both 12 & 66):\\n\", consistently_low[consistently_low].index.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81342628-0714-49c9-b17d-5e0b4073ac51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84031dff-c3e7-4e1a-9f14-3aeff2147ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0cfe20-7995-46d2-9307-d0e632f9400d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "761d8d86-9cfe-4106-a0a2-129603d4a831",
   "metadata": {},
   "source": [
    "## Fetch missing post 2018   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "ccc72500-e807-4b89-a189-d7ebeaacde96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, requests, pandas as pd\n",
    "\n",
    "def fetch_xpt(year_folder, filebase):  # year_folder: \"2017\" or \"2021\"\n",
    "    url = f\"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/{year_folder}/DataFiles/{filebase}.xpt\"\n",
    "    r = requests.get(url); r.raise_for_status()\n",
    "    df = pd.read_sas(io.BytesIO(r.content), format=\"xport\", encoding=\"latin1\")\n",
    "    df.columns = [c.upper() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "# Examples:\n",
    "prepandemic_demo = fetch_xpt(\"2017\", \"P_DEMO\")   # 2017–Mar 2020 combined (SDDSRVYR=66). :contentReference[oaicite:3]{index=3}\n",
    "prepandemic_hiq  = fetch_xpt(\"2017\", \"P_HIQ\")    # Health insurance, 2017–Mar 2020. :contentReference[oaicite:4]{index=4}\n",
    "demographics_21  = fetch_xpt(\"2021\", \"DEMO_L\")   # 2021–2023. :contentReference[oaicite:5]{index=5}\n",
    "hiq_21           = fetch_xpt(\"2021\", \"HIQ_L\")    # 2021–2023. :contentReference[oaicite:6]{index=6}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433d59c2-6786-4d68-a6ba-d864fac2549f",
   "metadata": {},
   "source": [
    "## Fetch missing: weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "34b91595-e0f8-4131-a0bf-96963508fb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_my_cov_aligned_short.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "1bd5845a-5480-4fc7-a7b9-dd04cebcbb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SEQN', 'SDDSRVYR', 'sdmvpsu', 'sdmvstra', 'RIDAGEYR', 'SEX', 'RACE',\n",
       "       'household_size', 'EDU', 'pir', 'SMK_AVG', 'SMK', 'ALCG2', 'met_hr',\n",
       "       'SMK_STATUS', 'CIGS_PER_DAY', 'PACK_YEARS', 'FORMER_SMOKER',\n",
       "       'DRINKS_PER_DAY', 'ALCOHOL_CAT', 'bmic', 'DIABE', 'HYPERTEN', 'chol_rx',\n",
       "       'CVD', 'cancer', 'probable_depression', 'ahei_total', 'unemployment2',\n",
       "       'sdoh_access', 'ins', 'HOQ065', 'marriage', 'SNAP', 'FS', 'WTINT2YR',\n",
       "       'WTMEC2YR', 'WTSAF2YR', 'WTINT4YR', 'WTMEC4YR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "d9c50a07-84d7-41ca-8c57-1d5c398f7fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-year weight non-missing (%) by cycle:\n",
      "           WTINT4YR  WTMEC4YR\n",
      "SDDSRVYR                    \n",
      "1.0            0.0       0.0\n",
      "2.0            0.0       0.0\n",
      "3.0            0.0       0.0\n",
      "4.0            0.0       0.0\n",
      "5.0            0.0       0.0\n",
      "6.0            0.0       0.0\n",
      "7.0            0.0       0.0\n",
      "8.0            0.0       0.0\n",
      "9.0            0.0       0.0\n",
      "10.0           0.0       0.0\n",
      "12.0           0.0       0.0\n",
      "66.0         100.0     100.0\n"
     ]
    }
   ],
   "source": [
    "df = df_my_cov_aligned_short.copy()\n",
    "\n",
    "cov4 = (df.groupby(\"SDDSRVYR\")[[\"WTINT4YR\",\"WTMEC4YR\"]]\n",
    "          .apply(lambda g: g.notna().mean().mul(100).round(1)))\n",
    "print(\"4-year weight non-missing (%) by cycle:\\n\", cov4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "40f4f16a-3017-45b4-b76a-1dfce6f97d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent non-missing by cycle (%):\n",
      "           WTINT2YR  WTMEC2YR  WTSAF2YR\n",
      "SDDSRVYR                              \n",
      "1.0          100.0     100.0     100.0\n",
      "2.0          100.0     100.0     100.0\n",
      "3.0          100.0     100.0     100.0\n",
      "4.0          100.0     100.0     100.0\n",
      "5.0          100.0     100.0     100.0\n",
      "6.0          100.0     100.0     100.0\n",
      "7.0          100.0     100.0     100.0\n",
      "8.0          100.0     100.0     100.0\n",
      "9.0          100.0     100.0     100.0\n",
      "10.0         100.0     100.0     100.0\n",
      "12.0           0.0     100.0       0.0\n",
      "66.0           0.0       0.0       0.0\n",
      "\n",
      "Non-missing counts and total N per cycle:\n",
      "           WTINT2YR  WTMEC2YR  WTSAF2YR      N\n",
      "SDDSRVYR                                     \n",
      "1.0           9965      9965      9965   9965\n",
      "2.0          11039     11039     11039  11039\n",
      "3.0          10122     10122     10122  10122\n",
      "4.0          10348     10348     10348  10348\n",
      "5.0          10149     10149     10149  10149\n",
      "6.0          10537     10537     10537  10537\n",
      "7.0           9756      9756      9756   9756\n",
      "8.0          10175     10175     10175  10175\n",
      "9.0           9971      9971      9971   9971\n",
      "10.0          9254      9254      9254   9254\n",
      "12.0             0     11933         0  11933\n",
      "66.0             0         0         0  15560\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = df_my_cov_aligned_short.copy()\n",
    "cols = [\"WTINT2YR\",\"WTMEC2YR\",\"WTSAF2YR\"]\n",
    "present = [c for c in cols if c in df.columns]\n",
    "\n",
    "# % non-missing by cycle\n",
    "pct_nonmiss = (\n",
    "    df.groupby(\"SDDSRVYR\")[present]\n",
    "      .apply(lambda g: g.notna().mean().mul(100))\n",
    "      .round(1)\n",
    "      .sort_index()\n",
    ")\n",
    "print(\"Percent non-missing by cycle (%):\\n\", pct_nonmiss)\n",
    "\n",
    "# (optional) counts non-missing + total N per cycle\n",
    "nonmiss_n = df.groupby(\"SDDSRVYR\")[present].apply(lambda g: g.notna().sum()).astype(\"Int64\")\n",
    "N = df.groupby(\"SDDSRVYR\").size().rename(\"N\")\n",
    "print(\"\\nNon-missing counts and total N per cycle:\\n\", nonmiss_n.join(N))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62df218b-d073-4d9c-991b-4bf516aae171",
   "metadata": {},
   "source": [
    "#### fetch weight from demo for post 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "4276916f-7fb6-45e3-b91e-3fd568e0d2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-fetch coverage (%):\n",
      "           WTINT2YR  WTMEC2YR  WTPH2YR  WTSAF2YR  WTINTPRP  WTMECPRP  WTSAFPRP  \\\n",
      "SDDSRVYR                                                                        \n",
      "1.0          100.0      93.1      0.0      86.4       0.0       0.0       0.0   \n",
      "2.0          100.0      94.9      0.0      88.2       0.0       0.0       0.0   \n",
      "3.0          100.0      95.3      0.0      88.2       0.0       0.0       0.0   \n",
      "4.0          100.0      96.2      0.0      87.0       0.0       0.0       0.0   \n",
      "5.0          100.0      96.2      0.0      86.2       0.0       0.0       0.0   \n",
      "6.0          100.0      97.3      0.0      87.7       0.0       0.0       0.0   \n",
      "7.0          100.0      95.7      0.0      88.1       0.0       0.0       0.0   \n",
      "8.0          100.0      96.4      0.0      87.9       0.0       0.0       0.0   \n",
      "9.0          100.0      95.7      0.0      87.1       0.0       0.0       0.0   \n",
      "10.0         100.0      94.1      0.0      88.0       0.0       0.0       0.0   \n",
      "12.0         100.0     100.0     67.6      33.5       0.0       0.0       0.0   \n",
      "66.0           0.0       0.0      0.0       0.0     100.0     100.0      32.7   \n",
      "\n",
      "          wt_int  wt_mec  wt_fasting  wt_phlebotomy  \n",
      "SDDSRVYR                                             \n",
      "1.0        100.0    93.1        86.4            0.0  \n",
      "2.0        100.0    94.9        88.2            0.0  \n",
      "3.0        100.0    95.3        88.2            0.0  \n",
      "4.0        100.0    96.2        87.0            0.0  \n",
      "5.0        100.0    96.2        86.2            0.0  \n",
      "6.0        100.0    97.3        87.7            0.0  \n",
      "7.0        100.0    95.7        88.1            0.0  \n",
      "8.0        100.0    96.4        87.9            0.0  \n",
      "9.0        100.0    95.7        87.1            0.0  \n",
      "10.0       100.0    94.1        88.0            0.0  \n",
      "12.0       100.0   100.0        33.5           67.6  \n",
      "66.0       100.0   100.0        32.7            0.0  \n"
     ]
    }
   ],
   "source": [
    "import io, requests, pandas as pd, numpy as np\n",
    "\n",
    "def fetch_xpt(year_folder, filebase):\n",
    "    url = f\"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/{year_folder}/DataFiles/{filebase}.xpt\"\n",
    "    r = requests.get(url); r.raise_for_status()\n",
    "    out = pd.read_sas(io.BytesIO(r.content), format=\"xport\", encoding=\"latin1\")\n",
    "    out.columns = [c.upper() for c in out.columns]\n",
    "    out[\"SEQN\"] = pd.to_numeric(out[\"SEQN\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    return out\n",
    "\n",
    "def safe_cov(df, cols):\n",
    "    have = [c for c in cols if c in df.columns]\n",
    "    if not have: \n",
    "        return pd.DataFrame()\n",
    "    return (df.groupby(\"SDDSRVYR\")[have]\n",
    "              .apply(lambda g: g.notna().mean().mul(100).round(1))\n",
    "              .sort_index())\n",
    "\n",
    "df = df_my_cov_aligned_short.copy()\n",
    "df[\"SEQN\"] = pd.to_numeric(df[\"SEQN\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# ---- cycle 12 (Aug 2021–Aug 2023): DEMO_L -> WTINT2YR/WTMEC2YR ; lab file -> WTPH2YR ; fasting labs -> WTSAF2YR\n",
    "mask12 = df[\"SDDSRVYR\"].eq(12.0)\n",
    "\n",
    "# core interview/exam weights\n",
    "demo12 = fetch_xpt(\"2021\",\"DEMO_L\").set_index(\"SEQN\")\n",
    "for col in [\"WTINT2YR\",\"WTMEC2YR\"]:\n",
    "    if col in demo12:\n",
    "        df.loc[mask12, col] = df.loc[mask12, \"SEQN\"].map(demo12[col])\n",
    "\n",
    "# phlebotomy weight (WTPH2YR) is included in blood lab files (e.g., HDL_L, TCHOL_L, CBC_L)\n",
    "WTPH2YR_map = None\n",
    "for base in [\"HDL_L\", \"TCHOL_L\", \"CBC_L\", \"GHB_L\"]:\n",
    "    try:\n",
    "        lab = fetch_xpt(\"2021\", base)\n",
    "        if \"WTPH2YR\" in lab.columns:\n",
    "            WTPH2YR_map = lab.set_index(\"SEQN\")[\"WTPH2YR\"]\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] {base} fetch failed: {e}\")\n",
    "\n",
    "if WTPH2YR_map is not None:\n",
    "    df.loc[mask12, \"WTPH2YR\"] = df.loc[mask12, \"SEQN\"].map(WTPH2YR_map)\n",
    "\n",
    "# fasting weight (WTSAF2YR) lives in fasting lab components (GLU_L and/or INS_L); NOT in DEMO/FASTQX_L\n",
    "WTSAF2YR_map = None\n",
    "for base in [\"GLU_L\", \"INS_L\"]:\n",
    "    try:\n",
    "        lab = fetch_xpt(\"2021\", base)\n",
    "        if \"WTSAF2YR\" in lab.columns:\n",
    "            WTSAF2YR_map = lab.set_index(\"SEQN\")[\"WTSAF2YR\"]\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] {base} fetch failed: {e}\")\n",
    "\n",
    "if WTSAF2YR_map is not None:\n",
    "    df.loc[mask12, \"WTSAF2YR\"] = df.loc[mask12, \"SEQN\"].map(WTSAF2YR_map)\n",
    "\n",
    "# ---- cycle 66 (2017–Mar 2020 pre-pandemic): P_DEMO -> WTINTPRP/WTMECPRP ; fasting lab -> WTSAFPRP\n",
    "mask66 = df[\"SDDSRVYR\"].eq(66.0)\n",
    "demo66 = fetch_xpt(\"2017\",\"P_DEMO\").set_index(\"SEQN\")\n",
    "for col in [\"WTINTPRP\",\"WTMECPRP\"]:\n",
    "    if col in demo66:\n",
    "        df.loc[mask66, col] = df.loc[mask66, \"SEQN\"].map(demo66[col])\n",
    "\n",
    "WTSAFPRP_map = None\n",
    "for base in [\"P_GLU\", \"P_INS\", \"P_TRIGLY\"]:\n",
    "    try:\n",
    "        lab = fetch_xpt(\"2017\", base)\n",
    "        if \"WTSAFPRP\" in lab.columns:\n",
    "            WTSAFPRP_map = lab.set_index(\"SEQN\")[\"WTSAFPRP\"]\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] {base} fetch failed: {e}\")\n",
    "\n",
    "if WTSAFPRP_map is not None:\n",
    "    df.loc[mask66, \"WTSAFPRP\"] = df.loc[mask66, \"SEQN\"].map(WTSAFPRP_map)\n",
    "\n",
    "# ---- treat 0 weights as missing (eligible but no specimen)\n",
    "for w in [\"WTMEC2YR\",\"WTSAF2YR\",\"WTPH2YR\",\"WTMECPRP\",\"WTSAFPRP\"]:\n",
    "    if w in df.columns:\n",
    "        df[w] = df[w].mask(df[w].eq(0))\n",
    "\n",
    "# ---- unified convenience weights\n",
    "df[\"wt_int\"]        = np.where(mask66, df.get(\"WTINTPRP\"),  df.get(\"WTINT2YR\"))\n",
    "df[\"wt_mec\"]        = np.where(mask66, df.get(\"WTMECPRP\"),  df.get(\"WTMEC2YR\"))\n",
    "df[\"wt_fasting\"]    = np.where(mask66, df.get(\"WTSAFPRP\"),  df.get(\"WTSAF2YR\"))\n",
    "df[\"wt_phlebotomy\"] = np.where(mask12, df.get(\"WTPH2YR\"),   np.nan)   # only 2021–2023\n",
    "\n",
    "# ---- quick coverage check\n",
    "print(\"Post-fetch coverage (%):\\n\",\n",
    "      safe_cov(df, [\"WTINT2YR\",\"WTMEC2YR\",\"WTPH2YR\",\"WTSAF2YR\",\n",
    "                    \"WTINTPRP\",\"WTMECPRP\",\"WTSAFPRP\",\n",
    "                    \"wt_int\",\"wt_mec\",\"wt_fasting\",\"wt_phlebotomy\"]))\n",
    "\n",
    "df_my_cov_aligned_short = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0f8ebb-ce10-4c21-8c92-22c4d7b09ac8",
   "metadata": {},
   "source": [
    "#### sanity check for weight fetching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "901c7ab3-8539-4a8b-b451-89b3e97203e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[note] wt_fasting present but no fasting analytes detected in frame.\n"
     ]
    }
   ],
   "source": [
    "# sanity warnings\n",
    "if (df[\"SDDSRVYR\"].eq(12.0) & df[\"wt_phlebotomy\"].isna()).mean() > 0.4:\n",
    "    print(\"[warn] Many 2021–23 rows lack WTPH2YR. Make sure you merged from a blood lab used in your sample.\")\n",
    "\n",
    "# example: ensure fasting weight used only when a fasting analyte is present\n",
    "fasting_vars_present = any(c in df.columns for c in [\"GLU\", \"INS\", \"TRIGLY\"])  # adapt to your var names\n",
    "if not fasting_vars_present and df[\"wt_fasting\"].notna().any():\n",
    "    print(\"[note] wt_fasting present but no fasting analytes detected in frame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f60837e-c86c-4acf-beae-891252aa2619",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f03742e7-5df3-4a16-8bb6-6783396e6834",
   "metadata": {},
   "source": [
    "## Fetch missing: ins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6169fa4a-26f2-49f4-a430-68e4625c7d6f",
   "metadata": {},
   "source": [
    "#### Step 1 — pre-check coverage for ins (cycles 12 & 66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "e82e7570-8b0e-4eaf-8182-7eb4fa313204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before fill — % non-missing 'ins':\n",
      "SDDSRVYR\n",
      "12.0    5.6\n",
      "66.0    9.4\n",
      "Name: ins, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = df_my_cov_aligned_short.copy()\n",
    "\n",
    "POST = {12.0, 66.0}\n",
    "def pct_nonmiss(d, col): \n",
    "    return d.groupby(\"SDDSRVYR\")[col].apply(lambda s: s.notna().mean()*100).round(1)\n",
    "\n",
    "print(\"Before fill — % non-missing 'ins':\")\n",
    "print(pct_nonmiss(df[df.SDDSRVYR.isin(POST)], \"ins\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "f8b18dad-e22e-473a-9b14-3a217bc83797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         <NA>\n",
       "1            1\n",
       "2         <NA>\n",
       "3         <NA>\n",
       "4            1\n",
       "          ... \n",
       "128804    <NA>\n",
       "128805    <NA>\n",
       "128806    <NA>\n",
       "128807    <NA>\n",
       "128808    <NA>\n",
       "Name: ins, Length: 128809, dtype: Int64"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_my_cov_aligned_short[\"ins\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22ad2e2-c927-4fed-b134-a163e4af728b",
   "metadata": {},
   "source": [
    "#### Step 2 helper: fetch + standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "094b725c-3454-4006-bca5-2d552ec31f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, io, requests\n",
    "\n",
    "def fetch_xpt(year_folder: str, filebase: str) -> pd.DataFrame:\n",
    "    url = f\"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/{year_folder}/DataFiles/{filebase}.xpt\"\n",
    "    r = requests.get(url); r.raise_for_status()\n",
    "    out = pd.read_sas(io.BytesIO(r.content), format=\"xport\", encoding=\"latin1\")\n",
    "    out.columns = [c.upper() for c in out.columns]\n",
    "    out[\"SEQN\"] = pd.to_numeric(out[\"SEQN\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    return out\n",
    "\n",
    "def choose_hiq_source_for_cycle(df, cycle):\n",
    "    candidates = [(\"2017\",\"P_HIQ\"), (\"2021\",\"HIQ_L\")]\n",
    "    sel = df[\"SDDSRVYR\"].eq(float(cycle))\n",
    "    seqn_cycle = pd.Index(df.loc[sel, \"SEQN\"].dropna().astype(\"Int64\"))\n",
    "    best, best_overlap = None, -1\n",
    "    for yr, fb in candidates:\n",
    "        try:\n",
    "            hiq = fetch_xpt(yr, fb)\n",
    "            ov = len(seqn_cycle.intersection(hiq[\"SEQN\"]))\n",
    "            if ov > best_overlap:\n",
    "                best, best_overlap = (yr, fb, hiq), ov\n",
    "        except Exception as e:\n",
    "            print(f\"[warn] {yr}/{fb} fetch failed: {e}\")\n",
    "    if best is None or best_overlap == 0:\n",
    "        print(f\"[cycle {cycle}] No matching HIQ (overlap=0).\")\n",
    "        return None\n",
    "    yr, fb, hiq = best\n",
    "    print(f\"[cycle {cycle}] Using {yr}/{fb} (overlap={best_overlap})\")\n",
    "    return hiq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb887aa-dc44-41fb-aef7-996931e20efd",
   "metadata": {},
   "source": [
    "#### Step 3 — overwrite ins for a cycle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "a317e30b-3ce9-4cfc-a0c3-61e18bc76d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overwrite_ins_for_cycle(df_in: pd.DataFrame, cycle: int) -> pd.DataFrame:\n",
    "    df_out = df_in.copy()\n",
    "    df_out[\"SEQN\"] = pd.to_numeric(df_out[\"SEQN\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    if \"ins\" not in df_out: df_out[\"ins\"] = pd.NA\n",
    "\n",
    "    hiq = choose_hiq_source_for_cycle(df_out, cycle)\n",
    "    if hiq is None or \"HIQ011\" not in hiq.columns: \n",
    "        return df_out\n",
    "\n",
    "    # Map HIQ011 -> 1/0 (leave others as NA)\n",
    "    src = hiq.set_index(\"SEQN\")[\"HIQ011\"].map({1:1, 2:0}).astype(\"Int8\")\n",
    "\n",
    "    sel_idx = df_out.index[df_out[\"SDDSRVYR\"].eq(float(cycle))]\n",
    "    # backup for audit\n",
    "    df_out.loc[sel_idx, \"ins_prev\"] = df_out.loc[sel_idx, \"ins\"].astype(\"Int8\")\n",
    "\n",
    "    # aligned overwrite for the whole cycle\n",
    "    mapped = df_out.loc[sel_idx, \"SEQN\"].map(src)\n",
    "    df_out.loc[sel_idx, \"ins\"] = mapped.values\n",
    "\n",
    "    # compact dtype\n",
    "    try: df_out[\"ins\"] = df_out[\"ins\"].astype(\"Int8\")\n",
    "    except: pass\n",
    "\n",
    "    # tiny audit\n",
    "    before = df_in.loc[sel_idx, \"ins\"].notna().mean()*100\n",
    "    after  = df_out.loc[sel_idx, \"ins\"].notna().mean()*100\n",
    "    changed = (df_out.loc[sel_idx, \"ins\"] != df_out.loc[sel_idx, \"ins_prev\"]).sum()\n",
    "\n",
    "    # with this NA-safe version:\n",
    "    changed = (df_out.loc[sel_idx, \"ins\"].fillna(-1) !=\n",
    "           df_out.loc[sel_idx, \"ins_prev\"].fillna(-1)).sum()\n",
    "    print(f\"[cycle {cycle}] non-miss ins: {before:.1f}% → {after:.1f}% | rows changed: {changed}\")\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7edeb45-64e3-4f3b-800c-231f89f878de",
   "metadata": {},
   "source": [
    "#### Step 4 — run for 12 and 66 + quick check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "a2916ea6-1f21-44ac-aa68-0489630d4a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: SDDSRVYR\n",
      "12.0    5.6\n",
      "66.0    9.4\n",
      "Name: ins, dtype: float64\n",
      "[cycle 12] Using 2021/HIQ_L (overlap=11933)\n",
      "[cycle 12] non-miss ins: 5.6% → 99.5% | rows changed: 11203\n",
      "[cycle 66] Using 2017/P_HIQ (overlap=15560)\n",
      "[cycle 66] non-miss ins: 9.4% → 99.8% | rows changed: 14056\n",
      "After : SDDSRVYR\n",
      "12.0    99.5\n",
      "66.0    99.8\n",
      "Name: ins, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def pct_nonmiss(d, col): \n",
    "    return d.groupby(\"SDDSRVYR\")[col].apply(lambda s: s.notna().mean()*100).round(1)\n",
    "\n",
    "df = df_my_cov_aligned_short.copy()\n",
    "print(\"Before:\", pct_nonmiss(df[df.SDDSRVYR.isin([12.0,66.0])], \"ins\"))\n",
    "\n",
    "df = overwrite_ins_for_cycle(df, 12)\n",
    "df = overwrite_ins_for_cycle(df, 66)\n",
    "\n",
    "print(\"After :\", pct_nonmiss(df[df.SDDSRVYR.isin([12.0,66.0])], \"ins\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a6445d-8883-49b6-a71c-5cef3018b1cf",
   "metadata": {},
   "source": [
    "#### Step 5 - merge back "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "e4b4b16f-add3-400e-84e7-84db4c2a0b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cycle 12] Using 2021/HIQ_L (overlap=11933)\n",
      "[cycle 12] non-miss ins: 5.6% → 99.5% | rows changed: 11203\n",
      "[cycle 66] Using 2017/P_HIQ (overlap=15560)\n",
      "[cycle 66] non-miss ins: 9.4% → 99.8% | rows changed: 14056\n",
      "SDDSRVYR\n",
      "12.0    99.5\n",
      "66.0    99.8\n",
      "Name: ins, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1) fill on a working copy using your overwrite_ins_for_cycle(...)\n",
    "df_ins = df_my_cov_aligned_short.copy()\n",
    "for cyc in (12, 66):\n",
    "    df_ins = overwrite_ins_for_cycle(df_ins, cyc)  # overwrites entire cycle\n",
    "\n",
    "# 2) merge filled values back into your main df\n",
    "mask = df_my_cov_aligned_short['SDDSRVYR'].isin([12.0, 66.0])\n",
    "df_my_cov_aligned_short.loc[mask, 'ins'] = df_ins.loc[mask, 'ins'].astype('Int8')\n",
    "\n",
    "# (optional) drop helper audit column if it exists\n",
    "df_my_cov_aligned_short.drop(columns=['ins_prev'], errors='ignore', inplace=True)\n",
    "\n",
    "# 3) quick check\n",
    "print(pct_nonmiss(df_my_cov_aligned_short[df_my_cov_aligned_short.SDDSRVYR.isin([12.0,66.0])], \"ins\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad5ce0a-433e-48c2-9e07-8008773fdba7",
   "metadata": {},
   "source": [
    "#### step 6 check merged ins result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "5cc8a866-fea0-4c08-b697-1b17119aa1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted % insured by cycle:\n",
      " SDDSRVYR\n",
      "1.0     69.8\n",
      "2.0     72.4\n",
      "3.0     68.4\n",
      "4.0     67.0\n",
      "5.0     63.4\n",
      "6.0     61.1\n",
      "7.0     63.1\n",
      "8.0     66.8\n",
      "9.0     70.0\n",
      "10.0    70.5\n",
      "12.0    92.7\n",
      "66.0    88.1\n",
      "Name: pct_ins_unweighted, dtype: Float64\n",
      "\n",
      "Weighted % insured by cycle (wt_int):\n",
      " SDDSRVYR\n",
      "1.0     76.4\n",
      "2.0     77.6\n",
      "3.0     75.2\n",
      "4.0     75.0\n",
      "5.0     74.1\n",
      "6.0     72.0\n",
      "7.0     71.9\n",
      "8.0     74.0\n",
      "9.0     79.2\n",
      "10.0    77.0\n",
      "12.0    91.7\n",
      "66.0    88.6\n",
      "Name: pct_ins_wt_wt_int, dtype: float64\n",
      "\n",
      "Weighted % insured by cycle — adults 18+ (wt_int):\n",
      " SDDSRVYR\n",
      "1.0     76.4\n",
      "2.0     77.6\n",
      "3.0     75.2\n",
      "4.0     75.0\n",
      "5.0     74.1\n",
      "6.0     72.0\n",
      "7.0     71.9\n",
      "8.0     74.0\n",
      "9.0     79.2\n",
      "10.0    77.0\n",
      "12.0    90.4\n",
      "66.0    86.7\n",
      "Name: pct_ins_wt_wt_int, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = df_my_cov_aligned_short.copy()\n",
    "\n",
    "def pct_ins_by_cycle(df, weight_col=None, mask=None):\n",
    "    # keep valid 0/1 ins\n",
    "    base = df.loc[df['ins'].isin([0, 1])].copy()\n",
    "\n",
    "    # align mask to base index if provided\n",
    "    if mask is not None:\n",
    "        mask_aligned = pd.Series(mask, index=df.index).reindex(base.index, fill_value=False)\n",
    "        base = base.loc[mask_aligned]\n",
    "\n",
    "    if weight_col is None:\n",
    "        out = (base.groupby('SDDSRVYR', observed=True)['ins']\n",
    "                   .mean()\n",
    "                   .mul(100)\n",
    "                   .round(1)\n",
    "                   .rename('pct_ins_unweighted'))\n",
    "        return out\n",
    "\n",
    "    def wmean(g):\n",
    "        if weight_col not in g:\n",
    "            return np.nan\n",
    "        w = g[weight_col]\n",
    "        x = g['ins'].astype(float)\n",
    "        m = x.notna() & w.notna() & (w > 0)\n",
    "        if not m.any():\n",
    "            return np.nan\n",
    "        return np.average(x[m], weights=w[m]) * 100.0\n",
    "\n",
    "    out = (base.groupby('SDDSRVYR', observed=True)\n",
    "               .apply(wmean, include_groups=False)\n",
    "               .round(1)\n",
    "               .rename(f'pct_ins_wt_{weight_col}'))\n",
    "    return out\n",
    "\n",
    "# Unweighted\n",
    "unw = pct_ins_by_cycle(df)\n",
    "\n",
    "# Interview-weighted using your unified weight\n",
    "wt = pct_ins_by_cycle(df, weight_col='wt_int')\n",
    "\n",
    "# Adults only\n",
    "adults_mask = df['RIDAGEYR'] >= 18\n",
    "wt_adult = pct_ins_by_cycle(df, weight_col='wt_int', mask=adults_mask)\n",
    "\n",
    "print(\"Unweighted % insured by cycle:\\n\", unw)\n",
    "print(\"\\nWeighted % insured by cycle (wt_int):\\n\", wt)\n",
    "print(\"\\nWeighted % insured by cycle — adults 18+ (wt_int):\\n\", wt_adult)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db96fa2a-7aa2-46f4-8150-c095960d5180",
   "metadata": {},
   "source": [
    "## Fetch missing: marriage from DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "b03f0ea6-9ef0-40d2-a8d3-a35cd6155b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, io, requests\n",
    "\n",
    "def fetch_xpt(year_folder: str, filebase: str) -> pd.DataFrame:\n",
    "    url = f\"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/{year_folder}/DataFiles/{filebase}.xpt\"\n",
    "    r = requests.get(url); r.raise_for_status()\n",
    "    out = pd.read_sas(io.BytesIO(r.content), format=\"xport\", encoding=\"latin1\")\n",
    "    out.columns = [c.upper() for c in out.columns]\n",
    "    out[\"SEQN\"] = pd.to_numeric(out[\"SEQN\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    return out\n",
    "\n",
    "def choose_demo_source_for_cycle(df, cycle):\n",
    "    candidates = [(\"2017\",\"P_DEMO\"), (\"2021\",\"DEMO_L\")]  # pre-pandemic vs 2021–22\n",
    "    seqn_cycle = pd.Index(df.loc[df[\"SDDSRVYR\"].eq(float(cycle)), \"SEQN\"].dropna().astype(\"Int64\"))\n",
    "    best, best_overlap = None, -1\n",
    "    for yr, fb in candidates:\n",
    "        try:\n",
    "            demo = fetch_xpt(yr, fb)\n",
    "            ov = len(seqn_cycle.intersection(demo[\"SEQN\"]))\n",
    "            if ov > best_overlap:\n",
    "                best, best_overlap = (yr, fb, demo), ov\n",
    "        except Exception as e:\n",
    "            print(f\"[warn] {yr}/{fb} fetch failed: {e}\")\n",
    "    if best is None or best_overlap == 0:\n",
    "        print(f\"[cycle {cycle}] No matching DEMO (overlap=0).\"); return None\n",
    "    yr, fb, demo = best\n",
    "    print(f\"[cycle {cycle}] Using {yr}/{fb} (overlap={best_overlap})\")\n",
    "    return demo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff8692b-f351-4132-a3da-469e1fdead3f",
   "metadata": {},
   "source": [
    "#### Step 1 — helpers (fetch + choose correct DEMO file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "4ff2827f-6ad9-4ecb-8204-4342c52b4822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# --- helper: pull marital status from a DEMO file, tolerant to name changes\n",
    "def get_marriage_series(year_folder: str, demo_file: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Returns a Series of marital status indexed by SEQN from the requested DEMO file.\n",
    "    Tries common NHANES column names across vintages.\n",
    "    \"\"\"\n",
    "    demo = fetch_xpt(year_folder, demo_file).set_index(\"SEQN\")\n",
    "    for cand in [\"DMDMARTZ\", \"P_MARITL\", \"DMDMARTL\", \"MARITALZ\", \"MARITAL\"]:\n",
    "        if cand in demo.columns:\n",
    "            s = pd.to_numeric(demo[cand], errors=\"coerce\").astype(\"Int64\")\n",
    "            s.name = cand\n",
    "            return s\n",
    "    raise KeyError(f\"No marital-status column found in {year_folder}/{demo_file}.xpt\")\n",
    "\n",
    "def overwrite_marriage_for_cycle(df_in: pd.DataFrame,\n",
    "                                 cycle_code: int,\n",
    "                                 year_folder: str,\n",
    "                                 demo_file: str,\n",
    "                                 add_labels: bool = True,\n",
    "                                 keep_prev: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    HARD OVERWRITE: replace ALL rows' `marriage` for SDDSRVYR == cycle_code\n",
    "    with codes from DEMO (joined on SEQN). Keeps 77/99 as-is.\n",
    "    \"\"\"\n",
    "    df = df_in.copy()\n",
    "    df[\"SEQN\"] = pd.to_numeric(df[\"SEQN\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # ensure target column exists\n",
    "    if \"marriage\" not in df.columns:\n",
    "        df[\"marriage\"] = pd.Series(pd.NA, index=df.index, dtype=\"Int64\")\n",
    "\n",
    "    mask = df[\"SDDSRVYR\"].eq(float(cycle_code))\n",
    "    idx = df.index[mask]\n",
    "\n",
    "    before = df.loc[idx, \"marriage\"].notna().mean() * 100\n",
    "    if keep_prev:\n",
    "        df.loc[idx, \"marriage_prev\"] = df.loc[idx, \"marriage\"]\n",
    "\n",
    "    # source from DEMO\n",
    "    src = get_marriage_series(year_folder, demo_file)  # Int64, indexed by SEQN\n",
    "    src_col = src.name\n",
    "    seqn = df.loc[idx, \"SEQN\"]\n",
    "    overlap = seqn.isin(src.index).sum()\n",
    "\n",
    "    # map & overwrite entire cycle\n",
    "    mapped = seqn.map(src)  # Int64 with NA where no match\n",
    "    df.loc[idx, \"marriage\"] = mapped.values.astype(\"Int64\")\n",
    "\n",
    "    after = df.loc[idx, \"marriage\"].notna().mean() * 100\n",
    "    changed = (\n",
    "        (df.loc[idx, \"marriage\"].fillna(-1) !=\n",
    "         (df.loc[idx, \"marriage_prev\"].fillna(-1) if keep_prev else df_in.loc[idx, \"marriage\"].fillna(-1)))\n",
    "        .sum()\n",
    "    )\n",
    "\n",
    "    print(f\"[cycle {cycle_code}] Using {year_folder}/{demo_file} col={src_col} (overlap={overlap})\")\n",
    "    print(f\"[cycle {cycle_code}] marriage non-miss: {before:.1f}% → {after:.1f}% | rows changed: {changed}\")\n",
    "\n",
    "    if add_labels:\n",
    "        labels = {\n",
    "            1: \"Married\", 2: \"Widowed\", 3: \"Divorced\", 4: \"Separated\",\n",
    "            5: \"Never married\", 6: \"Living with partner\",\n",
    "            77: \"Refused\", 99: \"Don't know\"\n",
    "        }\n",
    "        df.loc[idx, \"marriage_label\"] = df.loc[idx, \"marriage\"].map(labels)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ccff32-1f20-4191-a118-a4d140a36e45",
   "metadata": {},
   "source": [
    "#### Step 2 - Build a correct marriage3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "1e768588-9da1-44a6-aade-24764d70eaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collapse rules:\n",
    "# - If detailed codes present (any of {4,5,6}): 1/6 -> 1; 2/3/4 -> 2; 5 -> 3\n",
    "# - If already collapsed (only {1,2,3}): keep as-is\n",
    "detailed_map  = {1:1, 6:1, 2:2, 3:2, 4:2, 5:3}\n",
    "collapsed_map = {1:1, 2:2, 3:3}\n",
    "\n",
    "def make_marriage3_by_cycle(df: pd.DataFrame, src_col: str = \"marriage\") -> pd.Series:\n",
    "    out = pd.Series(pd.NA, index=df.index, dtype=\"Int64\")\n",
    "    # iterate by cycle for correct logic per vintage\n",
    "    for cyc, gidx in df.groupby(\"SDDSRVYR\").groups.items():\n",
    "        vals = set(pd.Series(df.loc[gidx, src_col]).dropna().unique().tolist())\n",
    "        if {4,5,6} & vals:  # detailed present\n",
    "            mapped = df.loc[gidx, src_col].map(detailed_map)\n",
    "        else:               # already collapsed\n",
    "            mapped = df.loc[gidx, src_col].map(collapsed_map)\n",
    "        out.loc[gidx] = mapped.astype(\"Int64\")\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b1ba33-304e-4b06-9b6d-2bc738b223c4",
   "metadata": {},
   "source": [
    "#### Step 3 - Run the overwrite for your two special cycles, then build marriage3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "9bce4662-676a-4c3b-a1ab-9d3d913a59ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cycle 12] Using 2021/DEMO_L col=DMDMARTZ (overlap=11933)\n",
      "[cycle 12] marriage non-miss: 65.3% → 65.3% | rows changed: 0\n",
      "[cycle 66] Using 2017/P_DEMO col=DMDMARTZ (overlap=15560)\n",
      "[cycle 66] marriage non-miss: 59.3% → 59.3% | rows changed: 0\n"
     ]
    }
   ],
   "source": [
    "# Work on a copy (or do it in place if you prefer)\n",
    "df_my_cov_aligned_short = overwrite_marriage_for_cycle(\n",
    "    df_my_cov_aligned_short, 12, \"2021\", \"DEMO_L\",\n",
    "    add_labels=True, keep_prev=True\n",
    ")\n",
    "df_my_cov_aligned_short = overwrite_marriage_for_cycle(\n",
    "    df_my_cov_aligned_short, 66, \"2017\", \"P_DEMO\",\n",
    "    add_labels=True, keep_prev=True\n",
    ")\n",
    "\n",
    "# Build the 3-level variable across all cycles\n",
    "df_my_cov_aligned_short[\"marriage3\"] = make_marriage3_by_cycle(df_my_cov_aligned_short, \"marriage\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec22315-2b6f-419c-a6ef-43677e6a0702",
   "metadata": {},
   "source": [
    "#### Step 4 - Sanity checks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "0208a5e4-ebaa-4d56-aef8-055a0aa3e502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adult (18+) marriage coverage by cycle (% non-missing):\n",
      " SDDSRVYR\n",
      "1.0      89.8\n",
      "2.0      99.9\n",
      "3.0      99.9\n",
      "4.0     100.0\n",
      "5.0      95.3\n",
      "6.0      95.3\n",
      "7.0      94.8\n",
      "8.0      94.4\n",
      "9.0      95.4\n",
      "10.0     95.1\n",
      "12.0     95.6\n",
      "66.0     95.2\n",
      "Name: marriage, dtype: float64\n",
      "\n",
      "Adult 77/99 (%) among non-missing:\n",
      " SDDSRVYR     \n",
      "1.0       p77    0.14\n",
      "          p99    0.04\n",
      "2.0       p77    0.07\n",
      "          p99    0.00\n",
      "3.0       p77    0.00\n",
      "          p99    0.00\n",
      "4.0       p77    0.13\n",
      "          p99    0.00\n",
      "5.0       p77    0.07\n",
      "          p99    0.00\n",
      "6.0       p77    0.05\n",
      "          p99    0.02\n",
      "7.0       p77    0.11\n",
      "          p99    0.02\n",
      "8.0       p77    0.03\n",
      "          p99    0.02\n",
      "9.0       p77    0.03\n",
      "          p99    0.02\n",
      "10.0      p77    0.11\n",
      "          p99    0.00\n",
      "12.0      p77    0.05\n",
      "          p99    0.06\n",
      "66.0      p77    0.09\n",
      "          p99    0.02\n",
      "Name: marriage, dtype: float64\n",
      "\n",
      "Collapsed 3-level distribution (all cycles):\n",
      " SDDSRVYR  marriage3\n",
      "1.0       1            2717\n",
      "          2            1030\n",
      "          3            2316\n",
      "          <NA>         3902\n",
      "2.0       1            3418\n",
      "          2            1238\n",
      "          3            2597\n",
      "          <NA>         3786\n",
      "3.0       1            3066\n",
      "          2            1198\n",
      "          3            2502\n",
      "          <NA>         3356\n",
      "4.0       1            3179\n",
      "          2            1098\n",
      "          3            2412\n",
      "          <NA>         3659\n",
      "5.0       1            3517\n",
      "          2            1422\n",
      "          3             992\n",
      "          <NA>         4218\n",
      "6.0       1            3669\n",
      "          2            1446\n",
      "          3            1099\n",
      "          <NA>         4323\n",
      "7.0       1            3123\n",
      "          2            1242\n",
      "          3            1188\n",
      "          <NA>         4203\n",
      "8.0       1            3382\n",
      "          2            1272\n",
      "          3            1112\n",
      "          <NA>         4409\n",
      "9.0       1            3441\n",
      "          2            1227\n",
      "          3            1048\n",
      "          <NA>         4255\n",
      "10.0      1            3252\n",
      "          2            1305\n",
      "          3            1006\n",
      "          <NA>         3691\n",
      "12.0      1            4136\n",
      "          2            2022\n",
      "          3            1625\n",
      "          <NA>         4150\n",
      "66.0      1            5279\n",
      "          2            2148\n",
      "          3            1795\n",
      "          <NA>         6338\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "# Adult (>=18) coverage\n",
    "adults_mask = df_my_cov_aligned_short[\"RIDAGEYR\"] >= 18\n",
    "cov_adult = (df_my_cov_aligned_short.loc[adults_mask]\n",
    "             .groupby(\"SDDSRVYR\", observed=True)[\"marriage\"]\n",
    "             .apply(lambda s: s.notna().mean()*100, include_groups=False)\n",
    "             .round(1))\n",
    "print(\"Adult (18+) marriage coverage by cycle (% non-missing):\\n\", cov_adult)\n",
    "\n",
    "# 77/99 among non-missing adults\n",
    "def code_shares(s: pd.Series) -> pd.Series:\n",
    "    s2 = s.dropna()\n",
    "    if s2.empty:\n",
    "        return pd.Series({\"p77\": np.nan, \"p99\": np.nan})\n",
    "    return pd.Series({\"p77\": (s2.eq(77).mean()*100).round(2),\n",
    "                      \"p99\": (s2.eq(99).mean()*100).round(2)})\n",
    "\n",
    "adult_codes = (df_my_cov_aligned_short.loc[adults_mask]\n",
    "               .groupby(\"SDDSRVYR\", observed=True)[\"marriage\"]\n",
    "               .apply(code_shares, include_groups=False))\n",
    "print(\"\\nAdult 77/99 (%) among non-missing:\\n\", adult_codes)\n",
    "\n",
    "# Collapsed 3-level distribution (all cycles)\n",
    "dist3_all = (df_my_cov_aligned_short\n",
    "             .groupby(\"SDDSRVYR\", observed=True)[\"marriage3\"]\n",
    "             .value_counts(dropna=False)\n",
    "             .sort_index())\n",
    "print(\"\\nCollapsed 3-level distribution (all cycles):\\n\", dist3_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "f5347468-48c2-4d5e-8190-9a330f32fa12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adult weighted % married/partner (marriage3==1) by cycle:\n",
      " SDDSRVYR\n",
      "1.0     59.9\n",
      "2.0     62.1\n",
      "3.0     61.1\n",
      "4.0     63.5\n",
      "5.0     63.4\n",
      "6.0     63.3\n",
      "7.0     61.4\n",
      "8.0     62.1\n",
      "9.0     63.9\n",
      "10.0    62.0\n",
      "12.0    60.3\n",
      "66.0    61.6\n",
      "Name: pct_married3_wt, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def wt_prop_by_cycle(df: pd.DataFrame, col: str, value, weight: str = \"wt_int\", mask=None) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Weighted % of df[col] == value within each SDDSRVYR.\n",
    "    Denominator = sum of weights among rows with non-missing df[col] in that cycle.\n",
    "    \"\"\"\n",
    "    base = df\n",
    "    if mask is not None:\n",
    "        base = base.loc[pd.Series(mask, index=df.index)]\n",
    "    base = base.loc[base[weight].notna() & (base[weight] > 0)]\n",
    "\n",
    "    def prop(g: pd.DataFrame):\n",
    "        w = g[weight]\n",
    "        den = w[g[col].notna()].sum()\n",
    "        if den == 0:\n",
    "            return np.nan\n",
    "        num = w[g[col].eq(value)].sum()\n",
    "        return (num / den) * 100.0\n",
    "\n",
    "    return (base.groupby(\"SDDSRVYR\", observed=True)\n",
    "                .apply(prop, include_groups=False)\n",
    "                .round(1))\n",
    "\n",
    "# Example: adult weighted % married/partner (marriage3==1)\n",
    "adult_weighted_married = wt_prop_by_cycle(\n",
    "    df_my_cov_aligned_short, col=\"marriage3\", value=1,\n",
    "    weight=\"wt_int\", mask=adults_mask\n",
    ").rename(\"pct_married3_wt\")\n",
    "\n",
    "print(\"\\nAdult weighted % married/partner (marriage3==1) by cycle:\\n\", adult_weighted_married)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8921a3-02b1-47a5-bec5-092c46dbf34d",
   "metadata": {},
   "source": [
    "## save df_my_cov_aligned_short "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "b39a775c-7661-4bc5-b8be-d8891f4d0aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved: /Users/dengshuyue/Desktop/SDOH/analysis/output/cov_concise_99_23.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "OUT = Path(\"/Users/dengshuyue/Desktop/SDOH/analysis/output\")\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "handoff = OUT / \"cov_concise_99_23.parquet\"\n",
    "df_my_cov_aligned_short.to_parquet(handoff, index=False)\n",
    "print(\"✓ Saved:\", handoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d788747f-213a-4f9f-8630-b7dfab7c98a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
