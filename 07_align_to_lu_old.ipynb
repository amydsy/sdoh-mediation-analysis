{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d3f2050-e263-48c8-ace0-48b75e929269",
   "metadata": {},
   "source": [
    "## set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3e39b36e-3c61-4228-8725-98d36a4373c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mine: (128809, 82) | lu: (101316, 75)\n",
      "Loaded: /Users/dengshuyue/Desktop/SDOH/analysis/output/demo_mt_cov_dp_sdoh.parquet\n",
      "Loaded: /Users/dengshuyue/Desktop/SDOH/analysis/data/cov/nhanes_primary_anal_full_singleimputation_v2.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = Path(\"/Users/dengshuyue/Desktop/SDOH/analysis\")\n",
    "OUT  = ROOT / \"output\"\n",
    "\n",
    "MY_PATH = OUT / \"demo_mt_cov_dp_sdoh.parquet\"\n",
    "LU_PATH = ROOT / \"data/cov/nhanes_primary_anal_full_singleimputation_v2.csv\"\n",
    "\n",
    "df_my_cov_1999_2023 = pd.read_parquet(MY_PATH)\n",
    "df_lu_cov_1999_2018 = pd.read_csv(LU_PATH)\n",
    "\n",
    "print(\"mine:\", df_my_cov_1999_2023.shape, \"| lu:\", df_lu_cov_1999_2018.shape)\n",
    "print(\"Loaded:\", MY_PATH)\n",
    "print(\"Loaded:\", LU_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f801de9a-af35-467e-b2c5-b964fe5ce35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>SDMVPSU</th>\n",
       "      <th>SDMVSTRA</th>\n",
       "      <th>WTMEC2YR</th>\n",
       "      <th>AGE_YR</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>SEX</th>\n",
       "      <th>FEMALE</th>\n",
       "      <th>SMK_STATUS</th>\n",
       "      <th>...</th>\n",
       "      <th>FS_HH</th>\n",
       "      <th>FS_ADULT</th>\n",
       "      <th>FS_FINAL</th>\n",
       "      <th>HHFDSEC</th>\n",
       "      <th>ADFDSEC</th>\n",
       "      <th>FS_HH4</th>\n",
       "      <th>FS_ADULT4</th>\n",
       "      <th>FS_SOURCE_HH</th>\n",
       "      <th>FS_SOURCE_FINAL</th>\n",
       "      <th>SNAP_SOURCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10982.898896</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28325.384898</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>NEVER</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>HHFDSEC</td>\n",
       "      <td>household</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>46192.256945</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10251.260020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>99445.065735</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>FORMER</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>HHFDSEC</td>\n",
       "      <td>household</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39656.600444</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25525.423409</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>FORMER</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>31510.587866</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7575.870247</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22445.808572</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>CURRENT</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEQN  SDDSRVYR  SDMVPSU  SDMVSTRA      WTMEC2YR  AGE_YR  RIAGENDR SEX  \\\n",
       "0     1       1.0      1.0       5.0  10982.898896     2.0         2   F   \n",
       "1     2       1.0      3.0       1.0  28325.384898    77.0         1   M   \n",
       "2     3       1.0      2.0       7.0  46192.256945    10.0         2   F   \n",
       "3     4       1.0      1.0       2.0  10251.260020     1.0         1   M   \n",
       "4     5       1.0      2.0       8.0  99445.065735    49.0         1   M   \n",
       "5     6       1.0      2.0       2.0  39656.600444    19.0         2   F   \n",
       "6     7       1.0      2.0       4.0  25525.423409    59.0         2   F   \n",
       "7     8       1.0      1.0       6.0  31510.587866    13.0         1   M   \n",
       "8     9       1.0      2.0       9.0   7575.870247    11.0         2   F   \n",
       "9    10       1.0      1.0       7.0  22445.808572    43.0         1   M   \n",
       "\n",
       "   FEMALE SMK_STATUS  ...  FS_HH  FS_ADULT  FS_FINAL  HHFDSEC ADFDSEC  FS_HH4  \\\n",
       "0       1        NaN  ...   <NA>      <NA>      <NA>     <NA>    <NA>    <NA>   \n",
       "1       0      NEVER  ...      0         0         0        1       1       1   \n",
       "2       1        NaN  ...   <NA>      <NA>      <NA>     <NA>    <NA>    <NA>   \n",
       "3       0        NaN  ...   <NA>      <NA>      <NA>     <NA>    <NA>    <NA>   \n",
       "4       0     FORMER  ...      0         0         0        1       1       1   \n",
       "5       1        NaN  ...   <NA>      <NA>      <NA>     <NA>    <NA>    <NA>   \n",
       "6       1     FORMER  ...   <NA>      <NA>      <NA>     <NA>    <NA>    <NA>   \n",
       "7       0        NaN  ...   <NA>      <NA>      <NA>     <NA>    <NA>    <NA>   \n",
       "8       1        NaN  ...   <NA>      <NA>      <NA>     <NA>    <NA>    <NA>   \n",
       "9       0    CURRENT  ...   <NA>      <NA>      <NA>     <NA>    <NA>    <NA>   \n",
       "\n",
       "   FS_ADULT4  FS_SOURCE_HH  FS_SOURCE_FINAL  SNAP_SOURCE  \n",
       "0       <NA>          <NA>             <NA>         <NA>  \n",
       "1          1       HHFDSEC        household         <NA>  \n",
       "2       <NA>          <NA>             <NA>         <NA>  \n",
       "3       <NA>          <NA>             <NA>         <NA>  \n",
       "4          1       HHFDSEC        household         <NA>  \n",
       "5       <NA>          <NA>             <NA>         <NA>  \n",
       "6       <NA>          <NA>             <NA>         <NA>  \n",
       "7       <NA>          <NA>             <NA>         <NA>  \n",
       "8       <NA>          <NA>             <NA>         <NA>  \n",
       "9       <NA>          <NA>             <NA>         <NA>  \n",
       "\n",
       "[10 rows x 82 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_my_cov_1999_2023.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f9e039-fde5-4a1e-9282-a4937ea3fc0e",
   "metadata": {},
   "source": [
    "#### 1) Helpers (used later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f735d0c5-a7c0-482f-abfd-3375b3cec0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) HELPERS (robust + imports np)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _norm_str_col(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Lowercase + strip + turn 'nan' into actual NaN.\"\"\"\n",
    "    s = series.astype(str).str.strip().str.lower()\n",
    "    return s.replace({\"nan\": np.nan})\n",
    "\n",
    "def _num_summary(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"Lightweight numeric summary for a set of columns.\"\"\"\n",
    "    rows = []\n",
    "    for c in cols:\n",
    "        s = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "        rows.append({\n",
    "            \"column\": c,\n",
    "            \"n\": len(s),\n",
    "            \"na_rate\": float(s.isna().mean()),\n",
    "            \"min\": np.nanmin(s.values),\n",
    "            \"p25\": np.nanpercentile(s.values, 25),\n",
    "            \"median\": np.nanmedian(s.values),\n",
    "            \"p75\": np.nanpercentile(s.values, 75),\n",
    "            \"max\": np.nanmax(s.values),\n",
    "            \"mean\": np.nanmean(s.values),\n",
    "            \"std\": np.nanstd(s.values),\n",
    "            \"unique_non_na\": int(s.nunique(dropna=True)),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def _binary_sig(series: pd.Series) -> str | None:\n",
    "    \"\"\"Detect common binary encodings.\"\"\"\n",
    "    vals = set(_norm_str_col(series).dropna().unique())\n",
    "    if vals <= {\"0\",\"1\"}: return \"0/1\"\n",
    "    if vals <= {\"yes\",\"no\"}: return \"yes/no\"\n",
    "    if vals <= {\"true\",\"false\"}: return \"true/false\"\n",
    "    if vals <= {\"male\",\"female\"}: return \"male/female\"\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c72ac48-4459-436b-8b33-47a79e540bdb",
   "metadata": {},
   "source": [
    "#### 2) Column set differences (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bbaacf23-26c4-4d58-85ee-ecc295b2bd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Columns] only_in_lu: 69 | only_in_my: 76 | in_both: 6\n",
      "• only_in_lu (first 20): ['MetS', 'MetS_bp', 'MetS_count', 'MetS_fpg', 'MetS_hdl', 'MetS_triglycerides', 'MetS_wc', 'WTINT2YR', 'WTSAF2YR', 'X', 'adiposity_pri', 'adiposity_sec', 'age', 'age_cat', 'angina', 'angina_rx', 'asthma', 'bmi', 'bp_pri', 'bp_sec']\n",
      "• only_in_my (first 20): ['ADFDSEC', 'AGE_YR', 'ALCOHOL_CAT', 'BMI', 'BMI_CLAS', 'BMXHT', 'BMXWT', 'CANCER', 'CENSORED', 'CIDI_12M_MDE', 'CIDI_SCORE_RAW', 'CIGS_PER_DAY', 'DBP', 'DEP_HARMONIZED', 'DEP_IMP', 'DEP_SOURCE', 'DIABETES', 'DMDHHSIZ', 'DPQ_CAT', 'DRINKS_PER_DAY']\n"
     ]
    }
   ],
   "source": [
    "# 2) COLUMN SET DIFFERENCES (a)\n",
    "\n",
    "cols_my = set(df_my_cov_1999_2023.columns)\n",
    "cols_lu = set(df_lu_cov_1999_2018.columns)\n",
    "\n",
    "audit_only_in_lu = sorted(cols_lu - cols_my)\n",
    "audit_only_in_my = sorted(cols_my - cols_lu)\n",
    "audit_in_both    = sorted(cols_my & cols_lu)\n",
    "\n",
    "print(f\"[Columns] only_in_lu: {len(audit_only_in_lu)} | only_in_my: {len(audit_only_in_my)} | in_both: {len(audit_in_both)}\")\n",
    "print(\"• only_in_lu (first 20):\", audit_only_in_lu[:20])\n",
    "print(\"• only_in_my (first 20):\", audit_only_in_my[:20])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "67beccc1-932f-43f6-a166-1ed8867afbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 columns\n",
      "['SEQN', 'SDDSRVYR', 'SDMVPSU', 'SDMVSTRA', 'WTMEC2YR', 'AGE_YR', 'RIAGENDR', 'SEX', 'FEMALE', 'SMK_STATUS', 'CIGS_PER_DAY', 'PACK_YEARS', 'FORMER_SMOKER', 'DRINKS_PER_DAY', 'ALCOHOL_CAT', 'LTPA', 'METSCORE', 'IMP', 'BMXWT', 'BMXHT', 'BMI', 'BMI_CLAS', 'DIABETES', 'HTN', 'HIGH_CHOL', 'CVD', 'CANCER', 'SBP', 'DBP', 'TCHOL', 'HDL', 'LDL', 'TG', 'DMDHHSIZ', 'ELIGSTAT', 'MORTSTAT', 'PERMTH_EXM', 'PERMTH_INT', 'UCOD_LEADING', 'IS_POST2018', 'IS_ADULT', 'MORTALITY_COVERED', 'EVENT', 'CENSORED', 'FU_YRS_EXM', 'FU_YRS_INT', 'UCOD_LABEL', 'PHQ9', 'PHQ9_GE10', 'DPQ_CAT', 'DEP_IMP', 'CIDI_SCORE_RAW', 'CIDI_12M_MDE', 'WTSCI2YR', 'DEP_HARMONIZED', 'DEP_SOURCE', 'PIR', 'PIR_CAT', 'INDFMINC', 'EDU', 'EDU_CAT', 'RACE_ETH', 'MARITAL', 'MARITAL_CAT', 'EMPLOY', 'UNEMPLOYMENT', 'HOD050', 'HOQ065', 'INS', 'SNAP', 'FSDHH', 'FS', 'FS_HH', 'FS_ADULT', 'FS_FINAL', 'HHFDSEC', 'ADFDSEC', 'FS_HH4', 'FS_ADULT4', 'FS_SOURCE_HH', 'FS_SOURCE_FINAL', 'SNAP_SOURCE']\n",
      "75 columns\n",
      "['X', 'SEQN', 'SDDSRVYR', 'WTINT2YR', 'WTMEC2YR', 'WTSAF2YR', 'SDMVPSU', 'SDMVSTRA', 'age', 'sex', 're', 'edu', 'pir', 'tchol', 'hdl', 'ldl', 'tg', 'wc', 'bmi', 'dm_self', 'hba1c', 'fpg', 'chf', 'chd', 'mi', 'stroke', 'cancer', 'emphysema', 'bronchitis', 'asthma', 're2', 'copd', 'sbp', 'dbp', 'dm_rx', 'chol_rx', 'angina_rx', 'htn_rx', 'roseQ', 'no_na', 'age_cat', 'pir_cat', 'edu2', 'CVD', 'lung_disease', 'diabetes', 'tchol_hdl', 'angina', 'lipid_pri', 'adiposity_pri', 'bp_pri', 'glucose_pri', 'cvd_pri', 'lipid_sec', 'adiposity_sec', 'bp_sec', 'glucose_sec', 'cvd_sec', 'optimal_pri_count', 'intermediate_pri_count', 'poor_pri_count', 'optimal_sec_count', 'intermediate_sec_count', 'poor_sec_count', 'optimal_all', 'poor_all', 'optimal_all_sec', 'poor_all_sec', 'MetS_hdl', 'MetS_triglycerides', 'MetS_bp', 'MetS_wc', 'MetS_fpg', 'MetS_count', 'MetS']\n"
     ]
    }
   ],
   "source": [
    "# mine\n",
    "print(len(df_my_cov_1999_2023.columns), \"columns\")\n",
    "print(df_my_cov_1999_2023.columns.tolist())\n",
    "\n",
    "# lu\n",
    "print(len(df_lu_cov_1999_2018.columns), \"columns\")\n",
    "print(df_lu_cov_1999_2018.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34575e49-2360-4d48-912e-0fea2df49d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7bfad80d-91ca-4d43-9bf0-5bc1efc110d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable              Type         Data/Info\n",
      "--------------------------------------------\n",
      "df_lu_cov_1999_2018   DataFrame    Shape: (101316, 75)\n",
      "df_my_cov_1999_2023   DataFrame    Shape: (128809, 82)\n"
     ]
    }
   ],
   "source": [
    "# %whos DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "678b5491-1541-4e55-a8c0-7f25b7788af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_my_cov_1999_2023[['MORTALITY_COVERED', 'EVENT', \"UCOD_LABEL\", \"CANCER\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe75417-424d-40b0-843a-61fdb05e689b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e31c2cc-a3de-4aa4-b520-32a3ef182a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a4a1f-76d6-46fc-b9af-ab27acadd403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b9d2ee-8cb1-4bca-8041-28b411616d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dbeec05-2a00-401b-bf34-a9962ef84005",
   "metadata": {},
   "source": [
    "## Align column same as lu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8363147b-a244-46dc-ae0d-74f24846e2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed 15 columns automatically.\n",
      "Examples: [('AGE_YR', 'age'), ('BMI', 'bmi'), ('CANCER', 'cancer'), ('DBP', 'dbp'), ('DIABETES', 'diabetes'), ('EDU', 'edu'), ('HDL', 'hdl'), ('LDL', 'ldl'), ('PIR', 'pir'), ('PIR_CAT', 'pir_cat')]\n",
      "Still missing from your data (present in Lu): ['X', 'WTINT2YR', 'WTSAF2YR', 'wc', 'dm_self', 'hba1c', 'fpg', 'chf', 'chd', 'mi', 'stroke', 'emphysema', 'bronchitis', 'asthma', 're2', 'copd', 'dm_rx', 'chol_rx', 'angina_rx', 'htn_rx', 'roseQ', 'no_na', 'age_cat', 'edu2', 'lung_disease', 'tchol_hdl', 'angina', 'lipid_pri', 'adiposity_pri', 'bp_pri', 'glucose_pri', 'cvd_pri', 'lipid_sec', 'adiposity_sec', 'bp_sec', 'glucose_sec', 'cvd_sec', 'optimal_pri_count', 'intermediate_pri_count', 'poor_pri_count', 'optimal_sec_count', 'intermediate_sec_count', 'poor_sec_count', 'optimal_all', 'poor_all', 'optimal_all_sec', 'poor_all_sec', 'MetS_hdl', 'MetS_triglycerides', 'MetS_bp', 'MetS_wc', 'MetS_fpg', 'MetS_count', 'MetS']\n",
      "Final order starts with: ['SEQN', 'SDDSRVYR', 'WTMEC2YR', 'SDMVPSU', 'SDMVSTRA', 'age', 'sex', 're', 'edu', 'pir', 'tchol', 'hdl', 'ldl', 'tg', 'bmi']\n"
     ]
    }
   ],
   "source": [
    "import re, difflib\n",
    "import pandas as pd\n",
    "\n",
    "# === Inputs (your two originals) ===\n",
    "mine = df_my_cov_1999_2023.copy()\n",
    "lu   = df_lu_cov_1999_2018.copy()\n",
    "\n",
    "lu_cols = list(lu.columns)\n",
    "mine_cols = list(mine.columns)\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def norm(s: str) -> str:\n",
    "    # Lower, drop non-alnum (so AGE_YR -> ageyr; RACE_ETH -> raceeth)\n",
    "    return re.sub(r'[^0-9a-z]+', '', s.lower()) if isinstance(s, str) else s\n",
    "\n",
    "lu_norm_to_name = {}\n",
    "for c in lu_cols:\n",
    "    lu_norm_to_name.setdefault(norm(c), c)  # keep first occurrence\n",
    "\n",
    "# Minimal synonyms (expand as needed if you see mismatches)\n",
    "# YOUR column name -> Lu column name\n",
    "synonyms = {\n",
    "    'AGE_YR':'age',\n",
    "    'SEX':'sex',\n",
    "    'RACE_ETH':'re',\n",
    "    'EDU':'edu',\n",
    "    'PIR':'pir',\n",
    "    'TCHOL':'tchol',\n",
    "    'HDL':'hdl',\n",
    "    'LDL':'ldl',\n",
    "    'TG':'tg',\n",
    "    'WC':'wc',\n",
    "    'BMI':'bmi',\n",
    "    'SBP':'sbp',\n",
    "    'DBP':'dbp',\n",
    "    'DIABETES':'diabetes',\n",
    "    'CVD':'CVD',          # Lu uses uppercase \"CVD\" in your list\n",
    "    'CANCER':'cancer',\n",
    "    'DM_RX':'dm_rx',\n",
    "    'CHOL_RX':'chol_rx',\n",
    "    'HTN_RX':'htn_rx',\n",
    "    'ANGINA_RX':'angina_rx',\n",
    "    'ANGINA':'angina',\n",
    "    'AGE_CAT':'age_cat',\n",
    "    'PIR_CAT':'pir_cat',\n",
    "    'EDU2':'edu2',\n",
    "    'METS_HDL':'MetS_hdl',\n",
    "    'METS_TRIGLYCERIDES':'MetS_triglycerides',\n",
    "    'METS_BP':'MetS_bp',\n",
    "    'METS_WC':'MetS_wc',\n",
    "    'METS_FPG':'MetS_fpg',\n",
    "    'METS_COUNT':'MetS_count',\n",
    "    'ROSEQ':'roseQ',\n",
    "    'NO_NA':'no_na',\n",
    "    'LUNG_DISEASE':'lung_disease',\n",
    "    'BP_PRI':'bp_pri',\n",
    "    'GLUCOSE_PRI':'glucose_pri',\n",
    "    'LIPID_PRI':'lipid_pri',\n",
    "    'ADIPOSITY_PRI':'adiposity_pri',\n",
    "    'CVD_PRI':'cvd_pri',\n",
    "    'BP_SEC':'bp_sec',\n",
    "    'GLUCOSE_SEC':'glucose_sec',\n",
    "    'LIPID_SEC':'lipid_sec',\n",
    "    'ADIPOSITY_SEC':'adiposity_sec',\n",
    "    'CVD_SEC':'cvd_sec',\n",
    "    # Common admin/weight vars:\n",
    "    'WTMEC2YR':'WTMEC2YR',\n",
    "    'SDDSRVYR':'SDDSRVYR',\n",
    "    'SDMVPSU':'SDMVPSU',\n",
    "    'SDMVSTRA':'SDMVSTRA',\n",
    "}\n",
    "\n",
    "# Columns we should **never** rename (IDs/keys that already match)\n",
    "protect_exact = set(['SEQN','SDDSRVYR','SDMVPSU','SDMVSTRA','WTMEC2YR'])\n",
    "\n",
    "# ---------- Build mapping (your -> lu) ----------\n",
    "mapping = {}          # final mapping to apply\n",
    "used_targets = set()  # to avoid collisions (two src -> one dst)\n",
    "\n",
    "for src in mine_cols:\n",
    "    if src in protect_exact or src.endswith('_lu'):\n",
    "        continue\n",
    "\n",
    "    # 1) If exact Lu name already, keep as-is\n",
    "    if src in lu_cols:\n",
    "        continue\n",
    "\n",
    "    # 2) Synonym override\n",
    "    if src in synonyms and synonyms[src] in lu_cols and synonyms[src] not in used_targets and synonyms[src] not in mine_cols:\n",
    "        mapping[src] = synonyms[src]\n",
    "        used_targets.add(synonyms[src])\n",
    "        continue\n",
    "\n",
    "    # 3) Case-insensitive exact\n",
    "    ci = next((dst for dst in lu_cols if isinstance(dst, str) and dst.lower() == src.lower()), None)\n",
    "    if ci and ci not in used_targets and ci not in mine_cols:\n",
    "        mapping[src] = ci\n",
    "        used_targets.add(ci)\n",
    "        continue\n",
    "\n",
    "    # 4) Normalized name match\n",
    "    nsrc = norm(src)\n",
    "    if nsrc in lu_norm_to_name:\n",
    "        dst = lu_norm_to_name[nsrc]\n",
    "        if dst not in used_targets and dst not in mine_cols:\n",
    "            mapping[src] = dst\n",
    "            used_targets.add(dst)\n",
    "            continue\n",
    "\n",
    "    # 5) Fuzzy match for stragglers (safe threshold)\n",
    "    # Only attempt for alphas; ignore obviously different admin columns you don't want changed\n",
    "    candidates = difflib.get_close_matches(src, lu_cols, n=1, cutoff=0.92)\n",
    "    if candidates:\n",
    "        dst = candidates[0]\n",
    "        if dst not in used_targets and dst not in mine_cols:\n",
    "            mapping[src] = dst\n",
    "            used_targets.add(dst)\n",
    "            continue\n",
    "\n",
    "# ---------- Apply rename ----------\n",
    "mine_renamed = mine.rename(columns=mapping).copy()\n",
    "\n",
    "# ---------- Reorder to Lu’s order (extras at end; keep *_lu at very end) ----------\n",
    "ordered = [c for c in lu_cols if c in mine_renamed.columns]\n",
    "extras  = [c for c in mine_renamed.columns if c not in ordered and not c.endswith('_lu')]\n",
    "audit   = [c for c in mine_renamed.columns if c.endswith('_lu')]\n",
    "\n",
    "df_my_cov_aligned = mine_renamed[ordered + extras + audit].copy()\n",
    "\n",
    "# ---------- Report ----------\n",
    "renamed_pairs = sorted(mapping.items(), key=lambda x: x[0].lower())\n",
    "missing_in_mine = [c for c in lu_cols if c not in df_my_cov_aligned.columns]\n",
    "\n",
    "print(f\"Renamed {len(renamed_pairs)} columns automatically.\")\n",
    "print(\"Examples:\", renamed_pairs[:10])\n",
    "print(\"Still missing from your data (present in Lu):\", missing_in_mine)\n",
    "print(\"Final order starts with:\", df_my_cov_aligned.columns[:15].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e97df4b-008b-4040-bd01-36bde77cd0a9",
   "metadata": {},
   "source": [
    "#### Adding missing column merge from lu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a1a71025-28dc-4f8d-a728-5d304affe7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-renamed 15 columns to Lu names.\n",
      "Filled from Lu (newly added): ['X', 'WTINT2YR', 'WTSAF2YR', 'wc', 'dm_self', 'hba1c', 'fpg', 'chf', 'chd', 'mi', 'stroke', 'emphysema', 'bronchitis', 'asthma', 're2', 'copd', 'dm_rx', 'chol_rx', 'angina_rx', 'htn_rx'] ...\n",
      "Still missing Lu cols: []\n",
      "Final starts with: ['X', 'SEQN', 'SDDSRVYR', 'WTINT2YR', 'WTMEC2YR', 'WTSAF2YR', 'SDMVPSU', 'SDMVSTRA', 'age', 'sex', 're', 'edu', 'pir', 'tchol', 'hdl']\n"
     ]
    }
   ],
   "source": [
    "import re, pandas as pd\n",
    "\n",
    "# === 0) Start from the two originals ===\n",
    "mine = df_my_cov_1999_2023.copy()\n",
    "lu   = df_lu_cov_1999_2018.copy()\n",
    "\n",
    "# === 1) Auto-rename YOUR columns to Lu's names (case/underscore-insensitive + synonyms) ===\n",
    "def norm(s: str) -> str:\n",
    "    return re.sub(r'[^0-9a-z]+', '', s.lower()) if isinstance(s, str) else s\n",
    "\n",
    "lu_cols = list(lu.columns)\n",
    "mine_cols = list(mine.columns)\n",
    "\n",
    "# First pass: normalized name index for Lu\n",
    "lu_norm_to_name = {}\n",
    "for c in lu_cols:\n",
    "    lu_norm_to_name.setdefault(norm(c), c)\n",
    "\n",
    "# Synonyms (YOUR -> Lu)\n",
    "synonyms = {\n",
    "    'AGE_YR':'age','SEX':'sex','RACE_ETH':'re','EDU':'edu','PIR':'pir',\n",
    "    'TCHOL':'tchol','HDL':'hdl','LDL':'ldl','TG':'tg',\n",
    "    'WC':'wc','BMI':'bmi','SBP':'sbp','DBP':'dbp',\n",
    "    'DIABETES':'diabetes','CVD':'CVD','CANCER':'cancer',\n",
    "    'DM_RX':'dm_rx','CHOL_RX':'chol_rx','HTN_RX':'htn_rx','ANGINA_RX':'angina_rx','ANGINA':'angina',\n",
    "    'AGE_CAT':'age_cat','PIR_CAT':'pir_cat','EDU2':'edu2',\n",
    "    'METS_HDL':'MetS_hdl','METS_TRIGLYCERIDES':'MetS_triglycerides','METS_BP':'MetS_bp',\n",
    "    'METS_WC':'MetS_wc','METS_FPG':'MetS_fpg','METS_COUNT':'MetS_count',\n",
    "    'ROSEQ':'roseQ','NO_NA':'no_na','LUNG_DISEASE':'lung_disease',\n",
    "    'BP_PRI':'bp_pri','GLUCOSE_PRI':'glucose_pri','LIPID_PRI':'lipid_pri','ADIPOSITY_PRI':'adiposity_pri',\n",
    "    'CVD_PRI':'cvd_pri','BP_SEC':'bp_sec','GLUCOSE_SEC':'glucose_sec','LIPID_SEC':'lipid_sec',\n",
    "    'ADIPOSITY_SEC':'adiposity_sec','CVD_SEC':'cvd_sec',\n",
    "    # admin/weights that already match:\n",
    "    'WTMEC2YR':'WTMEC2YR','SDDSRVYR':'SDDSRVYR','SDMVPSU':'SDMVPSU','SDMVSTRA':'SDMVSTRA'\n",
    "}\n",
    "\n",
    "protect_exact = {'SEQN','SDDSRVYR','SDMVPSU','SDMVSTRA','WTMEC2YR'}\n",
    "\n",
    "mapping = {}\n",
    "used_targets = set()\n",
    "for src in mine_cols:\n",
    "    if src in protect_exact or src.endswith('_lu'):\n",
    "        continue\n",
    "    if src in lu_cols:\n",
    "        continue\n",
    "    # synonyms first\n",
    "    if src in synonyms and synonyms[src] in lu_cols and synonyms[src] not in used_targets and synonyms[src] not in mine.columns:\n",
    "        mapping[src] = synonyms[src]; used_targets.add(synonyms[src]); continue\n",
    "    # case-insensitive exact\n",
    "    ci = next((dst for dst in lu_cols if isinstance(dst, str) and dst.lower()==src.lower()), None)\n",
    "    if ci and ci not in used_targets and ci not in mine.columns:\n",
    "        mapping[src] = ci; used_targets.add(ci); continue\n",
    "    # normalized match\n",
    "    nc = norm(src)\n",
    "    if nc in lu_norm_to_name:\n",
    "        dst = lu_norm_to_name[nc]\n",
    "        if dst not in used_targets and dst not in mine.columns:\n",
    "            mapping[src] = dst; used_targets.add(dst); continue\n",
    "\n",
    "mine = mine.rename(columns=mapping)\n",
    "\n",
    "# === 2) Identify Lu columns you still lack, and merge ONLY those in ===\n",
    "missing = [c for c in lu_cols if c not in mine.columns]\n",
    "# keys must exist in both:\n",
    "for k in ['SEQN','SDDSRVYR']:\n",
    "    if k not in mine.columns or k not in lu.columns:\n",
    "        raise KeyError(f\"Key {k} missing in one of the frames\")\n",
    "\n",
    "# subset Lu to keys + missing, drop dup keys, then merge\n",
    "lu_sub = lu[['SEQN','SDDSRVYR'] + missing].copy()\n",
    "dup_ct = lu_sub.duplicated(['SEQN','SDDSRVYR']).sum()\n",
    "if dup_ct:\n",
    "    print(f\"[warn] Dropping {dup_ct} duplicate rows on keys in Lu subset\")\n",
    "    lu_sub = lu_sub.drop_duplicates(['SEQN','SDDSRVYR'], keep='first')\n",
    "\n",
    "# Merge (no suffix needed—these cols are missing in 'mine')\n",
    "aligned = mine.merge(lu_sub, on=['SEQN','SDDSRVYR'], how='left')\n",
    "\n",
    "# === 3) Reorder to Lu order first, then any extras ===\n",
    "order = [c for c in lu_cols if c in aligned.columns]\n",
    "extras = [c for c in aligned.columns if c not in order]\n",
    "df_my_cov_aligned = aligned[order + extras].copy()\n",
    "\n",
    "# === 4) Quick report\n",
    "print(f\"Auto-renamed {len(mapping)} columns to Lu names.\")\n",
    "print(\"Filled from Lu (newly added):\", missing[:20], \"...\" if len(missing)>20 else \"\")\n",
    "still_missing = [c for c in lu_cols if c not in df_my_cov_aligned.columns]  # should be empty\n",
    "print(\"Still missing Lu cols:\", still_missing)\n",
    "print(\"Final starts with:\", df_my_cov_aligned.columns[:15].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a387281-7882-4c51-ba81-c3900f687368",
   "metadata": {},
   "source": [
    "#### clean and check merged file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "08296f13-4ec7-45fd-b717-6b71de8c01f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X' in df_my_cov_aligned.columns:\n",
    "    df_my_cov_aligned = df_my_cov_aligned.drop(columns=['X'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d3eef66a-68ac-49ee-9d7e-a540b2df4565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# binary flags\n",
    "bin_cols = ['dm_self','chf','chd','mi','stroke','emphysema','bronchitis','asthma',\n",
    "            'copd','dm_rx','chol_rx','angina_rx','htn_rx','angina']\n",
    "for c in df_my_cov_aligned.columns.intersection(bin_cols):\n",
    "    df_my_cov_aligned[c] = pd.to_numeric(df_my_cov_aligned[c], errors='coerce').astype('Int8')\n",
    "\n",
    "# labs/metrics\n",
    "num_cols = ['wc','hba1c','fpg','tchol_hdl','MetS_hdl','MetS_triglycerides',\n",
    "            'MetS_bp','MetS_wc','MetS_fpg','MetS_count']\n",
    "for c in df_my_cov_aligned.columns.intersection(num_cols):\n",
    "    df_my_cov_aligned[c] = pd.to_numeric(df_my_cov_aligned[c], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7dd60df9-88e2-4fc9-850d-e2123eb130db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>WTINT2YR</th>\n",
       "      <th>WTMEC2YR</th>\n",
       "      <th>WTSAF2YR</th>\n",
       "      <th>SDMVPSU</th>\n",
       "      <th>SDMVSTRA</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>re</th>\n",
       "      <th>...</th>\n",
       "      <th>FS_HH</th>\n",
       "      <th>FS_ADULT</th>\n",
       "      <th>FS_FINAL</th>\n",
       "      <th>HHFDSEC</th>\n",
       "      <th>ADFDSEC</th>\n",
       "      <th>FS_HH4</th>\n",
       "      <th>FS_ADULT4</th>\n",
       "      <th>FS_SOURCE_HH</th>\n",
       "      <th>FS_SOURCE_FINAL</th>\n",
       "      <th>SNAP_SOURCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9727.078709</td>\n",
       "      <td>10982.898896</td>\n",
       "      <td>75131.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26678.636376</td>\n",
       "      <td>28325.384898</td>\n",
       "      <td>60586.147294</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>HHFDSEC</td>\n",
       "      <td>household</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43621.680548</td>\n",
       "      <td>46192.256945</td>\n",
       "      <td>121969.841152</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10346.119327</td>\n",
       "      <td>10251.260020</td>\n",
       "      <td>4624.687273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91050.846620</td>\n",
       "      <td>99445.065735</td>\n",
       "      <td>234895.205650</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>HHFDSEC</td>\n",
       "      <td>household</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36508.250375</td>\n",
       "      <td>39656.600444</td>\n",
       "      <td>13379.800000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>F</td>\n",
       "      <td>NH Black</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22352.088620</td>\n",
       "      <td>25525.423409</td>\n",
       "      <td>57661.621988</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31600.089655</td>\n",
       "      <td>31510.587866</td>\n",
       "      <td>76026.438279</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7529.435502</td>\n",
       "      <td>7575.870247</td>\n",
       "      <td>14694.924957</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21071.164059</td>\n",
       "      <td>22445.808572</td>\n",
       "      <td>60202.416895</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEQN  SDDSRVYR      WTINT2YR      WTMEC2YR       WTSAF2YR  SDMVPSU  \\\n",
       "0     1       1.0   9727.078709  10982.898896   75131.200000      1.0   \n",
       "1     2       1.0  26678.636376  28325.384898   60586.147294      3.0   \n",
       "2     3       1.0  43621.680548  46192.256945  121969.841152      2.0   \n",
       "3     4       1.0  10346.119327  10251.260020    4624.687273      1.0   \n",
       "4     5       1.0  91050.846620  99445.065735  234895.205650      2.0   \n",
       "5     6       1.0  36508.250375  39656.600444   13379.800000      2.0   \n",
       "6     7       1.0  22352.088620  25525.423409   57661.621988      2.0   \n",
       "7     8       1.0  31600.089655  31510.587866   76026.438279      1.0   \n",
       "8     9       1.0   7529.435502   7575.870247   14694.924957      2.0   \n",
       "9    10       1.0  21071.164059  22445.808572   60202.416895      1.0   \n",
       "\n",
       "   SDMVSTRA   age sex                re  ...  FS_HH  FS_ADULT  FS_FINAL  \\\n",
       "0       5.0   2.0   F    Other Hispanic  ...   <NA>      <NA>      <NA>   \n",
       "1       1.0  77.0   M  Mexican American  ...      0         0         0   \n",
       "2       7.0  10.0   F  Mexican American  ...   <NA>      <NA>      <NA>   \n",
       "3       2.0   1.0   M    Other Hispanic  ...   <NA>      <NA>      <NA>   \n",
       "4       8.0  49.0   M  Mexican American  ...      0         0         0   \n",
       "5       2.0  19.0   F          NH Black  ...   <NA>      <NA>      <NA>   \n",
       "6       4.0  59.0   F    Other Hispanic  ...   <NA>      <NA>      <NA>   \n",
       "7       6.0  13.0   M  Mexican American  ...   <NA>      <NA>      <NA>   \n",
       "8       9.0  11.0   F    Other Hispanic  ...   <NA>      <NA>      <NA>   \n",
       "9       7.0  43.0   M    Other Hispanic  ...   <NA>      <NA>      <NA>   \n",
       "\n",
       "   HHFDSEC  ADFDSEC  FS_HH4  FS_ADULT4  FS_SOURCE_HH  FS_SOURCE_FINAL  \\\n",
       "0     <NA>     <NA>    <NA>       <NA>          <NA>             <NA>   \n",
       "1        1        1       1          1       HHFDSEC        household   \n",
       "2     <NA>     <NA>    <NA>       <NA>          <NA>             <NA>   \n",
       "3     <NA>     <NA>    <NA>       <NA>          <NA>             <NA>   \n",
       "4        1        1       1          1       HHFDSEC        household   \n",
       "5     <NA>     <NA>    <NA>       <NA>          <NA>             <NA>   \n",
       "6     <NA>     <NA>    <NA>       <NA>          <NA>             <NA>   \n",
       "7     <NA>     <NA>    <NA>       <NA>          <NA>             <NA>   \n",
       "8     <NA>     <NA>    <NA>       <NA>          <NA>             <NA>   \n",
       "9     <NA>     <NA>    <NA>       <NA>          <NA>             <NA>   \n",
       "\n",
       "   SNAP_SOURCE  \n",
       "0         <NA>  \n",
       "1         <NA>  \n",
       "2         <NA>  \n",
       "3         <NA>  \n",
       "4         <NA>  \n",
       "5         <NA>  \n",
       "6         <NA>  \n",
       "7         <NA>  \n",
       "8         <NA>  \n",
       "9         <NA>  \n",
       "\n",
       "[10 rows x 135 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check \n",
    "df_my_cov_aligned.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e031a47b-4602-4cce-b912-700441a38853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chd</th>\n",
       "      <th>mi</th>\n",
       "      <th>dm_rx</th>\n",
       "      <th>MetS_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          chd   mi  dm_rx  MetS_count\n",
       "SDDSRVYR                             \n",
       "1.0       1.0  1.0    1.0         1.0\n",
       "2.0       1.0  1.0    1.0         1.0\n",
       "3.0       1.0  1.0    1.0         1.0\n",
       "4.0       1.0  1.0    1.0         1.0\n",
       "5.0       1.0  1.0    1.0         1.0\n",
       "6.0       1.0  1.0    1.0         1.0\n",
       "7.0       1.0  1.0    1.0         1.0\n",
       "8.0       1.0  1.0    1.0         1.0\n",
       "9.0       1.0  1.0    1.0         1.0\n",
       "10.0      1.0  1.0    1.0         1.0\n",
       "12.0      0.0  0.0    0.0         0.0\n",
       "66.0      0.0  0.0    0.0         0.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['chd','mi','dm_rx','MetS_count']\n",
    "(\n",
    "    df_my_cov_aligned\n",
    "    .groupby('SDDSRVYR')[cols]\n",
    "    .apply(lambda g: g.notna().mean())  # fraction non-missing per cycle\n",
    "    .round(3)\n",
    "    .sort_index()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce88a305-711c-49c4-8fc2-de471bb6e39d",
   "metadata": {},
   "source": [
    "#### check what column missing -23 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "abdf0300-3df3-4d30-b055-46cad7232f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction non-missing by cycle (all columns):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>12.0</th>\n",
       "      <th>66.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SEQN</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WTINT2YR</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WTMEC2YR</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WTSAF2YR</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SDMVPSU</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FS_HH4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FS_ADULT4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FS_SOURCE_HH</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FS_SOURCE_FINAL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNAP_SOURCE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "SDDSRVYR         12.0   66.0\n",
       "SEQN              1.0  1.000\n",
       "WTINT2YR          0.0  0.000\n",
       "WTMEC2YR          1.0  0.000\n",
       "WTSAF2YR          0.0  0.000\n",
       "SDMVPSU           1.0  1.000\n",
       "...               ...    ...\n",
       "FS_HH4            0.0  0.549\n",
       "FS_ADULT4         0.0  0.000\n",
       "FS_SOURCE_HH      0.0  0.549\n",
       "FS_SOURCE_FINAL   0.0  0.549\n",
       "SNAP_SOURCE       0.0  0.443\n",
       "\n",
       "[134 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vars with 0.0 coverage in both cycles (94): ['WTINT2YR', 'WTSAF2YR', 'tchol', 'hdl', 'ldl', 'tg', 'wc', 'bmi', 'dm_self', 'hba1c', 'fpg', 'chf', 'chd', 'mi', 'stroke', 'cancer', 'emphysema', 'bronchitis', 'asthma', 're2', 'copd', 'sbp', 'dbp', 'dm_rx', 'chol_rx', 'angina_rx', 'htn_rx', 'roseQ', 'no_na', 'age_cat'] ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = df_my_cov_aligned  # your aligned frame\n",
    "\n",
    "# --- choose post-2018 cycles you care about ---\n",
    "target_cycles = [12.0, 66.0]\n",
    "\n",
    "# keep only rows from those cycles that actually exist\n",
    "present_cycles = sorted([c for c in target_cycles if c in set(df['SDDSRVYR'].unique())])\n",
    "if not present_cycles:\n",
    "    raise ValueError(\"None of the target cycles are present in SDDSRVYR.\")\n",
    "\n",
    "post = df[df['SDDSRVYR'].isin(present_cycles)].copy()\n",
    "\n",
    "# columns except the grouping key\n",
    "cols_no_group = [c for c in post.columns if c != 'SDDSRVYR']\n",
    "\n",
    "# Fraction non-missing for EVERY column, per cycle (variables as rows)\n",
    "cov_all = (\n",
    "    post.groupby('SDDSRVYR')[cols_no_group]\n",
    "        .apply(lambda g: g.notna().mean(numeric_only=False))\n",
    "        .T\n",
    "        .round(3)\n",
    "    # columns are cycles (e.g., 12.0, 66.0)\n",
    ")\n",
    "\n",
    "# pretty display if available\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    print(\"Fraction non-missing by cycle (all columns):\")\n",
    "    display(cov_all)\n",
    "except Exception:\n",
    "    print(\"Fraction non-missing by cycle (all columns):\\n\", cov_all)\n",
    "\n",
    "# Ensure both target cycle columns exist for the zero-coverage check\n",
    "cov_for_check = cov_all.reindex(columns=target_cycles, fill_value=0.0)\n",
    "\n",
    "# Columns with 0.0 coverage in both cycles\n",
    "zero_both_mask = (cov_for_check.iloc[:, 0] == 0) & (cov_for_check.iloc[:, 1] == 0)\n",
    "zero_both = cov_for_check.index[zero_both_mask].tolist()\n",
    "\n",
    "print(f\"Vars with 0.0 coverage in both cycles ({len(zero_both)}):\",\n",
    "      zero_both[:30], \"...\" if len(zero_both) > 30 else \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "eda87594-1d1c-4f78-b849-9398abe57c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Missing in at least one post-2018 cycle: 106\n",
      "['WTINT2YR', 'WTMEC2YR', 'WTSAF2YR', 'tchol', 'hdl', 'ldl', 'tg', 'wc', 'bmi', 'dm_self', 'hba1c', 'fpg', 'chf', 'chd', 'mi', 'stroke', 'cancer', 'emphysema', 'bronchitis', 'asthma', 're2', 'copd', 'sbp', 'dbp', 'dm_rx', 'chol_rx', 'angina_rx', 'htn_rx', 'roseQ', 'no_na'] ...\n",
      "\n",
      "❌ Missing in BOTH 12.0 and 66.0: 94\n",
      "['WTINT2YR', 'WTSAF2YR', 'tchol', 'hdl', 'ldl', 'tg', 'wc', 'bmi', 'dm_self', 'hba1c', 'fpg', 'chf', 'chd', 'mi', 'stroke', 'cancer', 'emphysema', 'bronchitis', 'asthma', 're2', 'copd', 'sbp', 'dbp', 'dm_rx', 'chol_rx', 'angina_rx', 'htn_rx', 'roseQ', 'no_na', 'age_cat'] ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>12.0</th>\n",
       "      <th>66.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WTINT2YR</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WTMEC2YR</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WTSAF2YR</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tchol</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hdl</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FS_HH4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FS_ADULT4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FS_SOURCE_HH</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FS_SOURCE_FINAL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNAP_SOURCE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "SDDSRVYR         12.0   66.0\n",
       "WTINT2YR          0.0  0.000\n",
       "WTMEC2YR          1.0  0.000\n",
       "WTSAF2YR          0.0  0.000\n",
       "tchol             0.0  0.000\n",
       "hdl               0.0  0.000\n",
       "...               ...    ...\n",
       "FS_HH4            0.0  0.549\n",
       "FS_ADULT4         0.0  0.000\n",
       "FS_SOURCE_HH      0.0  0.549\n",
       "FS_SOURCE_FINAL   0.0  0.549\n",
       "SNAP_SOURCE       0.0  0.443\n",
       "\n",
       "[106 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = df_my_cov_aligned  # your aligned frame\n",
    "\n",
    "# --- Define post-2018 cycles ---\n",
    "post_cycles = [12.0, 66.0]\n",
    "\n",
    "# Keep only those rows\n",
    "post = df[df['SDDSRVYR'].isin(post_cycles)].copy()\n",
    "\n",
    "# --- Compute fraction non-missing for each column by cycle ---\n",
    "cov_all = (\n",
    "    post.groupby('SDDSRVYR')\n",
    "        .apply(lambda g: g.notna().mean(numeric_only=False), include_groups=False)\n",
    "        .T.round(3)\n",
    ")\n",
    "\n",
    "# --- Identify columns missing in either or both cycles ---\n",
    "missing_any = cov_all.index[(cov_all == 0).any(axis=1)].tolist()\n",
    "missing_both = cov_all.index[(cov_all == 0).all(axis=1)].tolist()\n",
    "\n",
    "print(\"🔎 Missing in at least one post-2018 cycle:\", len(missing_any))\n",
    "print(missing_any[:30], \"...\" if len(missing_any) > 30 else \"\")\n",
    "\n",
    "print(\"\\n❌ Missing in BOTH 12.0 and 66.0:\", len(missing_both))\n",
    "print(missing_both[:30], \"...\" if len(missing_both) > 30 else \"\")\n",
    "\n",
    "# Optional: show a nice table of just the missing vars\n",
    "missing_table = cov_all.loc[missing_any]\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    display(missing_table)\n",
    "except:\n",
    "    print(missing_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761d8d86-9cfe-4106-a0a2-129603d4a831",
   "metadata": {},
   "source": [
    "## Fill columns missing post 2018   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc72500-e807-4b89-a189-d7ebeaacde96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ce371ff7-7e94-4ba6-9658-ea34f3db1c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LABS ===\n",
      "shape: (20266, 7)\n",
      "cols: ['SEQN', 'SDDSRVYR', 'LBXTC', 'LBDHDD', 'LBXTR', 'LBXGLU', 'LBXGH']\n",
      "SEQN overlap with post-2018: 20266\n",
      "\n",
      "=== MCQ ===\n",
      "shape: (26730, 11)\n",
      "cols: ['SEQN', 'SDDSRVYR', 'MCQ160A', 'MCQ160B', 'MCQ160C', 'MCQ160D', 'MCQ160E', 'MCQ160F', 'MCQ160M', 'MCQ160P', 'MCQ160L']\n",
      "SEQN overlap with post-2018: 26730\n",
      "\n",
      "Filled LABS (post-2018) non-missing share:\n",
      "tchol        0.644\n",
      "hdl          0.644\n",
      "tg           0.169\n",
      "fpg          0.306\n",
      "hba1c        0.598\n",
      "tchol_hdl    0.644\n",
      "dtype: float64\n",
      "\n",
      "Filled MCQ (post-2018) non-missing share:\n",
      "chf       0.284\n",
      "chd       0.284\n",
      "angina    0.284\n",
      "mi        0.284\n",
      "stroke    0.284\n",
      "dtype: float64\n",
      "\n",
      "Post-2018 non-missing share (key fields):\n",
      "MetS_count    1.000\n",
      "BMXWT         0.830\n",
      "BMXHT         0.788\n",
      "BMI           0.786\n",
      "wc            0.755\n",
      "tchol         0.644\n",
      "hdl           0.644\n",
      "tchol_hdl     0.644\n",
      "hba1c         0.598\n",
      "fpg           0.306\n",
      "chd           0.284\n",
      "mi            0.284\n",
      "chf           0.284\n",
      "stroke        0.284\n",
      "tg            0.169\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = df_my_cov_aligned.copy()\n",
    "post_mask = df['SDDSRVYR'].isin([12.0, 66.0])\n",
    "\n",
    "# ---------- 1) Inspect what's in LABS and MCQ ----------\n",
    "def head_info(name, obj):\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    if isinstance(obj, pd.DataFrame) and not obj.empty:\n",
    "        print(\"shape:\", obj.shape)\n",
    "        print(\"cols:\", list(obj.columns[:20]))\n",
    "        # overlap in SEQN with your post-2018 rows\n",
    "        inter = set(df.loc[post_mask, 'SEQN']).intersection(set(obj['SEQN'])) if 'SEQN' in obj.columns else set()\n",
    "        print(\"SEQN overlap with post-2018:\", len(inter))\n",
    "    else:\n",
    "        print(\"(empty)\")\n",
    "\n",
    "if 'LABS' in globals(): head_info(\"LABS\", LABS)\n",
    "if 'MCQ'  in globals(): head_info(\"MCQ\", MCQ)\n",
    "\n",
    "# Make sure SEQN dtypes agree (prevents silent non-matches)\n",
    "if 'SEQN' in df.columns:\n",
    "    df['SEQN'] = pd.to_numeric(df['SEQN'], errors='coerce')\n",
    "\n",
    "for tbl in ['LABS','MCQ']:\n",
    "    if tbl in globals() and isinstance(globals()[tbl], pd.DataFrame) and 'SEQN' in globals()[tbl].columns:\n",
    "        globals()[tbl]['SEQN'] = pd.to_numeric(globals()[tbl]['SEQN'], errors='coerce')\n",
    "\n",
    "# ---------- 2) Retry LABS fill (robust) ----------\n",
    "if 'LABS' in globals() and isinstance(LABS, pd.DataFrame) and not LABS.empty:\n",
    "    # Which analytes do we actually have?\n",
    "    pairs_all = {'tchol':'LBXTC','hdl':'LBDHDD','tg':'LBXTR','fpg':'LBXGLU','hba1c':'LBXGH'}\n",
    "    have = {dst:src for dst,src in pairs_all.items() if src in LABS.columns}\n",
    "    if have:\n",
    "        # Pre-create dest so right-side gets _labs suffix\n",
    "        for dst in have:\n",
    "            if dst not in df.columns:\n",
    "                df[dst] = pd.NA\n",
    "\n",
    "        # Merge ONLY post-2018 persons to reduce memory\n",
    "        post_seqn = df.loc[post_mask, ['SEQN']].drop_duplicates()\n",
    "        labs_sub = post_seqn.merge(LABS[['SEQN'] + list(have.values())], on='SEQN', how='left')\n",
    "\n",
    "        df = df.merge(labs_sub, on='SEQN', how='left', suffixes=('','_labs'))\n",
    "\n",
    "        # Fill where NA and right side present\n",
    "        for dst, src in have.items():\n",
    "            rhs = f'{src}_labs'\n",
    "            if rhs in df.columns:\n",
    "                m = post_mask & df[dst].isna() & df[rhs].notna()\n",
    "                df.loc[m, dst] = df.loc[m, rhs]\n",
    "\n",
    "        # ratio if both present\n",
    "        if all(c in df.columns for c in ['tchol','hdl','tchol_hdl']):\n",
    "            m = post_mask & df['tchol_hdl'].isna() & df['tchol'].notna() & df['hdl'].notna() & (df['hdl']!=0)\n",
    "            df.loc[m, 'tchol_hdl'] = df.loc[m, 'tchol'] / df.loc[m, 'hdl']\n",
    "\n",
    "        # clean up\n",
    "        drop_cols = [f'{src}_labs' for src in have.values() if f'{src}_labs' in df.columns]\n",
    "        df.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
    "\n",
    "        # Quick audit\n",
    "        print(\"\\nFilled LABS (post-2018) non-missing share:\")\n",
    "        cols = [c for c in ['tchol','hdl','tg','fpg','hba1c','tchol_hdl'] if c in df.columns]\n",
    "        if cols:\n",
    "            print(df.loc[post_mask, cols].notna().mean().round(3))\n",
    "\n",
    "# ---------- 3) MCQ (CVD history) — corrected & case-insensitive ----------\n",
    "if 'MCQ' in globals() and isinstance(MCQ, pd.DataFrame) and not MCQ.empty:\n",
    "    # only bring MCQ rows for post-2018 persons\n",
    "    post_seqn = df.loc[post_mask, ['SEQN','SDDSRVYR']].drop_duplicates()\n",
    "    mcq_sub = post_seqn.merge(MCQ, on=['SEQN','SDDSRVYR'], how='left')\n",
    "\n",
    "    # merge (no suffixing; we'll drop MCQ160* afterward)\n",
    "    df = df.merge(mcq_sub, on=['SEQN','SDDSRVYR'], how='left', suffixes=('',''))\n",
    "\n",
    "    # helper: pick first existing column from candidates (exact or case-insensitive)\n",
    "    def pick_any(frame, names):\n",
    "        for n in names:\n",
    "            if n in frame.columns:\n",
    "                return n\n",
    "        lower_map = {c.lower(): c for c in frame.columns}\n",
    "        for n in names:\n",
    "            if n.lower() in lower_map:\n",
    "                return lower_map[n.lower()]\n",
    "        return None\n",
    "\n",
    "    # Correct mapping (stroke is f/F), support J vs L and any casing\n",
    "    mcq_map_fixed = {\n",
    "        'chf':    ['MCQ160b','MCQ160B'],\n",
    "        'chd':    ['MCQ160c','MCQ160C'],\n",
    "        'angina': ['MCQ160d','MCQ160D'],\n",
    "        'mi':     ['MCQ160e','MCQ160E'],\n",
    "        'stroke': ['MCQ160f','MCQ160F'],\n",
    "    }\n",
    "\n",
    "    for out, candidates in mcq_map_fixed.items():\n",
    "        raw = pick_any(df, candidates)\n",
    "        if raw and out in df.columns:\n",
    "            m = post_mask & df[out].isna() & df[raw].notna()\n",
    "            df.loc[m, out] = (df.loc[m, raw] == 1).astype('Int8')\n",
    "\n",
    "    # drop raw MCQ columns to keep your schema clean\n",
    "    drop_mcq = [c for c in df.columns if c.startswith('MCQ160')]\n",
    "    if drop_mcq:\n",
    "        df.drop(columns=drop_mcq, inplace=True, errors='ignore')\n",
    "\n",
    "    # quick coverage report\n",
    "    cols = [c for c in ['chf','chd','angina','mi','stroke'] if c in df.columns]\n",
    "    if cols:\n",
    "        print(\"\\nFilled MCQ (post-2018) non-missing share:\")\n",
    "        print(df.loc[post_mask, cols].notna().mean().round(3))\n",
    "\n",
    "# ---------- 4) Recompute MetS flags ONLY where inputs exist ----------\n",
    "sex = df.get('sex', pd.Series(index=df.index, dtype='object')).astype(str).str.lower()\n",
    "\n",
    "def set_flag(col, mask_bool):\n",
    "    if col in df.columns:\n",
    "        m = post_mask & df[col].isna() & mask_bool.notna()\n",
    "        df.loc[m, col] = mask_bool[m].astype('Int8')\n",
    "\n",
    "if {'MetS_hdl','hdl'}.issubset(df.columns):\n",
    "    present = df['hdl'].notna() & sex.isin(['male','female'])\n",
    "    hdl_abn = pd.Series(pd.NA, index=df.index)\n",
    "    hdl_abn[present & (sex=='male')]   = (df.loc[present & (sex=='male'), 'hdl'] < 40)\n",
    "    hdl_abn[present & (sex=='female')] = (df.loc[present & (sex=='female'), 'hdl'] < 50)\n",
    "    set_flag('MetS_hdl', hdl_abn)\n",
    "\n",
    "if {'MetS_triglycerides','tg'}.issubset(df.columns):\n",
    "    present = df['tg'].notna()\n",
    "    set_flag('MetS_triglycerides', (df['tg'] >= 150).where(present))\n",
    "\n",
    "if 'MetS_fpg' in df.columns and ('fpg' in df.columns or 'hba1c' in df.columns):\n",
    "    present = df.get('fpg', pd.Series(index=df.index)).notna() | df.get('hba1c', pd.Series(index=df.index)).notna()\n",
    "    flag = ((df.get('fpg', 0) >= 100) | (df.get('hba1c', 0) >= 6.5)).where(present)\n",
    "    set_flag('MetS_fpg', flag)\n",
    "\n",
    "# Waist/BP MetS flags are already set earlier if their inputs exist\n",
    "\n",
    "# ---------- 5) Save back and show coverage ----------\n",
    "df_my_cov_aligned = df\n",
    "\n",
    "check = [c for c in ['BMXWT','BMXHT','BMI','wc','SBP','DBP','tchol','hdl','tg','fpg','hba1c','tchol_hdl','chd','mi','chf','stroke','MetS_count'] if c in df.columns]\n",
    "print(\"\\nPost-2018 non-missing share (key fields):\")\n",
    "if check:\n",
    "    print(df.loc[post_mask, check].notna().mean().round(3).sort_values(ascending=False))\n",
    "else:\n",
    "    print(\"(no key fields to report)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5c79bf4b-e2a0-4aa5-8394-83ae076a5a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MetS_hdl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128709</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128710</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128711</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128712</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128713</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128804</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128805</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128806</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128807</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128808</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MetS_hdl\n",
       "128709       0.0\n",
       "128710       0.0\n",
       "128711       0.0\n",
       "128712       0.0\n",
       "128713       0.0\n",
       "...          ...\n",
       "128804       0.0\n",
       "128805       0.0\n",
       "128806       0.0\n",
       "128807       0.0\n",
       "128808       0.0\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df_my_cov_aligned[['MetS_hdl']].tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2d6e94-0822-48af-89a5-878420daf88e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de879d47-43a6-43fc-a195-fcb568909d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00594207-5bda-4e2d-919d-7520d1d72bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890b9ca8-22c5-4035-a1f3-276abbc56177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "35edcc53-330f-448f-b9e0-2a4698c577a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled (post-2018) columns: ['MetS_wc']\n",
      "Fraction non-missing by cycle (post cycles):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>12.0</th>\n",
       "      <th>66.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SEQN</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WTINT2YR</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WTMEC2YR</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WTSAF2YR</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SDMVPSU</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBXTC</th>\n",
       "      <td>0.577</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBDHDD</th>\n",
       "      <td>0.577</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBXTR</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBXGLU</th>\n",
       "      <td>0.308</td>\n",
       "      <td>0.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBXGH</th>\n",
       "      <td>0.563</td>\n",
       "      <td>0.626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "SDDSRVYR   12.0   66.0\n",
       "SEQN      1.000  1.000\n",
       "WTINT2YR  0.000  0.000\n",
       "WTMEC2YR  1.000  0.000\n",
       "WTSAF2YR  0.000  0.000\n",
       "SDMVPSU   1.000  1.000\n",
       "...         ...    ...\n",
       "LBXTC     0.577  0.696\n",
       "LBDHDD    0.577  0.696\n",
       "LBXTR     0.000  0.299\n",
       "LBXGLU    0.308  0.305\n",
       "LBXGH     0.563  0.626\n",
       "\n",
       "[142 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = df_my_cov_aligned.copy()\n",
    "POST = [12.0, 66.0]\n",
    "post_mask = df['SDDSRVYR'].isin(POST)\n",
    "filled = []\n",
    "\n",
    "def maybe_merge(left, right, cols, suffix):\n",
    "    \"\"\"Merge if right exists and has the needed cols.\"\"\"\n",
    "    if isinstance(right, pd.DataFrame) and all(c in right.columns for c in cols):\n",
    "        return left.merge(right[cols], on='SEQN', how='left', suffixes=('', suffix))\n",
    "    return left\n",
    "\n",
    "def fill_na(dst, src):\n",
    "    if dst in df.columns and src in df.columns:\n",
    "        m = post_mask & df[dst].isna() & df[src].notna()\n",
    "        if m.any():\n",
    "            df.loc[m, dst] = df.loc[m, src]\n",
    "            filled.append(dst)\n",
    "\n",
    "# ---------- BMX ----------\n",
    "if 'bmx_2019_2023' in globals():\n",
    "    df = maybe_merge(df, bmx_2019_2023, ['SEQN','BMXWT','BMXHT','BMXWAIST'], '_bmx')\n",
    "    for dst, src in [('BMXWT','BMXWT_bmx'), ('BMXHT','BMXHT_bmx')]:\n",
    "        fill_na(dst, src)\n",
    "    # waist -> wc\n",
    "    if 'BMXWAIST_bmx' in df.columns:\n",
    "        fill_na('wc', 'BMXWAIST_bmx')\n",
    "    # BMI\n",
    "    m = post_mask & df['BMI'].isna() & df['BMXWT'].notna() & df['BMXHT'].notna()\n",
    "    df.loc[m, 'BMI'] = df.loc[m,'BMXWT'] / (df.loc[m,'BMXHT']/100.0)**2\n",
    "    if m.any(): filled.append('BMI')\n",
    "    # BMI class\n",
    "    if 'BMI_CLAS' in df.columns:\n",
    "        bins = [0,18.5,25,30,float('inf')]; labels = ['under','normal','over','obese']\n",
    "        m = post_mask & df['BMI_CLAS'].isna() & df['BMI'].notna()\n",
    "        df.loc[m, 'BMI_CLAS'] = pd.cut(df.loc[m,'BMI'], bins=bins, labels=labels)\n",
    "        if m.any(): filled.append('BMI_CLAS')\n",
    "    df.drop(columns=[c for c in df.columns if c.endswith('_bmx')], inplace=True, errors='ignore')\n",
    "\n",
    "# ---------- BPX ----------\n",
    "if 'bpx_2019_2023' in globals():\n",
    "    keep = [c for c in ['SEQN','BPXSY1','BPXSY2','BPXSY3','BPXDI1','BPXDI2','BPXDI3'] if c in bpx_2019_2023.columns]\n",
    "    if len(keep) >= 2:\n",
    "        tmp = bpx_2019_2023[keep].copy()\n",
    "        tmp['SBP_mean'] = tmp[[c for c in ['BPXSY1','BPXSY2','BPXSY3'] if c in tmp]].mean(axis=1)\n",
    "        tmp['DBP_mean'] = tmp[[c for c in ['BPXDI1','BPXDI2','BPXDI3'] if c in tmp]].mean(axis=1)\n",
    "        df = df.merge(tmp[['SEQN','SBP_mean','DBP_mean']], on='SEQN', how='left')\n",
    "        fill_na('SBP', 'SBP_mean')\n",
    "        fill_na('DBP', 'DBP_mean')\n",
    "        df.drop(columns=['SBP_mean','DBP_mean'], inplace=True, errors='ignore')\n",
    "\n",
    "# ---------- LAB ----------\n",
    "if 'lab_2019_2023' in globals():\n",
    "    poss = ['SEQN','LBXTC','LBDHDD','LBDLDL','LBXTR','LBXGLU','LBXGH']\n",
    "    keep = [c for c in poss if c in lab_2019_2023.columns]\n",
    "    if len(keep) > 1:\n",
    "        df = maybe_merge(df, lab_2019_2023, keep, '_lab')\n",
    "        pairs = {'tchol':'LBXTC_lab','hdl':'LBDHDD_lab','ldl':'LBDLDL_lab',\n",
    "                 'tg':'LBXTR_lab','fpg':'LBXGLU_lab','hba1c':'LBXGH_lab'}\n",
    "        for dst, src in pairs.items():\n",
    "            fill_na(dst, src)\n",
    "        # tchol/hdl ratio\n",
    "        if all(c in df.columns for c in ['tchol','hdl','tchol_hdl']):\n",
    "            m = post_mask & df['tchol_hdl'].isna() & df['tchol'].notna() & df['hdl'].notna() & (df['hdl']!=0)\n",
    "            df.loc[m, 'tchol_hdl'] = df.loc[m,'tchol']/df.loc[m,'hdl']\n",
    "            if m.any(): filled.append('tchol_hdl')\n",
    "        df.drop(columns=[c for c in df.columns if c.endswith('_lab')], inplace=True, errors='ignore')\n",
    "\n",
    "# ---------- MCQ (CVD history) ----------\n",
    "if 'mcq_2019_2023' in globals():\n",
    "    keep = [c for c in ['SEQN','MCQ160B','MCQ160E','MCQ160F','MCQ160G'] if c in mcq_2019_2023.columns]\n",
    "    if len(keep) > 1:\n",
    "        df = df.merge(mcq_2019_2023[keep], on='SEQN', how='left')\n",
    "        for out, raw in [('chd','MCQ160E'),('mi','MCQ160F'),('chf','MCQ160B'),('stroke','MCQ160G')]:\n",
    "            if out in df.columns and raw in df.columns:\n",
    "                m = post_mask & df[out].isna()\n",
    "                df.loc[m, out] = (df.loc[m, raw] == 1).astype('Int8')\n",
    "                if m.any(): filled.append(out)\n",
    "\n",
    "# ---------- RXQ (Medications) ----------\n",
    "if 'rxq_2019_2023' in globals() and 'SEQN' in rxq_2019_2023.columns:\n",
    "    # Replace this logic with your ATC/RxClass classification\n",
    "    class_col = 'DRUG_CLASS'\n",
    "    if class_col in rxq_2019_2023.columns:\n",
    "        rx = rxq_2019_2023[['SEQN', class_col]].copy()\n",
    "        rx['dm_f']   = rx[class_col].str.contains('antidiabet', case=False, na=False)\n",
    "        rx['htn_f']  = rx[class_col].str.contains('antihypertens', case=False, na=False)\n",
    "        rx['chol_f'] = rx[class_col].str.contains('statin|lipid', case=False, na=False)\n",
    "        rx['ang_f']  = rx[class_col].str.contains('nitrate|antiangina|ranolazine', case=False, na=False)\n",
    "        flags = (rx.groupby('SEQN')[['dm_f','htn_f','chol_f','ang_f']].any()\n",
    "                   .rename(columns={'dm_f':'dm_rx','htn_f':'htn_rx','chol_f':'chol_rx','ang_f':'angina_rx'})\n",
    "                   .reset_index())\n",
    "        df = df.merge(flags, on='SEQN', how='left', suffixes=('','_new'))\n",
    "        for col in ['dm_rx','htn_rx','chol_rx','angina_rx']:\n",
    "            if col in df.columns and f'{col}_new' in df.columns:\n",
    "                m = post_mask & df[col].isna()\n",
    "                df.loc[m, col] = df.loc[m, f'{col}_new'].fillna(False).astype('Int8')\n",
    "                df.drop(columns=[f'{col}_new'], inplace=True)\n",
    "\n",
    "# ---------- MetS components & count ----------\n",
    "if 'sex' in df.columns:\n",
    "    sex = df['sex'].astype(str).str.lower()\n",
    "    def set_bin(col, mask_bool):\n",
    "        if col in df.columns:\n",
    "            m = post_mask & df[col].isna()\n",
    "            df.loc[m, col] = mask_bool[m].astype('Int8')\n",
    "            if m.any(): filled.append(col)\n",
    "\n",
    "    # components\n",
    "    if 'BMXWAIST' in df.columns:  # for wc criterion\n",
    "        wc_abn = ((sex=='male') & (df['BMXWAIST']>=102)) | ((sex=='female') & (df['BMXWAIST']>=88))\n",
    "        set_bin('MetS_wc', wc_abn)\n",
    "\n",
    "    if all(c in df.columns for c in ['SBP','DBP']):\n",
    "        bp_abn = (df['SBP']>=130) | (df['DBP']>=85) | (df.get('htn_rx', 0)==1)\n",
    "        set_bin('MetS_bp', bp_abn)\n",
    "\n",
    "    if 'tg' in df.columns:\n",
    "        set_bin('MetS_triglycerides', df['tg']>=150)\n",
    "\n",
    "    if 'hdl' in df.columns:\n",
    "        hdl_abn = ((sex=='male') & (df['hdl']<40)) | ((sex=='female') & (df['hdl']<50))\n",
    "        set_bin('MetS_hdl', hdl_abn)\n",
    "\n",
    "    set_bin('MetS_fpg', (df.get('fpg', pd.Series(index=df.index))>=100) | (df.get('hba1c', pd.Series(index=df.index))>=6.5))\n",
    "\n",
    "    # count\n",
    "    if 'MetS_count' in df.columns:\n",
    "        m = post_mask & df['MetS_count'].isna()\n",
    "        comps = [c for c in ['MetS_wc','MetS_bp','MetS_triglycerides','MetS_hdl','MetS_fpg'] if c in df.columns]\n",
    "        if comps:\n",
    "            comp_sum = df[comps].replace({pd.NA:0}).astype('Int8').sum(axis=1, min_count=1)\n",
    "            df.loc[m, 'MetS_count'] = comp_sum[m]\n",
    "            if m.any(): filled.append('MetS_count')\n",
    "\n",
    "# ---------- Food security ----------\n",
    "if 'fs_2019_2023' in globals():\n",
    "    fs_cols = [c for c in ['SEQN','FS','FS_FINAL','FS_HH','FS_ADULT','HHFDSEC','ADFDSEC','FS_HH4','FS_ADULT4','FS_SOURCE_HH','FS_SOURCE_FINAL','SNAP_SOURCE'] if c in fs_2019_2023.columns]\n",
    "    if fs_cols:\n",
    "        df = df.merge(fs_2019_2023[fs_cols], on='SEQN', how='left', suffixes=('','_fsnew'))\n",
    "        for base in [c for c in fs_cols if c!='SEQN']:\n",
    "            newc = f'{base}_fsnew'\n",
    "            if base in df.columns and newc in df.columns:\n",
    "                m = post_mask & df[base].isna()\n",
    "                df.loc[m, base] = df.loc[m, newc]\n",
    "        df.drop(columns=[c for c in df.columns if c.endswith('_fsnew')], inplace=True, errors='ignore')\n",
    "\n",
    "# ---------- Summary ----------\n",
    "print(\"Filled (post-2018) columns:\", sorted(set(filled)))\n",
    "\n",
    "# quick coverage re-check for post cycles\n",
    "post_cov = (\n",
    "    df[df['SDDSRVYR'].isin(POST)]\n",
    "      .groupby('SDDSRVYR')\n",
    "      .apply(lambda g: g.notna().mean(numeric_only=False), include_groups=False)\n",
    "      .T.round(3)\n",
    ")\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    print(\"Fraction non-missing by cycle (post cycles):\")\n",
    "    display(post_cov)\n",
    "except Exception:\n",
    "    print(post_cov)\n",
    "\n",
    "df_my_cov_aligned = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb17b8d-2df0-4697-9cf4-67f69e508677",
   "metadata": {},
   "source": [
    "#### check after fetch and merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c1e3178e-e35d-4dee-b05e-11b4f865cd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 columns:\n",
      " ['ADFDSEC', 'ALCOHOL_CAT', 'BMI', 'BMI_CLAS', 'BMXHT', 'BMXWAIST', 'BMXWT', 'CENSORED', 'CIDI_12M_MDE', 'CIDI_SCORE_RAW', 'CIGS_PER_DAY', 'CVD', 'DEP_HARMONIZED', 'DEP_IMP', 'DEP_SOURCE', 'DMDHHSIZ', 'DPQ_CAT', 'DRINKS_PER_DAY', 'EDU_CAT', 'ELIGSTAT', 'EMPLOY', 'EVENT', 'FEMALE', 'FORMER_SMOKER', 'FS', 'FSDHH', 'FS_ADULT', 'FS_ADULT4', 'FS_FINAL', 'FS_HH', 'FS_HH4', 'FS_SOURCE_FINAL', 'FS_SOURCE_HH', 'FU_YRS_EXM', 'FU_YRS_INT', 'HHFDSEC', 'HIGH_CHOL', 'HOD050', 'HOQ065', 'HTN', 'IMP', 'INDFMINC', 'INS', 'IS_ADULT', 'IS_POST2018', 'LBDHDD', 'LBXGH', 'LBXGLU', 'LBXTC', 'LBXTR', 'LTPA', 'MARITAL', 'MARITAL_CAT', 'METSCORE', 'MORTALITY_COVERED', 'MORTSTAT', 'MetS', 'MetS_bp', 'MetS_count', 'MetS_fpg', 'MetS_hdl', 'MetS_triglycerides', 'MetS_wc', 'PACK_YEARS', 'PERMTH_EXM', 'PERMTH_INT', 'PHQ9', 'PHQ9_GE10', 'RIAGENDR', 'SDDSRVYR', 'SDDSRVYR_src', 'SDMVPSU', 'SDMVSTRA', 'SEQN', 'SMK_STATUS', 'SNAP', 'SNAP_SOURCE', 'UCOD_LABEL', 'UCOD_LEADING', 'UNEMPLOYMENT', 'WTINT2YR', 'WTMEC2YR', 'WTSAF2YR', 'WTSCI2YR', 'adiposity_pri', 'adiposity_sec', 'age', 'age_cat', 'angina', 'angina_rx', 'asthma', 'bmi', 'bp_pri', 'bp_sec', 'bronchitis', 'cancer', 'chd', 'chf', 'chol_rx', 'copd', 'cvd_pri', 'cvd_sec', 'dbp', 'diabetes', 'dm_rx', 'dm_self', 'edu', 'edu2', 'emphysema', 'fpg', 'glucose_pri', 'glucose_sec', 'hba1c', 'hdl', 'htn_rx', 'intermediate_pri_count', 'intermediate_sec_count', 'ldl', 'lipid_pri', 'lipid_sec', 'lung_disease', 'mi', 'no_na', 'optimal_all', 'optimal_all_sec', 'optimal_pri_count', 'optimal_sec_count', 'pir', 'pir_cat', 'poor_all', 'poor_all_sec', 'poor_pri_count', 'poor_sec_count', 're', 're2', 'roseQ', 'sbp', 'sex', 'stroke', 'tchol', 'tchol_hdl', 'tg', 'wc']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>dtype</th>\n",
       "      <th>n_nonnull</th>\n",
       "      <th>n_unique</th>\n",
       "      <th>na_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADFDSEC</td>\n",
       "      <td>Int64</td>\n",
       "      <td>9798</td>\n",
       "      <td>4</td>\n",
       "      <td>0.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALCOHOL_CAT</td>\n",
       "      <td>category</td>\n",
       "      <td>68861</td>\n",
       "      <td>3</td>\n",
       "      <td>0.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BMI</td>\n",
       "      <td>object</td>\n",
       "      <td>21608</td>\n",
       "      <td>20855</td>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMI_CLAS</td>\n",
       "      <td>string</td>\n",
       "      <td>87799</td>\n",
       "      <td>4</td>\n",
       "      <td>0.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMXHT</td>\n",
       "      <td>float64</td>\n",
       "      <td>109895</td>\n",
       "      <td>1225</td>\n",
       "      <td>0.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>stroke</td>\n",
       "      <td>Int8</td>\n",
       "      <td>109122</td>\n",
       "      <td>3</td>\n",
       "      <td>0.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>tchol</td>\n",
       "      <td>float64</td>\n",
       "      <td>119034</td>\n",
       "      <td>366</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>tchol_hdl</td>\n",
       "      <td>float64</td>\n",
       "      <td>119034</td>\n",
       "      <td>21058</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>tg</td>\n",
       "      <td>float64</td>\n",
       "      <td>105966</td>\n",
       "      <td>697</td>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>wc</td>\n",
       "      <td>float64</td>\n",
       "      <td>122080</td>\n",
       "      <td>1264</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             col     dtype  n_nonnull  n_unique  na_rate\n",
       "0        ADFDSEC     Int64       9798         4    0.924\n",
       "1    ALCOHOL_CAT  category      68861         3    0.465\n",
       "2            BMI    object      21608     20855    0.832\n",
       "3       BMI_CLAS    string      87799         4    0.318\n",
       "4          BMXHT   float64     109895      1225    0.147\n",
       "..           ...       ...        ...       ...      ...\n",
       "138       stroke      Int8     109122         3    0.153\n",
       "139        tchol   float64     119034       366    0.076\n",
       "140    tchol_hdl   float64     119034     21058    0.076\n",
       "141           tg   float64     105966       697    0.177\n",
       "142           wc   float64     122080      1264    0.052\n",
       "\n",
       "[143 rows x 5 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = df_my_cov_aligned  # assumes it exists\n",
    "\n",
    "# 1) Just the column names (alphabetical)\n",
    "cols = sorted(df.columns.tolist())\n",
    "print(f\"{len(cols)} columns:\\n\", cols)\n",
    "\n",
    "# 2) Detailed summary per column\n",
    "summary = (\n",
    "    pd.DataFrame({\n",
    "        \"col\": df.columns,\n",
    "        \"dtype\": df.dtypes.astype(str),\n",
    "        \"n_nonnull\": df.notna().sum().values,\n",
    "        \"n_unique\": df.nunique(dropna=True).values,\n",
    "        \"na_rate\": df.isna().mean().round(3).values,\n",
    "    })\n",
    "    .sort_values(\"col\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "summary\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a31a3ce5-7eeb-4e23-9b5f-c48e7aa133f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MetS_hdl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128769</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128770</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128771</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128772</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128773</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128774</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128775</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128776</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128777</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128778</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128779</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128780</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128781</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128782</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128783</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128784</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128785</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128786</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128787</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128788</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128789</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128790</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128791</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128792</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128793</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128794</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128795</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128796</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128797</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128798</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128799</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128800</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128801</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128802</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128803</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128804</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128805</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128806</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128807</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128808</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MetS_hdl\n",
       "128769       0.0\n",
       "128770       0.0\n",
       "128771       0.0\n",
       "128772       0.0\n",
       "128773       0.0\n",
       "128774       0.0\n",
       "128775       0.0\n",
       "128776       0.0\n",
       "128777       0.0\n",
       "128778       0.0\n",
       "128779       0.0\n",
       "128780       0.0\n",
       "128781       0.0\n",
       "128782       0.0\n",
       "128783       0.0\n",
       "128784       0.0\n",
       "128785       0.0\n",
       "128786       0.0\n",
       "128787       0.0\n",
       "128788       0.0\n",
       "128789       0.0\n",
       "128790       0.0\n",
       "128791       0.0\n",
       "128792       0.0\n",
       "128793       0.0\n",
       "128794       0.0\n",
       "128795       0.0\n",
       "128796       0.0\n",
       "128797       0.0\n",
       "128798       0.0\n",
       "128799       0.0\n",
       "128800       0.0\n",
       "128801       0.0\n",
       "128802       0.0\n",
       "128803       0.0\n",
       "128804       0.0\n",
       "128805       0.0\n",
       "128806       0.0\n",
       "128807       0.0\n",
       "128808       0.0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df_my_cov_aligned[['MetS_hdl']].tail(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ac2d08-b435-43d6-98e5-047623ac79cb",
   "metadata": {},
   "source": [
    "#### remove duplicate columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c337512d-ebde-45ff-af02-f4d52a266adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 columns; top coverage preview:\n",
      "                   col  nonnull   na_rate    pct\n",
      "0               FEMALE   128809  0.000000  1.000\n",
      "1             IS_ADULT   128809  0.000000  1.000\n",
      "2          IS_POST2018   128809  0.000000  1.000\n",
      "3    MORTALITY_COVERED   128809  0.000000  1.000\n",
      "4           MetS_count   128809  0.000000  1.000\n",
      "5             MetS_fpg   128809  0.000000  1.000\n",
      "6             MetS_hdl   128809  0.000000  1.000\n",
      "7   MetS_triglycerides   128809  0.000000  1.000\n",
      "8              MetS_wc   128809  0.000000  1.000\n",
      "9             RIAGENDR   128809  0.000000  1.000\n",
      "10            SDDSRVYR   128809  0.000000  1.000\n",
      "11             SDMVPSU   128809  0.000000  1.000\n",
      "12            SDMVSTRA   128809  0.000000  1.000\n",
      "13                SEQN   128809  0.000000  1.000\n",
      "14                 age   128809  0.000000  1.000\n",
      "15                  re   128809  0.000000  1.000\n",
      "16                 sex   128809  0.000000  1.000\n",
      "17                  wc   122080  0.052240  0.948\n",
      "18                 hdl   119034  0.075888  0.924\n",
      "19               tchol   119034  0.075888  0.924\n",
      "\n",
      "Consolidation plan (preview):\n",
      "\n",
      "[bmi] winner -> bmi; drop -> ['BMI']\n",
      "   col    pct  nonnull   na_rate\n",
      "0  bmi  0.682    87799  0.318378\n",
      "1  BMI  0.168    21608  0.832248\n",
      "\n",
      "[tchol] winner -> tchol; drop -> ['LBXTC']\n",
      "     col    pct  nonnull   na_rate\n",
      "0  tchol  0.924   119034  0.075888\n",
      "1  LBXTC  0.138    17718  0.862447\n",
      "\n",
      "[hdl] winner -> hdl; drop -> ['LBDHDD']\n",
      "      col    pct  nonnull   na_rate\n",
      "0     hdl  0.924   119034  0.075888\n",
      "1  LBDHDD  0.138    17718  0.862447\n",
      "\n",
      "[tg] winner -> tg; drop -> ['LBXTR']\n",
      "     col    pct  nonnull  na_rate\n",
      "0     tg  0.823   105966  0.17734\n",
      "1  LBXTR  0.036     4650  0.96390\n",
      "\n",
      "[fpg] winner -> fpg; drop -> ['LBXGLU']\n",
      "      col    pct  nonnull   na_rate\n",
      "0     fpg  0.852   109732  0.148103\n",
      "1  LBXGLU  0.065     8416  0.934663\n",
      "\n",
      "[hba1c] winner -> hba1c; drop -> ['LBXGH']\n",
      "     col    pct  nonnull   na_rate\n",
      "0  hba1c  0.914   117768  0.085716\n",
      "1  LBXGH  0.128    16452  0.872276\n",
      "\n",
      "[wc] winner -> wc; drop -> ['BMXWAIST']\n",
      "        col    pct  nonnull  na_rate\n",
      "0        wc  0.948   122080  0.05224\n",
      "1  BMXWAIST  0.161    20764  0.83880\n",
      "\n",
      "[sddsrvyr] winner -> SDDSRVYR; drop -> ['SDDSRVYR_src']\n",
      "            col   pct  nonnull   na_rate\n",
      "0      SDDSRVYR  1.00   128809  0.000000\n",
      "1  SDDSRVYR_src  0.18    23160  0.820199\n",
      "\n",
      "Resolved duplicates summary:\n",
      "- bmi: kept bmi; dropped ['BMI']\n",
      "- tchol: kept tchol; dropped ['LBXTC']\n",
      "- hdl: kept hdl; dropped ['LBDHDD']\n",
      "- tg: kept tg; dropped ['LBXTR']\n",
      "- fpg: kept fpg; dropped ['LBXGLU']\n",
      "- hba1c: kept hba1c; dropped ['LBXGH']\n",
      "- wc: kept wc; dropped ['BMXWAIST']\n",
      "- sddsrvyr: kept SDDSRVYR; dropped ['SDDSRVYR_src']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = df_my_cov_aligned.copy()\n",
    "\n",
    "# -------- 1) Coverage table --------\n",
    "cov = (\n",
    "    pd.DataFrame({\n",
    "        \"col\": df.columns,\n",
    "        \"nonnull\": df.notna().sum().values,\n",
    "        \"na_rate\": df.isna().mean().values\n",
    "    })\n",
    "    .assign(pct=lambda x: (x[\"nonnull\"] / len(df)).round(3))\n",
    "    .sort_values([\"pct\",\"col\"], ascending=[False,True])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print(f\"{len(df.columns)} columns; top coverage preview:\")\n",
    "print(cov.head(20))\n",
    "\n",
    "# -------- 2) Alias groups you likely have duplicates for --------\n",
    "# Winner is chosen by highest non-missing. If tie, the first name in each group wins.\n",
    "ALIASES = {\n",
    "    # case / spelling duplicates\n",
    "    \"bmi\":        [\"BMI\", \"bmi\"],\n",
    "    \"sbp\":        [\"SBP\", \"sbp\"],\n",
    "    \"dbp\":        [\"DBP\", \"dbp\"],\n",
    "    \"tchol\":      [\"tchol\", \"LBXTC\"],\n",
    "    \"hdl\":        [\"hdl\", \"LBDHDD\"],\n",
    "    \"tg\":         [\"tg\", \"LBXTR\"],\n",
    "    \"fpg\":        [\"fpg\", \"LBXGLU\"],\n",
    "    \"hba1c\":      [\"hba1c\", \"LBXGH\"],\n",
    "    \"wc\":         [\"wc\", \"BMXWAIST\"],\n",
    "    \"bmxht\":      [\"BMXHT\", \"bmxht\"],\n",
    "    \"bmxwt\":      [\"BMXWT\", \"bmxwt\"],\n",
    "    \"tchol_hdl\":  [\"tchol_hdl\"],\n",
    "    \"sddsrvyr\":   [\"SDDSRVYR\", \"SDDSRVYR_src\"],\n",
    "\n",
    "    # common harmonized vs raw pairs you showed:\n",
    "    \"chd\":        [\"chd\"],\n",
    "    \"mi\":         [\"mi\"],\n",
    "    \"chf\":        [\"chf\"],\n",
    "    \"stroke\":     [\"stroke\"],\n",
    "    \"angina\":     [\"angina\"],\n",
    "\n",
    "    # lowercase versions of PRI/SEC sets (kept as-is; not merged):\n",
    "    # 'sbp/dbp' above already mapped; these stay independent scores:\n",
    "    # adiposity_pri/sec, bp_pri/sec, lipid_pri/sec, glucose_pri/sec, cvd_pri/sec ...\n",
    "}\n",
    "\n",
    "# Only consider aliases that actually exist in your df\n",
    "ALIASES = {k:[c for c in v if c in df.columns] for k,v in ALIASES.items()}\n",
    "ALIASES = {k:v for k,v in ALIASES.items() if len(v) >= 2}\n",
    "\n",
    "# -------- 3) Decide winners by coverage --------\n",
    "plan = []\n",
    "for canon, cols in ALIASES.items():\n",
    "    sub = cov[cov[\"col\"].isin(cols)].sort_values([\"pct\", \"col\"], ascending=[False, True])\n",
    "    winner = sub.iloc[0][\"col\"]\n",
    "    losers = [c for c in cols if c != winner]\n",
    "    plan.append((canon, winner, losers, sub[[\"col\",\"pct\",\"nonnull\",\"na_rate\"]].reset_index(drop=True)))\n",
    "\n",
    "print(\"\\nConsolidation plan (preview):\")\n",
    "for canon, winner, losers, stats in plan:\n",
    "    print(f\"\\n[{canon}] winner -> {winner}; drop -> {losers}\")\n",
    "    print(stats)\n",
    "\n",
    "# -------- 4) Apply coalesce-and-drop (safe by default) --------\n",
    "EXECUTE = False  # <<< set True to modify df_my_cov_aligned\n",
    "\n",
    "if EXECUTE:\n",
    "    for canon, winner, losers, _ in plan:\n",
    "        # fill winner with any non-missing from losers (in order)\n",
    "        for lo in losers:\n",
    "            df[winner] = df[winner].where(df[winner].notna(), df[lo])\n",
    "        # drop losers\n",
    "        df.drop(columns=losers, inplace=True, errors=\"ignore\")\n",
    "\n",
    "    # Optional: enforce canonical names (rename raw to tidy lowercase where desired)\n",
    "    RENAME = {\n",
    "        \"LBXTC\":\"tchol\", \"LBDHDD\":\"hdl\", \"LBXTR\":\"tg\", \"LBXGLU\":\"fpg\", \"LBXGH\":\"hba1c\",\n",
    "        \"BMXHT\":\"BMXHT\", \"BMXWT\":\"BMXWT\",  # keep CDC BMI sources uppercase (your choice)\n",
    "        \"SDDSRVYR\":\"SDDSRVYR\",  # keep canonical survey cycle name\n",
    "    }\n",
    "    # Only rename if present and not already the desired name\n",
    "    df.rename(columns={k:v for k,v in RENAME.items() if k in df.columns and k != v}, inplace=True)\n",
    "\n",
    "    # Write back\n",
    "    df_my_cov_aligned = df\n",
    "    print(\"\\n✓ Applied consolidation. New column count:\", df.shape[1])\n",
    "\n",
    "# -------- 5) Quick report of resolved duplicates --------\n",
    "resolved = {canon:(winner, losers) for canon, winner, losers, _ in plan}\n",
    "print(\"\\nResolved duplicates summary:\")\n",
    "for k,(w,losers) in resolved.items():\n",
    "    print(f\"- {k}: kept {w}; dropped {losers if losers else '[]'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0462b57-3b4b-4aad-bff4-916eaa38ff52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aac471-7a99-4edd-a9fb-9aeab881be7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26cd745b-6f31-4132-88a5-4b3b34fbef03",
   "metadata": {},
   "source": [
    "#### try fetch from nhance web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d26337a-e99f-4c31-bc13-0e8ca9f3c593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82e7570-8b0e-4eaf-8182-7eb4fa313204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b18dad-e22e-473a-9b14-3a217bc83797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce73e108-5ca1-41a2-bd51-78b1bbb4b0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094b725c-3454-4006-bca5-2d552ec31f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deaf76d-0d7e-4087-9743-87763449cd48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a317e30b-3ce9-4cfc-a0c3-61e18bc76d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340c05c8-e1f7-4409-aaf9-20678869cd18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2916ea6-1f21-44ac-aa68-0489630d4a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d786da-a7cb-4858-a381-a2b327b0cdc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
