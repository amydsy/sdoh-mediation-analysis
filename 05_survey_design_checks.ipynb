{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e6acb1b",
   "metadata": {},
   "source": [
    "# 05 â€” Survey Design Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ad2336",
   "metadata": {},
   "source": [
    "Run first cell:\n",
    "```python\n",
    "%run 00_bootstrap.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aee2b8",
   "metadata": {},
   "source": [
    "<h2>ðŸ§® Generate Weighted Demographic Summary Table</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ce0e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python does not support full survey design (strata + PSU) out of the box\n",
    "# below code not working \n",
    "# === Load data ===\n",
    "data_path = \"/Users/dengshuyue/Desktop/SDOH/analysis/data/\"\n",
    "df = pd.read_pickle(os.path.join(data_path, \"SODH_diet_mort.pkl\"))\n",
    "\n",
    "# Drop rows missing survey design variables\n",
    "df = df.dropna(subset=['wt10', 'sdmvstra', 'sdmvpsu'])\n",
    "\n",
    "# === Weighted proportions for categorical variables ===\n",
    "def weighted_props(df, var, weight):\n",
    "    d = df[[var, weight]].dropna()\n",
    "    counts = d.groupby(var)[weight].sum()\n",
    "    total_weight = d[weight].sum()\n",
    "    props = (counts / total_weight).round(3)\n",
    "    return counts.round(0).astype(int), (props * 100).round(1)\n",
    "\n",
    "# === Use Taylor Linearization for SEs of continuous variables ===\n",
    "from linearmodels.survey import SurveyDesign, SurveyMean\n",
    "\n",
    "def survey_mean_se(df, var, weight='wt10', strata='sdmvstra', cluster='sdmvpsu'):\n",
    "    # Remove missing\n",
    "    d = df[[var, weight, strata, cluster]].dropna()\n",
    "\n",
    "    # Define survey design\n",
    "    design = sm.survey.SurveyDesign(\n",
    "        strata=d[strata],\n",
    "        cluster=d[cluster],\n",
    "        weights=d[weight],\n",
    "    )\n",
    "\n",
    "    # Fit the design-based estimator\n",
    "    survey_var = sm.survey.SurveyMean(d[var], design)\n",
    "    return float(survey_var.mean), float(survey_var.std)\n",
    "\n",
    "# === Variable dictionaries ===\n",
    "cat_vars = {\n",
    "    'SEX': {1: 'Male', 2: 'Female'},\n",
    "    'RACE': {1: 'Non-Hispanic White', 2: 'Non-Hispanic Black', 3: 'Hispanic', 4: 'Other'},\n",
    "    'EDU': {1: 'Less than high school', 2: 'High school or equivalent', 3: 'Some college', 4: 'College or above'},\n",
    "    'pir': {1: '<1.3', 2: '1.3~2.99', 3: '>=3'},\n",
    "    'SNAP': {0: 'Not participant', 1: 'Participant', 2: 'Income eligible non-participant'},\n",
    "    'SMK': {1: 'Nonsmokers', 2: 'Former smokers', 3: '<15 cigarettes/day', 4: '15-24.9 cigarettes/day', 5: 'â‰¥ 25 cigarettes/day'},\n",
    "    'ALCG2': {1: 'Nondrinkers', 2: 'Moderate drinker', 3: 'Heavy drinker', 4: 'Missing'},\n",
    "    'bmic': {1: 'BMI <18.5', 2: '18-24.9', 3: '25-29.9', 4: 'BMI â‰¥30'}\n",
    "}\n",
    "\n",
    "binary_vars = ['DIABETES', 'CVD', 'dm_rx', 'chol_rx', 'angina', 'cancer', 'lung_disease', 'MORTSTAT']\n",
    "cont_vars = ['RIDAGEYR', 'met_hr', 'bmi', 'hba1c', 'sbp', 'dbp', 'hdl', 'ldl', 'tg', 'HEI2015_TOTAL_SCORE']\n",
    "\n",
    "# === Generate summary ===\n",
    "rows = []\n",
    "\n",
    "# Categorical\n",
    "for var, mapping in cat_vars.items():\n",
    "    counts, props = weighted_props(df, var, 'wt10')\n",
    "    for code, label in mapping.items():\n",
    "        if code in counts.index:\n",
    "            rows.append({\n",
    "                \"Variable\": var,\n",
    "                \"Category\": label,\n",
    "                \"Overall\": f\"{counts[code]:,.0f} ({props[code]}%)\"\n",
    "            })\n",
    "\n",
    "# Binary (weighted %)\n",
    "for var in binary_vars:\n",
    "    val, se = survey_mean_se(df, var)\n",
    "    rows.append({\n",
    "        \"Variable\": var,\n",
    "        \"Category\": \"1\",\n",
    "        \"Overall\": f\"{val * 100:.1f}% ({se * 100:.1f})\"\n",
    "    })\n",
    "\n",
    "# Continuous (mean Â± SE)\n",
    "for var in cont_vars:\n",
    "    mean, se = survey_mean_se(df, var)\n",
    "    rows.append({\n",
    "        \"Variable\": var,\n",
    "        \"Category\": \"\",\n",
    "        \"Overall\": f\"{mean:.2f} ({se:.2f})\"\n",
    "    })\n",
    "\n",
    "# === Create summary table ===\n",
    "demo_table = pd.DataFrame(rows)\n",
    "\n",
    "# === Save and preview ===\n",
    "output_path = os.path.join(data_path, \"demo_summary.csv\")\n",
    "demo_table.to_csv(output_path, index=False)\n",
    "\n",
    "# Show preview\n",
    "demo_table.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccac4648",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Load data ===\n",
    "df = pd.read_pickle(os.path.join(data_path, \"SODH_diet_mort.pkl\"))\n",
    "\n",
    "# Drop missing survey design variables (weight pooled: WTDRD1)\n",
    "df = df.dropna(subset=['wt10', 'sdmvstra', 'sdmvpsu'])\n",
    "\n",
    "# === Helper functions ===\n",
    "def weighted_mean(x, w):\n",
    "    d = pd.DataFrame({'x': x, 'w': w}).dropna()\n",
    "    return np.sum(d.x * d.w) / np.sum(d.w)\n",
    "\n",
    "# not standard \n",
    "# def weighted_se(x, w):\n",
    "#    d = pd.DataFrame({'x': x, 'w': w}).dropna()\n",
    "#    mean = weighted_mean(d.x, d.w)\n",
    "#    return np.sqrt(np.sum(d.w * (d.x - mean)**2) / ((len(d) - 1) * np.sum(d.w) / len(d)))\n",
    "\n",
    "# Only acceptable if weights are uniform\n",
    "# def weighted_se(x, w):\n",
    "#    d = pd.DataFrame({'x': x, 'w': w}).dropna()\n",
    "#    mean = np.sum(d.x * d.w) / np.sum(d.w)\n",
    "#    var = np.sum(d.w * (d.x - mean)**2) / np.sum(d.w)\n",
    "#    se = np.sqrt(var / len(d))  # Approximate\n",
    "#    return se\n",
    "\n",
    "# ðŸ”¥ Check best practice for estimating SE with survey weights\n",
    "\n",
    "def weighted_se(x, w):\n",
    "    d = pd.DataFrame({'x': x, 'w': w}).dropna()\n",
    "    mean = np.sum(d.x * d.w) / np.sum(d.w)\n",
    "    eff_n = (np.sum(d.w))**2 / np.sum(d.w**2)  # Effective sample size\n",
    "    var = np.sum(d.w * (d.x - mean)**2) / np.sum(d.w)\n",
    "    se = np.sqrt(var / eff_n)\n",
    "    return se\n",
    "\n",
    "    \n",
    "def weighted_props(df, var, weight):\n",
    "    d = df[[var, weight]].dropna()\n",
    "    counts = d.groupby(var)[weight].sum()\n",
    "    total_weight = d[weight].sum()\n",
    "    props = (counts / total_weight).round(3)\n",
    "    return counts.round(0).astype(int), (props * 100).round(1)\n",
    "\n",
    "# === Categorical variables ===\n",
    "cat_vars = {\n",
    "    'SEX': {1: 'Male', 2: 'Female'},\n",
    "    'RACE': {1: 'Non-Hispanic White', 2: 'Non-Hispanic Black', 3: 'Hispanic', 4: 'Other'},\n",
    "    'EDU': {1: 'Less than high school', 2: 'High school or equivalent', 3: 'Some college', 4: 'College or above'},\n",
    "    'pir': {1: '<1.3', 2: '1.3~2.99', 3: '>=3'},\n",
    "    'SNAP': {0: 'Not participant', 1: 'Participant', 2: 'Income eligible non-participant'},\n",
    "    'SMK': {1: 'Nonsmokers', 2: 'Former smokers', 3: '<15 cigarettes/day', 4: '15-24.9 cigarettes/day', 5: 'â‰¥ 25 cigarettes/day'},\n",
    "    'ALCG2': {1: 'Nondrinkers', 2: 'Moderate drinker', 3: 'Heavy drinker', 4: 'Missing'},\n",
    "    'bmic': {1: 'BMI <18.5', 2: '18-24.9', 3: '25-29.9', 4: 'BMI â‰¥30'}\n",
    "}\n",
    "\n",
    "rows = []\n",
    "\n",
    "for var, mapping in cat_vars.items():\n",
    "    counts, props = weighted_props(df, var, 'wt10')\n",
    "    for code, label in mapping.items():\n",
    "        if code in counts.index:\n",
    "            rows.append({\n",
    "                \"Variable\": var,\n",
    "                \"Category\": label,\n",
    "                \"Overall\": f\"{counts[code]:,.0f} ({props[code]}%)\"\n",
    "            })\n",
    "\n",
    "# === Binary variables ===\n",
    "binary_vars = ['DIABETES', 'CVD', 'dm_rx', 'chol_rx', 'angina', 'cancer', 'lung_disease', 'MORTSTAT']\n",
    "for var in binary_vars:\n",
    "    val = weighted_mean(df[var].fillna(0), df['wt10']) * 100\n",
    "    rows.append({\n",
    "        \"Variable\": var,\n",
    "        \"Category\": \"1\",\n",
    "        \"Overall\": f\"{val:.1f}%\"\n",
    "    })\n",
    "\n",
    "# === Continuous variables ===\n",
    "cont_vars = ['RIDAGEYR', 'met_hr', 'bmi', 'hba1c', 'sbp', 'dbp', 'hdl', 'ldl', 'tg', 'HEI2015_TOTAL_SCORE']\n",
    "for var in cont_vars:\n",
    "    mean = weighted_mean(df[var], df['wt10'])\n",
    "    se = weighted_se(df[var], df['wt10'])\n",
    "    rows.append({\n",
    "        \"Variable\": var,\n",
    "        \"Category\": \"\",\n",
    "        \"Overall\": f\"{mean:.2f} ({se:.2f})\"\n",
    "    })\n",
    "\n",
    "# === Create summary table ===\n",
    "demo_table = pd.DataFrame(rows)\n",
    "\n",
    "# Save, preview\n",
    "\n",
    "# Optionally: save to CSV\n",
    "# demo_table.to_csv(\"demo_summary.csv\", index=False)\n",
    "demo_table.to_csv(output_path, index=False)\n",
    "\n",
    "demo_table.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0897509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data: drop rows with missing mortality status or weight\n",
    "mort_df = df[['MORTSTAT', 'WTDRD1']].dropna()\n",
    "\n",
    "# Calculate total weighted sum\n",
    "total_weight = mort_df['WTDRD1'].sum()\n",
    "\n",
    "# Weighted percentage of deceased (MORTSTAT == 1)\n",
    "dead_weight = mort_df.loc[mort_df['MORTSTAT'] == 1, 'WTDRD1'].sum()\n",
    "weighted_pct_dead = (dead_weight / total_weight) * 100\n",
    "\n",
    "print(f\"Weighted percentage deceased: {weighted_pct_dead:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09111b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define unweighted counts and proportions\n",
    "def unweighted_props(df, var):\n",
    "    counts = df[var].value_counts(dropna=False).sort_index()\n",
    "    props = counts / counts.sum() * 100\n",
    "    return counts, props.round(1)\n",
    "\n",
    "# Now use it for 'sex'\n",
    "counts, props = unweighted_props(df, 'sex')\n",
    "\n",
    "# Optionally map codes to labels\n",
    "sex_labels = {1: 'Male', 2: 'Female'}\n",
    "for val in counts.index:\n",
    "    label = sex_labels.get(val, val)\n",
    "    print(f\"{label}: {counts[val]} ({props[val]}%)\")\n",
    "18530+19890\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
